{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이동경로 로그를 기반으로 가상 경로를 예측하는 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size) # (5+128, 128)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_tensor, hidden_tensor):\n",
    "        combined = torch.cat((input_tensor, hidden_tensor), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [(\"page1\", \"page2\", \"page3\", \"page4\"),\n",
    "                 (\"page1\", \"page2\", \"page4\"),\n",
    "                 (\"page1\", \"page2\", \"page3\"),\n",
    "                 (\"page1\", \"page2\", \"page4\", \"page5\")]\n",
    "\n",
    "pages = [\"page1\", \"page2\", \"page3\", \"page4\", \"page5\"]\n",
    "page_to_index = {pages[i] : i for i in range(len(pages))}\n",
    "# {'page1': 0, 'page2': 1, 'page3': 2, 'page4': 3, 'page5': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_tensor(sequence):\n",
    "    tensor = torch.zeros(len(sequence), 1, len(pages)) # 4(input page 수) x 5(총 page 수) 0으로 채워짐\n",
    "    '''\n",
    "    (\"page1\", \"page2\", \"page3\", \"page4\") \n",
    "    =>  tensor([[[0., 0., 0., 0., 0.]], : page1\n",
    "            [[0., 0., 0., 0., 0.]], : page2\n",
    "            [[0., 0., 0., 0., 0.]], : page3\n",
    "            [[0., 0., 0., 0., 0.]]]) : page4\n",
    "            \n",
    "    (\"page1\", \"page2\", \"page3\")\n",
    "    => tensor([[[0., 0., 0., 0., 0.]], : page1\n",
    "        [[0., 0., 0., 0., 0.]], : page2\n",
    "        [[0., 0., 0., 0., 0.]]]) : page3\n",
    "    '''\n",
    "    \n",
    "    for i, page in enumerate(sequence):\n",
    "        tensor[i][0][page_to_index[page]] = 1 # i번째 텐서의 0번째 줄의 \"page n\"의 인덱스에 1\n",
    "        '''\n",
    "        (\"page1\", \"page2\", \"page3\")\n",
    "        => tensor([[[1., 0., 0., 0., 0.]], : page1\n",
    "        [[0., 1., 0., 0., 0.]], : page2\n",
    "        [[0., 0., 1., 0., 0.]]]) : page3\n",
    "        '''\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tensors = [sequence_to_tensor(sequence) for sequence in training_data] # () 한 줄 한 줄 씩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor1 : tensor([[[1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0.]]])\n",
      "tensor2 : tensor([[[1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0.]]])\n",
      "tensor3 : tensor([[[1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0.]]])\n",
      "tensor4 : tensor([[[1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for tensor in training_tensors:\n",
    "    print(\"tensor{} : {}\".format(i, tensor))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1000 | Loss: 5.0214\n",
      "Epoch: 101/1000 | Loss: 2.0295\n",
      "Epoch: 201/1000 | Loss: 1.4853\n",
      "Epoch: 301/1000 | Loss: 1.2209\n",
      "Epoch: 401/1000 | Loss: 1.0716\n",
      "Epoch: 501/1000 | Loss: 0.9767\n",
      "Epoch: 601/1000 | Loss: 0.9118\n",
      "Epoch: 701/1000 | Loss: 0.8652\n",
      "Epoch: 801/1000 | Loss: 0.8305\n",
      "Epoch: 901/1000 | Loss: 0.8041\n",
      "Input:  ('page1', 'page2', 'page3')\n",
      "Output:  page4\n"
     ]
    }
   ],
   "source": [
    "training_tensors = [sequence_to_tensor(sequence) for sequence in training_data] # () 한 줄 한 줄 씩\n",
    "\n",
    "input_size = len(pages) # 5\n",
    "hidden_size = 128\n",
    "output_size = len(pages)\n",
    "\n",
    "rnn = RNN(input_size, hidden_size, output_size)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr = 0.001)\n",
    "\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    for tensor in training_tensors:\n",
    "        hidden = rnn.init_hidden()\n",
    "        rnn.zero_grad()\n",
    "        loss = 0\n",
    "        \n",
    "        # torch.Size([4, 1, 5])\n",
    "        for i in range(tensor.size()[0]-1): # 첫번째 문장의 경우 4-1 = 3. 총 0, 1, 2 반복\n",
    "            '''\n",
    "            print(f\"tensor {i} : {tensor[i]}\") [[1., 0., 0., 0., 0.]]\n",
    "            print(f'tensor {i} shape : {tensor[i].shape}') [1, 5]\n",
    "            '''\n",
    "            \n",
    "            output, hidden = rnn(tensor[i], hidden)\n",
    "            '''\n",
    "            print(f'output : {output}') [[0., 1., 0., 0., 0.]]\n",
    "            print(f'output.shape : {output.shape}') [1, 5]\n",
    "            print(f'hidden : {hidden}')\n",
    "            print(f'hidden.shape : {hidden.shape}') [1, 128]\n",
    "            \n",
    "            print(f\"tensor {i+1} : {tensor[i+1]}\") [[0., 1., 0., 0., 0.]]\n",
    "            print(f'tensor {i+1} shape : {tensor[i+1].shape}') [1, 5]\n",
    "\n",
    "            print(f'torch.argmax(tensor {i+1}): {torch.argmax(tensor[i+1])}')  tensor([1])\n",
    "            print(f'torch.argmax(tensor {i+1}).shape: {tensor[i+1].shape}')  torch.Size([1])\n",
    "            '''\n",
    "            loss += criterion(output, torch.argmax(tensor[i+1], dim=1)) # tensor([1]). tensor[i+1] 중 가장 큰 인덱스 반환\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: {}/{} | Loss: {:.4f}\".format(epoch+1, num_epochs, loss.item()))\n",
    "        \n",
    "        \n",
    "def predict(sequence):\n",
    "    tensor = sequence_to_tensor(sequence)\n",
    "    hidden = rnn.init_hidden()\n",
    "    for i in range(tensor.size()[0]-1):\n",
    "        output, hidden = rnn(tensor[i], hidden)\n",
    "    _, topi = output.topk(1) # 텐서의 가장 큰 값 및 주소\n",
    "    return pages[topi.item()] # 텐서에서 정수 값으로 변경\n",
    "\n",
    "test_sequence = (\"page1\", \"page2\", \"page3\")\n",
    "print(\"Input: \", test_sequence)\n",
    "print(\"Output: \", predict(test_sequence))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.Tensor([[0., 1., 0., 0., 0.]]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1301496431.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[51], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    torch.argmax(tensor 1): tensor([1])\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "#dim=1\n",
    "torch.argmax(tensor 1): tensor([1])\n",
    "torch.argmax(tensor 1).shape: torch.Size([1])\n",
    "\n",
    "# dim=0\n",
    "torch.argmax(tensor 1): tensor([0, 0, 0, 0, 0])\n",
    "torch.argmax(tensor 1).shape: torch.Size([5])\n",
    "\n",
    "torch.argmax(tensor 1): 1\n",
    "torch.argmax(tensor 1).shape: torch.Size([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
