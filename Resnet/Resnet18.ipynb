{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a902e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8e05768e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b63da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        '''\n",
    "        in_planes : 입력 필터개수\n",
    "        out_planes : 출력 필터개수\n",
    "        '''\n",
    "        # 3x3 필터를 사용 (너비와 높이를 줄일 때는 stride값 조절)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size = 3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes) # 배치정규화\n",
    "        \n",
    "        # 3x3 필터를 사용 (패딩1이므로 이미지가 동일하게 나옴)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x) # 핵심 부분\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "662f3a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_class=10):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        \n",
    "        # 64개의 3x3필터 사용\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_class)\n",
    "        \n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "def Resnet18():\n",
    "    return Resnet(BasicBlock, [2,2,2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7afd4d",
   "metadata": {},
   "source": [
    "## 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8493602b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [01:45<00:00, 1614533.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform_train = transforms.Compose([ #불러오는 이미지 데이터에 전처리 및 augmentaion을 다양하게 적용할 때 이용하는 메서드\n",
    "    transforms.RandomCrop(32, padding=4), #잘라낼 크기 설정. 그 크기만큼 랜덤으로 잘라냄\n",
    "    transforms.RandomHorizontalFlip(), # 해당이미지를 50%의 확률로 좌우반전\n",
    "    transforms.ToTensor(), #딥러닝 모델의 input으로 이용할 수 있게 이미지 데이터를 tensor형태로 변환 및 0~1로 정규화\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# torchvision dataset의 CIFAR10다운로드\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# 모델에 넣기 위한 데이터 세팅\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2) #num_workers는 dataset의 데이터를 gpu로 전송할 때 필요한 전처리를 수행할 때 사용하는 subprocess의 수\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a73e12db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9c6cde9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(train_dataset.data[30])\n",
    "print(train_dataset.targets[30]) # 0 : airplane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51306fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 3, 32, 32]), torch.Size([128]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, target = next(iter(train_loader))\n",
    "data.shape, target.shape\n",
    "# data : 배치사이즈, 채널, 가로, 세로\n",
    "# target : label 128개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5da03009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[127].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0a7ec56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 9, 1, 5, 9, 8, 4, 3, 1, 5, 9, 6, 4, 4, 8, 4, 9, 7, 2, 5, 7, 4, 7, 5,\n",
       "        7, 2, 6, 8, 5, 8, 4, 0, 8, 2, 0, 3, 6, 6, 3, 2, 0, 2, 4, 0, 5, 0, 1, 1,\n",
       "        1, 9, 7, 8, 0, 1, 6, 5, 2, 8, 3, 6, 0, 6, 5, 5, 7, 6, 6, 3, 8, 1, 8, 6,\n",
       "        7, 0, 0, 9, 4, 1, 7, 5, 6, 8, 1, 4, 0, 8, 5, 3, 8, 5, 8, 6, 9, 8, 3, 6,\n",
       "        9, 8, 2, 6, 5, 9, 7, 9, 4, 0, 3, 4, 3, 6, 1, 6, 4, 0, 3, 0, 2, 0, 5, 7,\n",
       "        6, 9, 1, 2, 7, 1, 4, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e9d854",
   "metadata": {},
   "source": [
    "## 환경설정 및 train, test정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73cb07ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version : 2.1.2+cu118, cuda is available : True\n"
     ]
    }
   ],
   "source": [
    "print(f\"torch version : {torch.__version__}, cuda is available : {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f289d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "net = Resnet18()\n",
    "net = net.to(device)\n",
    "\n",
    "learning_rate = 0.1\n",
    "file_name = 'resnet18_cifar10.pth'\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002) # weight_decay : 가중치 감소를 통한 가중치 정형화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "19826f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 64, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 128, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 256, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "parameters = list(net.parameters())\n",
    "for i in range(len(parameters)):\n",
    "    print(parameters[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c50027ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resnet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a7f2213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print(f\"\\n[ Train epoch : {epoch}]\")\n",
    "    net.train() # 모델을 학습모드로 설정\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device) # image와 target을 장비에 할당\n",
    "        optimizer.zero_grad() #optimizer gradient 초기화\n",
    "              \n",
    "        outputs = net(inputs) #장비에 할당된 이미지를 모델의 input으로 이용해 output을 계산\n",
    "        #print(\"output : \", outputs)\n",
    "        #print(\"output.shape : \", outputs.shape) #output.shape :  torch.Size([128, 10]) 128개 이미지 각각 class 10에 대한 확률 \n",
    "        loss = criterion(outputs, targets) # 계산된 output과 target을 criterion(CrossEntropy)를 이용해서 loss 계산\n",
    "        #print(\"loss : \", loss) # loss :  tensor(2.38660)\n",
    "        loss.backward() # loss 계산한 결과를 바탕으로 back propagation을 통해 계산된 gradient값을 각 파라미터에 할당\n",
    "\n",
    "        optimizer.step() # gradient값을 이용해 파라미터값 업데이트\n",
    "        train_loss += loss.item() # tensor에 하나의 값만 존재한다면 scalar값을 얻을 수 있음. 만일 여러개 존재한다면 사용 불가.\n",
    "              \n",
    "        '''\n",
    "        for i in range(outputs.size(1)): #10\n",
    "            print(outputs[i])'''\n",
    "        # outputs[0] : 첫번째 이미지에 대한 10개의 클래스 중 확률 값. 첫번째 이미지의 label은 9. \n",
    "        # tensor([-0.6967,  0.4949, -0.3854,  0.6380,  0.4872, -0.4960, -1.0212,  0.2237, 0.5431, -0.8949], device='cuda:0', grad_fn=<SelectBackward0>)\n",
    "        '''        \n",
    "        for j in range(len(outputs.max(1))):\n",
    "            print(\"output max :\", outputs.max(1))'''\n",
    "        _, predicted = outputs.max(1) # output의 크기가 배치크기x클래스개수. 최댓값과 최댓값의 위치를 산출. _으로 처리하여 해당 출력값은 저장하지 않고, 최댓값의 위치만 predicted에 저장하겠다.\n",
    "        # values=tensor([3.3213, 1.3654, 3.1423, 2.0251, 1.9749, 2.1859, 1.1904, 2.1445, 2.3648, ... ] 128개\n",
    "        # indices=tensor([5, 9, 1, 1, 5, 8, 9, 5, 7, 5, 0, 8, 7, 1, 9, 5, 4, 1, 1, 5, 1, 5, 6, 2, ... ] => predicted. 128개\n",
    "        \n",
    "        total += targets.size(0) # 128\n",
    "        current_correct = predicted.eq(targets).sum().item() # 배열과 targets가 일치하는지 검사하고 sum으로 일치하는 것들의 개수의 합을 숫자로 출력\n",
    "        correct += current_correct\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('\\nCurrent batch : ', str(batch_idx))\n",
    "            print(f'Current batch average train accuracy : {current_correct}/{target.size(0)} => {current_correct/target.size(0)}')\n",
    "            print(f'Current batch average train loss : {loss.item()}/{targets.size(0)} => {loss.item()/targets.size(0)}')\n",
    "            \n",
    "    print(f'\\nTotal average train accuracy : {correct}/{total} => {correct/total}')\n",
    "    print(f'Total average train loss : {train_loss}/{total} => {train_loss/total}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "de781fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    print('\\n[Test epoch : %d]' % epoch)\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        total += targets.size(0) # 128\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss += criterion(outputs, targets).item()\n",
    "        \n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    print('\\nTotal average test accuracy : ', correct/total)\n",
    "    print('Total average test loss : ', loss/total)\n",
    "    \n",
    "    state = {\n",
    "        'net' : net.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + file_name)\n",
    "    print('Model Saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798dc146",
   "metadata": {},
   "source": [
    "## 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8a1310ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Train epoch : 0]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 9/128 => 0.0703125\n",
      "Current batch average train loss : 2.422952890396118/128 => 0.018929319456219673\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 41/128 => 0.3203125\n",
      "Current batch average train loss : 1.8995040655136108/128 => 0.014839875511825085\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 46/128 => 0.359375\n",
      "Current batch average train loss : 1.6757712364196777/128 => 0.013091962784528732\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 45/128 => 0.3515625\n",
      "Current batch average train loss : 1.7577013969421387/128 => 0.013732042163610458\n",
      "\n",
      "Total average train accuracy : 15120/50000 => 0.3024\n",
      "Total average train loss : 751.9228405952454/50000 => 0.015038456811904907\n",
      "\n",
      "[Test epoch : 0]\n",
      "\n",
      "Total average test accuracy :  0.4013\n",
      "Total average test loss :  0.0128086887717247\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  41.82959461212158\n",
      "\n",
      "[ Train epoch : 1]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 59/128 => 0.4609375\n",
      "Current batch average train loss : 1.473456859588623/128 => 0.011511381715536118\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 65/128 => 0.5078125\n",
      "Current batch average train loss : 1.4018856287002563/128 => 0.010952231474220753\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 55/128 => 0.4296875\n",
      "Current batch average train loss : 1.5574123859405518/128 => 0.01216728426516056\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 63/128 => 0.4921875\n",
      "Current batch average train loss : 1.3883635997772217/128 => 0.010846590623259544\n",
      "\n",
      "Total average train accuracy : 22952/50000 => 0.45904\n",
      "Total average train loss : 569.4679329395294/50000 => 0.011389358658790589\n",
      "\n",
      "[Test epoch : 1]\n",
      "\n",
      "Total average test accuracy :  0.4725\n",
      "Total average test loss :  0.011835823476314544\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  84.94957876205444\n",
      "\n",
      "[ Train epoch : 2]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 62/128 => 0.484375\n",
      "Current batch average train loss : 1.3933942317962646/128 => 0.010885892435908318\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 78/128 => 0.609375\n",
      "Current batch average train loss : 1.171748399734497/128 => 0.009154284372925758\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 85/128 => 0.6640625\n",
      "Current batch average train loss : 1.063597321510315/128 => 0.008309354074299335\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 79/128 => 0.6171875\n",
      "Current batch average train loss : 0.9994543790817261/128 => 0.007808237336575985\n",
      "\n",
      "Total average train accuracy : 28651/50000 => 0.57302\n",
      "Total average train loss : 463.86343729496/50000 => 0.0092772687458992\n",
      "\n",
      "[Test epoch : 2]\n",
      "\n",
      "Total average test accuracy :  0.3474\n",
      "Total average test loss :  0.017989854085445404\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  125.79995799064636\n",
      "\n",
      "[ Train epoch : 3]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 83/128 => 0.6484375\n",
      "Current batch average train loss : 1.0134247541427612/128 => 0.007917380891740322\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 79/128 => 0.6171875\n",
      "Current batch average train loss : 1.0790023803710938/128 => 0.00842970609664917\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 83/128 => 0.6484375\n",
      "Current batch average train loss : 1.0132560729980469/128 => 0.007916063070297241\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 91/128 => 0.7109375\n",
      "Current batch average train loss : 0.819049060344696/128 => 0.006398820783942938\n",
      "\n",
      "Total average train accuracy : 32612/50000 => 0.65224\n",
      "Total average train loss : 383.33608067035675/50000 => 0.007666721613407135\n",
      "\n",
      "[Test epoch : 3]\n",
      "\n",
      "Total average test accuracy :  0.529\n",
      "Total average test loss :  0.011708550989627838\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  167.4310929775238\n",
      "\n",
      "[ Train epoch : 4]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 92/128 => 0.71875\n",
      "Current batch average train loss : 0.821894645690918/128 => 0.006421051919460297\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 84/128 => 0.65625\n",
      "Current batch average train loss : 0.9771410822868347/128 => 0.007633914705365896\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 94/128 => 0.734375\n",
      "Current batch average train loss : 0.7354402542114258/128 => 0.005745626986026764\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 101/128 => 0.7890625\n",
      "Current batch average train loss : 0.608015775680542/128 => 0.004750123247504234\n",
      "\n",
      "Total average train accuracy : 35015/50000 => 0.7003\n",
      "Total average train loss : 332.2939949631691/50000 => 0.006645879899263382\n",
      "\n",
      "[Test epoch : 4]\n",
      "\n",
      "Total average test accuracy :  0.6481\n",
      "Total average test loss :  0.008213679426908493\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  210.8257133960724\n",
      "\n",
      "[ Train epoch : 5]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 88/128 => 0.6875\n",
      "Current batch average train loss : 0.8964007496833801/128 => 0.007003130856901407\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 90/128 => 0.703125\n",
      "Current batch average train loss : 0.8444173336029053/128 => 0.0065970104187726974\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 96/128 => 0.75\n",
      "Current batch average train loss : 0.6788588166236877/128 => 0.0053035845048725605\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 98/128 => 0.765625\n",
      "Current batch average train loss : 0.6772733926773071/128 => 0.005291198380291462\n",
      "\n",
      "Total average train accuracy : 37159/50000 => 0.74318\n",
      "Total average train loss : 285.57227033376694/50000 => 0.005711445406675339\n",
      "\n",
      "[Test epoch : 5]\n",
      "\n",
      "Total average test accuracy :  0.7055\n",
      "Total average test loss :  0.006695982956886291\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  252.86223363876343\n",
      "\n",
      "[ Train epoch : 6]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 101/128 => 0.7890625\n",
      "Current batch average train loss : 0.6143972873687744/128 => 0.00479997880756855\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 100/128 => 0.78125\n",
      "Current batch average train loss : 0.6185502409934998/128 => 0.004832423757761717\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 96/128 => 0.75\n",
      "Current batch average train loss : 0.6159358620643616/128 => 0.004811998922377825\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 105/128 => 0.8203125\n",
      "Current batch average train loss : 0.5979745388031006/128 => 0.004671676084399223\n",
      "\n",
      "Total average train accuracy : 38969/50000 => 0.77938\n",
      "Total average train loss : 247.1490935087204/50000 => 0.004942981870174408\n",
      "\n",
      "[Test epoch : 6]\n",
      "\n",
      "Total average test accuracy :  0.7178\n",
      "Total average test loss :  0.006584754186868667\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  294.88220715522766\n",
      "\n",
      "[ Train epoch : 7]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 98/128 => 0.765625\n",
      "Current batch average train loss : 0.7160720229148865/128 => 0.005594312679022551\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 107/128 => 0.8359375\n",
      "Current batch average train loss : 0.5104755163192749/128 => 0.003988089971244335\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 106/128 => 0.828125\n",
      "Current batch average train loss : 0.4579694867134094/128 => 0.003577886614948511\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 99/128 => 0.7734375\n",
      "Current batch average train loss : 0.6054665446281433/128 => 0.00473020737990737\n",
      "\n",
      "Total average train accuracy : 40230/50000 => 0.8046\n",
      "Total average train loss : 222.07957723736763/50000 => 0.004441591544747352\n",
      "\n",
      "[Test epoch : 7]\n",
      "\n",
      "Total average test accuracy :  0.7909\n",
      "Total average test loss :  0.005000711697340012\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  336.80432868003845\n",
      "\n",
      "[ Train epoch : 8]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 105/128 => 0.8203125\n",
      "Current batch average train loss : 0.5285069346427917/128 => 0.0041289604268968105\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 106/128 => 0.828125\n",
      "Current batch average train loss : 0.5902115106582642/128 => 0.004611027427017689\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 109/128 => 0.8515625\n",
      "Current batch average train loss : 0.4481726586818695/128 => 0.0035013488959521055\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 111/128 => 0.8671875\n",
      "Current batch average train loss : 0.3741564154624939/128 => 0.0029230969958007336\n",
      "\n",
      "Total average train accuracy : 41166/50000 => 0.82332\n",
      "Total average train loss : 198.70980724692345/50000 => 0.003974196144938469\n",
      "\n",
      "[Test epoch : 8]\n",
      "\n",
      "Total average test accuracy :  0.812\n",
      "Total average test loss :  0.004428582003712654\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  378.82532477378845\n",
      "\n",
      "[ Train epoch : 9]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 102/128 => 0.796875\n",
      "Current batch average train loss : 0.5250594019889832/128 => 0.004102026578038931\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 113/128 => 0.8828125\n",
      "Current batch average train loss : 0.35487931966781616/128 => 0.0027724946849048138\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 105/128 => 0.8203125\n",
      "Current batch average train loss : 0.6102154850959778/128 => 0.004767308477312326\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 110/128 => 0.859375\n",
      "Current batch average train loss : 0.3961142599582672/128 => 0.0030946426559239626\n",
      "\n",
      "Total average train accuracy : 41982/50000 => 0.83964\n",
      "Total average train loss : 181.05103886127472/50000 => 0.0036210207772254944\n",
      "\n",
      "[Test epoch : 9]\n",
      "\n",
      "Total average test accuracy :  0.8168\n",
      "Total average test loss :  0.004338094463944435\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  420.6031382083893\n",
      "\n",
      "[ Train epoch : 10]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 112/128 => 0.875\n",
      "Current batch average train loss : 0.3616065979003906/128 => 0.0028250515460968018\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 116/128 => 0.90625\n",
      "Current batch average train loss : 0.2628709375858307/128 => 0.0020536791998893023\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 112/128 => 0.875\n",
      "Current batch average train loss : 0.355532705783844/128 => 0.002777599263936281\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 105/128 => 0.8203125\n",
      "Current batch average train loss : 0.49496591091156006/128 => 0.003866921178996563\n",
      "\n",
      "Total average train accuracy : 42490/50000 => 0.8498\n",
      "Total average train loss : 168.51935335993767/50000 => 0.0033703870671987534\n",
      "\n",
      "[Test epoch : 10]\n",
      "\n",
      "Total average test accuracy :  0.8363\n",
      "Total average test loss :  0.0038518272399902342\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  462.444242477417\n",
      "\n",
      "[ Train epoch : 11]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 117/128 => 0.9140625\n",
      "Current batch average train loss : 0.27172932028770447/128 => 0.002122885314747691\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 112/128 => 0.875\n",
      "Current batch average train loss : 0.36547181010246277/128 => 0.0028552485164254904\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 110/128 => 0.859375\n",
      "Current batch average train loss : 0.34384459257125854/128 => 0.0026862858794629574\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 115/128 => 0.8984375\n",
      "Current batch average train loss : 0.36803579330444336/128 => 0.0028752796351909637\n",
      "\n",
      "Total average train accuracy : 43038/50000 => 0.86076\n",
      "Total average train loss : 156.9158753156662/50000 => 0.003138317506313324\n",
      "\n",
      "[Test epoch : 11]\n",
      "\n",
      "Total average test accuracy :  0.8468\n",
      "Total average test loss :  0.003653474223613739\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  504.20541620254517\n",
      "\n",
      "[ Train epoch : 12]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.24321740865707397/128 => 0.0019001360051333904\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 114/128 => 0.890625\n",
      "Current batch average train loss : 0.35141295194625854/128 => 0.002745413687080145\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 115/128 => 0.8984375\n",
      "Current batch average train loss : 0.2991938889026642/128 => 0.002337452257052064\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 113/128 => 0.8828125\n",
      "Current batch average train loss : 0.3535110652446747/128 => 0.002761805197224021\n",
      "\n",
      "Total average train accuracy : 43550/50000 => 0.871\n",
      "Total average train loss : 145.88784289360046/50000 => 0.002917756857872009\n",
      "\n",
      "[Test epoch : 12]\n",
      "\n",
      "Total average test accuracy :  0.8155\n",
      "Total average test loss :  0.0043962860465049745\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  546.1984984874725\n",
      "\n",
      "[ Train epoch : 13]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 113/128 => 0.8828125\n",
      "Current batch average train loss : 0.31615740060806274/128 => 0.00246997969225049\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 116/128 => 0.90625\n",
      "Current batch average train loss : 0.3053949773311615/128 => 0.002385898260399699\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 110/128 => 0.859375\n",
      "Current batch average train loss : 0.4120224416255951/128 => 0.0032189253251999617\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.24350126087665558/128 => 0.0019023536005988717\n",
      "\n",
      "Total average train accuracy : 43852/50000 => 0.87704\n",
      "Total average train loss : 139.63988392055035/50000 => 0.002792797678411007\n",
      "\n",
      "[Test epoch : 13]\n",
      "\n",
      "Total average test accuracy :  0.8322\n",
      "Total average test loss :  0.004124590599536896\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  587.9843244552612\n",
      "\n",
      "[ Train epoch : 14]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 110/128 => 0.859375\n",
      "Current batch average train loss : 0.4076295495033264/128 => 0.0031846058554947376\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 112/128 => 0.875\n",
      "Current batch average train loss : 0.34531959891319275/128 => 0.0026978093665093184\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.2603916525840759/128 => 0.002034309785813093\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 111/128 => 0.8671875\n",
      "Current batch average train loss : 0.3432610332965851/128 => 0.002681726822629571\n",
      "\n",
      "Total average train accuracy : 44044/50000 => 0.88088\n",
      "Total average train loss : 134.19121412932873/50000 => 0.0026838242825865744\n",
      "\n",
      "[Test epoch : 14]\n",
      "\n",
      "Total average test accuracy :  0.8258\n",
      "Total average test loss :  0.0041519902974367145\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  629.9720454216003\n",
      "\n",
      "[ Train epoch : 15]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 117/128 => 0.9140625\n",
      "Current batch average train loss : 0.2694631814956665/128 => 0.0021051811054348946\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 113/128 => 0.8828125\n",
      "Current batch average train loss : 0.3589230179786682/128 => 0.0028040860779583454\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 117/128 => 0.9140625\n",
      "Current batch average train loss : 0.24401824176311493/128 => 0.0019063925137743354\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 111/128 => 0.8671875\n",
      "Current batch average train loss : 0.3285399377346039/128 => 0.002566718263551593\n",
      "\n",
      "Total average train accuracy : 44371/50000 => 0.88742\n",
      "Total average train loss : 126.8866957873106/50000 => 0.002537733915746212\n",
      "\n",
      "[Test epoch : 15]\n",
      "\n",
      "Total average test accuracy :  0.822\n",
      "Total average test loss :  0.004264075899124146\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  671.9830136299133\n",
      "\n",
      "[ Train epoch : 16]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 114/128 => 0.890625\n",
      "Current batch average train loss : 0.31214553117752075/128 => 0.002438636962324381\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.29293134808540344/128 => 0.0022885261569172144\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 111/128 => 0.8671875\n",
      "Current batch average train loss : 0.33329150080680847/128 => 0.002603839850053191\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 116/128 => 0.90625\n",
      "Current batch average train loss : 0.27616170048713684/128 => 0.0021575132850557566\n",
      "\n",
      "Total average train accuracy : 44476/50000 => 0.88952\n",
      "Total average train loss : 124.39121033251286/50000 => 0.0024878242066502573\n",
      "\n",
      "[Test epoch : 16]\n",
      "\n",
      "Total average test accuracy :  0.853\n",
      "Total average test loss :  0.0035826224774122236\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  713.7108206748962\n",
      "\n",
      "[ Train epoch : 17]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.2294161319732666/128 => 0.0017923135310411453\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 115/128 => 0.8984375\n",
      "Current batch average train loss : 0.3072589039802551/128 => 0.002400460187345743\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 116/128 => 0.90625\n",
      "Current batch average train loss : 0.30925410985946655/128 => 0.0024160477332770824\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 113/128 => 0.8828125\n",
      "Current batch average train loss : 0.3264065980911255/128 => 0.002550051547586918\n",
      "\n",
      "Total average train accuracy : 44759/50000 => 0.89518\n",
      "Total average train loss : 116.76411361992359/50000 => 0.002335282272398472\n",
      "\n",
      "[Test epoch : 17]\n",
      "\n",
      "Total average test accuracy :  0.8096\n",
      "Total average test loss :  0.004690411373972893\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  755.5424983501434\n",
      "\n",
      "[ Train epoch : 18]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.24093371629714966/128 => 0.0018822946585714817\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 115/128 => 0.8984375\n",
      "Current batch average train loss : 0.25504472851753235/128 => 0.0019925369415432215\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 111/128 => 0.8671875\n",
      "Current batch average train loss : 0.3467555046081543/128 => 0.0027090273797512054\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 114/128 => 0.890625\n",
      "Current batch average train loss : 0.31212183833122253/128 => 0.002438451861962676\n",
      "\n",
      "Total average train accuracy : 44946/50000 => 0.89892\n",
      "Total average train loss : 114.65932476520538/50000 => 0.0022931864953041076\n",
      "\n",
      "[Test epoch : 18]\n",
      "\n",
      "Total average test accuracy :  0.849\n",
      "Total average test loss :  0.003609101989865303\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  797.4792900085449\n",
      "\n",
      "[ Train epoch : 19]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 115/128 => 0.8984375\n",
      "Current batch average train loss : 0.24626970291137695/128 => 0.0019239820539951324\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 114/128 => 0.890625\n",
      "Current batch average train loss : 0.3470848500728607/128 => 0.0027116003911942244\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 113/128 => 0.8828125\n",
      "Current batch average train loss : 0.3215382695198059/128 => 0.0025120177306234837\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 124/128 => 0.96875\n",
      "Current batch average train loss : 0.14695459604263306/128 => 0.0011480827815830708\n",
      "\n",
      "Total average train accuracy : 44988/50000 => 0.89976\n",
      "Total average train loss : 114.46137854456902/50000 => 0.00228922757089138\n",
      "\n",
      "[Test epoch : 19]\n",
      "\n",
      "Total average test accuracy :  0.8363\n",
      "Total average test loss :  0.004101222997903824\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  839.1043705940247\n",
      "\n",
      "[ Train epoch : 20]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 116/128 => 0.90625\n",
      "Current batch average train loss : 0.27484947443008423/128 => 0.002147261518985033\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 111/128 => 0.8671875\n",
      "Current batch average train loss : 0.37564942240715027/128 => 0.0029347611125558615\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 116/128 => 0.90625\n",
      "Current batch average train loss : 0.2342965453863144/128 => 0.0018304417608305812\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 115/128 => 0.8984375\n",
      "Current batch average train loss : 0.24669161438941956/128 => 0.0019272782374173403\n",
      "\n",
      "Total average train accuracy : 45208/50000 => 0.90416\n",
      "Total average train loss : 108.23062033951283/50000 => 0.0021646124067902566\n",
      "\n",
      "[Test epoch : 20]\n",
      "\n",
      "Total average test accuracy :  0.8692\n",
      "Total average test loss :  0.003152229177951813\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  881.0241997241974\n",
      "\n",
      "[ Train epoch : 21]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 120/128 => 0.9375\n",
      "Current batch average train loss : 0.16995522379875183/128 => 0.0013277751859277487\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 116/128 => 0.90625\n",
      "Current batch average train loss : 0.26391837000846863/128 => 0.002061862265691161\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.25928765535354614/128 => 0.0020256848074495792\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 120/128 => 0.9375\n",
      "Current batch average train loss : 0.2338179498910904/128 => 0.0018267027335241437\n",
      "\n",
      "Total average train accuracy : 45243/50000 => 0.90486\n",
      "Total average train loss : 105.52706477791071/50000 => 0.0021105412955582143\n",
      "\n",
      "[Test epoch : 21]\n",
      "\n",
      "Total average test accuracy :  0.8563\n",
      "Total average test loss :  0.003381561052799225\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  922.6815755367279\n",
      "\n",
      "[ Train epoch : 22]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 122/128 => 0.953125\n",
      "Current batch average train loss : 0.13378798961639404/128 => 0.0010452186688780785\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.2073260098695755/128 => 0.0016197344521060586\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 116/128 => 0.90625\n",
      "Current batch average train loss : 0.289531946182251/128 => 0.0022619683295488358\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 117/128 => 0.9140625\n",
      "Current batch average train loss : 0.22354158759117126/128 => 0.0017464186530560255\n",
      "\n",
      "Total average train accuracy : 45436/50000 => 0.90872\n",
      "Total average train loss : 102.72217231988907/50000 => 0.0020544434463977816\n",
      "\n",
      "[Test epoch : 22]\n",
      "\n",
      "Total average test accuracy :  0.8511\n",
      "Total average test loss :  0.0038104586839675905\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  964.602597951889\n",
      "\n",
      "[ Train epoch : 23]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.21383331716060638/128 => 0.0016705727903172374\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.2514137029647827/128 => 0.001964169554412365\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 112/128 => 0.875\n",
      "Current batch average train loss : 0.356417715549469/128 => 0.0027845134027302265\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 116/128 => 0.90625\n",
      "Current batch average train loss : 0.2576095461845398/128 => 0.002012574579566717\n",
      "\n",
      "Total average train accuracy : 45477/50000 => 0.90954\n",
      "Total average train loss : 100.18329218775034/50000 => 0.002003665843755007\n",
      "\n",
      "[Test epoch : 23]\n",
      "\n",
      "Total average test accuracy :  0.8502\n",
      "Total average test loss :  0.0036555491164326666\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1006.4107954502106\n",
      "\n",
      "[ Train epoch : 24]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 122/128 => 0.953125\n",
      "Current batch average train loss : 0.2016611397266388/128 => 0.0015754776541143656\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 116/128 => 0.90625\n",
      "Current batch average train loss : 0.28081321716308594/128 => 0.002193853259086609\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.23179201781749725/128 => 0.0018108751391991973\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.2158934623003006/128 => 0.0016866676742210984\n",
      "\n",
      "Total average train accuracy : 45693/50000 => 0.91386\n",
      "Total average train loss : 97.08605173975229/50000 => 0.001941721034795046\n",
      "\n",
      "[Test epoch : 24]\n",
      "\n",
      "Total average test accuracy :  0.8658\n",
      "Total average test loss :  0.0032856455460190774\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1048.0434112548828\n",
      "\n",
      "[ Train epoch : 25]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 120/128 => 0.9375\n",
      "Current batch average train loss : 0.22292768955230713/128 => 0.0017416225746273994\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 115/128 => 0.8984375\n",
      "Current batch average train loss : 0.32878589630126953/128 => 0.002568639814853668\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 115/128 => 0.8984375\n",
      "Current batch average train loss : 0.224862739443779/128 => 0.0017567401519045234\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 121/128 => 0.9453125\n",
      "Current batch average train loss : 0.1259896159172058/128 => 0.0009842938743531704\n",
      "\n",
      "Total average train accuracy : 45756/50000 => 0.91512\n",
      "Total average train loss : 95.57849729061127/50000 => 0.0019115699458122253\n",
      "\n",
      "[Test epoch : 25]\n",
      "\n",
      "Total average test accuracy :  0.8485\n",
      "Total average test loss :  0.0037477633714675905\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1089.9749624729156\n",
      "\n",
      "[ Train epoch : 26]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 114/128 => 0.890625\n",
      "Current batch average train loss : 0.27711933851242065/128 => 0.0021649948321282864\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.27464163303375244/128 => 0.002145637758076191\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 117/128 => 0.9140625\n",
      "Current batch average train loss : 0.2329075038433075/128 => 0.0018195898737758398\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.3037887513637543/128 => 0.0023733496200293303\n",
      "\n",
      "Total average train accuracy : 45802/50000 => 0.91604\n",
      "Total average train loss : 94.78932071477175/50000 => 0.001895786414295435\n",
      "\n",
      "[Test epoch : 26]\n",
      "\n",
      "Total average test accuracy :  0.8659\n",
      "Total average test loss :  0.003129044097661972\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1131.5899984836578\n",
      "\n",
      "[ Train epoch : 27]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 115/128 => 0.8984375\n",
      "Current batch average train loss : 0.24580051004886627/128 => 0.0019203164847567677\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.2016817331314087/128 => 0.0015756385400891304\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 122/128 => 0.953125\n",
      "Current batch average train loss : 0.11793752014636993/128 => 0.0009213868761435151\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 116/128 => 0.90625\n",
      "Current batch average train loss : 0.22098389267921448/128 => 0.001726436661556363\n",
      "\n",
      "Total average train accuracy : 45935/50000 => 0.9187\n",
      "Total average train loss : 92.31789317727089/50000 => 0.0018463578635454178\n",
      "\n",
      "[Test epoch : 27]\n",
      "\n",
      "Total average test accuracy :  0.8802\n",
      "Total average test loss :  0.003016058760881424\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1173.3578901290894\n",
      "\n",
      "[ Train epoch : 28]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 120/128 => 0.9375\n",
      "Current batch average train loss : 0.20052774250507355/128 => 0.001566622988320887\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.17332243919372559/128 => 0.0013540815562009811\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 114/128 => 0.890625\n",
      "Current batch average train loss : 0.28665417432785034/128 => 0.002239485736936331\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 123/128 => 0.9609375\n",
      "Current batch average train loss : 0.14926382899284363/128 => 0.0011661236640065908\n",
      "\n",
      "Total average train accuracy : 46020/50000 => 0.9204\n",
      "Total average train loss : 89.8177612349391/50000 => 0.001796355224698782\n",
      "\n",
      "[Test epoch : 28]\n",
      "\n",
      "Total average test accuracy :  0.8668\n",
      "Total average test loss :  0.0034113466531038284\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1215.3158190250397\n",
      "\n",
      "[ Train epoch : 29]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 120/128 => 0.9375\n",
      "Current batch average train loss : 0.2305338829755783/128 => 0.0018010459607467055\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.20660759508609772/128 => 0.0016141218366101384\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 123/128 => 0.9609375\n",
      "Current batch average train loss : 0.15332384407520294/128 => 0.001197842531837523\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.21537035703659058/128 => 0.0016825809143483639\n",
      "\n",
      "Total average train accuracy : 45984/50000 => 0.91968\n",
      "Total average train loss : 89.9254025965929/50000 => 0.001798508051931858\n",
      "\n",
      "[Test epoch : 29]\n",
      "\n",
      "Total average test accuracy :  0.8693\n",
      "Total average test loss :  0.0032744361251592635\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1256.7673048973083\n",
      "\n",
      "[ Train epoch : 30]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 117/128 => 0.9140625\n",
      "Current batch average train loss : 0.21900078654289246/128 => 0.0017109436448663473\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 115/128 => 0.8984375\n",
      "Current batch average train loss : 0.278049498796463/128 => 0.0021722617093473673\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.2494051158428192/128 => 0.001948477467522025\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 115/128 => 0.8984375\n",
      "Current batch average train loss : 0.34726250171661377/128 => 0.002712988294661045\n",
      "\n",
      "Total average train accuracy : 46179/50000 => 0.92358\n",
      "Total average train loss : 86.4589121490717/50000 => 0.0017291782429814339\n",
      "\n",
      "[Test epoch : 30]\n",
      "\n",
      "Total average test accuracy :  0.8789\n",
      "Total average test loss :  0.0029833947882056235\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1298.523708820343\n",
      "\n",
      "[ Train epoch : 31]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 122/128 => 0.953125\n",
      "Current batch average train loss : 0.11484959721565247/128 => 0.0008972624782472849\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 115/128 => 0.8984375\n",
      "Current batch average train loss : 0.24008893966674805/128 => 0.0018756948411464691\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 121/128 => 0.9453125\n",
      "Current batch average train loss : 0.18213887512683868/128 => 0.0014229599619284272\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 115/128 => 0.8984375\n",
      "Current batch average train loss : 0.3294239342212677/128 => 0.002573624486103654\n",
      "\n",
      "Total average train accuracy : 46235/50000 => 0.9247\n",
      "Total average train loss : 85.63953720033169/50000 => 0.0017127907440066337\n",
      "\n",
      "[Test epoch : 31]\n",
      "\n",
      "Total average test accuracy :  0.8754\n",
      "Total average test loss :  0.0030394193664193153\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1340.1260061264038\n",
      "\n",
      "[ Train epoch : 32]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.20617330074310303/128 => 0.0016107289120554924\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 123/128 => 0.9609375\n",
      "Current batch average train loss : 0.16109512746334076/128 => 0.0012585556833073497\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 116/128 => 0.90625\n",
      "Current batch average train loss : 0.2973403334617615/128 => 0.0023229713551700115\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 117/128 => 0.9140625\n",
      "Current batch average train loss : 0.2365071326494217/128 => 0.001847711973823607\n",
      "\n",
      "Total average train accuracy : 46230/50000 => 0.9246\n",
      "Total average train loss : 85.77572406083345/50000 => 0.0017155144812166692\n",
      "\n",
      "[Test epoch : 32]\n",
      "\n",
      "Total average test accuracy :  0.8731\n",
      "Total average test loss :  0.003319664613902569\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1381.8791053295135\n",
      "\n",
      "[ Train epoch : 33]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 120/128 => 0.9375\n",
      "Current batch average train loss : 0.20805037021636963/128 => 0.0016253935173153877\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 120/128 => 0.9375\n",
      "Current batch average train loss : 0.19765742123126984/128 => 0.0015441986033692956\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 121/128 => 0.9453125\n",
      "Current batch average train loss : 0.19969886541366577/128 => 0.0015601473860442638\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 121/128 => 0.9453125\n",
      "Current batch average train loss : 0.1327625960111618/128 => 0.0010372077813372016\n",
      "\n",
      "Total average train accuracy : 46310/50000 => 0.9262\n",
      "Total average train loss : 83.81922620534897/50000 => 0.0016763845241069793\n",
      "\n",
      "[Test epoch : 33]\n",
      "\n",
      "Total average test accuracy :  0.8365\n",
      "Total average test loss :  0.004246820077300072\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1423.5306527614594\n",
      "\n",
      "[ Train epoch : 34]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 116/128 => 0.90625\n",
      "Current batch average train loss : 0.29133981466293335/128 => 0.002276092302054167\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 117/128 => 0.9140625\n",
      "Current batch average train loss : 0.18291687965393066/128 => 0.0014290381222963333\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 114/128 => 0.890625\n",
      "Current batch average train loss : 0.21973375976085663/128 => 0.0017166699981316924\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 121/128 => 0.9453125\n",
      "Current batch average train loss : 0.1456446796655655/128 => 0.0011378490598872304\n",
      "\n",
      "Total average train accuracy : 46357/50000 => 0.92714\n",
      "Total average train loss : 82.46772168576717/50000 => 0.0016493544337153434\n",
      "\n",
      "[Test epoch : 34]\n",
      "\n",
      "Total average test accuracy :  0.8789\n",
      "Total average test loss :  0.003148634108901024\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1465.6621825695038\n",
      "\n",
      "[ Train epoch : 35]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 116/128 => 0.90625\n",
      "Current batch average train loss : 0.23761895298957825/128 => 0.00185639807023108\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 123/128 => 0.9609375\n",
      "Current batch average train loss : 0.14019393920898438/128 => 0.0010952651500701904\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 117/128 => 0.9140625\n",
      "Current batch average train loss : 0.2536259591579437/128 => 0.0019814528059214354\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.23032113909721375/128 => 0.0017993838991969824\n",
      "\n",
      "Total average train accuracy : 46409/50000 => 0.92818\n",
      "Total average train loss : 82.275171905756/50000 => 0.00164550343811512\n",
      "\n",
      "[Test epoch : 35]\n",
      "\n",
      "Total average test accuracy :  0.8723\n",
      "Total average test loss :  0.003169642098248005\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1507.5361790657043\n",
      "\n",
      "[ Train epoch : 36]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.17664846777915955/128 => 0.001380066154524684\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.24358531832695007/128 => 0.0019030102994292974\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 121/128 => 0.9453125\n",
      "Current batch average train loss : 0.1702900379896164/128 => 0.001330390921793878\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.1543952077627182/128 => 0.001206212560646236\n",
      "\n",
      "Total average train accuracy : 46436/50000 => 0.92872\n",
      "Total average train loss : 80.77764924615622/50000 => 0.0016155529849231243\n",
      "\n",
      "[Test epoch : 36]\n",
      "\n",
      "Total average test accuracy :  0.882\n",
      "Total average test loss :  0.0029750495225191118\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1549.679955482483\n",
      "\n",
      "[ Train epoch : 37]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 121/128 => 0.9453125\n",
      "Current batch average train loss : 0.1276645064353943/128 => 0.0009973789565265179\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 122/128 => 0.953125\n",
      "Current batch average train loss : 0.17540420591831207/128 => 0.001370345358736813\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 117/128 => 0.9140625\n",
      "Current batch average train loss : 0.27504485845565796/128 => 0.002148787956684828\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 117/128 => 0.9140625\n",
      "Current batch average train loss : 0.1919260025024414/128 => 0.0014994218945503235\n",
      "\n",
      "Total average train accuracy : 46381/50000 => 0.92762\n",
      "Total average train loss : 81.03739592432976/50000 => 0.0016207479184865952\n",
      "\n",
      "[Test epoch : 37]\n",
      "\n",
      "Total average test accuracy :  0.8646\n",
      "Total average test loss :  0.003452320870757103\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1591.4848442077637\n",
      "\n",
      "[ Train epoch : 38]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 122/128 => 0.953125\n",
      "Current batch average train loss : 0.13251477479934692/128 => 0.0010352716781198978\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 120/128 => 0.9375\n",
      "Current batch average train loss : 0.22283168137073517/128 => 0.0017408725107088685\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.16223487257957458/128 => 0.0012674599420279264\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 121/128 => 0.9453125\n",
      "Current batch average train loss : 0.16042260825634003/128 => 0.0012533016270026565\n",
      "\n",
      "Total average train accuracy : 46419/50000 => 0.92838\n",
      "Total average train loss : 80.12272018194199/50000 => 0.0016024544036388397\n",
      "\n",
      "[Test epoch : 38]\n",
      "\n",
      "Total average test accuracy :  0.8509\n",
      "Total average test loss :  0.004053136636316776\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1633.6407732963562\n",
      "\n",
      "[ Train epoch : 39]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 121/128 => 0.9453125\n",
      "Current batch average train loss : 0.1884584128856659/128 => 0.0014723313506692648\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.22010870277881622/128 => 0.0017195992404595017\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 122/128 => 0.953125\n",
      "Current batch average train loss : 0.1422443687915802/128 => 0.0011112841311842203\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 116/128 => 0.90625\n",
      "Current batch average train loss : 0.2502676546573639/128 => 0.0019552160520106554\n",
      "\n",
      "Total average train accuracy : 46474/50000 => 0.92948\n",
      "Total average train loss : 80.09685279801488/50000 => 0.0016019370559602975\n",
      "\n",
      "[Test epoch : 39]\n",
      "\n",
      "Total average test accuracy :  0.8514\n",
      "Total average test loss :  0.0039074791684746745\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1675.4304015636444\n",
      "\n",
      "[ Train epoch : 40]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.17899024486541748/128 => 0.001398361288011074\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 123/128 => 0.9609375\n",
      "Current batch average train loss : 0.1169717013835907/128 => 0.0009138414170593023\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 121/128 => 0.9453125\n",
      "Current batch average train loss : 0.17035670578479767/128 => 0.0013309117639437318\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.2227392941713333/128 => 0.0017401507357135415\n",
      "\n",
      "Total average train accuracy : 46602/50000 => 0.93204\n",
      "Total average train loss : 76.44702098146081/50000 => 0.0015289404196292163\n",
      "\n",
      "[Test epoch : 40]\n",
      "\n",
      "Total average test accuracy :  0.877\n",
      "Total average test loss :  0.003238216219842434\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1717.428495645523\n",
      "\n",
      "[ Train epoch : 41]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 112/128 => 0.875\n",
      "Current batch average train loss : 0.2821687161922455/128 => 0.002204443095251918\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 120/128 => 0.9375\n",
      "Current batch average train loss : 0.2089473456144333/128 => 0.00163240113761276\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 123/128 => 0.9609375\n",
      "Current batch average train loss : 0.13781841099262238/128 => 0.0010767063358798623\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.2298336774110794/128 => 0.0017955756047740579\n",
      "\n",
      "Total average train accuracy : 46619/50000 => 0.93238\n",
      "Total average train loss : 75.80093710124493/50000 => 0.0015160187420248986\n",
      "\n",
      "[Test epoch : 41]\n",
      "\n",
      "Total average test accuracy :  0.878\n",
      "Total average test loss :  0.0031129905253648757\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1759.3699975013733\n",
      "\n",
      "[ Train epoch : 42]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 122/128 => 0.953125\n",
      "Current batch average train loss : 0.11450932174921036/128 => 0.0008946040761657059\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.21684208512306213/128 => 0.001694078790023923\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.20202213525772095/128 => 0.001578297931700945\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 117/128 => 0.9140625\n",
      "Current batch average train loss : 0.2407122701406479/128 => 0.0018805646104738116\n",
      "\n",
      "Total average train accuracy : 46629/50000 => 0.93258\n",
      "Total average train loss : 76.0601532831788/50000 => 0.0015212030656635762\n",
      "\n",
      "[Test epoch : 42]\n",
      "\n",
      "Total average test accuracy :  0.8779\n",
      "Total average test loss :  0.0031444095030426977\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1801.3831722736359\n",
      "\n",
      "[ Train epoch : 43]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.22596511244773865/128 => 0.0017653524409979582\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.21842516958713531/128 => 0.0017064466373994946\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.235194593667984/128 => 0.001837457763031125\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.17588403820991516/128 => 0.0013740940485149622\n",
      "\n",
      "Total average train accuracy : 46621/50000 => 0.93242\n",
      "Total average train loss : 76.58510776609182/50000 => 0.0015317021553218366\n",
      "\n",
      "[Test epoch : 43]\n",
      "\n",
      "Total average test accuracy :  0.8852\n",
      "Total average test loss :  0.002872778072953224\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1842.942783355713\n",
      "\n",
      "[ Train epoch : 44]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 122/128 => 0.953125\n",
      "Current batch average train loss : 0.1102772206068039/128 => 0.0008615407859906554\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 121/128 => 0.9453125\n",
      "Current batch average train loss : 0.1420530378818512/128 => 0.0011097893584519625\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 120/128 => 0.9375\n",
      "Current batch average train loss : 0.13751554489135742/128 => 0.0010743401944637299\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 114/128 => 0.890625\n",
      "Current batch average train loss : 0.2898811995983124/128 => 0.0022646968718618155\n",
      "\n",
      "Total average train accuracy : 46814/50000 => 0.93628\n",
      "Total average train loss : 72.85242745280266/50000 => 0.001457048549056053\n",
      "\n",
      "[Test epoch : 44]\n",
      "\n",
      "Total average test accuracy :  0.8825\n",
      "Total average test loss :  0.003040356074273586\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1884.7356297969818\n",
      "\n",
      "[ Train epoch : 45]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.24491600692272186/128 => 0.0019134063040837646\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 122/128 => 0.953125\n",
      "Current batch average train loss : 0.13523855805397034/128 => 0.0010565512347966433\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 122/128 => 0.953125\n",
      "Current batch average train loss : 0.2063199281692505/128 => 0.0016118744388222694\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 117/128 => 0.9140625\n",
      "Current batch average train loss : 0.2215837687253952/128 => 0.00173112319316715\n",
      "\n",
      "Total average train accuracy : 46637/50000 => 0.93274\n",
      "Total average train loss : 76.0674143359065/50000 => 0.0015213482867181302\n",
      "\n",
      "[Test epoch : 45]\n",
      "\n",
      "Total average test accuracy :  0.8896\n",
      "Total average test loss :  0.002802721393108368\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1926.5634524822235\n",
      "\n",
      "[ Train epoch : 46]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 125/128 => 0.9765625\n",
      "Current batch average train loss : 0.09650089591741562/128 => 0.0007539132493548095\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 119/128 => 0.9296875\n",
      "Current batch average train loss : 0.1672487109899521/128 => 0.0013066305546090007\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 123/128 => 0.9609375\n",
      "Current batch average train loss : 0.11227764189243317/128 => 0.0008771690772846341\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 120/128 => 0.9375\n",
      "Current batch average train loss : 0.23814073204994202/128 => 0.001860474469140172\n",
      "\n",
      "Total average train accuracy : 46835/50000 => 0.9367\n",
      "Total average train loss : 71.51888351887465/50000 => 0.001430377670377493\n",
      "\n",
      "[Test epoch : 46]\n",
      "\n",
      "Total average test accuracy :  0.8814\n",
      "Total average test loss :  0.0031166888326406477\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  1968.2799401283264\n",
      "\n",
      "[ Train epoch : 47]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 116/128 => 0.90625\n",
      "Current batch average train loss : 0.24950754642486572/128 => 0.0019492777064442635\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 120/128 => 0.9375\n",
      "Current batch average train loss : 0.19125671684741974/128 => 0.0014941931003704667\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 115/128 => 0.8984375\n",
      "Current batch average train loss : 0.24547843635082245/128 => 0.0019178002839908004\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.20534799993038177/128 => 0.0016042812494561076\n",
      "\n",
      "Total average train accuracy : 46849/50000 => 0.93698\n",
      "Total average train loss : 72.6051467731595/50000 => 0.00145210293546319\n",
      "\n",
      "[Test epoch : 47]\n",
      "\n",
      "Total average test accuracy :  0.8912\n",
      "Total average test loss :  0.0027662612400949\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  2010.3004846572876\n",
      "\n",
      "[ Train epoch : 48]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 121/128 => 0.9453125\n",
      "Current batch average train loss : 0.1470816284418106/128 => 0.0011490752222016454\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 121/128 => 0.9453125\n",
      "Current batch average train loss : 0.149227112531662/128 => 0.0011658368166536093\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 124/128 => 0.96875\n",
      "Current batch average train loss : 0.07627794146537781/128 => 0.0005959214176982641\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 117/128 => 0.9140625\n",
      "Current batch average train loss : 0.25284644961357117/128 => 0.0019753628876060247\n",
      "\n",
      "Total average train accuracy : 46658/50000 => 0.93316\n",
      "Total average train loss : 75.79919262230396/50000 => 0.0015159838524460793\n",
      "\n",
      "[Test epoch : 48]\n",
      "\n",
      "Total average test accuracy :  0.8922\n",
      "Total average test loss :  0.0027525394394993783\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  2052.485185146332\n",
      "\n",
      "[ Train epoch : 49]\n",
      "\n",
      "Current batch :  0\n",
      "Current batch average train accuracy : 125/128 => 0.9765625\n",
      "Current batch average train loss : 0.08076314628124237/128 => 0.000630962080322206\n",
      "\n",
      "Current batch :  100\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.210272878408432/128 => 0.001642756862565875\n",
      "\n",
      "Current batch :  200\n",
      "Current batch average train accuracy : 118/128 => 0.921875\n",
      "Current batch average train loss : 0.1992718130350113/128 => 0.0015568110393360257\n",
      "\n",
      "Current batch :  300\n",
      "Current batch average train accuracy : 122/128 => 0.953125\n",
      "Current batch average train loss : 0.13158580660820007/128 => 0.001028014114126563\n",
      "\n",
      "Total average train accuracy : 46806/50000 => 0.93612\n",
      "Total average train loss : 72.14271062985063/50000 => 0.0014428542125970126\n",
      "\n",
      "[Test epoch : 49]\n",
      "\n",
      "Total average test accuracy :  0.8842\n",
      "Total average test loss :  0.0028937289983034134\n",
      "Model Saved!\n",
      "\n",
      "Time elapsed :  2094.6440393924713\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = learning_rate\n",
    "    if epoch >= 50:\n",
    "        lr /=10\n",
    "    if epoch >= 100:\n",
    "        lr /= 10\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(0,50):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    print('\\nTime elapsed : ', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e9a25e",
   "metadata": {},
   "source": [
    "## 새로운 이미지 검증(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1f4f34e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7f223e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275, 183)\n",
      "(32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAz8AAAGiCAYAAADJMnj3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOz9ebhtV13nC3/GmM1qdn/6nOQkpIeYABIkRBqjRiJe8fLAJRW4ZSFVAgrBh8rleiu+0oQHjaW3lCsilM+14BbNtdQXtcoSyoICfBFQRJBOYhLSJ+fkdLtd3ZxzjPePMdvV7D3XyT45Z+f8Psk+e625xhxzzDHnXHt8x68ZylprEQRBEARBEARBeIqjz3QDBEEQBEEQBEEQngxE/AiCIAiCIAiCcE4g4kcQBEEQBEEQhHMCET+CIAiCIAiCIJwTiPgRBEEQBEEQBOGcQMSPIAiCIAiCIAjnBCJ+BEEQBEEQBEE4JxDxIwiCIAiCIAjCOYGIH0EQBEEQBEEQzglE/AiCIAiCIJwhlFLceuutZ7oZU/O5z30OpRSf+9znznRTBGEqRPwIgiAIgiAIgnBO4J/pBgiCIAiCIAg7ixe/+MV0u13CMDzTTRGEqRDLjyAIgiAIQg02NjbOdBPOGrTWNJtNtJahpLCzkDtWEARBEARhiHe9610opfjOd77Da17zGpaWlnjhC1+Yf/7Rj36Ua6+9llarxa5du7jlllt46KGHKnXcfffdvPKVr+TAgQM0m00uuOACbrnlFlZWVkaO96d/+qdcffXVNBoNvu/7vo9PfepTlc8feOAB3vSmN3HllVfSarXYvXs3r3rVq7j//vsr5T784Q+jlOKv/uqveOMb38ju3buZn5/nX/yLf8HJkydHjvvJT36SF73oRczMzDA3N8f/9D/9T3z729/esn/GxfzccMMNXH311XzjG9/gh37oh2i321x22WX88R//MQCf//znue6662i1Wlx55ZV8+tOfPqVzBPJjtFotLrjgAt7znvfwoQ99CKXUSPlTPUfhqYm4vQmCIAiCIEzgVa96FZdffjm/+qu/irUWgF/5lV/h7W9/OzfffDM/+7M/y9GjR3nf+97Hi1/8Yr72ta+xuLjIYDDgpptuot/v85a3vIUDBw7wyCOP8Od//ucsLy+zsLCQH+MLX/gCn/jEJ3jTm97E3Nwcv/3bv80rX/lKHnzwQXbv3g3AV77yFb74xS9yyy23cMEFF3D//ffzgQ98gBtuuIHvfOc7tNvtSrtvvfVWFhcXede73sVdd93FBz7wAR544IFctAB85CMf4bWvfS033XQT//bf/ls6nQ4f+MAHeOELX8jXvvY1nva0p03dXydPnuQnf/InueWWW3jVq17FBz7wAW655RY+9rGP8da3vpWf+7mf4zWveQ2/8Ru/wf/yv/wvPPTQQ8zNzU11jo888gg//MM/jFKK22+/nZmZGf7v//v/ptFojLTndJyjsMOxgiAIgiAIQoV3vvOdFrCvfvWrK9vvv/9+63me/ZVf+ZXK9m9+85vW9/18+9e+9jUL2D/6oz/a9DiADcPQ3nPPPfm2f/iHf7CAfd/73pdv63Q6I/t+6UtfsoD9j//xP+bbPvShD1nAXnvttXYwGOTbf/3Xf90C9s/+7M+stdaura3ZxcVF+/rXv75S5+HDh+3CwsLI9mE++9nPWsB+9rOfzbf90A/9kAXsxz/+8Xzbd7/7XQtYrbX98pe/nG//b//tv1nAfuhDH5r6HN/ylrdYpZT92te+lm87fvy43bVrlwXsfffdty3nKDw1Ebc3QRAEQRCECfzcz/1c5f0nPvEJjDHcfPPNHDt2LP85cOAAl19+OZ/97GcBcsvOf/tv/41Op7PpMW688UYuvfTS/P0zn/lM5ufn+d73vpdva7Va+esoijh+/DiXXXYZi4uL/P3f//1InW94wxsIgiB///M///P4vs9f/MVfAPDf//t/Z3l5mVe/+tWV8/A8j+uuuy4/j2mZnZ3llltuyd9feeWVLC4u8oxnPIPrrrsu3569PpVz/NSnPsX111/Ps5/97Hzbrl27+F//1/+10pbTdY7Czkbc3gRBEARBECZw8cUXV97ffffdWGu5/PLLx5bPBMfFF1/Mbbfdxm/+5m/ysY99jBe96EX81E/9FP/8n//zissbwIUXXjhSz9LSUiVGp9vtcuedd/KhD32IRx55JHfBA8bGEA23b3Z2lvPOOy+Ph7n77rsB+JEf+ZGx5zE/Pz92+1ZccMEFuVtdxsLCAocOHRrZBpzSOT7wwANcf/31I8e+7LLLKu9P1zkKOxsRP4IgCIIgCBMoWyMAjDEopfjkJz+J53kj5WdnZ/PX/+7f/Tt+5md+hj/7sz/jL//yL/mFX/gF7rzzTr785S9zwQUX5OXG1QNUBv9vectb+NCHPsRb3/pWrr/+ehYWFlBKccstt2CMmfq8sn0+8pGPcODAgZHPff/UhoiTzuWpdI7CzkauuiAIgiAIQk0uvfRSrLVcfPHFXHHFFVuWv+aaa7jmmmv45V/+Zb74xS/yghe8gA9+8IO85z3vmeq4f/zHf8xrX/ta/t2/+3f5tl6vx/Ly8tjyd999Nz/8wz+cv19fX+exxx7jJ37iJ/LzANi3bx833njjVG05XdQ9x4suuoh77rlnZP/hbWfjOQpnHon5EQRBEARBqMkrXvEKPM/jjjvuqFgtwFkxjh8/DsDq6ipxHFc+v+aaa9Ba0+/3pz6u53kjx3vf+95HkiRjy//e7/0eURTl7z/wgQ8QxzEvfelLAbjpppuYn5/nV3/1VyvlMo4ePTp1G58odc/xpptu4ktf+hJf//rX820nTpzgYx/72Ei5s+0chTOPWH4EQRAEQRBqcumll/Ke97yH22+/nfvvv5+Xv/zlzM3Ncd999/Enf/InvOENb+Btb3sb/+N//A9uvfVWXvWqV3HFFVcQxzEf+chH8DyPV77ylVMf9yd/8if5yEc+wsLCAldddRVf+tKX+PSnP52nwh5mMBjwoz/6o9x8883cdddd/O7v/i4vfOEL+amf+inAxbt84AMf4Kd/+qd5znOewy233MLevXt58MEH+a//9b/yghe8gN/5nd95Qn01LXXP8Rd/8Rf56Ec/yo/92I/xlre8JU91feGFF3LixIk85uhsPEfhzCPiRxAEQRAEYQr+zb/5N1xxxRX81m/9FnfccQcAhw4d4iUveUkuLp71rGdx00038V/+y3/hkUceod1u86xnPYtPfvKTPP/5z5/6mP/X//V/4XkeH/vYx+j1erzgBS/g05/+NDfddNPY8r/zO7/Dxz72Md7xjncQRRGvfvWr+e3f/u1KMoLXvOY1HDx4kF/7tV/jN37jN+j3+5x//vm86EUv4nWve90p9MwTo+45Hjp0iM9+9rP8wi/8Ar/6q7/K3r17efOb38zMzAy/8Au/QLPZzMuebeconHmUHbYvCoIgCIIgCDuSD3/4w7zuda/jK1/5Cs997nPPdHOeVN761rfy7//9v2d9fX1iggVBkJgfQRAEQRAEYUfR7XYr748fP85HPvIRXvjCF4rwETZF3N4EQRAEQRCEHcX111/PDTfcwDOe8QyOHDnC7//+77O6usrb3/72M9004SxHxI8gCIIgCIKwo/iJn/gJ/viP/5jf+73fQynFc57zHH7/93+fF7/4xWe6acJZjsT8CIIgCIIgCIJwTiAxP4IgCIIgCIIgnBOI+BEEQRAEQRAE4ZxAYn4EQRAEYRswxvDoo48yNzdXWUtFEARBOL1Ya1lbW+PgwYNovbltR8SPIAiCIGwDjz76KIcOHTrTzRAEQThneeihh7jgggs2LSPiRxAEQRBS3v/+9/Mbv/EbHD58mGc961m8733v43nPe16tfefm5gB4++//Hc327Jblp7EOTZWbyNavV6n6wwCj6rfBTlHWYwormalfr5mmf6dog6dM7bKKKdqrz/zaNHpKi6U/1T2c1C47TTP0NE2e4jma4lZDUf/aRUn9+2dA/bKYKa7FFCc31VfPFIWtrX9uW1lyAPqddX7tDdfm38ObIeJHEARBEID/9J/+E7fddhsf/OAHue6663jve9/LTTfdxF133cW+ffu23D8TM832LM321n+ARfw4RPw4zgrxM5WSgOCpLH6m0B3TiB9vCvGjRfwA9cRPRp3vVUl4IAiCIAjAb/7mb/L617+e173udVx11VV88IMfpN1u8x/+w384000TBEEQtgkRP4IgCMI5z2Aw4Ktf/So33nhjvk1rzY033siXvvSlM9gyQRAEYTsRtzdBEAThnOfYsWMkScL+/fsr2/fv3893v/vdsfv0+336/X7+fnV19bS2URAEQXjiiOVHEARBEE6BO++8k4WFhfxHMr0JgiCc/Yj4EQRBEM559uzZg+d5HDlypLL9yJEjHDhwYOw+t99+OysrK/nPQw899GQ0VRAEQXgCiPgRBEEQznnCMOTaa6/lM5/5TL7NGMNnPvMZrr/++rH7NBoN5ufnKz+CIAjC2Y3E/AiCIAgCcNttt/Ha176W5z73uTzvec/jve99LxsbG7zuda87000TBEEQtgkRP4IgCIIA/LN/9s84evQo73jHOzh8+DDPfvaz+dSnPjWSBGErtNa11qU4Xev8TLcmUP21V6ZZ0JIp1sJhmnV+TtNSOGaK9XimWgh0ikvhT9NnU1zjae4zNc21AJSpf/9Ms/bTIImmaEP9Nvu6/rDX86a52er3Q8ur3waV1O+zeJrbcgq/L2umaO8U19jY+te4zrpE0xxbxI8gCIIgpNx6663ceuutZ7oZgiAIwmlCYn4EQRAEQRAEQTgnEPEjCIIgCIIgCMI5gYgfQRAEQRAEQRDOCUT8CIIgCIIgCIJwTiDiRxAEQRAEQRCEcwIRP4IgCIIgCIIgnBOI+BEEQRAEQRAE4ZxAxI8gCIIgCIIgCOcEIn4EQRAEQRAEQTgn8M90AwRBEAThqYQxFmPsluWU2rpMhqfqz1UqrWqXBVO7pJ5mutTWr7d+SbBqinOz05SdohFMU+8UFSfxaalXTXHvJCap3wYgnqLNaopOVlO0w0wxjz/Q9e82z69fb9gIa5e1tn6f+V7toiivfntrfD0V9Zr6UiEx09wP9TE1nnvt1a9RLD+CIAiCIAiCIJwTiPgRBEEQBEEQBOGcQMSPIAiCIAiCIAjnBCJ+BEEQBEEQBEE4JxDxIwiCIAiCIAjCOYGIH0EQBEEQBEEQzglE/AiCIAiCIAiCcE4g4kcQBEEQBEEQhHMCET+CIAiCIAiCIJwTiPgRBEEQBEEQBOGcwD/TDRAEQRCEpxKep/A8tXVBa2vXGej6ZXWNQ+dNoH69xpr6ZaeoVzFFg039er0p6tVqirLU7wemKDtN/05z78RxXLusmqIf0j1ql5zi0mHxpmhD/X5TNqlfdoohchzXb0M8xbPhB/XboNQUz8YUF0NRv8/sFPdwoqa4xnXObapnWBAEQRAEQRAE4RxAxI8gCIIgCIIgCOcEIn4EQRAEQRAEQTgnEPEjCIIgCIIgCMI5gYgfQRjDhz/8YZRS3H///We6KYIgCIIgCMI2IeJHEARBEARBEIRzAhE/gjCGn/7pn6bb7XLRRRed6aYIgiAIgiAI24Ss8yMIY/A8D8+bZp0BQRAEQRAE4WxHLD+CMIbhmJ+nPe1p/ORP/iSf+9zneO5zn0ur1eKaa67hc5/7HACf+MQnuOaaa2g2m1x77bV87Wtfq9T3jW98g5/5mZ/hkksuodlscuDAAf7lv/yXHD9+fOTY2TGazSaXXnop//7f/3ve9a53jV187qMf/SjXXnstrVaLXbt2ccstt/DQQw9te38IgiAIgiA8FRDLjyDU5J577uE1r3kNb3zjG/nn//yf83/+n/8nL3vZy/jgBz/IL/3SL/GmN70JgDvvvJObb76Zu+66C63d/MJ//+//ne9973u87nWv48CBA3z729/m937v9/j2t7/Nl7/85VzYfO1rX+PHf/zHOe+887jjjjtIkoR3v/vd7N27d6Q9v/Irv8Lb3/52br75Zn72Z3+Wo0eP8r73vY8Xv/jFfO1rX2NxcfFJ6xtBEARBEISdgIgfQajJXXfdxRe/+EWuv/56AK666ipuuukmXv/61/Pd736XCy+8EIClpSXe+MY38ld/9VfccMMNALzpTW/if/vf/rdKfc9//vN59atfzRe+8AVe9KIXAfDOd74Tz/P467/+aw4ePAjAzTffzDOe8YzKvg888ADvfOc7ec973sMv/dIv5dtf8YpX8P3f//387u/+bmW7IAhPHp5K8FWydUFla9dpraldNrGjVuJJaF3fvbd+reBN0QZjavRV3ob6faamcF22U51d/bJW13ewUWaKc5vCb8fWrxY7TWGYyj18nPfCdqC8+s/GVC2Yoi809e9hf4pGqCSuXdaYKb4jpihrvUbtstqb4rmfwvnMq/FseFM8FOL2Jgg1ueqqq3LhA3DdddcB8CM/8iO58Clv/973vpdva7Va+eter8exY8d4/vOfD8Df//3fA5AkCZ/+9Kd5+ctfngsfgMsuu4yXvvSllbZ84hOfwBjDzTffzLFjx/KfAwcOcPnll/PZz352u05bEARBEAThKYNYfgShJmWBA7CwsADAoUOHxm4/efJkvu3EiRPccccd/MEf/AGPP/54pfzKygoAjz/+ON1ul8suu2zk2MPb7r77bqy1XH755WPbGgRBnVMSBEEQBEE4pxDxIwg1mWTen7S97D5w880388UvfpH//X//33n2s5/N7Owsxhh+/Md/fCpTdYYxBqUUn/zkJ8cef3Z2duo6BUEQBEEQnuqI+BGE08zJkyf5zGc+wx133ME73vGOfPvdd99dKbdv3z6azSb33HPPSB3D2y699FKstVx88cVcccUVp6fhgiAIgiAITzEk5kcQTjOZZWY4kPS9733vSLkbb7yRP/3TP+XRRx/Nt99zzz188pOfrJR9xSteged53HHHHSP1WmvHptAWBEEQBEE41xHLjyCcZubn53nxi1/Mr//6rxNFEeeffz5/+Zd/yX333TdS9l3vehd/+Zd/yQte8AJ+/ud/niRJ+J3f+R2uvvpqvv71r+flLr30Ut7znvdw++23c//99/Pyl7+cubk57rvvPv7kT/6EN7zhDbztbW97Es9SEARBEATh7EfEjyA8CXz84x/nLW95C+9///ux1vKSl7yET37yk5WsbgDXXnstn/zkJ3nb297G29/+dg4dOsS73/1u/vEf/5Hvfve7lbL/5t/8G6644gp+67d+izvuuANwyRde8pKX8FM/9VNP2rkJgiAIgiDsFJSdNqm7IAhPOi9/+cv59re/PRInJAjC2cPq6ioLCwv8xh/9I632XI09pljXZYp1fqZZzWSadX6mGi5MUXSadX6m6rOzYZ2fKWqdar2jKZpr4/r1Tjsk1NOsY7Tj1vmpf//oaa7HNOv8TLF2zela54cp1vmZ5jmKp4m8qbHOT6+zxv/n5stYWVlhfn5+07IS8yMIZxndbrfy/u677+Yv/uIv8gVTBUEQBEEQhFND3N4E4Szjkksu4Wd+5me45JJLeOCBB/jABz5AGIb84i/+4plumiAIgiAIwo5GxI8gnGX8+I//OP/v//v/cvjwYRqNBtdffz2/+qu/OnFBU0EQzi485X62pr6LSA2vj5zpXJGmKMsU7mlTuOkZW7/eSeuqPVGSKVzODNO4Ck7hXmT6tYuG7Vbtssk0rkhxXLsswBS32lT3pefXH56quFO7rN9o1i5romnu9/pFp+njJDk9rpCNKZ4jwxTudNO46U3lYbl1YT3FRTijbm/vf//7edrTnkaz2eS6667jb//2b89kcwThrOBDH/oQ999/P71ej5WVFT71qU/xnOc850w3SxAEQRAEYcdzxsTPf/pP/4nbbruNd77znfz93/89z3rWs7jpppt4/PHHz1STBEEQhHOUd73rXSilKj9Pf/rTz3SzBEEQhG3mjImf3/zN3+T1r389r3vd67jqqqv44Ac/SLvd5j/8h/9wppokCIIgnMN83/d9H4899lj+84UvfOFMN0kQBEHYZs5IzM9gMOCrX/0qt99+e75Na82NN97Il770pS33N8bw6KOPMjc3d9pSJwqCIAijWGtZW1vj4MGDU/nw7wR83+fAgQNnuhmCIAjCaeSMiJ9jx46RJAn79++vbN+/f//IQo4A/X6ffr8IBHzkkUe46qqrTns7BUEQhPE89NBDXHDBBWe6GdvK3XffzcGDB2k2m1x//fXceeedXHjhhWe6WYIgCMI2siOyvd155535CvZlfun3/obWTHUhucwSdCoWofI+2UJfp7QGrAVQKOWlmXQ2b0udY1jAYjEqzbqxxelppTcvkx5SA8punXOozuJZNm2YzXJuPGGjnDtrD4uiRiNr1whoPeWidttDFkuwOa5l/lDWlPJu5TpqZ4MxCVjXA1q7+0Oh0ntFoZVyfWzdPWlJuzz9J3tdbr0ZymQ06flTKj00rm5jDMYYLNYdy1pXQHloVe9ryathdbAW+lFUudaW4tnO7wcA7a6Nzfe1lfIGd+4Kjba6OCFGn+Fpvzfqlt/uchl1vi89z0MpRa+zxp0/+/3MzdVZxHPncN111/HhD3+YK6+8kscee4w77riDF73oRXzrW9+aeK7DE3Orq6tPVnMFQRCEU+SMiJ89e/bgeR5HjhypbD9y5MhYl4Pbb7+d2267LX+/urrKoUOHaM3M0UxX0S7/8T5VV7hx4mfS+005LeInHagp49TKFtQbZKfCZ9vEjxsagsJsmzui2XbxA0C2qvkZ8Jqse3/6E4VEsd1aW1P82DT1bCp+SnVkA35PKWyqUqxxyS01uG2l19lVhtH7YrL4UZUJBWNMLnpy8QNo5acrzm/dR3VdrnQU58fNMJkAwq22ba11bU7bXQgf15RiX4VCo6zK5OATmyhJ9zvVfbejzrr3YyZ+pt1vp/DSl740f/3MZz6T6667josuuog//MM/5F/9q381dp9JE3OCIAjC2csZET9hGHLttdfymc98hpe//OWAG0R95jOf4dZbbx0p32g0aDQaE+vb7A/yNH+gywO08utyPac2SNl8n7pNVCqbqVbbNmivI3zcses20mLzYeF2UBpsb/NYa3uHm6eR7J7Lr0Fqkyndq9OdTWrdSEWPSuuJh8QJkK/qoVS6woeienUniJ/h11m9m/12O9maz4M65cH98B1qscVkQfrc5887dqQOZbP9s89So5XKzhOmvbvOtJB4iumYbWFxcZErrriCe+65Z2KZSRNzgiAIwtnLGXN7u+2223jta1/Lc5/7XJ73vOfx3ve+l42NDV73utedqSaNMCyAptixNPbZMUPsbWabz3vqAf6EavK63Iz/k03dQW429K6ecza6VhXrn8rtGFugS8cu7TC8t8WObMv2VFZhlSU3xNV8PupYDt1xygJvMtYO980kCutQ3ve5Px9gLZ5SlSXcyneaRhVucpNbM+F1PcougdtFfTFzrn4/bc36+jr33nsvP/3TPz2xzFYTc4IgCMLZxxkTP//sn/0zjh49yjve8Q4OHz7Ms5/9bD71qU+NJEHYjLJr1xN1xxhXT2UG2I7OAG9RIcXA4omPsrMhmGKbBu3b40VWpRQbsm1DKmVLlp8n3uK8XUqdFmtSHba6h3JRYbNIr3Sf3AKE82Ib3mdTqtajctxL9ruO+1ZuNUmbk92Tp9KNw89cXVfN7DRMreWhDUqrkYfGdWFhrtHZRgo3P0i/A0oCKHfsLOtImwmYwhI0DYXVaLtvxjr9c4oTPE9B3va2t/Gyl72Miy66iEcffZR3vvOdeJ7Hq1/96jPdNEEQBGEbOaMJD2699daxbm7TsFk8xKnUNezqNrXoyZjK9UXVHjDZaTzetnFQU/v0VXVifXsOfnqqOhNDvjpCoShTskeknaoy1aGyslPcEOmovRrwX044UHLzKg5Q3b/8duhabxbvM+79uMmLug6TdS0/rn2l5B+Vm7PYWP7YFclEZ1Vzpo0tBL61I/2Qbq7VPledmupRrfNdVHbD27QcdW+fp75f3MMPP8yrX/1qjh8/zt69e3nhC1/Il7/8Zfbu3XsKtZ3qlMBktA6mKFv/2FP9bVPTpDavZ+0FCEw4Rb31hy3G1EwGw3R9pj2vdlmbxhzWoRXWL2unaC9e/S+Y4SQ2W1bt1++LqW4fW78vVK9+ohEzxfKWNqnfF3FSv4/tFH2cxPX7wUxxS+gpzm2arwgb1H8+p1kpwdb4e6qm+M7ZEdneJjHJ2vNE/OefWGzPJLaqq+4QxG7/n9RtH9OU4ze2u+7tQymo/5W9zcfeskTZpS0bmA/FmYwZuG9WW263UKTJM4r/jDX5H7zM2ukN/3EfFkFppVrryj1Z55nMRM/wT3b8es+ec87bHEWWliATMZkBqGyxyixYw6eX97Ya7mOXCiIz1jjrUPXLufZXUHbsmubcutkCIRVgWyVHKQnpLap7yvMHf/AHZ7oJgiAIwpPAjhY/wrnBtmuoHRDd7WYwtnfUqbYYCJeFx2bWGzcAd+NqY4rMccNlx4mf8m+t9Yj1J8sCtz1YLEkqf9wUU2Ffqqa5Hr4jhref3vG/ndr6s1V95C59m1daP67xHFFAgiAIwlOeHS1+fN/H90dPYbOU1ZOYNOM8zhJUP3hb13dnGzr2uNldrRRKqyGTqS3WTykNUNyA9EwM8p0P0KSJ7DrnObbWWq4+Na0G1qK8mj5BNQd9xqTHTl3TshgOlZodMkuNG/TnzcgPVG22q0fXsRHVPGeTHtDmAsjmDdCklpHSPWPieOLtkwkILGCKdXE2cznNhA5DZcttL6fAnnS9y9vL1qnN+qDdbJXqtyTGkCQJxmbptg3GWJRX9LhOTy8zjJRaznDHZALilBKk5F6L9b4rJmXQG1+1qiX0t2yzKsqVMwEKgiAIwk5kR4sfariA1B1cbzUAOD3ucFtTHTCCmyUuPq/49g817UwYOCoz5qcyGHwix57iWPWcDOuvlZIL0jxupiSA0g8yi0neBlVuc/k4NWJZpjjXIsbH5AItb4MtEmnkdgJLHgM0vr6sEGBVuvjnqADY6tnbNLHCmDTzZSYdZ5zFyvf9YtCusjgn5RykbZHLTedCtXSeJTe5tMa0fdUJlrIAmprcPa3ehMW4Y4xOKpTau0mV07TZ3eNnv9VUEARBEDZjR4sfm64SvxmnY/2M6eqsO0hV+a8ifqK0f+pnpPKhWh7FUbxWhTUhG3CfGYbV2HA7yhKpThtPw4CrhngYjuOoUWm6X3UVmWxbEeAx2hYXe1Lur/pHriOEMje6PE11ap2zqXnDKlCmEEYq3Vapo2TRKwxIFtBka+VMWidrUjuHyw1bsgpR4c6iWkcRmTMcO1T8rh5LWSdyTKm8h8Zq8LRbxHP4vMvucZBZ+cr1Vichptb7dR+DaVE1LdS1Hi91xr5NBEEQBGE72dHiJ45j4i0yYYxzi3uinB5BNbzFVjaqNOha55+Rz+JXF4ks9q+TOWt7HVjKomdStMS4weuTSTo4z0wcW8yK109GUnVFVJX/im3DAqgseqoCCKzJht1P0BJUEQBFooBM+Kj8WKVDpZafkXF57gamcutHLbe7dJKibEEdn13RYK0plcu2UylXNLawsmmt0FpV4onSo5esb05IeTqdT9AKYyw+Gs8rpZQYsfhkaBIs1iZ5oSLVdda+LbujSp7CsZ7lp8wTcrlzB69dTqVukWd6QVZBEARBeCLsaPFTJ97BGIOukU/v7F/rIhtZnc3tLAajjrN1kHQmRFfp6JtYRPLX1sKUKUcnH5D0vjGF3ktFDyXhBYUbXGVbqaqqRSsTJdlrOyJuMowxI65h41yuymsNTSo3XCYTO9mP53kVS5CNivJly5SyyolbrVHWoirmm7En7fpwSDA8MQGSCh87vfDZss4aJqVTF02CIAiCsDN5youfrNx2cXpc3qplyzPbKh/EMDI2GjeYPCvI3fW2y+1tO5NSZwNhUj+uLUpvc59OWkx0rCAyZvskmhqyImWiJe+CYnu9YxZWLDsmq9hmbm9l17TR2J6indYWMVLl12PbMWQhU6rQMdUMcta5+ZWPm+6QWacqd+6YY1qchWm869u0YsKSppwot6b+3mPjjbKJktLriftvXaao7GydzBAEQRCE+uxo8VOHqYLgtzHzWHr02sce3q96jHSGm9EZ8GkCzM8MZ5vbW+nYWxy+/pozUxy1lvjJFh2t5/JW78BZ1EapvgnudnVRgLFMGRc1+b517m6lBo+4T1YvViGWVKlfbeo6V1h7kySuCBVrszTXtiKKytcmt7mpMVdAaZTWlD8pG41ODcU0AmM4tqr6vVA/iKh+mwtr0tn5PSMIgiAI9djR4idzc9mKWgHhU/xBr58dqXaVY+sfPY4qJTwo5ryrMmmKA5+WMcxOGBjZfMC+tRfh1tahCmpMpFU2OM1ETylJR3a9Rq6bNViT1JuTryvaM0FhbZ5cLJv5z1zgMjlUNjjm+9uSJcSWLSRpxrhNrB6TUpxX97GlVdY3tyQNL4ya/U6ShCyzW7b+UJQMwOqq7hsj2fJ6KtvG9MPQOTxxylafzescFYzjYqfK1W5dX+3vs1qlBEEQBOHsZkeLn/IA6Ilyymlqn0TKs+JZAHeBLQmhmnPx2254Obv7r0pmWdmccgxMHbK4EWVLSQ+UKvraJFRieaomidLLadJsb33vOg8/4wRQ2fJkSyEnWdIDVcjsEc/ArDxglQa0q2eLeJ5xg/ZK+1IrzqlaUDLBky2UmtdpLXEU5yK3cGNzbnTlVniel+uPydFWGovaxkQh6QGVGu9jN1z6DMbouGPvpGf87Geavzl1JvoyprlFplq3qWYGQYApmovvB7XLTtNcz6tf71R//6fwxDZ6UL/awUbtsr3u5smeyjRmd9cu6ydh7bIAStXvjDiO6rdjinut2a5/s63F/dplbVy/3jhJ6tc7xQM6TdlE1R/Sx1M8R8bWv25ho34bPK9+I+qEQCtdv692tPipY/lJat6QWqlauQQUdRafzJxqstfZnmV7zfA28tcq22bLMT/jBE9xvMpWVSucpXpSdqs21juH+g439ZsG5fVFxvdZcVQ7ZltpHzuFRBtKBlCbsSP4IvtenYQH04ifLf9o2+G3KpfK+Z2aXv/UEOTieIbuoUoPq6GtJauJSgf0xWucsMrERnopVLbb0CUtn07WlVlXVE9VVcplbm/DxEmS350WBdqirHYPSebKhRM/SpetruPuM4Wxdki/PkH308ptqirdMfIUlvu59Myq9Joqxgm3zZ7hYUvbpKNnF8fWMZcKgiAIwlnLjhY/eVRzefA4rsy4QWQ5jXT+MzQbXfq38rJWFi7rpqjygYJGpb5G2aFVPgLMBqPZQQxFCeNcdlJHHUu6JovNj5LuYRkepmWu/9nr4XVabGXck/WCHfN6qB/KMmyoYgslwZZJuaJfVWm6vRh0b9GTylkrFLi+UGboRNy2qvwqLAmlk2Q47qUqUKebMa02siSU0nvOWovN3OAyi0c2bTnhQHnrlSpd0dqH36JQJqGr12vk4LDlsW35XqrsRyGtMqUzNL7OhLnKLR4lea9cIoH8zlPFwNv1SdHYfDogFz7jMZV6VPq/Kt3m6f1jydc6sob0ec0Ol52wU2NKZ/2QCZ/RDsqu41YopdKvFDv2yaOyrdoDeQdQiCP3vG9d05iWZI13tefKtPwdOM3sgSAIgiCcfexs8ZNSmZ3eQui4t6ryG0jdlMoz/dkgqbxjdox64sdakwolJ3jcYM6tHeNmmFVJm1VnsfOBu7Xk6XWtW6HF2mIIk+05MkOvit8j2yqvy4MbRTXzFEOfDR0pG3uZ0f7NZv8njbHqWTZSoZL3Q/a+NHizxTZVibex+Ux4/j4rOzSAq3iejVFjmw5gx51C2VVuyG1u7EKf1YO5XrZ2W1O05104esTq+/L9UqPOXELlgr78Oy1hKe4HW77jXLrp7PlU5cutIHMchEIMFvEsKvfSG39OxTkYzyuVUVhlXTxQJqaUAqWxiUmrKU9SlOOf3LOsNWnCA0oWn7KALvWH3uTeyWq3qbW3dD46/3x4W1nEF2dqcQ55lfO36V6lyYjh2otbW1X3KW/Li9i0r051hkAQBEEQzjxPCfGz1cry01AMN91MbzH7WxpYq60GpW6g7Yplg6TsMzeAssYtuFi48wxNj+dl0/pGjjD6ety2Op+PFzvl10Ozv1BM+9vM5SarVcMUS4PWoeSdxOZnUxY1ZfPBuH22q3GlqqeMD3qysdsa0zbGAlHaMlqusDgU9/pQzJ4q1zZ875WFrap3KVUml7V7glQhaMzIwF9R6DCVt0NlIqx0X5UcGDdpRnbzbd5Qa60TgGk7RvtyXK2l743MykbVyqnyT6dlklWohFh+BEEQhB3MU0L8PFEU5QnNccOF6iCmniuLrgwSJsV1wHSBrFlrtpe68/zj32cWlmnctOrhLsqOGGud0SD0s1lypaiyGNjkiipbWElxw/fMalTYgWBz4VEc0gkYmwqh0h5q6He5jZPmArL36YKxheDPtpGaZbMDZ5MBmzUShvxPt2C6aQ1BEARBEKrsaPEzSYSMyzI1vH14HZ3ip1xP8XnZVU5v4coy7ANUDogeF9BeO2td2bBxhhRBZaA9nBDAWqzKkhOMsRYNsfU5ZwPlNJ7nLM/Gt93UuSfOnPBJ5e7YJk56LtlibF6S0NkjVHo28li5rMAW556Lk9J+hfyyeYVlu0vl0VXV560syPKabCqqcsufLSyANYwooy2uu8O4cxfhIwiCIAhbsaPFTz74Gh4zZAMShsfLtjTAKQkaSnUMuaGNG4DWy+ZkcX5vw374O3OAMilD2UjK4srbyefqunrrvigPhM9m3GC33rXdzpTqZy49+7jnaxxDJhY1fDlL6bFV4a41UsuY53GqZym17GbPf9mFrvwVUsq1WPq0Wg5IU5pTEjq2SIteNjBZS2XN0bQdRTKSoQ/PQoaniURjCYIgCDuZHS1+3EyurQxmsmDj7L0ZST9bfp+6naXvs3jeov7xlqL6KYiLY40NdN8pLkspdQRQ1o9VM9UYRgbBkwtW3Z3qt+/JZXuPXX8h3SkWqdz2/skESelaj5g8xvmQZRbD6oxDntzAVTp6tJIAqnMuWQkPVcqfSH4/ZXkzdNoSne6UJc7I0myr0ufW+c+lB3AWH1Wy+GQTKQqX6S9L8a1Ku2SnnU+6VM7+7GZre64gCIIgnN3saPFTh3oDpekGhbUzbJnCLWh4DZCsXdMs1Lql19DZQJZq90y3Qxhhe8V2ORnIqdeRv1KldYGGJiDGPSPTPDMAesg6PDyIz0TRuM+HX4+2HlLtk75On3VrQavxD4Mtv7BMtWqiIAiCIAinzI4WPxqLpwpXE1t2gyNzq8oESJGjSQ2NZKqDGzvyWVZpVrWxNVfytaODtGoMQ+ruU2NAOiIotk1djMY6jS9WHt0x+bXW5DE6W7Az5rrrUaQl35rtdnubRtBs37Gz58RQLEJbtuxkaqNsc3G/y1bYvDWZ5lG2KkJsYSEqUqin8XKmxnOogLJ4Kn8XDFkf1fDnMHKHpkevuLsV5Wz6qa3sO04w5dssVJMibHEti0WSivtt3LaxrRcEQRAEYdvFz5133sknPvEJvvvd79JqtfjBH/xB/u2//bdceeWVeZkbbriBz3/+85X93vjGN/LBD35wqmOVBxJ2aCBl7WiWsKpL25j6hmayxyU8yBavrEvZLan8+1RjF87UcGa4P4uxVnVxVbfeTu1aaw7Gz5Rb15nl7E544Bhp4vB7W/1gOAaPshAqu5lWKkilSO7SOoXgyw+R3rG5y1lhCqpMfNiqKBoVLrZk5bGFi1u6v0tdXZx4PeNYKhYL9bV50dwnb5Ntpwlxe6uHwqDU1uvBbbUOVLXwNH8n6tdrTP16TVJnjTtHXGs9PIdSgynK1j+3IKhvUbVTLNGg658arbBZu2wYdWqXvfqSXbXLPrJR/9yOrU33N0VP0W/KD+rXW2dyK8XzwtplbVL//LSuf//4U9yX08Wr1q83bLTqt+E0fZNP9Z02BbbGbTbNNdh28fP5z3+eN7/5zfzAD/wAcRzzS7/0S7zkJS/hO9/5DjMzM3m517/+9bz73e/O37fb7amPNSlgflJ8zbgylVig0jotk9YOclna6n7zVd16NmvTmRrEPtHjKqUqs83jznPSMZ6oFWIk2UJtK8iIHS1fVHQ4JXndNOSjNdbnifbPNP24vW5v5H1WXq+qkskQlfahqhglJmdeBGfZGfosC8CZ4hyGxXo2vLH5n2uncjRglCpc49K4NVMSQZa0HJlIcokM8iQH2HxsmqU5sYAyZrSeMXW7d9meW11PN8FQ7YdsW/X87ZSP2GbP0JlLriEIgiAI28e2i59PfepTlfcf/vCH2bdvH1/96ld58YtfnG9vt9scOHDgCR3LGIMxmwuRrf5gl1dnLy8JWB0ED5evxzgLT/1kCaOxDsaYqVyrhkVbmXx7zdmV4baUV7gvlcJSBJePY1Lq8TrHH7dWUvm9S0O+tVhx1yHBWovv+yRJQhRFtNttOp0OnuehtabX66G1rtVO5Xkj12ZS32/VtmmYFBPzRBhOw14+VvHa/fYD6Pe76YSARWuPOE4YDNxMbhA0mGnPkcS2JJJU5TjFKdvSr3wawv3kI3u3r1YK7Xt5PeXfRW0WYy02/Y5QSqG0RivwtEal1za/Z4aez7JbW74mF6PfOyqrW7nkCaQzX8aYvB82R+WiK2tn3t7h564kAMuW6eJzl2Mh6zM97Ns3qQUTvivqTCQJgiAIwk5iutU1T4GVlRUAdu2qmmg/9rGPsWfPHq6++mpuv/12Op365t7txg2vnlouU9uNtTYf9JV/kiQhSZL0fYI1yVnfl8YYut0unuflg1+lFCdPniQMQ7TWxHE89eKzddhJA8fJwqdwfur1ekRRRJI4ER0EAe12m5mZGVqtNmEYbmHlOb3ozNVtCJvFsJVi2YbvbVt+Xbr/p7E81f+pFydX67iKkovU2f0sCoIgCMKTzWlNeGCM4a1vfSsveMELuPrqq/Ptr3nNa7jooos4ePAg3/jGN/g//o//g7vuuotPfOITY+vp9/v0+/38/erqKpDZGbbzj3thBZpE/bHbaRg4Q+2xTBYjUY5dqMywZ25F2Sz7Fv7k1trKsa0qeZUrVczoK4XKkwdnYQhpnMSwl+lwEoVJaDWx2Faz1BP2wlpLFEU0Go181jtJknyQa60lCIL6dQ7dF+WFbSdlKtuu9OfbLSg2y642vD0IPKz1cFafwhXOWc+yc7fk6bBT6011gd/sVijdr8qVU8q9duEwadLpPKtJVkfmFVfcc4WjW/Y9ke5jjcvRoJXzYdMqzcqosEmCsaZ6n5eelYrVstI5oDL/MqVclre0IXXcn226X56wZUyJ0VT9RZuq7m5pv52GKYjsK+IJJ/kTBEEQhDPIaRU/b37zm/nWt77FF77whcr2N7zhDfnra665hvPOO48f/dEf5d577+XSSy8dqefOO+/kjjvuGNlezD8/UU7HX3OLUqdJANU6vB0ZSLuxZ9XFLx2G16uS0cFfeb2k7JNqG7NB6JjwOmvqqck0CH2S6970KIIgIIoiwjDMBY/nOTeqzKXJ933iOK5ZZeGSNUn4TIpRGrlOpyBmTqdFZTPXt7DRRCnlrH5pPzrRUogla03u2TVUc+l1NmgnFw9KFbdH+XUmBqrdWXX9yj/L97MU60XZNEGaSYNv3I9J4nxdMJgsrDM3t+KKq9L9XTonWzOkNBPDJcFXbK4TA5Sdc6ZOOG0Gn+37zhUEQRCEM8NpEz+33norf/7nf85f/dVfccEFF2xa9rrrrgPgnnvuGSt+br/9dm677bb8/erqKocOHdreBtew+kxfX71B6elKdrBVvM805zscTzPZlUlVerKYlc+OPdLIye0vqhyJvSh2r4qGOn2ptabVanHy5Mm8vDGGVquV16OUyuOB6lEItFOJZRpnDTodguZUkyiMWn6cuJ+dbeP7HoPBIHd/ywRQOV5Kl6x37pxVyfCXDfqVs8w4M8+msS/ltkwSkKr0WSUZ9xhRY5TKXd0yuWFK4iV7bXH3z/herKoOC3ilY2fbisQJeU9inBlqbH+PO/dxyViKMsotsHp65nTEk04QBEHY0Wy7+LHW8pa3vIU/+ZM/4XOf+xwXX3zxlvt8/etfB+C8884b+3mj0aDRaIxsP7tnIc/eljmmG8H4vj9W/IwOyiBK6sx41z3+kHrarMYphIfv+8zPzwPkVp/BYMCuXbuI4zgfyA9ngJtIyX1qXLtgc3e3YaYVUNtdbvj6jhMeSrmYH0uC9sBHgzJgFUrp9KcYkGehQtnlVHa852NlnZ+hwX8dS9q489GZkLHOkGhNMYrPPDZtkoxYk8a5ioIB7ZW0Tsmtrtz2dIdxyVK9UqkkO8/MbXRCn0/iVFwlBUEQBOFcZdvFz5vf/GY+/vGP82d/9mfMzc1x+PBhABYWFmi1Wtx77718/OMf5yd+4ifYvXs33/jGN/jX//pf8+IXv5hnPvOZUx2r6grzRFClGeg6x607KDn1Fm0XW2ccq5e2WymVu4Vl78e9NsaiShnksoFuMetfbK+HzX+V3e6eyGDPWstgMGBpaYmVlRWMMQRBwJEjR1haWkrduAz9fp8gCGpe76pfV10hNmy1OFVrT62MdFMMpvWYbH6jQjfm4YcfY26+TbPZJAxDwjDEJNmAnDyWSutiqqLIJld1ocu2VeyIatQCVBx/VFQOC0yV3nwqtYRYUrc6O96trbDGVNevKiRcvkM1p8CYrh1xg5uApyCeUHTSNRvuh5F7yNb9NqtPHvOzzfUKgiAIwpPJtoufD3zgAwDccMMNle0f+tCH+Jmf+RnCMOTTn/40733ve9nY2ODQoUO88pWv5Jd/+ZenPtY4d5BTZ7o01DVKpWWL1xOPPM1AfqoRTTECKnmOlSqxI+UmV1Waos8r23xgtlnsSyYwtjyD1EIwKcr6VNzewIm0Yo0ai+d5WGs5ceIEvu/nAqDu/VVJADHUvq0GqpNig7bbolO3bD3LDyQJLC8vE4QejUYj77eYLCNa9T4rqkjvj5H4sLSsLT5xkqm0UHCuNMrWRWehycXKhFgbS3EPD6edz69BXkn6QpWejZIasqVJg8r1HEo0UCtjoMr2JI37oTCNUVjZqudCfi5O65TF2uRn84kiwkcQBEHY6ZwWt7fNOHToEJ///Oe3+7DbyBaDZ1WjTFHwNFBf/VSuhYVsJfqKFUWVCoyh8Owx+ZpAWbB3USgdzCqFKa2quFlAfx2RUoSDFEO7Ldf6GQmin3BSuCyCZQHWbDZ49JGHmZ2bY3FhkaDVrAw8h2srHymrphrXMjnhwVbxKpu2f9wp1bjd6k4WDMd3leuvts3S7XRI4gWUUvhp6vA4SoqU0OWxfO7yNtShYy5ZOSFHJVFBKa6mehdOeg1Fsgz3UxY+xVpDbs2n4fMtPC7L12j0vsv6Zli4btXdhWTCiR1VPldyV8HyuZAJPZUJutKzPXziY7pjuEjlK23cKU6cNBEEQRCEncdpzfa28xgeaYzBAqchi9vWTOFzYofKWptPZNvyFHlW7VjrVDY4dy+NVSUPOVvy8nIz1NmAzeYuhOXmPDF3tdyGYLN2bVZH1SIwikvF7fk+x46dwNcarcGahAN7d/O3X/4C5x04wNxMg1ZjhsTE7pzSeyPrAk3WdcPuW2VRkxnMhoXfsMVr3Ehzc4FYtaLYkT7ffJ/S0cZc+6qrWzomB8BUhAjK4CtFw/NpaJ9AecRxzKDXJ0kSV1Z7oDPRVUhTld43Nre4uoOYMW3YiqrILxITTOqU7POy8Bk+9xHrW9mlDsZcw/J9mb1WE9tQOiBg3f1kleuG9GtI2SwJxOghht30ysZbY6t3VFkYlVqW1lNYnPK090WV1W/ETCVJruutUcb9bFVsmvt8msNP8TfK86YpW3/IUMeyn1E/scx05zaNY0jg1+/hpunWLttPwtplL7jo4vpld43GQU/i0ZPLtcvSn6lfFvC8qH5Zf1wE5HiSKe5LG9fvi/lG/evcs/VvoCiZ4lmuswZCVrZ2SWotrZARBvWf5WnGbdM899uNP8X5i/jJUdRZm6eOG1uG1vUe9LpB9UqT393Z4Dtz8TElTWNR6MqYSZFYN8Bylpl0HyDuG7civHILQhpV9IJVoLOBVLr8SbbNlGacE6wrlx/z9Fi9qs5QxZoo2VgsSWISY2iEAda6BTezP+xJkqAtxMYQG0OUQD8yBC0fTyXYuMdMq40erOKbWRqqS8AGsTUYPKzSWHQ6THXnr6zFw6KswtM+oEtiRxWD+rT146/xeIuFtW7R2OGYm3ICgUL4mFp/5NMcbOneunS0sr3MkhhDHMf4nqbZCIijPv1eF2UtM+0mSRRhTULU6/IPf/tl5oIXMOMHNKwmNgk6Mm6tHz8kCBsM4ihXsPk9md5U7ixsPjz3VCY0KYbsQ8kJrM0smDW/kDOhUCqf52tLXd2stZCYmn9o0nWLSj2nSqnOcwGu3DluhjLuWnheSGrKSWtI+yjJBKr7oE4LdVrcphnkxk3pDE8QDOsZNeZNIfhE/AiCIAg7lx0ufmpYaqaprXZV9Y85TdB7/fpKQ6Bs4Ja79qR1qurwppj9taVtCrTOBz5uOZ1iUKjT+pXCiS6Vzf+nbmj5MVVJ+ExD3X7UrrWqNEgr7ZoNlT1P42nnspVEETZx7cIaHn7wQfbt2YvyfVAegR+yuLgEcQ+NIfQD+t1VrrzsIvbs3c2uhTZzc00GKxug3DAyG4Qq6wSETmfLy7PvruuGrTF1emZYBNncMpLfG5lFQGUCNjMTjHN5GkUVAVTY/K5I74VhVztlGQx6+B5oLA3fx5oIbSJ8X9EIWwQLsxw6cICZVhNtDMmgj/J8wiAgNgZrLDax+NonNibtO5uKkSz7mnutrcnOKGstqmT9GhGOWwifwrIxJDpLFpOKdWSKeLHqXTvGLJO9n0Kc6WwGIm2iKsxXVIw/pVvBDDWm3C5FaZJiOF5r4rmUtpXMPdldYnPL0Jmb2RMEQRCEJ8oOFz/bTd3B+OmxbNQ67vAUbSp8hode5SaOuLpRFFb5miXZDHbV0lB5rUYT+pZflwec20H5nLIhWNGkdFBXOn9dTq1srVuzJQFjEx5++CFmZ2ZottooX6M9j2bYoLveR1tFoxGwsbzMhYfOp9lq4GkwSYzWKnf2Ukq7xAYmfQ9kn2ZWDZULwsLtreipupYfJ3zK8rWIPUoH76cQF1RtQyGEhuvQWuH7Ib04wq27o9CeIrGQxAOsUlhf44cB+/bsYa7dJvT9dNCs8JQmKcfUlPrHiYLUJSi1HFqbiqJMMNihXpngNjnNfVanjtr1ZTm6s7enGNOWlnb3qrUV97RKH1gY630xeunS4sVTuv3fVGL1EQRBEHY2In7OAur7fReryI8Nb55Qz7jsYuknJX/vzcXPpPpGWjiFFas+haUiPcrIpwDa8/C0Io5jIPMjtxib8Mgjj3DogkNoz8WmYJ0lAmvQ2q37Y61l3769dHtdVlZXWOv0CGcX0MoDPKzWaDRKK7R1DkUKjVJgEpULn6oAymbNCze96kCZsZ9lQqIoN/n61B+0Zy9yew+pAql0re/7zLRaYBJ8X4GNsYlx6b+jPlEUsbG+TiMIabVazMzO0mq30NpnkBiSVDAp7aGVphcNqs7ImTugpRj0W4vFuLgXRu+vcSKl7nlPKj9ue606ra1MQky652uLIOsWUc19S7PNZWtq9iLrxyHD0tCZceYmaARBEATh7EbEz5ScjvTDZ4TUl8alcx7O7DU60B4ODh93fuMylz3hZgJWl7K4DY3rioBwN6A2xhLHMYHvp8kKXNaxdrtNHMckUYTvh5g44tjKcVqBwvqWXmfAbLuFjQ29Tpe19TUSNAdnF1HKA5XG9OChlHul8sgRi9I2XTizaNepWwMo+z2NXI/hrG3lLGWbYe3wIDk9VKlPFRANBpzodkmiAUmgwMRgEmaaTeYW51lfW2FjfZ0TJ44Dhl6vlwY5KmIgaMygPM/1kUrTmmfnnguftDHWxSzpkpx3Rav33vDrMyZ8gHLK7K2OvWWq69TiZYzJbYkZZuhet5AmhFPZbvn2kfYB2y+AxN1NEARB2PmI+EnZ7rVStp/SWh/K5vEQW6VSzraPWwgSsnVIRlMgb7W44mbpfbcz24fFuWFl2dZ0rn6y9hkXy4LCGktiEuI4pjUTQmzy833GM66k1WygNFgSjI0xJsbzGyhiOp0N5ts+jWbIAnOEYYhVnnN1Kzn2ORe3NN2EzWJ+LNYmeXzOcH8MD6q3XKAyO/MxYmecMM3W19mKKEqcQCuLx3JH5+3TBIHG04ZmGOApCDzFwuwse3Y16Hbn6XX6bKyu8dgjj3L8+FE8z0cpj8bMDHNBK61SobVPoxHQ7Q/S+yJ1cVO2lMjAutTYlRx6eqTvTtXlbfh+3EoQbVmfLWely3Yeep1+WPdR8NKYGouturhlmjHdpq17AmzJ5W1U/Aw1TFzVBEEQBCFHxM8psN3ip1592eAYMjewiWl5S/VOGlyXZ9eHD/9EXN9Oh9ubS4usitfuSOVPATDW5ANsnSY+MCZBa8WFF15IZ30D0rigOB7QajVohAHKGBJliaM+zaVZ58ZmLP3YpN5ZmclE5bPvuS3KlubZx/T38PZyP23+WSF2J1l8Jm2f3I9F11Xjkcr3gM2lZRLFRCp1v0pgY2MdT/WxieuPsBHw4EMP0Gy3mJ9fpNFoglZE0QAdBGjPwyVOGBTr/qR9lll9ylagwrWxyP62meCZ1voz/P6U66O8TlB2HcpmmmmXGbWYVMRXkz4w+jp3qxxfBsiTfJRmS2q3RBAEQRCe6oj4KXHWu6plqGLIP2zVyYuUBsbjyqj8n2wgNWrJGSZz4ZlkydhOd7ehAxRCYPizdJSp8jdO+GTtyhIF7N69h6PWEscJVmniOGJxcZ7QMxBpbOAR93s0ghCbGLpKMRgM8FvZeh2lGfT8VymddS5UsmtSHZQqhvs5rSMTIuQFRkRP+VzK20/lflWlc1ATEh5koi6OBihrSJRBWUNvY4POmiL0fdqtJkHg8dBDD3LZ5ZczNzfD7Nw8G70eg6hP6OXJ2Ol2u2jfJ7trM/dJnTWkIn6yVm5t8dnuhAd168x1W651MmtVEZNHdh/UapzJE3pYhtZsKnl1mvShLec8qbS21B6r9MTrKwiCIAjnMiJ+zhLqxxK535MSHowbvE1OeEAeqzGuHBSDQRcbVBVSkywc2+X2VowvDROHkSXho5TG9wO0DojiGEWWSMAJh5mZFlEUExsLcUIQ+BB3wSY0Qp848YAEY2KiqE9nY43W7CJoz8UOkQbl49IIu9Fq6srlgdJpSxVYY4vhrDWUjFdDfVYaJKvhwfdkkVMWQ1mCh607tJxRLLvu1lnDSr2ulMb3NEHgE/g+mBibxC72hxDf92m1WrSaDYwxtGdaLC4tMD+/iF1eJlrtuH6yhiRJGEQ9Qt1y9wek7m5gMHmbSuazoSZPttKcitjeSvjUt/6MsZzZ6mt3feo91zGGkXzxZQtP+tpqXemjya21W5YQBEEQhHMRET9PQWoJqUqiAGBMhq1yXWfCKpaPJ5UqRM4mYznPU2ilCUKP1ZPL+L6P53kopVhdXaXZCPE8j9hY2kFAv79B0l1FJQNCbdm1OAtJTKsRsnfPbpqtGTqJxZgkdUdSQAAYjFVom1otMLDJerbbkQRiMxe3uuJHpyJw2HGwiiVOIgYDt2q3TRIG/R79Xgcfy2yzgUniNOkB/MRP/DgzMy2OHXuc5ZVlZuYX2LVnidX1DTqddTy/weLiIr1+5PpgzEGtLV3r6fzFanGq7nHjyG2ANdo5lQvo0HzBsLtbWcrsEPu0IAiCIJyViPhJqRs3AfUHU+MyPY2bba4f85NNLY9aW8rvoQjyHidetNZpVS7ZgbXj3dbKM+EubXTBZm3eMsNVSl0Lked5oNyCpXqcQHO1kcQxURxjbMzs7KwTLdbieR7z87P0ul2iOHapmleWWZhrE4QhKgFtBvT7XQ4e2Euv1+P4iWP8wzf+kfaufZx36BJm2m2iCI6fXGN+bp4wCFDW0l/fACxe4OUCzWX5gixtc3bdnFZKLUGULQfDfelcn0wpe9ywxaJ83YMgGLGQlH8X1rzC7c2qzAqkAFONIUljpzwFcTwAawgDDz+1TJ04cZxoMEArS9gImJudAaUxFpIkJjZdkiTG831mZ9uYVFiXXS4zd8HCU6uwSFkzFPcywfpT57nZbJ/h/StxSZPqyywwxlbSd096jutarjRB/lyXV+cZXt/HGFM8N0qhdPG9ZfM4sfrfZa6azd1Wh63BO8Y9+IxSz+pX0zFy+qMPrwe3aeFk6zJ5vfXbqzeZEBrG8+v9zZi2DWqKRswEtYty4Ux974b7H/xu7bIPbdS/bt/5Zrd22ah+9/Lgo/XrBegljdpl/bD+kDNs1K/3or17apd93jPPr1323kcHtcuu9+p3spni2Ri7xtsEpvlqnuY7ojwW2bJefWru6FsX3rqI1vWfy3NC/GxneurtimuZPtYgc+GyI9O/w+2eVFdF4ClQaEDnA9/hAXN5gL1Z++pmihtuY12LiFYKtEuGrCt1l0QfigS3sCmel8b9uLgTrVU+aDRJQpzERIM+SRKgbIJWFs/TWBOhtSKJIzrraxx9/DD7W7MkcYRNYoyBOOoDCb4HHh6Jp4mTCGtVnjJaKRhOH55hjCFJCjEyHpWKn6RW8omy2MyuXfmnWkcuxciFmVWl+ymzcaX3m4Ig9PGUhzYGYxJ63S6DQY8wcJnc/MB3giBJSJKI2CSAwfM0Wis6nW4hruyERBl5+8tCqDinca/PFONcTmvvO0aUYsHqsusflReVvjClRAblcJ7UOkr+jJ+aACq3cVI5ET+CIAjCTmaK+QDhiVAe7DyRrFVuvnx0gFv+gWKQMvyTfabTrGdOV7jPsrie8s9W28Z9XodsX8/ztvypBFQUvVH6XfxoT9FsNuh0O4Cz+lhrOXz4MEmSpPE1lpl2i36vS6/bIYkjAt8j8D3WVldYWVmm1+vQnmkyPztDv7PB8snjrK0to7QhifqYJEIpQ6sVorXFmji3NJXPy/f93P3O80b7avKPs3hprfP6yvWWt2f9WZdMFhbzztU+VICnFJ7SNMMms+0Z5mZd+u/ExGgFrWaDXbuWWFhYwGJIkogkjhlEfZIkQqfuhr1+n5WVFYzJXPMm3Otl365NzmV4kL6dP1n9m/5kokLnKrcQHNkPo9uKSYeSVSsta9GVdhhrSbAk1mCGtuf76mqd+fuKdcbW+0knVcrVFd1sqZzaDuav/uqveNnLXsbBgwdRSvGnf/qnlc+ttbzjHe/gvPPOo9VqceONN3L33XefmcYKgiAIp41zwvJzJhhODrBtZAESNY6f/R6bKSx3y8jW+alaY4YHhMOuL5u9ruvOVsc9brIsHGM9SF3KtFb4JVGgPcVX//7v+MHnX+/W77E+ytMsLiyxNNOg4Vnifpe7vv33fO/uu1BaETabPPvZ19Cc3c1qJ6IfD0D5NMOQXncNZQbQbNFutvA8MJ4CT6O0xvMKUZL1h7P4JLWFrlIazxu6ZjUtbMPXq+z2VrXwZI5vargCVOrS5fs+jdDHV9A36/T7fZRWzM7Mcv755zMz1+LYieMMBhGDKObk6iqd7gbziw2arQa+3wC1m0EUlc59e56J7VxPahoyAZS7LKmh3yk2FUvudTFpUXZbtel/ScWKSX57u/JFvVprd22ybXpU+BTla9xrw5dCDVugSu93eLTRxsYGz3rWs/iX//Jf8opXvGLk81//9V/nt3/7t/l//p//h4svvpi3v/3t3HTTTXznO9+h2WyegRYLgiAIpwMRP6fAtIJmktvOdC48wzO2m7OZFSZ3i3HvKA9qxgm2UdepyYPx+oN7VVv8FKu+FFvyptvivUoHa4PBgIWFBTY21klMTBAE3H///Tzn+7+fZrOB72v6gwHdDYuf9Bl4FmX6zLSaaNNGaUXQaNJuN1G+Ym62yawO0H6DxCg6nQ6eAlQEaMIQYlwqYpVaZMoiMkkSBoMBSeLc2MrCaHL/gNb+0Lbx/Z7FqpRjNyqiB1JXthGZU8TcZOPmdPVMi8JP64gi58oW9wcoLGHg02yGhGHAw488SKfbZWlpF7t276bRbvPQI0ew1roYq2iDQWwIwgbOFXDSs6Py36q4mGPdI8t9+2STnYNGpamnJ08CgLsfnLWx2u4iLbbbPja+K6urLICUcm1Q5NanygRHPrkxzTmV3pRcavPHawotdTbz0pe+lJe+9KVjP7PW8t73vpdf/uVf5n/+n/9nAP7jf/yP7N+/nz/90z/llltueTKbKgiCIJxGRPycZsa5uo2NeagR81N19dqcsuVprBWAcoD0tG0pyo0TWNsZYwVZjMXQuefT40VbtecBljiO0Z52nxqXcjkIfOIowpgEz/OYbbfBDoiiAcQJno0IA591kxD1+2x0N1jvdtjoQ9iew2+20X6DOI0NDn0fZQO6ZoBFYZSPUT6QVETI8CC9rugb7p9J4nPctR0uZ11jKCRveUQ7NFjHBTdGUYQX+BhjXGpwE2OtJQxCkrTv+4Menc4GURIThD5zczPEFhrhCfzAw1qFsS72Z/yNNjzqJrVAVs9hWNidLuq4bZrUpc2iCz2SZrpQZdVQ3q5UakBJrWzKpsFNlCwtRdB5pQ1qqM7U0lOO78lEz6j4qd9XWb9n7nLD+guq1+Wpxn333cfhw4e58cYb820LCwtcd911fOlLXxLxIwiC8BRCxM+U1B6wbxHfcypxP0V2jq3Llo8zyZJTDISL7eNik86GIHOg4i40LgbI8zRa+QwGA+I4ysskScK+fXsx1hDHMb7vE4QhUa9HEkUolYCK0Z5i0O/R6XYw1hAmCcdOrjO7lBBEAxIUnW7ETKtNs9Eg8jw61oD2CdsLaN/Ji3HubVmcDkwjDvNXI/sNuzUOuyVWBFdWg8prGjpAySKkLCp1G2w0nbubtgYsBLpFu+XT7/bwfM9ldosjjDVk6x1Za6pWDcAPQpfJeeQ2yiwbQx+qUjruMQJ++Py2izriR6HSBURTKbmZ1af0vhA+5NbK8jY1lJ0xfVPsr4r2KaVG3lMWQPlOda2w1d9lQ9PZ8uifbg4fPgzA/v37K9v379+ffzaOfr9Pv9/P36+urp6eBgqCIAjbhoif08TwTPxmlp96A7ksXoBaI5I4jkfcpKrxP26q143Hq5aK4dflNm412JvGsrFlzIbKrD55E0sMC0GX3ED7zlqxsrJCGIYoBVE04NnPfjZBEJAkLlvZsccP4yvDfDvEb3hoT4GxDPo92q0me/fv48qrvo9jy+tYP2Ct0+exoydYWX6ItajHhlLYJKG7sU4/Trjyqu9ndqHhAtNTN7TM/S0IgrxvjDGpMNsKhUuJ7TLW1bbyjBMJ2fUuujW3/dhKH7rXszNt9u3bw9wMhBp8nYaWWJhpw9pKRBy7hV0fe+whOr0uRx4/wupah8ePn+To8WXmFpbwgwYmUQR4aD+o7Yo17lwrQiJ9X8d9cFrqiB+tFEbrwnF0EzfQjPLEwjjLne+PujgWoTaquHyp5UdnYgdQpaQjRb3F4sV1z3vcvVMVcMIwd955J3fccceZboYgCIIwBSJ+TiOnxWJSI+FBFmcyLFSGRRA2S3Otcj01SfRMYpzAqit+tuwfC1ZVA74nFgQnKiw0GiG9JM4zrGmt3Iyucf2iteLCCy8k7ncJVIQyfeKoR7vdZGnXAr7v0WgERFGf2bkWnUFCq93kokPnc+GhQyhlCTyPwNf4Crq9mFi1ia1PbJSLkYnj9PycfNPatYWEsofT5uduLW71y+p1HHaj2yzWqurqqNJxdGGbqdr+HGvr65w4foxAA8YQeOB7gElohj4bq6soDbPzbRrNAOXPEgYhYGk2Q/bt20OzPYuxmm63R3/Qpel5KLWZWBnvhjexdA0rzbTUfl6Vy5Zo87eTJwTGbS9bs7LfekjIDT9Xtix+Su5tFde39HOVJjKxtv76Lec6Bw4cAODIkSOcd955+fYjR47w7Gc/e+J+t99+O7fddlv+fnV1lUOHDp22dgqCIAhPnB0ufqoxH+MZN7x7IuXquS1No3vqWn7y9m2pGRRJYosJ49SPX2WuMll6W5tQznY+zu1tXNvGzVxneGnczeaMD1gfG1utbJHOeUK12T7RYIBJElrNRRbm50niBKUgbDRZWV1h99IuosGAQb9H1O8x127SCkKSSNFd79FoeMy0msRxRG9jnQfv/x733v8wvcQwv7ibCy+6hMuuuJwoilDW4mkIfY/llQ38xgwJAf3I0tno0uklDKKEJDEYo0oWIaiIuUzLZgtcpjP2luy+yGIwqgPmfPcJ12fY7S13flPDVh/XCJuXUIRhyEy7xaDTJer3SUy6IGps6NsIi0snvmvXLjpdj0EcYywM4oTeIMLgE6eaTfkBoaeLNqeLq1YziFUtU9k5ZOc3TvCVf28XdRY5VdlDlfkRDrVjUpsmWa+y35NcIlVJ5BSW0CHhk24pXPFIxXM9KamVSstmO5bukUp3PHVtPxdffDEHDhzgM5/5TC52VldX+Zu/+Rt+/ud/fuJ+jUaDxhSLMQqCIAhnnm1f5+dd73pXxb1KKcXTn/70/PNer8eb3/xmdu/ezezsLK985Ss5cuTIKR7NbvlTdxVbV67ej7Vmyx83Y19HnE03iLMWrFVDP267Me7HGlDodLpYud9W4UIzrCuXWIzJBMhoUH72e6sZ9nKZbABnTFIsKmqG+6bI3WasGfOTrWeS/mfThUsTgzLuR1uLts4Ny0PhAV762kehEoOHAmOwiUFZ8NAE2qPp+zR9D2ViGp4l9BWeMsSDLqvLxwl8jaeh313nofu/xyMP3E+80aHteeyZm2Gp3WSh2WC2EdAOPJq+Yq7pM+MbZv2EuQAWWh5zDY+WrwiUBZNgkpg4TsWQBWMVxpJfO2vS83RvUNaQzeFvdQ3GJVbIro1LjazR2kNpZ31xP7pIk+zWus1jR5T28HSI8kK010DrEFSA0gEot+6SHwTMzMziez6+dskN4sS6z70Ag4dRPsoP0UGQBuq751Epi1Y2N2Kkvlvpz5CL3tB3SZ178lTJ+muzH5VafbTWeOUfz8Mv/5TWd8rXZyqv/1T67Zc/G6ozX89Ja3dcpdFK4aHJHO/cV5clvbEgcb+zz7b6ofI+ffbT1/kxMlE1qlN3DOvr63z961/n61//OuCSHHz961/nwQcfRCnFW9/6Vt7znvfwn//zf+ab3/wm/+Jf/AsOHjzIy1/+8jPabkEQBGF7OS2Wn+/7vu/j05/+dHGQkj/7v/7X/5r/+l//K3/0R3/EwsICt956K694xSv467/+66mPo2qIGzdQqjtjuX0zm9ZWRwibzQ6PtYKMJBsYHXEUZUatVlr7KFUuA5SyOJVaRj5bPKZtGfkCoUPCKBsQFvsajEkyI0PevsoMdmrZMHY45id1yFLFGioasLFJrVXOepUvrJqXcXExQdgEazGDmF6vl7c3imNmm23MIMLXiqDRIOoP0EkPEhj01jhx/DGOH3mUC87fD9bS21jj4fvvY745z7VXXcVll1/Jeeefj0ksvoJEWSfWogFLMyHraxuQKNpeSLPhExAQYFi3BmMiBonFKLCZ0khn2bPeUBYUBuvyiQEaT3nYknvVJIZjpyZZEorhsjuOxmKVST+zqUjWxIll0OuBAV83XPtIUL7G9wz9Xhdrwfc8kighGsREkSExEDZnMF4D6wWARhlLksRopdBYtLUoky6oadOMcEpj068iRSoAGT2nrc57HNO4ntYTVcrF2GgPSn08SZzFcVzZe5JLaS1r8rht2fNtiomWrJyuKxCHKh5OiF5ksdPOCXOHip+/+7u/44d/+Ifz95m72mtf+1o+/OEP84u/+ItsbGzwhje8geXlZV74whfyqU996pTW+NGej/a2/vM6nYivv67VNNVO84zoKer1pnn2/Cni9/z6jfCmmN4Ng/qFl9e7tctGSbx1oZT7H3qsdtkLL6zvXnnh3qXaZefbG7XLAvR605Ttb10oZX2jfjtsv/61O3p0rnZZpetbdRvz9YfTOqn/bCSmftn6d9p0o92pRsam/vOpa4/NwSRbf/+pKb4jT4v48X0/96Eus7Kywu///u/z8Y9/nB/5kR8B4EMf+hDPeMYz+PKXv8zzn//8KY9Uw7Kipgv83T5OxzGHncLK78e93qzM6SJTPbZ6+EqbMqvckNucGiqXvtc628ViEkNCks+Aa62wmWUjFUjWGmeBKIaBWItzxcKSRH2OH3kMf/8C+/ceZPnEYb7ylb/BVwl/+Zd/zoH9+7jwgkPsXVrkJ256Gfv3n0+j2cYOIjrr68644Sk8bTFYVNwnJMIqhQYiLIGNCZQh0E5YqDyuSmGVSq+GSgf6ymVUI3VJzPooE69bjGS2dJnK3ltnDcxtb8pZKAtbXPnfTJbpUpuS3J5Z1AnaKmdpRGHxMNbDWo1V2Vo4mTh3e6s8jmmcoKd0vMmcNRkIN2Gcy94TYfgJGt5W/myH6pPTyg033LDptVBK8e53v5t3v/vdT2KrBEEQhCeb0yJ+7r77bg4ePEiz2eT666/nzjvv5MILL+SrX/0qURRV1lJ4+tOfzoUXXsiXvvSl6cVPXReMJ3skUPn7uvXBx1mCxsV3lOt0n42tbchCM6Z5pzAWmxRoP+4chvXOJg5bpfalgftZ3aUqjDHOLcxasGAweKnw8bRGBwHa81ILmrMcWGMwqeuPTQfxxmgSa8FqvLCJ5wccP7lMrz/g/EMXsn/vAvv27aEVhuzetcTTLryYCy+8iDBskhgYDFya7LDpozwwJESRc+fTOhM06dE81z6tlUt0YHBubVAErdvsehSRHJZUxKVWsLSbNsUvJ5hQ5Zn66hy+86pLRVUaFGLV8BKymTDJFOeQ+6aqzqw4KaMxZPEytvxhfrMp62rM3BXLp5VpZbuThuylzG2T0nBvlp1v3Pa6VgBrSz1V+p4oEltMa1GocczscDAx9k4QBEEQdgLbLn6uu+46PvzhD3PllVfy2GOPcccdd/CiF72Ib33rWxw+fJgwDFlcXKzs81RdS0ENq4AJDC/iuFlg+7hkA9MMoiat+7MVwy5vZYaFlrUqHyGp0iB/eJ/CHTFdtZ7M2KPy10opAs9zoseaNGbJy/dLEouxEQMV5zEWBrDapFag3M7k4mywLpbBCwgaLYxNmF9Y5JpnPotmCHt27yIZDGg3m1x62aVYLINBP01aoGg0QvxAk5gYmyRYk+QZ5Ywt2U4UqFT8aKfgsInFKmfqVTYvmcZdVC10blOR6nrTa1OOkSlVpZStfJZLE5uKn9TwVIis1C0yK1SpdJyVNY05Q6Uuc5nQVIX5Id0tjdfPXfwqteRi6MyPqrd6FqzKOs1OFD3jxM7wMz0udXxdNhNTm70/VbJLqUriShAEQRB2Ktsufl760pfmr5/5zGdy3XXXcdFFF/GHf/iHtFqtU6pz566lUG+YUAxStnZYOZUBzWQL0vTuQ8PVVEJ5UCOvSV8W1ojsn3KbVL5PMXgvslj5vpfGL3mpRQeMcdnTjDVEsYtHskqjPd8NwLNBpsrinCygXcwJCs8PQXl4vmZpZjfnHdxLv7NMtDBHb6NDIwjYs3cv6yu9NIGEh+cFBEEANiGJI6KoT2IiAr9BlgXMUh7Yuh+Ns/oksTN/KO2TO5fZkuh1DS4kgLa1zHTllMaZ5SytqhK/YStOdTb9t2T5ydcVqnGP2VTkDv9knZCWceeUxeZlMrR0n9vsbii2Fddre6hdUw0XQ2cty15O/+xku5RfZ++nrSttTnq9x8XzbQ+Zhh1e10gQBEEQdiKnPdX14uIiV1xxBffccw8/9mM/xmAwYHl5uWL9OXLkyNgYoYyduJaCG+xNO0hQeZKCOul9s4/rpD+ehLWm1mCmWsSmlpvqZ8WALpMtmw2YFN7ITHXaZ6kfVLZvv991giXNehX4QT7GNsYQG0tsDFprksz6ojTozOLj6jeJi7/xtU+zPcOR48e58Px9NFpNlIoIwgZHjz5OI/Boz8ww6Mc0mw0GgxhrXIIFkyR0u2t0ex2ipI/vK8LQz60mBktik3wAn51ikiQMBoM0g1pYEhrpsN86y1QRsGedn5oyWw7ezRgrxGifaye6lMKoQvgwJH6sdW2pf+d6bj9IBaiHSrMQKnCB+NZZunRq9dGpO51J75PsbtHY0rls00h+vOFxLLb072YVqiy7XmETGfOTWTerz2tVtAzVPMXXRVlEbUd9mx6L0pzFNtYrCIIgCGeCbU91Pcz6+jr33nsv5513Htdeey1BEPCZz3wm//yuu+7iwQcf5Prrr59YR6PRYH5+vvJz9uMGeKfCZu5lw4PbcRmmNnN/2Y5Z283qm7b+vO3aiZ5MVGkFnlJ4CpRJUGYASR8bDzBxDxv3IRkAMZ6yBJ6bnzZx5FROmklOKdA6y0yXDkyVptFsc/TYcU4sr7C20aEfJeggZH5hkaWlPczMzHJiZZmw2URrH2tc5q5sLRitNYHv4weaOB4Qm5jEJiRJQhzHJCZxbnrWYGxMNOjR7/aIBwMw6QKoxpRSE+PighIFSZqW3FonHrb4MXGCTVxa74mvTYy1CXn6cCzYBEtCdvBCNNewNqWGngSFIU1wkKZXt1aloULVbHbaZhmg3I8mS34wLHbOvPvbJCwm/c9Z28ppxodjfabNNCcIgiAIwuln2y0/b3vb23jZy17GRRddxKOPPso73/lOPM/j1a9+NQsLC/yrf/WvuO2229i1axfz8/O85S1v4frrrz+FTG9nMZmfSD5/vvkgqDrwseksrh2azS1m9jfLIDXsTjPMaKKEurPsZZe2wqXLjXKzdNdD09GMul45w44rp4cC8nOjTxok4hywDAvzLVTqatYfRPS668RJgjFu6K6UB9pD+wGeH6Cth9YBbtUft36MxZLotL3WsNHr0Z6ZIwgbhI0m7ZmQ40cfxqXGjtjoWhp+SLfbp9frY2KDp32McfMFbt0VH8+3xElCYiA2isQkxAkkRmMSZ5kySUISRUSDvottshZIwKYuZplgwFldbCoIrHFxS1sxnH52nAUgi/1xCQ9skfjAliw/2ee5m1p22W31J3dhK9zd8tgiW9z1rqgFk6A90GlqBKxFp0kSnD0tmyjQFAkWtpftrDFLFgFJ+iymFqxK8oFsQiITQtmzmT3HxfaMOvqnavEp1112ezsVq/Nkim+xbDLn1CZ1BEEQBOFsYNvFz8MPP8yrX/1qjh8/zt69e3nhC1/Il7/8Zfbu3QvAb/3Wb6G15pWvfCX9fp+bbrqJ3/3d393uZpx5VOXXFgxnjRp1Y8neDw+QhsXMOPeXyZnhXOxMHZQqW6RGP8vPYSuhVxodK4pBIPlrm5dzNgVDoJWzlpgeSa9Lv9NxVhgUyvMIwhaeDtxaObFB+R7aZEnVXPY0m4ouq9wCotYkNFtttPacu5q1JImhFQYoa9N+UcRR7NY4MhalDHEcMxgMMDZBeRZtFYkx6aKllthYEuNy8xubZaozJElEEvcxfpAvYJpnQsuuE0W/OA1ST5iW11py/ThqjcvtkKU6i5TX5bio0jErwrvclnKbClevfGBuS8exmdix7rytyS1BKov9oljHaTtlykhN22xcKT+v7n3pUOMEaOk5HHZbqytYiv1HLWXVuifH+Z0ytuzUJwiCIAg7k20XP3/wB3+w6efNZpP3v//9vP/973/Cxxq3OCiMDv7O1Jogbmi39bE3yw5Vfg+j5zKu3KR+mbTA4jSMG1CNxCip0fJqaIhfLFJq8l1yMZQO3rS1aJ0QdTuYqMug16G33mHQ7WEAzw9oBi1m2wFho0UUxwyiAVgfG7vFRT0/IAhCDBbPglEGqw2B9klsiAF6gz4woNFo0Ai8dJAOnvZK56SwCvqDiI2NDoYYz9coFRJbJ3QSY53oQWMSg0ksxiQkyYA4GWCSCEjQKrXq2KxndGbsKvrJ2hHROunaD4uf8ddqSGINmdyUMpVzVek5FWsSjeyUW5QMpJn0QGWLstpUblkDNiHUnrOWpe5v1igSNMpqTLpIbzyy6O0TJ8/O9iSN2Mvup6fD7a1OnafLha4Qq4IgCIKwczntCQ9OJ1n8Akz+g386hE+twYXN3ETqDRW2c8CilMKYegNJreuFfW3Vv0U/K9TQstrlpAcanVuR2q0G/X6fOI6x1uD7HlppEhtjjVt8M1AQ2IjBYB012GDfwgzxfEgYOHe1RrOJ12iyurbBfKtB0Jil14/4m7/9Kssrq+zdf4DnXPscVtY2mGm36XR6DPo9/HaLQTLA99u0Wi1aoeb4+gmOPPo4s60WC3NzBM0Z1tc7eJ6P9jyU8kgwKM9zsTbW0h1EqeeXTxQn9AYR551/iAcefJhuP2F9o8djjx5mvRsTNmaYbTdoNzTrG32SGHw/RGvPrUmkfBphQDTo0+l1QEOr3cLzNNbavK88z8uvm7UWz/Py18PxJ+Wr4IUhyvOwymBUJs11ep96kMbuYBQ2claYaDBAK0ugodn0gBhjYsASBAHGWjobffqxAd9nac8uTq6u0O/1wBoCHwYba1z3zOewa6FF6INnYaMD692ITi9ioxdxYrXLynonFcDF/VMnjm3yTUue9S+teOz+2et+v1/ruQmCEM8Ptj78E4y922oC40knz7By5pogCIIgCE+UHS1+zmoUFGu3nGIVNQXRpEVSt/M4tetT+T+UrQzlhTfJsn0Zg00Sl6AAi0oX+NRY0KDRhIGhZWBmromeDZibX2B+fp44cSmuo8QlFpjft8TDjzzKQ/cdZffuPRx99D7WN7rMNj1U3KXtJ/TXThB6Ps12QLffoRH6NEIfjKGz0aXZbHLRRU/DRANsYoiSGOX7JHECaTpp7Xk02nMYExMnfSLTR3maOElYWV/jxMkVmrNzKN9n+chRjjx+nE6nD/gszLVYnG8z027i+z4mBpQH1lmKsKC1gVDTosEgifB9D98vHtMgCPB9H9/30Vq7mKIJA/bKNVPKWahM7BzYPFNcG61Sq5MG66G0h/Y8fB2gTOp+qAyBb4kjy0ZqEYvjmHarzdpGhCYGrUkSt+5Ru9nA05bQ1+y78ACzMyGBr/A1KGPxdELoWZJAEVtNGCi0xmWa0x4oPfZcylaVLYWKSu9AvbnoySj38+b1jre0jS16CpMaddYLEs5uPGvwalgyp7o7plhddpp6p1lfS09Rs54in5JXcxIOINBR7bJrJx+oXfbRe79euyxJr3bRp11xbe2yV11+ae2yu2Ybtcs2w60nazJaexdrlwXQKq5dNvB31y5bXttxyzaE3taFUtZX6q8TaXrJ1oVS1Fz9c7O6/rXzpllVWtcf0tuaIQ8w8ud483qn8XiY4rvH1mhDPEU7RfycAnUtP7X/WJWCl7cFBZ5X7y4wtmaAuRo970zn5HrHVoOSyuv4VPZL3xqTYK3LzKYUzt1MZe5fEHiaRqBp6wYtz6fhA8oj9MDTikYYoP02nU6X2EbMzzbQdonWTJNLLjxIP4qYmZlh5dhj+EFAIwhJkpgospgEdi3uphEE+BosmthYVleWUdbiex6NIKQ/iFHKgHEpswMfgkbAIDH0BzH9qE97tk233ycxliAMWVlZodePMdbSbDYIwpCTy+u0Ww0CXzHob4DSaKUxNsnTQifWYmJ3NTxf4afrEGlP5QkKjDUY65IqaOssfKPiN3uRvXc+dcr38bRzS7Np8odsaZ7imrpkB9qm2fGsxSQGa+M8j0cRe6ZyIaC1B1pjjcFT4IU+voZmABcdWmAm9Ag88NJII02C71mCAEKj8Lw09kc7K1sd8VPPBcz9k3oYpu0v3Zelc/dq/+HYOratOP4UX+7pP9UkCcNHmhy/N1rZ9roR6vR7Sk/zx1gQBEEQzjKeEuJnO1MvbxtTHXZMloIneGjl1YwhqDmxMZxsodrnQ3WOvR42FzUZLm20E19ubZliPRitlBM/oUc7tCw0Nc1Au3ibJEJrje+HBA2f5ZMdjp84CUoz224QhJqLDp1HYgxRFLO+fIyw2WBubp5+P6I/SGjMLBB4btFTmySYJMKYhPW1NbRSNMIQEvC9Jr4fAhqTpCeQWDq9AeudDr1BB7/ZYhA5y0er3WZtfd0doxHQau1xqbLtY7SaPtZEdPsdwkYTTYA1LtmAVh5KWRJj0J5H4IfYCDzfWWGsMSgNVtk0hXaaKTsxaE9XLWuKXAFZm62do/Cth0ZhSwuO5skPbDakr34WJxHJIMKaCKzC92yeOhwFURKhtEJ7Lqse1qC1wvcUgYYgUOxeClGRclakNPubsjGeVvgeBL7C0xZsnFqdNOUs/OOe73Gib5hMqGXxWsM3bFUIjSaOmIQxpprdYDOmeKwzR8QCO20VpT1Pg0DJU5cLgiAIws5lR4sfxfi1bc6eNTPqzg7r7dQ+QLamzdacalB2NvOfWwDSX+NqywP5XYovd92swcaJW6vGZpm+NNgEjYtjCQKfZqNBu+nTbnu0wzRttTH4YchgEPHoI4/wlb/7Ct/69j+itceevXt5+lVX0esNnLgCfF+xvnKSo4cfJUksjdYsF+/eyyMPP8DePYtgI1ZXj3Pe/iX27NlNv9dj5eQy37nv21z9fc9hZi7E9wNnTdOafhxzcm2dYyeO0+mtE7Ra6Yl6GAyraxsAnHfwIPv3H6DdnuWSSy7hnnvvY2XlJHFi8DzwQy+d5dduoVRgEMUEYZNGq83y8gZBI8TzPOfehgWt8pifLLar2+2SrZXkKQ/P80YC7621dHo9ojhxukIbtGdR2rm9aa2d2xseXmrNSZIkzXYXgU1QynfxT84/jTiJWNtYdxn3tFu1R2lQ1pLEMZ5v8VSIMeBnqRFsTBIPMDYGnPVLKyd8TDJAK3/TBAWZS6ezNm1u3bSASUfreijmp3w/Z7/rxr85d8M6swaZraw+WX6GsoWnyMQ3zRzJ9MeuRyGYBUEQBGEnsqPFz5ng9Air+okR6mFxAexbo3W9Sezh087jyCvb05GmTXNCpQPOYp59XL0u25mnsrl+56qjFQS+R6MREjQ8BsmAQadP4IfOKgM8/OhhPvM/Pst9993HeqfL/gMH2L13LwsLC+zZG9LpdAAIGw2igXNDi2ODQePZmD/8+Ef48Zt+lAsvPEgz8GiEAf1el16ng00s559/iIceeYSFhS7N1ix+0ADPZ3Vtme/+0138413f5Z/uuYt2O6TX73Leeedx6SWX8Jn/8T+I45i3vPnneNbVT6fTcxnemg2Pr917F5/73Odpz8wyNzePMc4JLAgbeF5At9PDD5s0WjMcPnqC9swCQRii03gagGajSRAGeaIDZwXz8T2fIAxoNBoEQYDWOhU1Lg31zNw8zWbLbQ8MSnn4vofne2ksUYBWASa2DDoxGg8/8Gk2AhqBx9xsA6X69Lsr+L6fiy/PD/G1B0phsJhkQBz18JRPq9lifXXAbKjwbAJJhDF9TBxhrFs3ySQJcdIljnt42sejUXHwHRfDVieuLXev1EMbGPMcK5eyvB7TuLxN+1wP132qWRnruQVOV6kV3SMIgiDseHa8+Jnk5nY6rT/16647SDodbZ3GolOnzOYWNreWjCJb8DIt7VqSCRvlAmZV6uanU0uGJluThzTLG2Cd65vve6BgkCiS2JIoy8ZGB60Ua50+nX7E3gMHWYxjZmdnUdqj2+uzb/8B2jMzdLpdup0ujVaDvbt30x8kdPsDUCFPv/xy9u/by/69e/B9xaOPPcCXv/TXHLrgEJdecjmt5ixz3Zh+33Di5DLHT66wttGhF/V5/NjjrHe7BI0WYatJe3aWhYVF/CBgbm4OrTVho8kgSlhfX2NmpuUWOSVhfr6N9jxarRCTZo3zPIUfaPp9gyUiinusbayRWCdMVCZ+rKXX6Duxkoqf5eVllNZ4nldJhpCly06MIYmtcynLrBtejNIWl1tApdZHD4VPM2yxMLOEshoPF1vVbgUszLXw/ZjO2jK7di2yZ+8efN/nxMpJ2u1ZZmZnMfEAaxOXZlx7tJoNsAkmcXE+mhhFgiJdpDaBODHOrQ5TWyuULVuTsOl9NRwoOek7wrlhbv3cZPdqvXbWK5cxaX2vaTkdORHyMK+zxbAuCIIgCKfAjhY/mw3En6zjTma6Wd/tbnPdWd9ps1Zt3udVy89o1ZkkUqkrkiuvUXjKufmYPJ2uiy/QWmGUxmof6xkS5dFPnGtcojzC1gxB4LO8vJwuMGppz87Rnp1D930MEEcJgzjmwYceYqPTo9PtMxgYPK04/Ogj9LurhKHm3u/dxT13383+vfuYmWmzsrzK40fXWN/os7K2wcnVNfqDBBV4JAbCZov23Dzas/i+Jmg0aDZbLC0tEQQBQdAgTrIU3mmZwCcMfKI4QimL0hZlnDuY1j6WmCQxJFiU1liV2sKMIYrdgquJNQwiF/dkce5sSrm4Gz91iTPGrTEUxwlRNCCKDGHgXOistRgVYYmxmDTpBVijsNajGbZYnN2FTcBTmmborD+z7YBGw+JrQ6sVEoY+xhgefOhBDhw4yOzcLDZ119LZj04z2FmDUgalndDT2gUtGWtTFzK33Utd8Kx94u6sCuf2NmrkeaLfFePu7QklaxQct55Xtn1SxrczQm7MFfUjCIIg7Fx2tPjJKBbQVCNyY3TLxErOfmrP5tZ3eVE1g7zHzbRX4n0oWX+KEKDSIFHlaQ1t+s7FJXnoPL7Bzby7eHzrymuwnkZp5+ZlrEX5Lk2j32ixsGsvUdzn+AMP0mw0WNi1i/POPx8/DNFxRNhoMb/o8/CjD/P5z32O48dO0O316Xcj5ubmuPvub4GN8X1Fp7uC53m0Wm083+fb3/423/nH+4kSQPnooMHc4hIzrTZ+GKCCgF4csXzyGD1lWFxcIGw02LVrF0EQYK2h1+8yOzfLyWPH8TyN52kGgz5rG+u02i0Xl2Ksk4DaEg06DGKLUU48+UGR0jo2CYNBnyiJ0Eo7N7MkIQhDt4Boav1RSmETl0nPWJeyO4oT5ufnabfaWJMQE5GYCGNiEpOki7EqrHWxPidOnMBEJk88EXgKrWKaTdi3Z4FLLr6AXbvm+PZ3HuRb3/wW1sL555+HUgbf12B8tFYkSYSnFOCEj+9p0AGDOEIlNr9XtVb4gY/ne+m6Rt5kkZKGs5gxqYTLd2hm+TGUY4hU9Z4s7aC1ykXXZgwn/3iiDAuecZ+X01+f6hpB28VO+KoUBEEQhEnscPFTsjbklpbsj76man2xQ+WGt+0Mag08bP0c7nWzwtWrzJZkaPGvxg0WddbXCpSLtEd7mShyWc+MddctTh2kUNBuQb9nWFvrsba2xuLiIlEU0x0MGCQxNgHfCzl4/gVcetnl9PoDOp0O7XabZrNJ11ouu/Ryvv2tb3P/Aw9y7NgJrr32+fz1X/811gzQniUIPJYWZ7n4okt58OHDPPDwX/LAAw+zvj7ADxo0WyHttlsQ1cYJvV6PzuoaqyeWeeThh2n4mhCYa7XwlEfoh3zzH77JsSNHufbaa/nHf/xHvvrVr/LYY48R9fusrawxPzuPH/hpP6Vua55PHEfEg4jOegcTxekiqIZer0eUWnyyQbC1lo3lKHd5C8OQMI0R8qxFKQMaAl/TXV2mu7riBu/agOeSJGjl1tnw06QHyksXqg08F8tjDUk84OSJo8SDdUy0n9XVp2ETw/GjR/jKl7/IXLvFc571TDytXAyQdRnR1tc2iHYvuUVBtYfynajRsQ9JH5tEWA3a852ICxp4foi1acyaV4jlLHW808YWG5fvtRRbbHN3m8se6O6w4lkfe5+qs/eb4GxY30dEjyAIgvBUYEeLH6U9lM4Gj4ZC8JBvs5VtOh2gp0OjLMMY6Vo3NRalqzvla6ccKth80KYqo4zCcuUsIcrWy7bkZdneVMkuNibIO0turNL3UB0QGrKZ7qGZ94pwLASls9xYlPLdopWpe5tSoNPEbtZaYmOxNiHwfZTWReyP9V15z6OXeMQWHnt0g0AZQt9j/9IewNLrrdFdXWNjeZX+oA/WsL66yoljx3nm1dewsrbMieWTHDt2jCNHDrO0tMRzn/cDnFhZ5cixv+XIyRN4zRnW1mIafsiu3XvZvXcPiZ7j8RN9BtEA5be54KLzSRKL1h5BGBD1N2i2muyab3Pe3iWe9wPfj68VM60GzUZIGARE0YBms0liDM1Wi12Lezh44BALP7ybKIqdlSW2+L6PzdMwq9zC4/pIY22Atdq5wcUJg2jAoN937m9xQpIu8JolPrDGkpiEOI5J4pg4ca/jOMYkho1Oj8EgwhhDkiQMkog4+4ljkshgbIxJEqL+gF7PLeTXCAO0gu76STY21tize5EksiSJYtfCPM97zvcz6Kzzd3/zJX7ohh9ibWUZYyKsCrA25PDj64Sh54SRctbGtY0Ovd6AjW6PldV1ji8vM7+wh5lA4/seFo1RpPeni4sy+bvUkhOSx+Ari0uRnloOi6VoVGr92SSTW3prG7X1RIhV2ZNINX22TZNLl3cffm7ScnmxyqHS56ck0Cof20z0VT8oBJGtxPlkz10dssViy+JqWGhZawmmWNxVEARBEM5Wdrb4qfwxzlM6lUqUt5V+0sFmebHDbCHImgfeuow9lUxPpVnukWMVo586tZZd0qrpB0o+abjsXPk+I/uPbsvXD8kFULnlFk9rAi+g2+sTx5bA9/HDgMD3sYlx67PgLA69bjeNW8lWA7eg0kGvtdhBxEYnponG14pAKwLfo9/vs3z8BEcee4wjjz1Ge3aGPbt3M78wj7WW7373uzzy2MMAbGxscPToUY4fP85zf+AHeOaznsmuvfvYtec8Lrn0MI899hiDfp+wGdAMQ5ozM8RRBP2+cw8zFu1pGo2Qubk55ufm2LVriWazSaPZoNVuo4zB0zYXeVEUo7UiimIC7YNRtBotwqCZrrljC/eqkrWhbDdz6cB9rEmzgafB+EmSuLTX1uTWvSiOsdZ9bs1omUxQJcZijFtM1SYJURKTpD9REmNit08cx/S7XfqDgVu01Pew1nD86OOcWFlm357dLMzPYyJDu9mks77KI8vL9Ptdnv+85zI/O8NGZwMTGzbWe4Rhg+MnVjAmQWlNGAQMohhjIYoB7RP4LcKgkcb7uFig2BrSBN8udicNIlLK3SuJSZxVsXwLKpPfnplN0dnV7CaPY3EFtnq4srYU3yMU3x1jUnSPuLSV81eXDdB5q8d/b9gJ24u6R7edqnvcyLaa3zmCIAiCsBPY0eJnesa5vO1Mtmp5IXhKJSv6TlWFVkVvFduGj6Pywfq4GXK3g9YKZZNivZJ0Rj62iRuIaje730lirA1c/EZi8sEx1qaZwCzra5rWjJeuBWOxJiaOBiyfPMGxxx9ndXmFhcV5Ljj/fDzfYzAY8L3vfY/Hjz3Orl1LaK2ZmZkhjiMazZArn/F0LrvyGWi/xfzig8zMzLK6uoqxCXEUpS5XijBLv+1pmmHA7Owsu5aWOO/Afvbs2UOj4QbqiUnodzqYJAZSAYQijiKXrU5rlIXQ9+lHmZ+WHmsZNCV56sRPdi1UIfQzS17pd7fTGTP4HRbzGj8I0Z5LAqESS4LBGJd4ILYJKl1LKI5j+r0eiTWYOMZiiZOYlZMnObmyTOj77N29G4DZmRYz7SYb6xpMTBL1aczN0O979KKIXpzQ7TRYXl4jThK05zEz03bWBuXSY4dhk9kZTRCEzl4bxyRWkeDSk1sFVms87aXrEkGWCcKWb9+RTrCpjKxHnaWxXFJ6my7km8XhwLCuGcXm5aqvKTQPVfe24dd5TUMJEiYlRqhjIc7sTdl5lL8WK+sLVeo8W50Dzx58ZfDV1p4E0yxGq6YpO8UlmqYNuuYSCkDtteYcNVfbBo4+eE/tsr3lB2uXnQnrrfMFsLjnabXLJrZXu6yyYe2y2q9f9rvfe6B22ZWNTu2yAGFQ/zrvWdxTu+x6ul5eHfbuadcu+8jjq7XL9uP69/vc+krtst7u82qXbc0u1i7b21ivXdYPgtplQ1VfKtj6XeZmduvWq7f+Po1qlMnY4eLnVP4Q72zRA/Vbv3la6nI5hgbKWXmbDwht6a9pxdun8ldWEccxG90NFubmaDSaWGMYRANWV1ec60zgE/geGh9PG0Lf2Z9MkmDiAX4YugD8JMEkMWvLGzSTkCRQBJ4iCEP6/T4rK8t0ux1mZlpccMEFXH311dxz77088OCDXHrppVx+5RXs37+f2dlZPM/D8xTNJpxc6XD48RUefuhBvvp3f8tjjx4mDALOO+8AzUbIyZMn6fV6eJ7mgoPn8f3f//00G2EeTzM/0yZIvzTiOKbT6TDod2k2m3hagzX4WjHAEoYhM7OzzM/NsL62wsmTJ7EWmq0WVo37Q1sMRS2K0NfOzTG1FmWxXKY0yLXW4o/5sikPXAFnQbEJJi6O5Xnga4XCp6H96uBqfhblKaJBtlis5bx9uzFYov6A+fl5mk2f/Qf28oY3vJ7BYJALzePHjmKVShMeGB568EEWF5dot5v4QcDCwgLdbpdup4cxBu0pmo0AlcYWWRJQHtpTaC8VfKlrpLUGjBvoj/RgmnCjvBzNkzdMLwsSRl4Xl2y03GahPJOyvU1KjJAdo7Ahbv59Yan2oy3L8kygVU1rm9QmCIIgCGc/O1z8nGOo0uzsZsXqZG9LfwyK4QRXRVrrankoBkdZE7QFky/maNEYfA1JEjEYuBluT1sWl2ZpBr5zy4pj+oMuNu5B7JGYhGjQd2vdYAkChQ5AWQ9NQmdjhcSDMPDQPc1gMCBOBszOtVlcmmdubobl5WWuueYqXvTiH2R9vUtv0Ecpl7ksCHyWT67zzW9/i+/ddx+PP34UpX2ifp+l+RlarRbzs20WFhZ47nOezfz8PAtz8+zavcRjDz9CoxHk6+ZgE3rdQd5HjdBnaX6PSx9tEkwc0+v36fW7LoA+STBxxOL8HIN+P01R7eVDzCzeR1mVulMV/Z0linDaVOfXJl+rh2IgnA2GXTvM0G9nfbMmSoWFW20J48wVKo390qnlzhiLiWOwEPV77jPfWcB04LNhIkw8YH11hZPLx2i3G8zMNDDGEscDWq1GnnTBWstsu8HJkycJgoBwfp65VgsbRaz1u0RRRBiGtJttvLCBVVm8T9ofWqWmHkWicRaXtOmRqd7LefdlYX4227oDLBXZM7QtTbW59VAQBEEQhCo7W/ycguEnEw8j7lxk5v86FdYTF9O4ExT7DQ/WUiGStVnVG9LUWQNJpTEqqjhMcXyVvnb+ROkeFqtcQHnubmQLBzqwaE/hNQKwCdYYtNZurZ6oz3p3A4VBKwh8xeJ8i3YzJI4iYt+wuDCHspYw9AmDgND3USTopI+HQanCt0hrTa/n4kl04OF5Aaur6xw7foKVlVWUduvZxInLzPbYo4d56JFHSIxLEKC15ZJLLmbPnj0sLS6ysLBAHCe02y033rYJqysnaDUDGo0QrRRJHGOsS7wQxTGDwYBut0t/wwMMYRDQarWYm2nhkmcoon6f1ZVlfN9PLUhpcoKS5cem4qcsQpUFk8SVa65SC4geuoZa+3lN5auVRdU7XaTo9gbEcZJeLedOpvJ73uaXWiuL9nFJKJoBfuATNkICz6cf9+lpg9YJQaBYWpyj2+uTxBHWWFrNkF1LiwwGA6IoIkkSdu9eJAw8fD9gdnaG3YstlEnorK3RsxZPOWcabRNnvUkbksSWxLp4JaMUqR8iWa7pvB/cibhfVjsLmco3p7dzDRekGtnUFE4sajKHzvQKpv6g1StQflZVUY5Rl7LyfoVFqORWl9WZu8el2+xo+azSaS3Emftc9dhDtdjpXKoEQRAE4WxjR4ufrVw6xlIaLJT92CvuHjWOu/VhTjVI2I4MmbLf+WxuzYFNXQFU3WfM6zzFcDrcKx1f5QPoYhpe+QrP9wCLSWLigcs25mudJgYAZSxzMzMEnqIbRcRJn6Y/x+NHDqMV+J6L8UjiPg0P57KVxFgUvh+wsdHJhc16dwOtPbrdPt1ejyQxtFozrG90WF9fY2VllfX1DrFJWNq1iz27d9NqNTl48CBLS4vMzc0xO+OC9DORk5gEEkOr1UABcRTR73Xp9/ssLi65rGXWYJOYftR369Ro5YSDUoRhQDSI6Pd7RNGAsBESRTFJllkrdTYqW35y8ZNmzEuSKL/6RX+PXvlGozExJqR4rTBJnGb2SrP82ezzNINa+lpphae91NJl8LRH4IGnDZgISPA9RbPhs7zSx9oEt44PQEIQeMSxE1HK17SbIdrOorXnBKBSBFrTDAJU4gQPSeLEig/K89FYAq3Qtri7XCIMk96FCu3SGKTqIX1CVOH0pdK+rDtDUiuPSVavopSzIBUM1SOnr9TwniPvK5+MaYO1duTzfFv5ffnZ3fpURthMBEExASP2JEEQBGEns6PFz6mYfgrLStnCktZjTY2/7PXcaLbH8lPvWGPryV3XhsXNmO3ljHL5Z5ZyWEplAFayFKjS+6zNWivmZlrE0YCNjR7d7hraKhZ2LxH4iiSK6G6s4c00iPsdOmvLdDbW2TMf8k/f+Tr9XpckSUjihF5nnbnZFkm6wKfFBciDc8+KBjHHTp6g1ZpxV1VpFhaWWNq1h+PHT7KyssLGxgaLC7s4dGA/519wPucfPMieXUskJiaOIxdrEvWxceTcqozB09AKQ5RSdDfWWV9fZ3V1lY2NVeZnZwk8DaGPMg16/T6hp2kEPp5SDPp9fO0RYYmjPokxRFGfOEkzstkiuUEWp1K5RqkQMXEmfmxuKcj2L1+X2dmZkuWhcHfLsr9lQsclGNCATmOIbJpZza3JY9NFZj2tIQyc+5uJUcqglUEp6Hc72CTC96DZDDh58jhhs+nWA0LR7W3gBwFRv+8Er+dBEuMr67Ln9fqsr27Q73bxtYIwwFpL1B1gbOIWvMVl2AuCAKV1mg5cE1lDnBhim8ZJWuMsaJXMAdkv5bTbyNpTm7H181ZZqLciOMsWmLwExTOVX0onklRRrpyZsWIRUtV6i89Ht2UW7Urra64LVHn6S8/5sFxT+fmL6UcQBEHYuexo8aNKjifT7OMkRvVPuxoeOGyx/9bYGkOp4bqhPOSof6zTQJbwoNKy8sBnvGXL8yAMPeKox8bGOtGgTyPwOLh/H+cf2ENnY51jR4/y6NHDfPn/92kwMVG/T7MRcnDPj3L00QdQ1qXI9rTGs31MXCxTaa3lxImjtFptQLGx0eHEiRPMzcUYA4Mo4qGHHuHg+Ye48MKLuOLyK9i3bz8LC0so36PVaKAVHD92hF27l8DTxNGAtZ7LcHPgwAGiKGJtdZWHHnyAu+66i7XVFfr9HkkSoxRcfvGlLO7eRbO56NbzSRKXjQ6IoojHHnuMXYu7sHYecJaZIAjQvscgiul2+3nvjb2DncmCZNB397iCbFHT4R+gEDrpT1n8GGNya4+xKk+xXXXxspX3JhWaxhg63Q2UjRj0IqJoQL/fp9/vE/qaXmedxYUWR44eo9ftY+IEz/OwSczxY8dZX1snGsS0Wy02NrpYY/E9n7mZWbT2aYYNfN/H8zz6/YjZuVlMHBHHA/A1SeSjfQ/leWjt46cLuVqtSSz0egOwBqP0ps+Zc4er8yTWd3kthED2xBZTHeUJgSI7ls1Ll6dfqlMkVZfW4XqLuieUUeNc0rYQc3a03XbiZ/XqFARBEISzmR0ufk7RvWPoN+nyiXXrqid96pfdrP6yu4tbyHGKeuq4uo1JboCyKFW27Jg01ic7K0M1hqK0hGQC/d6AKBowPzfD/L5FGmHIsccf5//7//0sayvLaCzzc236nXUXhB9HeKFm9+IsNukTRwOSAdgkptvtcv/6GmifsNHECwIee+ww+/ftZ3Z2Hjdzbun3exw4cJDzDp7Pnj37ueLKpzM3N49SmkE/whjwQ5eeWpOwsDiHpyye79MMA7CW+753L//wtb/n2PHjbKyvo7XCmgRjEgLfY7bdTgWQ5cSJY6xvrNHd6HD06FGOHDmC1pqlpSXCMOT663+QZrPlLDvWsrq66uJ1PC/PFpe7vjEsJZ3gCRoBxsTOCpa4xUr7/QFxHBHHrl3ZGj4qza6mtU6z23lpvJXG89xvpXxAg1V5/JBSVXEFLnFDFDUJAp84WXL3gVLESUy/32NlZYUwbNAMPdrNBpdd8jQ8zyWzWF1ZYWZmnqXFeWzirEjGwMbaOtbgFov1ArrdHnGU0O/2WF5dZWVlhd3RHnrxgI1+h26vx+p6h/4gAq0JGiGLi7vZvWcf7bk5wkYL3/NJUJSkMRW5oNI7eFvH6oXbZyYkq2KGwiUujamDwkWu8r0wxnUu2za23lKxiWVKddaZGJrsjFd9rYZeC4IgCMJOZUeLnzQSYMp9xrm9cUb/otcJtHYFJ3uyDLu3Zau2D382XC7wQ0yaqQysGyxrDRisMWlXFfEFmdtLEsV4niYIfIyx9Ls92u0WrXaTIAhY31ilt7HGkUceZPnkSQLP4/HHHqHf7bAwN8vuxQM8FA9SlyqLr53rWdTr0NlYw5oEZQ1RbFzCAd9ZTizQbrdQ2rlF7d69m8uvfAYzM7PMzi4wN7/IwoJLYOAG+hCGIaCIEuc2hXEpqpd7XU6cOM7G+gb9fo9+r8fa2hob62v0+z3CIKDX6dJoBITNJrMzbRphSOB7hI0Qz9Mkg4gwCNi7dy9x7GJqZmdnWVtb5eTJk8SJodFosLq6SqPRIGw08MMG1loGUZLGV2j8MGR1dRVrLY1GSKvVxERdtKdc2u/UknPi+PFiAK0UntYMosi5iAGDaECz0XRXyVqsMSTG0AgbdDZ6mMTSaDTo9wd4nkcYBvi+T7/fJ4oGBGGAl2Zp63TX0/Y03DXQGs/32FhfJ2nFDPp9NjbWXFprpfG9gJl2m1YzpN/tgLU0G02U8gg8D5NYwC2CG4YhJrEk8wlL8RL7+/tptBr0Bn02eh02el0OKE2n23OLuKJAaRdThcXX4GnQSjGIEucGpxSeH6A8D08HGGvpdDooDF6aICEThNlzN2wp2wqjQKHzDHlB4NPvD0iSBM/TeJ77StXaWXziOK7sP/4Y41NXZ9d4OIZrq3bmbqu5hXvTwtV2VWdByFwuFYVVSU21fosgCIIgnF1su/h52tOexgMPPDCy/U1vehPvf//7ueGGG/j85z9f+eyNb3wjH/zgB7e7KRMoC59ijtMN7rfvj3qddNN5i4YGM+WA42JjNvAZf5zhIOXhAdO4cmkF2NQ1ylr342m/mOVNM2u59VUMKIvva2xs8RRuzR7lY+MYT4OJI/pxnyTq8/jhR7n/vvt4/Mhhnn7FFfR7HUwyoBn6HNi3F5NEeNo616UkptddJx70XFyJSfA9t6LlwtwcMdCPYgaDPktLS+xa2s2ePfs4//zzOXTRxczPL6K0B2iCoEEUJySJswu4AallbX2Vfq9H1O/R7a7SWV/jkYcf4uSJE3S7XZaWltx6PkFAI3QDdG1hcXGehYUFFhcWaDQClIIwCPC1R6/VYXZ2hla7TZIkRFHEYDDgoYceRml37JmZGVZXV5lfWKDb77PR6TKIIqLILezn+c6qdfz4cQDaM23m52dp+oqw4ee3qlKKEydPoHAJJXzfRynFYDDIkx50uy59tO/5GGtIkoR+v0+z0WJtZZ04SgjTtZKUUgRBSBD4RFFEt7tBs9nE993Xwtr6Cl5qqWo0QtrtGcIwoNft4nkeJkkY9LokTnkQBCGzM20Cz2Mw6DHoR2As7fYMJjFEUUwUJVhjaYQNjHWxPc2gydzcAt1Bl0AZZrw2XujTbrXp9vtEUUwcJ3R6fQIvXXwWg69I78vEDcy1h6ddP/m+JjHGxSxZ46xcaQbAcc9KebJg84cVjDKAdZY87fK+GZOgFDSbfip4soVHT2VyZmjLhGQWmzXSWeumsI5P/L4qbU9FkOdNY38WBEEQhLOLbRc/X/nKV0iSYrXmb33rW/zYj/0Yr3rVq/Jtr3/963n3u9+dv2+366/OW+VUgm8nWH6gdoDwaaGSpjb3m6lsHx6ebJbUYHgV+HGvgdylyv0kWBKs8Ql9H9/z8QONVh79XpcoGqAxLM7vIvY9rDH4SrN79yL+/n3c9717uOs7/8Q//dNd7Nu/l8ePPI5JYvbv28MLrn8ejzx0H1FkaDYC9u/bSzzoE5kIm8R4NmF9ZQWsod1sEPgejbCB9TR+c4ajJ07y2JEjrK6vc/31P8jzn/98Dh26kDBssLbRRSmX/tqiiKI+vUHE7MwcSnn0en1OnDjB9+5/gAcfeICTx4+xsDCDVtDdWAdrWVhYoNFoADA7P8fs7AzNZpP2ZU0uuOAg8/Pz+J7myJHDedxLksQMIpdh7u6772FpaYlLL72UP/zDP2Jp125+4Ad+gCuuuALf92k0Glxw0SHuvvtevvw3f8P6esdZVJot/MAF/Wfljp84TrMRcsMPvYBmI8DzPBSKOIk4+vgxOp0NsiCPY8eOEQYNksTg+x6BHxJFEQfPO59Wy1mAooFLnOBfFBBHhvX1DdrtNt3uBp1OF2Ms559/HhsbG3i+dgvTDgbs2ftM2u0Wa2urdDod9u7dx/LKMidPnKA902Zubo5Wo8ns7KyLxUExiPrQaGKTmJWTJ3j04Ue54IILOHF8mdXVdVZWVnn88WM84xnPYGO9Q7/vYouWlnbz8KMPowOPRjPEDzyiyMUQ+X5AGIT4jSY2iYj6XRQQzgREvR4KRRAEBI0QiyY2EUnsssI1Gz7JIHbJMZIoFzqV2CntbCRlN7VJKKDb79OPYhYWFly8V+pqaK2l2WyyvLzshLdS9YSCLVz26nyfbTmvYkFj0aft+0xifgRBEISdy7aLn71791be/9qv/RqXXnopP/RDP5Rva7fbHDhwYLsPXYtJCQ8Knvw/7MqaSpqDcckEsriL7WyeUopOZ50wDGm1WjSCAKUsUb+PWwzTgAHPU8SDPkk8YHZ+jlYQELRbbGysceTwY3zm039BGIb0ui61dGdjncsv+wGOH3mUjY0Veg1NuxGyvrLMxtoqgYJvf/MfOH7iGAtzszT8gEbDxeN0u1201gTaxw8aLCwtcmxlnfn5Bc674BDXPPOZPOMZ30c0iBgMIvr9NeYXd+H7AZ4fYNGsr63z4IP3MxjEHDt2jHvvvZdBP2Z+aQlrDO2ZlhM6JkHPzOIHAbOzszRDt07PwsIC7XaLbrfjXKWCgCiJWVvrcuLkCuc1GszOztJqtZiZmUHpu1DKS2N8PL75rW/z7GufSy+K2ej16fdX0Vrz+NFljh47yfLyKnff+z0narQmTgydTofFxUXm5+fpbKyTxBFXPf1Kdu9ZIAydVafX6/Lo4SN861vfTC08Md/4xte55JLLCMOAdrvF0tJu1tdXufHGl3DBBeczOzsD2nMDfs9HGYtBkRjL737w91hZXmF2bo5GI6TT6aA9xdzcLAcOHGBmpsU1V1+N9rSLL8Ljnnv+CWstu3btYmZ2nu/dey/3338fSimazRaeH2Biy3Oeey0XPe1prCyvkSQJl1x+GUHQoNfrc+/d9xGEIRdfdgVBEKZC0vKMa64mbAb4gYdSFs8L3HkOItbXO/zn//Ln7N+/nz179zE3v0B/fYPl9Q2U54FWxNZy4sQy/ShyC6QqjVIe1kCj2aTdbtFut5mdnSUIGuncgs3jqRqNBqpGVF0Y+gRhQOBrly0vicAamo0GJolQGAJf4/s+0ZDb24QnsbbXbRbfVKfOU5sc2rxGh4ifrdBYNk/DMT3TLJ4wjWfiNEmDtJ6mbH2rp/Lql903H9Yue3KtvpWyPbundtmZxf21yyZTWH/DMKhddmPQr1324PkHa5edOfFo7bIAc7OLtcsO4vpDzsWlhdplYxNtXSjlvAOt2mWjOl/fKb72ti6U0u2crF02nmISyxsMapdFzdWvtzmFJ1NS/5kz03hbqa3rVbr+sU9rzM9gMOCjH/0ot912W8Xi8LGPfYyPfvSjHDhwgJe97GW8/e1vPyXrT22XjjH7lX87tnegMBUVC0+xzs+4c9vKnS6z+tRKcf3/Z+/Pg2xLz/Je8PcNa9zzzjnPXHOVVKUBCSFGCQkkgd3GqH2v2r7RYK6ta3fjbht3Y3OvHYQwEUQYx22MOwLudbgxjja32xP4utsWIGzAtIUACU0lqYZTw5ky8+Sw572mb+g/1s48p06dqsojJKDEfiJ25tprv3utlbnXWvt7vvd9n4e6H0ZrjfeOoqiJR7lQGQsDjZCSMNBsbqwj8BRFxqd+7/fI5lOGowGDo0NMVXLhwnmG8xmT4QCw9DttQqWo8pzB4SHPP/8cRTZHivqLucwLvLVEQVAruylNGEaAIk1T0jRFCkkYpzywfobe6ir9lTVa7RbWOJrN1oIQ5Ozs7FAUBZPpjOlsTp4XDIYjkiTGGEscR3Q6bRwS7wSBjtjY2MA7SxTFdR9PoAnDgJV+nySOEUIwm02JwprolGXJLMsoyxLnBWVlEKogDCOOjoYIqdBBiNCaS/c/QK/XI88LhsMxK6srtFotjHVU1lJZh/WeJK4lvCWWRtrCGIeUmiCMUVqTlxVeaCrjcM5jnKDT66ODCFU5dBCzvrGNFxLr6ht1aSxHgzGHgyHd3gpRnJLlBdILyjxDCEmStljpd1EqIC8qPFM8LbQOGI2HeARntjVXrlzn0qX7WVtfI4ljQBDFDZqNBt1uF60DWo0mN65d44UXXsB7wTd/27fye7/zKd7yljdRFhn/6T/9J65ev84HP/hf0Wq1KUuD0Ip//9FfJkqSRalezsHhERcunuOxxx7h7LmzCDyz2Yw0TkjiBO9Aq5qaaCFQeCpTkkaaME4ojWE0nVDmM7a2t4niBKk1XkiiMK0lzLlVNmZMtRCBEHWpYxieuvcuDEKUDijLEiklxhiEEIRhyGQyIcuyWt1PylOKo7jb6M9rpZ7Ea2aoxaI37ytuRnq83z/KDPkSSyyxxBJL/AHxVSU/v/RLv8RwOOT7v//7T9b9+T//57lw4QLb29t89rOf5W/9rb/FU089xb/5N//mFbdzXGZ0jPF4DLBo6H2NwYK/Qyp2MSF613f9EVmX32kculi5WH8bFXqFfp87n9+NIL3Sa8cDOK0DvHUYU5e/xWFAmiQ4WzGZjCnyjPl8xvDoiCsvPkeaxNy8ucu1q1dYX1uh1WiwU5ZMRiMCLZiORlhToqUgUIrxcFSbnAZ1mVRtLNqi0WiC97UKWBjT6nQ5s71Np92mrAp6/TXWt8/QbLWJkgSlNdZ6RqNxTXgmE3b2bjKfz5nOZsyzHGs9lalwztQD9FaTfr/HLMtRUpEkCSv9FZy3dNu9hSCCQylNu9U8KQVsNFuUeUFelFRVhXUQRjFBGOEBYxxaa9Jmi7KqUEEIQiCVroezsi7Z0kGI88ey1gLnPVlWIKSuS6WShLPnzzIcj5BaU80tZVGSlxVCaKyzWOsQQtHvrxJGCbN5jnWetNEiXpTORVGEVAEOyWQyY5bltK2nKAyBDjn2cAmkBKF44MFHyIuKwWDI6toG586e4cbODZyzKB0yywrGkyndXp9GI8AYSxQlBGGMkApjHIHSKCGJggiEwJYVVVkymUyZzjJu3LjB4eERWZ6DVFTG0e51scDl559nlmVYW6v1BUlIZ6VH0myyvbXBPMtRQYB1jvlsTrvVot1q0e20SdOUg4Mj4iQmigKKfM7R/k1uXLvO9vYmcaiRSpFXi/4bFuVtQr1MKhzq3iFxipml42tIeOpeuYUv0jHR8c7VfWVlhbOWOI5fe3vUctz19f1a96CXmpm+0vZu/X5t+nVa0nfi9bUkP0ssscQSS7yO8VUlP//kn/wTPvCBD7C9fSvl+uEPf/hk+fHHH2dra4v3vOc9XL58mfvvv/+u2/mJn/gJPvKRj7xsveS1pZ9fVtzmb9XMv7SMw9+2/IeLY5ntW4Ox+hiOVZuOl28Xnz7GK/X73K3P526xx7PUSsbUZpj1XmplL8lkPGV35wZXX3yenevX2d+/SbfX5K1vfhPTScx8NsWv9Oh02nVmaD6DSHP96lWqoqSZNugvys3azRZhqOn3+6yvb7K+vk673SLP8np4KgNWVjd5+JE3srG2xnQ+od3p0e2vMM8LJtMpOgzxHq5cucLu7i5HR0c4aoJcq30ptA6Jk0adtQoDmo02m5ubjKYTGo0G7VabUEdYa1nprRIEAWVZoLXGOcNgOKQoC86fO8fuzg7RPKrlo3VAu9slaTTI8xzr3IK4nOfm/gHeQ1UZBsMRvbWMMI5pdTpY5xmMxqSNJlJphFTM5hnzLEdqzZlWizc+8QTPvfACR0dHTOYZ08m4Jj9S46yriVcY0l9ZJ4obVOaIeTYHoWk028RxssjiKZKkyXSWM5/nGOOojK17t6QCLyjKislkztvf8U4m0zmHR5/iwsX7ec+738XzL77Azs4NhoMjEIrDoyGtdo8wTpEIgjAhL0pAoKWkLAo21tbYWNsgimMqa9hYW2NwNMJ5CKOI8+fPo4OQ0licEKxtbvDEW9/Mzq/8KsPJFB2ErK5v0Gh3mOcFo+mEN2+9mTRtEGjNeDhiPB6zurrK6kqftdUVtNbs7uzSajbQwGwy4soLl3nq6Wd57LGHiSONRzIYT5HhjDBMiOK47uNK08Vn7V4iUhFF9ef8mtfrInsnEVhjiYJaCa8qSqIgpCpKjDGYsiSNT1FicZzMOUWa6NQlb7fd5151e/dKZPwf2RzREkssscQSS3xF8FUjPy+++CIf+9jHXjWjA/COd7wDgGefffYVyc+P/MiP8EM/9EMnz8fjMefOnfvKHewJ+fnj+a1+Owm610K/VyM+AI8+8giD4YDBYIB3hieeeJBnn36BT33qU3zm05/ixtUrvPHxR9je3OTMmS0mkwFFVtBIYs6e2SKfP0QYaoSzbG6skcYhq/0uvU6Xc1vbKKXodrusr/R5+OGHca42vRyNRiRxA60DEAVFVXHt+i5ZXiJUQKPTo7OyysbGJk9+4UscHB5yNBzw4pWrGFuRpinGGIbDIUfDIevr66SNlEazydmzZzl34TxVVeGcO5E3TloRQRCSxg0aSZvpZM7h0VFNZIzl4oUL7Ozu8cLzz1MWJdtb22RFSV4UNNKUXq9HEARoHZHntfFppzshCGMQqs7QeI/1EEdJ3c9SVuxdv8H6+jqVsYRRwubWGc6cPyDLMpxzdDo9ts+eZXf/gP2DQ7yvSYYOY6QKwSza4WVAGAV0e6scDcZkeUWchCRpm1arhdYaay3rG9sYC3lhMVYgVYSQmkBHOOvJszm7Nw9J0xa9/hpJ2uLKlatU1tNotInjEbP5LnGccuXqDjpIaDQ7nDt3jp2d6zz3/BV63Q5nzpzhyc89yYP3P8CZM2dpdTrc3D/g4//ld2g2m1y8dB8bW9s4ofAIoqRBmKRMZhnv+MZv4pnnr3A0mrJ7cx8ZRTTnbYrdkslsjDEVW5ubCOtIwpitrS2cMQRKs3djhyzLmAyHBFIQpgmT0ZCjmzcZHt6k10rZWO2DUkRJzOa5+zCWhdpcTXSyLHvJtXBcpnaqa0oKtFQEQcTBwQGtVl07vbu7yyOPPMxwOCRbKOLdw5V6D7Gn3NxX+Ha2JD1LLLHEEkt8LeCrRn5+7ud+jvX1db77u7/7VeM+/elPA7C1tfWKMbXPSPSy9WJhxvlq8LiXDgJeUvd2u+Tzq27mq4rTlqndOZ55LWJzt+d3Lr/wwgt0ul22t7cpi4xnnnmR5597niiKeO9730sSBvRXOrWstZJ85/vew+DwEG9LJuMx8kEW3j1t+o8/jnMGrGVlpYcWMBoOqaqCdqvF9tbWSW/XYDBgOJ6wurHOQ488xtkz2zz2yANsbp2pFcamc27cuMF/+fgnODgaMhrXimPWQaORUJWWJEl5+KENmp26VE0HAVFc9+hYa5AStA4Igrq87PzFc9y8ecDOzi7O7rOxcYZnn3ue/YN9wkDz0EMPUllLXpaUZUFelgxGY/JsTqfdJooTAleXMjnvcV5grEcpxcrqCpWx5EXJn/uv/2u0DsiKki8+9TST6Yy00eTpyy8wm89pdXt8+3veW4sbzOcnWaUoTnn4kcd4/Ik3kcQRg6MxT19+jjzLqIwhDAKkUvRW13ii3cE6d2JsWjfrC/IiBw95npM0mngpQWkGR2OUDFCyNj9ttbuUZcGDDz1Cs9Vhd/cGQRiTNlqkjVZ9LA8/hrGG/spa/beHMUJq8qKq+4iE5LHHHsPZkjRJ6Hd67N884J3v/AbW1tZotJp0jOF/+sf/Dx574+OcvXCRZrvD4dGQ1c0tLtx/H9O8xHzhC1g8Ooqx3jKezLhy9RoPPfAQzjrajQa9dpvnnnkWE1VYY0jimItvegJjDEFU+wqd3dri6OiANIlRwuOxxJHi2WeeQekIHYSE4a3HsfJbXeZoX/FavBNK1aVzO7vXmU6ntNrN2gdJQZbN0YGkqVLCKHzN+xOA96dv0jy1hL6H2gPtNfqDWNwjX2u/HG/v9t9LLLHEEkss8frDV4X8OOf4uZ/7Ob7v+77vxDME4PLly/zCL/wC3/Vd38XKygqf/exn+Rt/42/wrd/6rTzxxBP3vqPTKB6cru7tjxVesXenLri/tXj7uuP3vHRDi4XbfYwWggqL9+lAIyU4bzCmIgpDer0uYaBZ6XVReBpprWJVljmDgwMGR4eAI9CK9bVV9nZ3cN6iZe1JM88zVuQqQRjixaIkTQqyPKPX75KmKULCt3zbt9But2g0GuhA88WnnuGZy8/iPVhjmM6mDAYj0kaTKE5AaoSQdLptWq0madogSRPiJK6lrpUiDEMazQZSS6y15HnO/sEhg+GA1Y0NRuMxL754har0PPTQI4seIkslIE4SrDUURcF8NmVvbw9rLcZaEIIwinDeLjx6annwqqpQSmGt4/Ofe5Jf/43fwDnL297+dra2toiThPF4SmUtcRrjha9LrOKEJI0WUuK1qezKarfOVC36vObZlMFALk5zgZGC+WhElMSoOKYsC44GAwKlycMMvKfIS6I4YDbNUEoihMc5z97OLhINCIwxtFttiqJgPK5LyipTEQQapSWVqRiOh9z34CXSJEUpSV4U3Ny/SZwm9Fb6BFpxODyiv9rn+rUXyMo5pc0xruJd7/o2gsXxtVpNLlw8TxiFTMYTytIQhDF5lrO1sYVzAqUCjHOsrHRxpkB6w0q/R1HmNJL6XMnzjEv3XWI6nlCUOd44EILBcEAYR2T5HHB4b5nPpiglQEpQAbEOEFrXJFOKE9ENhERJgVYS72uC7O+aYRW3ra1L3eZZxlNfepo0TVhbXSMKA5qNBru7N5jNJgQ6QGsFLxFvErfyyy8hRY7TKb6dXuLF4+tGIuER/vh+d2sdi3V+8frLNeRuK7k9oUh+cbTLFNASSyyxxBKvX3xVyM/HPvYxrly5wg/8wA+8ZH0YhnzsYx/jp37qp5jNZpw7d44PfvCD/J2/83e+vB19GZVqt/GHl7z5XjZzanW+UzUw39rore36kwEHcIuseF4yaLo9eXVnIuslT+8Sc7wchBovLJUpMLakkSas9LuEWtNqpOSzKWWeIYWnynN2r1/Dmoog1CRhk0Yac92WOG/xXmKsZZ7nlMZQeYeTAhUGRI2UOI0Ik4g4jWmLNmubK0zGY7JixngyZDQc89wLz+GdX7jI15mVuNFA6xAHaKWJG0mtypYkiyZ2QRTVUtdSSowzzEdTGo0GlfHs7R9w7dp1nnjTW5nNcobDMfmCJOhAgQDnLGVZYJ3FeYexhqLI0YEm9hFRHKG0whQlxlQ4Z7FuYSAax8ymM55+6ml+5aMfpdVqc+nSfdx///1snz3DdDrnaDhgLY0pypL5fE4QBkghSJJwkfmB9bUeRVE3y1dVRZpGCOGIw4gwCGoCObVEkUIKiZKOMJBoKQCL8xYwRGGMCSUSi61qQQFrS6yr8B6MMYxG9Wc+z+YYV9JopnhhCSJF0ohImzHdXoder0dlKvI8Y5ZP6fb7rG1v4EzFtJjR6jVIRhFeWQqbEaUBDzx8Hzt7BxhXkiZtHnroAYwVdcZoPqcTxBSznCRtsbm6gas81nqU8jibIYWl02lSlhlJGJBlhpkxdNsdBoNDSlOLdMzyGVmZUbqKrMgRStBstXCuVsdTC73fNAqxKKQUaAHKO6SD6XxOWZUEQUC326Uypu6BEYLa81RgnVusq7MzWqpaea90HO0PiLZroRABaCn41Oc/Q7PZXOw/4KGHHsYLgfe3Ljy3uJa9uDWRIbnLPM3LbxK88v3kLu8Ux2RJLPZVC8Tc7il0cgQnhEiAcCfk6Pb9HosyLKnPEkssscQSr2d8VcjPd37nd961kfbcuXP8xm/8xldsP6eZB31VsdmXTXaejtXI19Rz97Wzuz89Ozue3b99G7ee+5NBy51HeOcQ5c7juHOr4mQ9IDzGFCjrQWiEFlhbohQIbyiyKaOjA6bjI1a6XQIlCaXg0kMPkJcZ4KmqgtHwCKkgSiJkoFDZnMxUTLKcME1ZXV3h3KVzbJ/dYDAckGUzUI7PffEzXH7mWfI8p5E2eMub3kKU6EX/haIqDRtbZ9Fhgg4Tojil0+kwHI/orq7X3jRZdlujf0JVVXzyE7/NM888w7d8y7cQRRFHRzOGwzmzWYXWCZ1uHzmZMBqPyfI5RZljreFLzzyFwxEnIVK22D67DTd2UKpLksTkZU5ZFURxiAwk0kvGszGdToeDvZuUWc7m6ibj6YSjw0PmszkCaDZj4sYGSmt0oAkCjVCK4dHBQtJbcLB/QKcTYcv0RHms2WwzHA5pNlICrZnOZzRThQ4DojAkiRO+vvMm5tMZeVHLcFelYX1jlfFoQhAERHHIfJrxljc9SlkalArotDscHBxijMHjsc4yHk+YZUM6vS6PPfEQG2dXMcYiAl9nAuMNJpMJeVmwdX4LgaPIRiSJ44n1x6iKOnN47v4tDqf7hA0FXlKaOe1WgzBMyHPDdJJxuLuHDptkw9pgNZUhZWXwtkIKUNrjqgzhKwaDPcqypCgKdnYU4/GUIAhJkpjBdMD69haTyYQgCun2+rz969dYW99gc3OTMAw5PBowGBaYPEeHGpUmaAF4w9NPfpbrN27QW+nzrd/6rWgpkVKDlGR5iZSKeVZgrCOMEvCeIA5IgggtYs6eucj6Ro9Ou42WgvFwn3/xv/w/ee9738uVF69y/cYu/8P/8KN4FF7ImgQJCcLh5KLcTDiEgEBIXm6hctuV6wW3ys1e7S5wa90xyfGIxa2o3sHtywgWKnfitvvf8fIi/vjuJBdk6TTGrUssscQSSyzxxxRfVbW3JU6HU9fxv4xInVIi6q47rd+vI42XUNmS+XTCjaMjsvGYQEpaaUo7TdlaWyMKNFVVoLzjyc99ljNntmg0G4Rpwjd+4zdQVRXXrl5hMp5S5iVvePBRHrv/YbSWlFXBc196hk/9/icZDA/I8wyBp9fpkE0ngMAZw9NPP0232yXQIUlSCwz01jaorEIGEUGUkEYxcbNFkeVUJieIIvZ29/jXv/iLvPUtb+Wd73wnK2tb3Lh+k7RRG4TGUROlY4rcsr9/xNWr16mqgul0ShSFdLsdnHOEkSaKWwRBwGw6ZTqd1iVfeUaezZmFmkajgXeWINBorQiCAHCsb6yzublJnMR87snPs7a2xupqnzgKORoOWN/aYJbNGI8HjEYjiiJDSGikCWmS0EgDZpMpoZZUlSGbZxTZhEYjZTw6YDarj+fSpfsQApwrGQ4nfOYzv7sw7QxIF6IM+zd3UEpjbU5R1D1BB4cznBFIJOPBkKqqCOJa8a4sy5oAupL5bMw8y9jZuUGr3aQymuHkkMpUGGNotJqMxod4b5DCcrA7RatFQtILpA4QHsrS4RxoqVlfW2EynCFsSSNWbD98P5UVNJIGQkgq4wh1TJyGWF9gXIF1BdPpjDRNCIMIpfSiRwfGozFlWdLr9RgOx/Q6fXqdPhfPX+LoaECsQsp5TjUvqaYFEY6NjVUQdclfr99h72Afn8+w2RgzUzz7xc/zxscfJ04DitLgFVS2ot2I8Sis9ZSlYXw0JIkSmknKWx5/I0oaQiw2m+OLGS/+/m+j3vVNJKEgVqCxOATe15aXThxTEgeLx0u7+u56oX6Z1/sd0x4nHkFykcxZLN8t9i7Hc0uOe4klllhiiSVev1iSn686TjdiuBfPnrvj7gOjl7795TFJVEtcO1sRRSFxHBMrhRIQKolSgrIsaTUbpGnMbDLi6pUXaLUaeBxpmrB1ZoswCOr5YQMUjmKU8anP/RYHB/sMhwOmszHGG4JQEwgoyoKj7IhARnS7XVZWV4mThAsXLtUywlLRbDQpvSeKI4zzZLMpo6NDGs0mzz7zFFmWsX32DOura6ytrtDptEjjiFArbu7tsnPjOkmSMBwe4Z0F70jimF6vBziiKKLf7y8kjiWNRmORDalLwwCOjo4AiKOQIEjodrtYU50oyTnnmM/nZFmG955Ws0Wr1STQmizLFgQrItCa0XAIeLa3tpjNJnhnaaQJcRgiEIRCkCYpeEdZFjhTEcUhpteiLLtkWUaz2ah9mOIEYyz/5bf+M5sbm7Q7bdrNBv1uFy0lSZKC91hrkVJTVQ4tYpSMUFLVsuGBQiqJ857JbES4MJyNOiHtZqPet60oqxJjK5SUNLttjo4OEUC/06UYz1Gi7oMxVUVRVbQbLaxzVFVFVVakSUrgBI0oxHlPqxFTVBVKFLV4gFTMpgcUcw1IjHHM5ln9OeAo3Yw8L8izjHa7i/cQEGLmhulgRigiqqpiMBhQliXxRkw2zJjNZ5RlQRKFuDwkyzMGwyGD/RDjLGfWV9ha69Ht9UAKytkYU8zxXtSZqmy28GISlKWh1erSTWJcZbHFlE4ak2dzylmGMTnKlYhAkk9G5OMBJp8QeItF4EUtbOAX/TXO+4XQQJ3NUXcjHC+5bfiXLvvj2LvfH8RtJbe3Z4xfkj1eTIDc6gF8dQi35D5LLLHEEku8/rEkP18l3C4wcK/ZmVciPMcePnfGvZba253ras+gWvHOO4f1FmctWtWZjCiKEM7iTVULAMymdemSjomimqz0u126vS5pIyFQitl0QpnlVPOCcpgzORyys3uDyaQuLTPOEMYBYRAilURpyMqSKE1pJC06zR6dbpdeZ5Vs4SMTxynjo0PiNMAYw3w2ZzQYsLGxhsBhqhKJJw5DtJJURc54PKQscpQUKAmyLvpBSYExNYk7f+4cCE8YhjSbTaIoIgzr3puiKKjK2tQ0CAJWV1cpigJrDVmWkWUZtirRWtekJggoypIwDNna2uLNb3kLq+srXLhwgTCKMNaQhClFUVAWBd45tJIUec58OsHkKRMhONzfx5mKJI5RSuKdZTg4IooDwihCSklZGo6CQ4IwYnNzi1a7TbvVIQojIh0TLh5p7AiDEOc8AkNVWeIwRRCiVUQUhhR5hXUWqRVhoDAmoTIlwgu0kCiliLTGO0OoVU2EtaQVRxRRCEASxohAEagQIyoKV2DKjCRqI2RNiMqywNiKTruD964uBwXiRFMWBUp5olhjTa1MpmSAdQpTOdrt1sI7qUKhSMKEOKp9c7yvPak2VtfqnikE3Va7lpe2Fm8tWgiCOMZWJcV8SlHkmDJjPh3U/T3CI7Umm46Z5zmDw0OQEqkCWu0eDkGj0SYIIlSoCaXAmQpvDMJalNeECnAepSVBp8V7vuM9nNlaJwwUzTRFLRTXvPcLAnQsb3CrJdDfTkJeE6e7n9ytRPbEpPQu0a+9b3Hy88vMNf/Jwh0muq8cdvr/pr+Hf7y4B5p6uvNuEXsPx3svsUkYnjp2Nh+cOnb6zCdPHbvy9d9y+thu59SxzWZ66tjpbWbur4Xx0eGpY6MweO2gBdJ7UegH4tbp/77hwfTUsUFlTh07GZ/+f2Hv4bws8tN/HlmWnzo2TU5/fbaj9VPHitN/zMzL7LWDFrBy5dSxgT79+SBfXuv9ijiNJ52+Bz+Gr3nycy834D+qb/U73eZvX3/78p3mpXeLeaXt37l8/LOsKoyt8M6eZHrCMMRXFUVVYsuSLJuTZXOiQJOmKffff4mtrU263Q5RHPDCi89z+fJl9nf3GO4dMrpxRCtsECe1UECz2wcFpSkQojbbTBoxUs7RQUSoI+IwZbW/iUTjbVUPQkXAZDhFKo2xliKbc3iwT7fTpNtugfc0Gyl4iykLRoMjbu7tMJtOWel3Wen1iKKIXqeNlAKzkNzu9Tr4hbdLHNeELk0S8nxOnucURYFzdWbo4YcfZn9/n5t7e+zv1+pvoVasra2dEKfhcEyr3eahhx9iY3OLMNT0VlaobFkTDCGYjidgHbPZhMP9PYytOLi5R7fVoSoKPv3pT6EQSCGIF5mo5y4/Q6PVoNfrEccp1nrSJKW/soryAa20zaMPPYa1EMcxSdTCOYV3IXlWD7itFUwmOSv9FsZ4nCqJAoXznmyeUxlFGAY44yjzgkApXAVZPsXbJlkxR0iJ1rImEYFGOoeznuloRjUPkHGIqSRV6XHGYW2IcCBE3XM0Ptij3e4RxQHOW0bDIWkSY2wJElQgiNKQMGgQ6gbeaZQM2N5eZzrNKMsK7z3NZpM8LynLxaMoOHP2DAcHh1hr2NxcIUlSrl69ShQpms0OURSxv7dHUeR4Z4njiPl8wmQ0qs9vb/FI8rLAI0FKlA7odFdYXdug1WzTSBKU0hS5YTodIz1EQYApc8JIoWSIkpoobvJX/8qHqYqK4XBCnhuEAOXr4ja/eLAgQR6BF4Lbr8g7xOxve/5KN6fTZZXvvHfcbRLlNNu5l/glllhiiSWW+OOIr3nyc1oIcbqSjtN/8d+uoHTvxSJfLqk5dcyJ7PUteO8pshxXVHhTgTWsdbuc2ax7fpI45Mz2OoOjfa5fvcIXPj9gNBry4rUXSZKYZpyyvb3Fo5ceppxlDIdDyqqksCVplJLPJ2T5HB1oVtfX2N46y/5gAEjSpMHa6gaT2YzxeI5Smn53naODugm/02qileDJz36GF59/gWtXrpBlGb1um0gp+r0OmxvrrK30mU0n9LsdGknM6uoK/c47aLSaHO4fUFY10YvTBrPZjLIsa6nqRflaVVVEUUS73SYIApSqhRTCMKAsS27evIkSoHVNBJMkIc8z0iglikJWVnrEcUzlLEEQEghfm6g6gwDm0zk3blxDK0GZ5YTdPlGcEKv6UlRAKFUtG24122vnaTZbgGCW5Txw3xsIo5jZxPDcM9d525u/gZsHI4xxgGQ2Fnz600+jgoAoignDCOdAyooolAgqxpMJcRwjlOfo6HBRmhfQajeZjMZ472vDz4Ykn5aLHiPLzvVreO/pdjuAYjwpWFm7n2kYUoukhTRaHcZZyXPPXcaYkn6/h7Elh6NrhKEC4RiNBqytr2BtxXQ6YTQa0Wo3OLN9jmpyRFEYtA54cfc6+/v7GGOIoohknJCmcV1uiEOlir3hDWQoKfKMo6ObdNodLj5yjqIoMFVFqEMuXDrPlSvXaknvqmJlfQ0hBPuH+1jvOHvuAgiorMM6j7GObF4SJgl4xTzLiKKEyhriJKEqSuZ5jjGCpo7J5jOMyYlixZvf8lYuP/Mc3d4aOkiYzS0IXT9QIGR9rxG+riOTCy8e73m5f85xjgheRn5OenbujpP2ntfAnyQi85u/+Zv85E/+JJ/85CfZ2dnhF3/xF/me7/mek9e///u/n5//+Z9/yXve97738dGPfvQP+UiXWGKJJZb4auJPBPk5zRe859Rib/ey54XJ4atv+LT9PreXvb2acelr7UOIxeyz8AtlNYH3deYn3doiCUO0qGWBu82ERhziTEVV5kzGQ/7Vv/h/cXBwEyUFnU6b+++/j8OjA8bjAbmeEa1rnHaY0DIr52TzjLCaYJwl7aRsbG7xhsffiHeQfeFLNFstOr0eKtCEQczwcABCcvbsBY4OjrC+orvSQWmJNRWNNOHcubO1IIEUFHnGww89SLvVJgwCHnzwAR57+GF0GDCbThiPxsRJRJ5nNBopUZJwY+8mcZKilDrxooqiiFarRSNJqMqSNE155plnaLfbtNsdLly4wHQ6ZTIaMp1OOTg4WBjwxmR5ThxL0rTBZFr7zFjnmOdzbt7c4w1veBRTFfR7HeJIMR2Nke023VYLW1asdvvcvLlLqAJsUWKp2FzfqEu6lCaOU3or6zQbbba3zzIYjTk4OmIyM7RbLbLcMMsqDg9G/I//t/87Ogipm9kFUZySlxPyfIQUhrXVLn/7R/42URTz8U/8//jlX/ll4jjmb/6Nv8ED99/Hs888w8/+7P9MqEO2Njd529vfzmOPPka3WfFv/+2/JQgCPIJZUWH1JygdJEnK+toaX/e2t3L23BmuHuxw48Z1pJJsbKzhvaWqakn0KArxScRDD92PHg25fGOX53Z2eWH3kEAFaKVJkoTxeMT6+jqb2xt0ul3+83/+TdrtFt1ujygKmQwmzGZTLl68QNpOUKni4PCQfC+vs6lItAwYTHLSVpOkXfciKS25fuMGz1+7xs39fV7c2ePXf/M3iOKE9Y1NLly4yKVLD7LeXyUvK8rSUlhH6RxpkhDEMThLHGmkMEzzMZWtSevBcIARglmeU04L0rRbewiJAC9ULW8gBFa6EwIkhANbLe4YL7l91HgtdetXeP34mr8963O3+8er3TdeujtxqtKDP66YzWa86U1v4gd+4Af43u/93rvGvP/97+fnfu7nTp7fzVx7iSWWWGKJ1zf+RJCfPyrcKmf58gUPbn/+5ZS9vWo8AlsZnDOARyjFSr9HI1JoKRDeI6zF2jrGe4dzlqPDA7LZDCk8whvms1Vu3rhBZUuStEGz0yAvSypZYWOPVBodh6RRCB5mZsYL11/gjW98gka7AQom8wn7+zfJsorDw0OCIMQZi9aKXrdDHEXMsxn5fI7Ac2ZrE2MtQRhQFSXhwjfHVRVpq0GkQ7Iir2f/A1375DhLVVZIpdC6NkQ97vWRUiJFSpqmpEmCMwatNevr68RxTJbNmU7HCCFotVqEYYiUkiAIaDQUs2lGXuQIqWrxhGaDK1evcPnyZZ69/AztVqP+/1mDROCdQyBQQtb9Ac6DsUgZoIVABgGd/gpWeFACJEgtePryU/TX10CCcZaj4YB+fwUdahpKYlzKLMsIXP1/l1KhBWRlAcpRuYK9wQ55NaO/1qPRSdGhIi9zZllGlpcEUcqlSw/y5OeexNkDLl2cUN0naDXX2dudUOQ5OgqJmikHxU1KKoIw5Ci/gU8K1i9+ANFw7M/2eOqpp1jp96kW/T946HQ7vLh3HRlH6CCgFIrf+cznqXt+FBJBVVUURc5jjz3G29/+Nt60ucHMVPyX//Sf6lIypcizjDNnt/nC5Wd46KGHePNb3gTTMf/T//yz6Cim01uhkTYxmeTB+x/k3LlzbGxsMC9yru/fJHeOqN2ivdLnzMWLjKdTCucYTKckR4eEzRY6iOrPRCms8cyKojbUFWAqA75kZiocnkRrMmtQaYLJSib5nKip8H4hdY3ECYUT4KVceO84hLBIKqS/s8TtWCpfcJIVelnjh7gt7qXrbwkb+Fubu235WA6hNtk9Banx9VbvpUfkjxM+8IEP8IEPfOBVY6IoYnNz8w/piJZYYokllvijwJL8fLUgbv/15Q8WXm1G9g8ieHA8+nHW4vFIWQ9sGmlKpD0Kj3eOPM/qxnDcScO6c4ZAK7wzVEXOZDggm05otJu02imEnslsjBQSpx1CQdDQ9FZ6ZPOM+WzG0889zWNPvJEwqftAJrMxURiTzUvKqkQqjfeOOInpdNooLcjzGd5ZiiwjTRK0DtBBwGwywXpHuTAgVULgnaUqC3CONI7rpn2tUVIgpaLRaBDF8SLztTCwVKIWMghDWKiVdTodtNZYa05IUhiluIVEtDEGKTXOewaHR0ynV+h2OzzUe5iiyDk42Gdvb5ebezfpdFpoLdFSEgUhwjmiIKAwppbWHk/IxRStNWGakLSb6FAjFHjlQDmuXn+RN1dfhxWeypUMp0OiNCFOIoJY0yAmbSUIFSAW5EdogQwkQVirtxXFjLzKiNKQbr/Lytoq+zcPGI5GzPOcMErYPnueT37yM1RHY/YPRozHOWe2thE+ZDQcIoKSlpLsHl1FpgJRSIbzPYaTHd71vm+kvZqiE8EL159jb7BLWRisdSilaA+6DCYTzly4j7Nnz9LqrXDlxi7zeYYEnDWMxyOCIGBalDR7PR587DHaK6s8+fQzTKdj8J6iLPk6/1YO9veZ5BnbF88Tt1s8+dTTTLOctNWi2+5hMtjdv8mb87cQNVOct8yrnO5anzCK6PZ6vOFNb2T/4AjrPGEUYwWMZ1NaLUUUhHgtUE5RFHWTqFJQ5BVSWQpX4p2hcBVWelQcIEKFl2ClAC9O+nvc4oHweFGLIMjbyt3EXQUNvhxJ+9smSk74zh1Kbydk6+WTKnfDKxTgfU3h13/911lfX6fX6/Ht3/7t/PiP/zgrK6dv9l1iiSWWWOKPP77myc8riQncPfireyyvhrtldY7Xw62/47XKTu4Wc2e5XL2v+jUlJUpplBIoWa+cTmuZZWxFMZ+w0mkjtQQP1hnCMKARh3hbYU1FNpmwsbrC429+nLWtdQazIcPxPqYqMMbUPRqxZLXfZBpJsmzM1WvPc+PGVRwGvKSqchrtFAf013pEUYIMJc1WA+csGk0SxTQaDQ5u7tciBQtfmzAMyfMc7xzOWnCeWT6jKsqT3hzhodVqkTaaJM0m86qkMu6l/5dF308UBighmc/nJ9kh7/yJEp4ScDgccnh4iNaafn8F7zxPPfUl/sN/+A/c98D9/NX/w18hTmI2Njfqxn7haTbTmlgZS6fZJJtO6PU6DK3hxrWrvPD8ZYaHR3gcSavBxdFDvOUdb0OHHhU4VARG5IjAUtmSSTZkmg/h0NPt90kbLYyA9bOrDEcTrLUYbxgcHmFdhp/neF8QRYppllMYS9xo0ltd5dq1G7xw9SqPPvYGkJK9m/vs7x+iVcSNnV129vZ49NGHuO+BBxhNZhyNDpneGPPs9S+xdd8mSMimMz5z5Rr/7V/5S1y4eIaj4UP89u98AhBIWRJHKXGcAJLJdM7O7k3Onr3AE0+8mXZ7hSDIcM5iqxKPZG19g+eev0zv9z/H173tHbzjHd/Ev/xXvwhC1dlIZkwmOdeu7zLLCpxXfPi/+0t86Pv+W37lV3+FZ595FmckkQr5L7/9W2TFjP5qm7Nntzl7fovNrQ2UVrz44os89PAlHnvjIxjrMZVF64iyNCRpTbLLyhDHirqUsC5Xm88z0lAjpKEsZwyGGWsb3VrCvBHhHQgMSM1xCSKivs69AKRHYAFb9//cdt3etTzNH5OgU5Kh420cv+PWnMcrbPtPNt7//vfzvd/7vVy6dInLly/z3//3/z0f+MAH+PjHP16rCN4FRVFQ3KbQNR6P/7AOd4klllhiiS8Tr2/ycy/E5nWAuxGbO2v1Twvn3Mn77yRWty+HYUgUBVRlwYsvvkikRD2Lnc052NvhX/+r/zf/17/5f0bjMXmG9JbDg33+4v/+v8FWBU9+7rPMp2M21lZ59snPcf35iK/7ujfBzX3On90mKwrG0wnnOy2uffFJBqMR48kUXRWMD/ewDlZWN1jf2CArJugkwMgKax2TckJm5njZQ2qFEILJZML58+cZj8fkec5gMODSpUsMBgOcc1hrCYJgIURQ937EccxkMiFNU5x3jMdjSu9ottrMZnOUqjNB89mETqdDHAaIhTxxGIZMJnVT/nA4ZG9vj7WVPsPhkPF4TKPR4KGHHqkV7D4fc3h4yNnz50iSmCRJ0FqRZRla1d46Y2up8oJASTrNBnu7e0xGQ970pie4dPE8kQ4QSuC1R3U0IraUdkZlcrypuO+RM1y++iQIRdD0HE2vEbUEh9OMo5kCofibP/JXEFIjhUTIWl0PLxF4irxgNJrQ63YZjjNW17f54P/2f8df/vD/kcHhEUmjhRSK7/4zf4o/9b/500gEUiiUkFzdvcb7/9S38+3f+S0YZ7DCoLuS8XxEnmcYY9AqpBO0cTPHGy49xo/+8N9lMp4hhMZUlqoyWOvJs5I4TghtROIb/ORH/j6/9Vu/RTafYa1lPp8yz3LeeN9jtFotrj59lQfP3c/f/j/9LT72sY/xqU99iiIq2HnuBv10henBlF/5pV/lPe98L9/1rj9NMSiZ7E74/Oc+QyMVVNWc357uMLj5LD/6kR/lwtkNpBSMJyNsfsh6fxtncwaTEYPBgE67R7PRxuYZuXFYD3npaDQaKFWziHZX4VzBrByhqzmdTgtVDhmNJqRJm/52m93dIXEs8DiMFRTW4vCoIMALj/OGoijwlScOQvRikF2WdQ+QDgKU0ggkZVlyi/i8NgHyt5Wy3R4p7ow65b1FC/mS319r+NCHPnSy/Pjjj/PEE09w//338+u//uu85z3vuet7fuInfoKPfOQjf1iHuMQSSyyxxFcAr2vyc09ZnSXuClNVFNkcvOXM5hZBEPDCc1cItGBjY4Pv/u7vpsgzhFY4bzk6uEmz2eBgf49HHn6IBx78s3z03/4izTjmYJ5xuH+T56yjX3k2RMDUVdhZyfzaDmv9Lq1ujzxtUXoQRUGv1yeNA/CGuJkyzUpmxZQoSWn1OxxNhsSHEZ12CyVE7Z+TxPR1LX8tlWQ8HiOUJIyi2kcnDOi220ymirKsannqJCYOQibzOXlZ0l1ZYTSennj7HBwc4GzF5uYmX/riF7n8zNMcHBzyPd/zPQwGA65fv8b1a1d56KGHwDm01njv2dnZIcsyhFDEcczFSxdopAn7+zdxztUlcA89wObWBkGgUaKWs44CTbuRIL3HFAWXzp+nqkoirZFKYKVn4jN8KHAL8hqEMcZZoihBCIUXAiU1RWXxXsCimR4hwcsTBQ9Rq1ugdYMkapNEXZIkBOexcW1OWhUlcRggpUdJR5oEdSmk94tSrLrvSypLmDicA4cijCMSIajCBtY5pJBEMkA5iROSME5oeLUwWq1wHtqtDlIqoigmCmMiXxJqx8WNPlL2EVIwGg6RCMI4qksRg5Dx3g5NAd/4lid47NJ58KACTafdZjgYsLO3Sy8MyAaHvOHSJVb/qz9H9We/mzgxVOUE5x1JmtCJLHZ+iBcCXRWspAJZDvGVIxUFuqVZW22glSLPCkoMzguc8MS6Fm0oTYkClDdEfo4QGZGXyGoMxQiEQSlHJzBUxRCHRguFlgEWT1lMcN6C8MRSI8MIgb+VKXXuRIZdSkmRV0ynU5IkRetXMHPwty++gqfPHSvvNeHzJ+mee99997G6usqzzz77iuTnR37kR/ihH/qhk+fj8Zhz5879YR3iEkssscQSXwZe1+RniXvD3QYu3jqcqZAC0iSpvWGcISAgSWMeeOB+4kDQiEJmE8O1a1dRSnDtyot0Wg067Yd469vfxuH166RaI41HHI45H7VZtRpVeKbzCpMf0euvkQFzAaUUFKMxeAh0SLPZxjlLURXIUKHjEKc8KgoIk7guV4sjHn70UaI4RsZ1+ZHDMzw8Im02UToAVw/7rPd1z4uue5cQgiAKkUVOWZbs7OyQFxWtVovBYMDTTz9FHIWsr6+TZxmHh0ccHR2dKMFlWcZoNKLdbjObTgiCAK01eZ6TZRlhELGy0udtb3sbnU7nREhBa02zmdJoNli0eiDwBFFQZy5lPcDv9Ls4a1CAkBIrwZgIp+SC09QZnEiAlBohZS2bjKAss9v6OkTd0+4XM//HtU6uzgYKLwlEiCtZiC7UxzQ4OiQONVUZ4JXE+7q3RWpqs1gBCIs3BusMznq8E8QiJg1TCOq9I0AKVR8fQBDgkgSBwDmLEIIkTTk42KcRWkJvUCZDSkFTzUjihDhN6MUt0igmShLEQlzA2QlxGNPc7OI3uzUxU4ooDJmvNjm31qYZeoSZcd9Wn0sbHaS0WD8Cn+NxCCkIzAxJbUinTEVbG7LpYU22rEV6hypGdQlcVuKMQ8oAbz1VMcZ5h8fhNEgMqpygqxyRG+xUYKcjqjKjNAV27ihLgRcaqSOCKEErhXAlXniEkugwIC8doBG6zvw458BDWdTZnqqyBFot+Oxx7drtYip39P1xumzx6WnM61Xm4MvHtWvXODw8ZGtr6xVjarXHpSLcEkssscTrCUvy8zWKO8vc7iZ4cDyc0QshAO89VVXRSFOCoCYXcRLR7zRphAFFNuXK1RdRwnPt6lVcmWPzGd/x3d/Nbx3ss9Jq4UrHKpqzjRVUITAzQ2NumFY5Xa/xZUmZlRgB03nB7u4eCMnq5iamLDDW0Ol1iNIGs2LOysY665ub9DtdmmlKcFZjvUMrjZQS6yylsbSCgEAHdSN8VTKazBCyzllU1jGejep+GwRFUfDkl55idW0dpRQ3b97k05/+DKsrPb7pm76JRqNBu93GWkuj0WA8HqOUwntPkiRUZUGaprTb7RPRg0AFbG1u0V9ZqX2CWq06g9NIKcsUY0u8cxhrsNYgpMeUBQqPFAItJc4ZysrWjfFKUTqFqSRSKaQQWOsIwgBrbW2XKReCFV7e9tnC8UC1ljQ/JkMCZwzCgVIBVVXgbIUO6jLH0eEBvhUTh5YwkLgqR4ragFQHEq0ESnnwBmMqvPX4ShMbRxTEi8+jPq+srTMaUgq0rpX1nKsQspZVt7bkxb1nCDodolaTKI0JQ01k9ohck5bs0u9FNJIApT3OOcqiIi8LgoWynFZ15m02n5BNcpSUbLYDnJmBEzQaTYIgJMtGjCcTwhDCSKOk4vDwBnEcY52pM4Xekx8eEYURzlpMZRnOxuR5iakcAkUYJZjSUpQlQgp0oFEalHSY8RHWFFQmZFbNmA9GlDqiiJrMZxWVUSBDVBATJSk6CvESZCBRgUZiKaYBKmwShMnJYHo+z07OL6UUaZosMnz+DsGCu/UKHq89TWrntOmfxXl1yug/bphOpzz77LMnz59//nk+/elP0+/36ff7fOQjH+GDH/wgm5ubXL58mR/+4R/mgQce4H3ve98f4VEvscQSSyzxlcaS/HyN49V8fwSeKI5r80nvmExGpHFEt9PB2pLxZMx8OuaBi1/PfDJmPB4i8GxvbuKrktHwiF//tY9xdOM6tig421+h19+A6wcEBYyPjsinUwIj6UVtmiph5gsCNDIIePHKi+yMhrRX1wiDgLDRoLm6waYXlM6RlwWPvvENJNTyz8Y6Ai05OjpCCVmrr2lFFCdkWUGlTS2VrDU3rl2n1W5jrGHnxg6//Cu/zDvf8Q2cOXuWyho+/7kn+c73n6XVatFut2m1mrTbbaSUxHEtrDAcDhmNRlhrabfbnD9/nqqq2NjYoNftYq2l2WzS6XSYT+dIIemFXWazCS++8DylqfDUJXJKC5IkJgwD4jSm2UwR3iG9R0tFHAU4YzFlhZIaGSQ0iTAegiBACEFVVCRJSJbVWQspBaYsQQjkwijTY/He43392zlXj5E9NNpNwiBGSkVV5lS2RGmwtmRyFDGZHFDNMqJWTLupEdIhlaklzfF4ZwGHUg4pJUpoZAXKlChXm3caZzBFjvW1fLqSAhlAkc+wrgLh0UqwuVKxtakIgoosH1NlBVt9y9HwOjcn1+j3V5kNHJPJBGssUtZkdz7PyfMCELRbHaqqYjqdEUUxrVab4XBEWZZIoTDWMB4foAKHtXmtsOY9N2/u0mw2cc4ipaTValNVVW12a2uiVRUO6yBQEUEQE0YRVWGYzjPcwgRWaZDKk2cTnCsJI42UMBlNkSpAq5jJuACdUFnIC8M8y8lthdQCLzzGOWal5+Jj30SU9EibHfr9Ptvb27Ra7bpPzbnatHWhLCilvKPl59XoyGv0BZ267u31L4jwe7/3e7z73e8+eX5crvZ93/d9/MzP/Ayf/exn+fmf/3mGwyHb29t853d+J3/v7/29Lyuz89UpD7yXz+D0sfdylPcUey/B1pw6NI3uLj5xN7z1bd986li1ff7UsTN3+j9uejQ6dWwUnX5Itr7WPnXsZHzz1LHt9Xs7b4Py6VPHtmbXTh37xd8/fezuzempYw8OTi9KsncwOXXs0aE9daz11aljgyA+deyNqzdOHatXN04d+9/9zf/LqWMfe/iNp44tq9P/H07zXaXv4b63JD9/AnC7JPadX8hREOBthTEVURDQ7bb5wpOfRwjH6kqXJIkYDMdoLM1Gyvr6Ks8//SUunTvDxbObdJKEzbVVfvnf/38oDo5oixD2p5zrbRAmTYSQgGRqCp7b2UdEAe2VdTYunufxb/4WMqDZX6HdX6NAooKEfJphjEUHAXEQY7KSyrqa8EjNmbObzGY583nOPCuI44Tf/t3fIU1S1lZX8ULwr/7Fv+DxJ57g4Ycf5sLFS6SNFo1Wm7TZwnnP2XNnUaoWI5jNZlSVIY5jjDFUVYUQgk6nQ6PRWKjKdbn/vksIIUiTmDAIMMYQhiEvvPACwguUrMvctNb0V1bQgUIqWTfw5zOMNcyzjHk+wwuHEoB1CO9RSlDlBdYYAh0Rhk2yUmKdIgyjBfnJyZOI+WyK9w4hPFWZoURdSidxCFkvq0XLT/2o+z8O95+vjUadI4kCdKgJIoWUsNbKuXb5i7isQao2OXPuAYoqIy9KyjKjqgqsKxGA1BItFaCYTK4hrAdXMywvPKqmSngceIvFMJ/W5WLOW7L5lNFkxFNPC6qqZJbNcKak0epjXIB1IXsHLfK8rMu+hCDQAdZ5vIUkaeARPPv8F+j3VjHG1nLSu4KjwwFhGOG9RylNq9lABhF55SiLnKIsyEuJHZUnZXh5Xvd+zecTnPWAxFvwKKyZURYDJpMZ81lOaQwIhVQacHVmyhbgDVLVAgbZLEMIjVIxxknCqIkXAdbVBF5GikYrJYrrMrfISZ5//gVQu1gvqaqSoijZ3Nji0qVLXLp0H+fOnSNN00UPm7tjFOpf5v8jxFLA7U68613vetUv0F/+5V/+QzyaJZZYYokl/qiwJD9foziVGaoA5x1lUWCq8sT4czaboRUI0aMoCqytEMJjTMV8PmdrawO8QwlBu91EeE+30yIkQIgQtRJx4Dy+zKm8x7fbXDh3hktveBQV1gM+mUToZpPVNEWGEVYqsumMUITEOiYKJVIH9UC90STLcsajMS+88CJnz59h58Yu4/EEqSSPv+FxDo+G5I2STrfLhYvn6PVXaLU7JGkDHUaMplPyoqyb3HWAXKhqtVoN2u3mS8xO86I4yfoURUFZ1iVrQVCXvhULFblj0YMwCIiCGLynLMs6iyA8xlYnA36UIAg1YmGYmTRSAiXxzuGtxbs6UyO1QusApSXhwlQyCDxKeKwShIFFudos1XuLoSKJgwUBAoFDYJHCnfSH1MV/FhKLNYYinyGlwHkHFSAFnRhiMSHwlmzkee5LUypbUVUlxlaYRa+Pd7U3jRAgPWgvqcoCU5m63E1CoOr5F+csxlSUZUFZFsRxRBCGFHnGZJotyuTAoZnlObNyjCXEESInJaPRhPlsjrEG5zyzaU5RVERhDEhGozGNRof5bM58ljObF2RZQavZoCwN1jvSJMZ6TjJiUH8uEgHeLZQQJc55nHX4heK0MR6ERIkAbyHLCoxxi/+mqqmmt0hpERiksCAtxpRUla0V8lSE0inGgl28ByERoUIFCh1KVFiLHYTNDbr9daIkRYiQ6XRKlmWLkrfaTLeqqrtL4t9F+O20xOfesxNLRrXEEkssscTrG0vy8zWOV+r9EYvBsjWmflizmC32eO8ACd4zGAyQUiJFbXBaVRWxZNF87SmLgmI6YaXfI5AhcdAgCTrMs5LKGbSz6DBg9aEHOPP4G9FaUdmKSZ5ReWi0ujghqcoS56CcV+hIoVC40rG7s8P65jpVZZhMZzz73PN0+ivc3D9kMBgQJwkqCMiLEikV1no63R6ra+s0Wi10EOI8VMZirMe5ulTpeCAZReGiHK0mP2rRQJ+mad1bIwTT6RTvLK1WEyEERVkQaI1SiqosicKQJIoXJWYe52viURlDZSoqVxJEIUGoCZRCBgqHBykQQoEAbxwy0EgtkUKCNATaoaUh0BVSCoSoh9CKHGdKnC2woiQJNVLUWRZchV+YbnpnauJlHZ6KMBJIUVG5Mc54sqLAO49UmjRpkuo5ofAUs5zJ4AYeUau6eXDOY22tRmYWamTe12WT83xOURRUVVUrsCm1IBCGvCjJ5jnee7TWCCHJsoKyKAnCECUlDsd0MsFYgfECi0RIzXA0ZjaZU1UVxjpm0zrbJ8Wx9LMhDFNm0znTyZzJNMNaQafdJC9KKmMIQ80sywhCtSg/VAgWpOfE3LPumVpZWUUJRVlUHBwNKIqKUCcooetsC6runVoQGWMNggqtPVLW/+OqqkvyhNRoZQhCyXxeYDwgFEIFEAgcDhnUhDhppGyf65K2DEHkUFKSxDGtVrP2pkpTlJLMZkUtJvESqelXKGt95ZdeilP7pwq8WwQv+c8SSyyxxBKvYyzJz0vwFfpWv30zfwTdwXfL+ryS4EFVlkgpCBbS0fPZnEYjRet6cHf58mW+4z3fSiDqgW4jTfnkx3+LP/2B7yANA65fv8Z0cMRD991Hs9untbLByoUHcXGKFJDlObPZlLIsOFK+FlIIIkqlONg/RLTrqfaitDQbXQYHYyajDGfrLMr/96Mf5Ru+5RtJWk2msxmj0YSNrW0mkxlCKoIoIk0beCGxDkpjGU8LhNSUlWWelygV0On2ieIED+R5wXQ6xXlPURishTiuCZCUkosXL7K+toZzjrW1VXZ2blCWJUkS431N+KypyWKe5XTabSpToZWi1WqiAoVxjrIqycsCl1nyPKOsanW3Wr7NEkUhodYoKRE4pBQoBDiDtwWaAhF6RAVaCcJQYaoCKQyOHGszvCuZjurf3pbYqqDIp5RFRlXlVKbAliXGFkShR2IpqwLrBVlW9xdFUUq7s0qkcjAZxkqqwoEIgQC8RjiJM1DlgrLyVNZTWsecMdNszjzLFwTI4hyYylOWhmxeMJsWSBmws7PHjRt7DIdTlAhotzpY5xhP67rqVqdDVs4pbU6YhHW2qbB46ixgFCaUpcVVdYYGIYligRQh1gVY2cIhyWlQSYsPgSTC5ntYBBKN9BJT5jWjExBEId1Oj3anw7ve9S7SpMHB/iEf//jvcPXqDiW1TLdX9edW5jmIEKkSrC2AAisFQnmcL3EiR+oAqQNQIV5GlNqAEyAlRCEEEqEEMlSoOCBoxgRRi+lkxnw6QynF2toaly5c5MK5c6z2+0igzHOiMEbp42v5lf12/EnG79XxipLYd40Vi70u2c8SSyyxxBKvXyzJz8twu4kgty2Lu7z+Wuu+erjbgOW11t25LKiTBVEYESQKISGbzXDGogNFqCTFbEo+m1PhKLKCIIx54s1fx2xu2N46zze849uo8gysRUYxNo4YaziaHWGqCiEkKhDkBnpBPetuKkORZeyNhjT7q3zpS0/xhS98kXd9y7vYubbDjRu7bG6u8L7v+BY++qsSqTVRnFB5x7zM8QIqZ6i8I1KSCku706LRSGi2U2bzEUkrQmuPqWaMJxlpLJGq9l5JkoRHH32UCxfvI04Szp+/yNbWFp1Om4P9mwRBPRsvEYzGQ1688gJKSVZWuzhXsb65WquWGUuRR3RabUaHhxjjUEQMhlPm+Zxmu0m302R9fYPZfIbzhnk2YzQeMpkOkRK0lkjhscYgZV0qVmQzyvmQRliQxgJBLfTQTGOy2YxQB1RlRZ4V9SDeVwhvEcKCsGjpAIeUtcIZcQi+hTF1U3GjEeG8onJDisIwGVq+dPkqphLs7Q0YDqbMZhWTWcnwaM54kjGdZEynJabyOMALgRGCTHiM97cJjynCMEWpAIHEOYmpQOuIqjRY0yQINyjKEiNW8VIg5JwkTcmLAi8tOlyUCgoHyoGxuNyS5QLClKTZQCnNdJJRzCsQGhVE6DCiLComE4dQGgEUWQZqDSoDMkDEEVChJdiiQMuQzsp5HnjgAbqr99NsNIka22xdnbC7X5HPcnwJyIAwSoACLzRWamryobBe1Ze7K8FrUDFChSAU89EcogQCDaI2myVu0lnt02ilxHGI0p4k1dhiRhKFnDlzhne/+93cd+n+OtNYFBweHJHEaS128DLNtZdf+cfmxkssscQSSyyxxEuxJD8n8ItC+UXJ10vIy+3rfF2q9JLX7yRMNY47GsSxMq24zStDCKSvJ4SPR47+eC8LJTZx+zoWs7R+cTTHgxsB0gvcyf7EyXsci6yP93ghkIvXauPKOr7ZbIG1uNIghaOVNjm3sU2gPUkS8p3vfg+urMA7VvtrvO9938Xg8AhvLUmcMrExMkzrbJKkLufC0YoUxBpjHdbUJqO7168zHo3xQKvd5nOf+xztbhcrLEkzRsYCmUCzHyETwfXBIaoBSTtFRgFmDiqKEFpQOcs8m2OdIS8yDgc3kWoFoSxFOeX82Q2ajZQkiVBK8e5vfyfr62tEYYxzkgcffhhjHZWpS9ucF0xmc+IkxTlDXhaEWjObT3j4sYcQwiMDT15kjKaHtc+PUoSxoNFQmDkU84xyNqaYTbh+9UVKU2JsyWw+YzqfMBgeUNkCIR3OlySJpqwynKuI4oBOp1YgE1iEt5hsjBaWtbUu62srRNE6SE9RWbRMaDW75HOLkiFZPmWeTZlnEwbDm0znszq5IWq57GeevcF8BnkOs7nl6OiIoqwQ1H0tQgUY45nPc6rS4pzAe4mzMdZFWNvF4jDCYq3Heo9DIMIIt1CWOz6PKxNhTH2ueQ++ckiV4qlwvqKqAqKkw6xYlFmqGCtCSuNwPqjPXrEgVN7fdlkJMJJipurzzaYn1541EmcF3gX1lWKP8x4pSoRYKlzp8Kb2z3FKE4VxXa6YK25eG9B4S4uN/iZZUrC+so0vP4c3CzEBL6kyg9AhMghAK6zwYCS4CoyprzivcIXBl7Y+XqlQSuLkcb7EkTQaXLjvPgpryYqc9fUVZvtX6LfabG9t8Mgjj7B95jxCa7J5xmw+xzlPM0mw1tblZ/6Vsz7H95LbJdD9LSOoW8uL/+mdDj7Hr7+cPNV3IYd71X0vscQSSyyxxB9nvK7Jz2nkRE83+3lcIuJPnr88c3PrC1+8JI47lm95cIjbnh6/T5xQlPrHnUd/7M1x55DkJFPDcbHLYlv+pdsR/tjYso47fi784j3ipcMdU1V4Y1ASms2UZjNEuBaBglYzZr3XJMtntSywqD1iOr0eUmpM5RhmBSDpdlcQ0mMp8TZDybpPhMriKkOgQkxhMGWt4tZIWuR5BUiUDtFhhNAKHQaoUOEkzMsSHQWoIMBT+9yEYQxe0Gw06XV76EARBJoL58/R63bodjpEkSaUgijUaK0QQLDeJ00jnANvLXEYnJiK1kTRU+ZzQq1wtgI8KlJEgSDQMdZWGFMQRwJbzZhPa3PT+WyKr0qUNZTZnOlkRF6UDIZH2EXD/3gyBunJ8xmVLXG+QiiPFI16WTi0VEjhakU1CUoLdJJQlRl5UTEaT/BCkU8t2Qy8TfAm5nB/znxmGE2HzLIJZTVnMh+e/M/KyjMeVRwcGrJ5QJbBdFIymVhUECKFQkqFUhrnPFUV4xa9TlrHqIWfjrW2ltIWEhZlV955vJOLc/nWNeMMIGrFNxanozESCFDaYS04p3Den1yfVWURMkLYmsS8fDJBnFyGzh1fb+rWpedffsXW0AQqRVJhrcGZ+rP1XuClxJaC+aTAVSM+/cnP0u9fwzm4fuUGplqUq6GQQuKsR6o68+J93bOFuD0ToxbX/C0iGITBwrC0QuoAnaY0Wy1UEJDGKUGcUFSWdrvD+fNnuO/CBe6/70GiKKbIa/EEgVpsh4Wqm3htHeE7e3lOuM/Lm3w8t0pl68/jFbYt7vi9xBJLLLHEEq9D3DP5+c3f/E1+8id/kk9+8pPs7Ozwi7/4i3zP93zPyevee370R3+Uf/yP/zHD4ZBv+qZv4md+5md48MEHT2KOjo74a3/tr/Hv/t2/Q0rJBz/4Qf7hP/yHNJvNezoWf9vg6Q+Gu81wvtJrp193nL25PeQ2obWT37cX2AHIY4Ik7pyTvRV9+yu3F8G8/D13vO5fOm6azWdI72ikMZ1uizCwzGegtSCKFErAzf0jTFniXd3M32l3aTYaWEry2YzSQltLvLeUpWGez5AKrLEY6/BeEKYNQp2SxoI4SVntbZAmbaKwQaDmSBEiCGpNe6FxXoKXxHGjbvL2AiU0nUYXbwSrvVUacYpUgjSKeNtb30agNY00JtCSXM+QSiDEwp/GGaQHbx0YB0VJoEMi4RdKaQ5blTjrEVi0liQ6ImmFjMYzqmKKMwXNRsJ0Omd0tMvOznWuXr3Cc888xdbaGsaUHB4coGRAlMQkcYKUirzI6XY7tLsdjKnIsjlIz0q/RxgFBIGqvZYkTKcTvLdoLUhSzWQ8ZDSdMRiPkddnjI5yBgcl2UyRTRU3rg3ZuXHEcDKiMBlKOZwyXLrvfnQYk80NL145IG1sY8qEshAUeQCiTxQ2EEJgbf25SSkxrsI5A8IiRBMhA0xVUFU54BAqJgiCmjBai6lKlNKLk9shpcKUBUIeZx1crdpnClQQ1F46RUFVVKiFf5E1lrKqiBtdjAdvb89dvhJe6xo9hiRQEcIr8GZBrOpzoiotzuZUpSELc375ox8jCAKCIGA6mdWmsEIjhEIs8q/eUZfhOQ/Yet9SLSYYHNLXQiB+IaYQBCHzvAAJOopIuh3a3TZFWdLqNWnFXfZ2rvKGR+7njY88yMXz59ja2iLPc7KsqNUEw6hWeysrpJRfln/McRncS0nOrdeWWGKJJZZY4k8K7pn8zGYz3vSmN/EDP/ADfO/3fu/LXv/7f//v89M//dP8/M//PJcuXeLv/t2/y/ve9z6+8IUvEMe1WdNf+At/gZ2dHX71V3+Vqqr4i3/xL/LhD3+YX/iFX/iD/0WvQ5xm8HHn4OVu773bdl7Z5LT+Hach3hvQjlk54freHjdv3mB4dJPB4U1u7l1jMjri6Gif1ZU+f+7P/Tma3TXm2YC02WD73CVUEHPjxg7Xb9zg+tUbvPDcC6ysrNHpdGi2OnR7K6xun+Hg8IiZ8eRTGB6WKN/C5BqTa3wZUuWKJOiTRpYwCAlVlwvbD5KIlGbaZq2xylZrDeaOlbSHaq+glCAf5HTCDtYaynGF0xJXCmQgUUrUnis6IJABBA6EBWXBWyJXIgSEoqIRCZQG7wVgidyUONFk1YjJaI/JeIjut8EUtOQU3dest7aJxIhGp0VlHY21BkmcEkYNlAwRaKwVNNIuRelIG2163RUm0xyl6rLAbJ6zs3vAc8+/yJUre0ynYyqTMZscMp3sM59Pay+e1S6YkNGhwdsGgeyjaKHUGs2mpyksQlVc379Cr//1PPTwY3S6a/zGb/wOn/3005jjUiw0UiRkM4/3JWARIiZuNHBmjhe1qagpPbYCpVLCsAHUCm5FVnE88A+jJkrJhX+QIQwTTOVqcQnvKIocvKTR6uGcw5iqzl6IAI++xVvkoh8Gt3i8GqE5zjKdbtBu7a2yPHGSt/U4V+Gco6o8zD0IRZ7n4D1KBaRpB6U01nqyeU3+vDPUDMguUqsSKQUSuTj+xYSMEDgBufWgFEGrSdxukaQp3W6HIE0xVY5xBW98w8O87z3fSr/dII0jpJRorYnjuM64Lf4GKV+91O1O3I3o3Pna3dYfxy/7hpZYYokllvhaxD2Tnw984AN84AMfuOtr3nt+6qd+ir/zd/4Of+bP/BkA/tk/+2dsbGzwS7/0S3zoQx/ii1/8Ih/96Ef53d/9Xd72trcB8I/+0T/iu77ru/gH/+AfsL29/Qf4c5a4G17R5FSADCV5XjEeTXnx+rOMBvusrXQobcnO/g32dq7yHd/x7UxGR5Rlzu7edeI0JI4S9g8HXH7+S1y7sQsIhoMJ03FOmVtu7hwxGeY0GjOyqeH+849gS0EoY6QKUIRcunA/zaSD60mED+g1VlAdTbvZR2not1q85fEnsEVJI/Q0GhHdpMd4PAZRz+bbyjI8PCRUqlZPC0OEq2WHvREYU0t3W2eocoVwFoWlEUq8zbD2OHtY+xapkyI4h808Nw/GeFOSaIVP6h6RNIqIdECVNkFAWUlcHJE7RyMr62yJEeRzQ1FYrBGMBobDwwnZ/ICyfK7uUXEC7wV5UTE4GlKUFcNRSJ41cE7TavZZ795Hnk/wGNqNFpNhTiWnFLnCVSnKJVS+Igxq75uymoDaZHX9jdz34Dewvn6GLz1dID53gI5KwGGrAudmIALCKERrjTGG2ewQ748H24tsDgLnFELWg3yPWyQ6NFJKyiJHSIX3higKOHfuAiv9FS5evEijkWKMQSr41//yf6EyhtXVDd7xjq/n0qULpGmT9fU1zp07S55X/K//6y/x2x//BM9ffu60Z/YpYjxZMbuNSh337x3/fQ6o+3W6nR7WWrIsR0pNEESYytZCDc6gZIBSEutMrfTma/nsugyu9szyx/zyOMVaWYJ+h9WtLdJ2E6ElQnqksAQSur023/nt38bFS9vMRxPG4zHWWlqtFlEUkee1ip5zjna7jTGmLqNbYoklllhiiSW+LHxFe36ef/55dnd3ee9733uyrtPp8I53vIOPf/zjfOhDH+LjH/843W73hPgAvPe970VKySc+8Qn+7J/9s6fe32nL3l5vZR2vlM25cyb2dlLzSu9/tW3WIgwSHcY0lCRtxHTaTc6eWeVgv8l4PGB/7wZBEBBGEdYasjwjm88WpVIlk8mYyfiIVqtDHGmCbpuw12BwNKlNLssCWxWksaqVrZRCq5A0ijm3fYY0CtGiTRJGhGFIoAWBTvE4ytLQaSbM3BzsmHI+rf1hhCUQFVhPWRa0U0gSDTicm4P3tbjWyR/sCSXgHBKH9BVlOSKUdfO4sZayrJhnGWYxw66URgch1lrCOCGKNNYF4GOc90ynJcNRSZblHAw8g2rCKM8ZzzK8FygV15LQpcc7gfMheW7J5oYsq4iiBkVRUpaG2SzjcDCg1+0TtroYGTCdTTjKKra7q7RaPYRwSATF8JCgGWMR5DONLQOc1xRWobQiaPTprXb4wtOX6W+cZfvcA3zTt3wbv/Frv0ZWzgk0pJ2AVqvD6soaOgjI85wvfuEL6Ejylre8mfX1DZx1dLtdZrM512/c4NrVq+zt3MALidIagccaB4QLYQJRi0krTRjGJElKmjZr/ygpeOTRJ3jhhecZDUd88YtP1VkvU2dklKpJ4Be/+HkOD/c5KSe7dcZy9+44d5fX7+xnEdTkRpw8BBohF8THu0WMI8sKnLNYW+GcJc/1onTTAB4pZW1G6wzHtqUKVfeReY+3dpHVkqBknc1KYuJ2h1avR5wmlKak2Wwwz+fc/8B9vPHxx+i0YqaTKd6Yk+xOnucAOOfqa0brE2+le8XdssavVPZ2Z2ncvWSTl1hiiSWWWOL1gK8o+dnd3QVgY2PjJes3NjZOXtvd3WV9ff2lB6E1/X7/JOZOFEVBURQnz8fj8VfysP9Y4LUIzFei7O1Ok1MAj0SIgCBUpFGLIgppNjs4azh/7iLjo0MaaQvhIVCaMAgwpSHQdWlap91i54bAmopQK3QQEwdNxsMxpioAVQ+4E0kjDbA2QAiFVtDrNJHCEUeaONJ1nwkQhnJRDjYn6cSEukT4El8ZXFUQRRGBtFhnweV02h2CCKqqoihLnLMoqeuZeH/cdC9w1iGxCApMNUCEEuscVWXIypLRdEKWl2gdEoYJOkzI5gVhZDDWM5tlQI51cHA44PBwyGQyJXOencmUUV6QVRXGOAJdYZ3Aowh0hPUGUzmqEoxTpGkT7+cUhWFmSiZlwXorIZYSFwgmVUaWlxgV02pFBLo2gs3sIU6FEChUFNLs9InCmixWZkY2PyRKE168doXel55kdXOLOOyiAhCFIYo1W2f6XLx4kfPnzuO9Z29vjy9+6fcRQrF9Zo1L913EGsvm5iaD4QBHztHRdbyfgdAIGdaKad4gZISUCudqA9ksyxkMBuzs7JIkMcbUfSpBEKGUZj6fc/nyZYRwzOc50+mU6XSKlJq8mOFNBTgQt2U3/C3icvdsz91lQ24t3fZeUXfv1Oe/5Vj30Hu7IGP2JBNYlnUpX236qxb9UQbvLbXVKUjvcH4xKXFsDiwkyADCEN3u0FvbJEwb6FCjIk0YBrTaKzxw/wUeefA+FJ5sNieQ8qSnpyxLoDaMDYKg7sdaSJWfBq9GaO58/fj5cdydMcvSt3vH6SfmTr9NscjKngbyHrar7+Eg7mW791KkKfzps5kiPP1BTOPeqWPPr56+6mRFFq8dtIC/h0ztaLB36thPfeG0GXL4+OdPH3tl59qpYwF2nxqeOnZ6cPqzYjYpTx07GMxPHbuyunrq2PHo9MeQZ9mpY0/Eek4BrUenjjXm9Nt9//vfd+rYRx5+/NSx91KZ8FLD7tcKPs399PTbe12ovf3ET/wEH/nIR17+wim+YF6Ps5SvlNG5W8yrLd++7u4xAuEVRVHinSGQAUc3x8zHUxqNkAfvf4zN1TVWOg1MlZPnc4pijilz0ihlbW2dNE3ZvXGTnd0d0qiBCGGSl4zHe1SVodHQdDoRcexpt0KKoqSqSozJUUFAlheEQUgUR+RFjrMQyBBrK7J8RCNNUConVI5A1RmdMPQ4VwCWOIZmSzGZ1uVCUnhKX+KdIi8qKlMtlMpqw1WBQSlLFBoKamJdlYaq8sysJXeeAInzCl96Pv/Ui8znFbN5wWScMZ1VOC8pCkNeVpSlJWn32BtnuCAgbfWwVEzGGc5DFEU0O+tM53NG2QiBoNnqsLK1iR4Nsdozs1PE1NHdaBKGGhuWHM1Ay5iZsbTimKSVoIqSUV5gsxJMQqPV4a1f9w7ObJ/FuZKrLzzFb/zKL7EXlpTlhN//9Cf4wlNfxNkQGWkikdLtN3njGx/l7W9/O1tbW0wmU5566imiOCSbDLh29QXsYsA/GB4ynU64sXONyXREnZGRCOFBSIQOCFSAkiFVJTDGsLu7y3OXL/PUl76Ix1MUBUpJPIsMRhBQFjlf+PynAY2QCoTEu2xBeFztV8Rx/RiLEaK89fwlMs+vdn3XrykR3TrvRU1sPO5ElK3mx4IoSnCuJj1SypfdW7z3OGx9DuHQfjEg9fKWzxECghjiGNVIafZXuPjwIxwN9qm8ZXNjFYHjO97zLjY31wmVIBCCvHZtrcvnnMM5h9a6zoYGAdZaiqJAa41Sp/+Cu/16fy3Bg1cSRThNZnmJJZZYYoklXi/4ipKfzc1NAPb29tja2jpZv7e3x5vf/OaTmJs3b77kfcYYjo6OTt5/J37kR36EH/qhHzp5Ph6POXfu3Ffy0F8X+Mo2INeEqJp7TA4CjW6kxGEX6SraUZvtjR6HIqIqpgRCoYIQnwtCFfHsk8/zxeppojhme/0Mb3/T1/O5z3+Wa1dfBFFRVDcZDUf0VxVx4xLXdp6psx2yRGhHFAVYOycILTos0WFFElicq5BKEkhPt+eoqn0wGUmU0GikqEgwnU4XA1RFnKQcDQ+4sbuD8yCVpjQVzWYT62r/eiklcZpApFFKYF3F1b3r5MWM3Z2bDIdjxpOMw6MJB4djTCUwRjCZF5w5cz9ZbtFBQpK2uX50yGQyY3V1k/7aGoEIOByOGFWC1e46Dz78CJPpmCeffJLKVMRpk97KOSbZ8+ze3CeMNc2VBkED3HxOpYZk7DMqXyRjDSsVE3eTsblBb+UCg9mAVdUm7kSkIiJqa0QaQBXSjiMefMM5kiBG6RQr1li52OfgxnMgLGUZUJkhfmoJWqvYouLG1Tn/Ye83+KV/+e8BiOIEHUZUhQaf8vufeorPfOa5Wp66mNdZD6FBanS0jqkqqrweIAupKfMcqdzxKUVZFkBFXhzPUjsQAa6aolSM1jFSRjiriZII7z1FkVPlGUqHeO/q8rET8nM80PZ3PBe8+uzZMUHyi76cWqmwzlBZPBZ/IqxworqwkI+XGHP77NWiXE5AEkZ4a3CmQOJPyFSdnZIQpahej6jVptHpsL69QVZVnL14AYllPh3yl/7if0O7HSN8ha/miDCk1Wown87J8gJjDEmSkKa1qenthGxJPJZYYokllljiD4avKPm5dOkSm5ub/Nqv/doJ2RmPx3ziE5/gr/7VvwrAO9/5TobDIZ/85Cf5uq/7OgD+43/8jzjneMc73nHX7UZRRBRFX8lD/WOF02Z6vqJqbwAeokAjbIizlirLiaQmCjS+8uxcu8knf/vjNNKAbDZCeMvG5hq9Tos0TAmbmlarhbGG+XhCu9Fga3OVaXbEBm1kULF9boVL922DKIiSJlmRU5oCLUN0EJDECiEtXmRoLZlnc/I8x+MJtGT/5i7NOKGsLMPxnLwoKCuDUoowUngNw8GcuLlKWdU9SZNZwWg2YTAaMp5Mmc1mZEXB4GCAcY7KOQaTMVGakGUF1tZlTXkpqFybRrtDu9GhrwKuXd9HiJCNtU22zt/PQfEldqbXOLu2yZmHHiWKYg5+95Mwy5BBhFQBVenwvi71ipMGcdqg2WyzsbWFVJ44jggijdQCFSh0qNGhIk4jmq10IYAwYzSeUOaOsrTkhaXM5ljr2FrbZH6Qc3D1Or/4b/4N0nmEcBgzYzad1JxAeMDUstHOYiZHyKCBEJpsXuFtLc+c5RZZFmgdETQSqsrgHXVfjxI1ERFikU6WdRbHH59DAqU9zpUn5YXOuVrmWriFz4/HmhlSK6wpsKYAGSAlZLOsjpGKMI6pyhneu0Up0O3GwmLBT24ztTp5ftcz+yWwtiY6dRmkw2O5vV9IoJDSU5YV3lmcrwBBFMYIES0U4QzWWoJaFx2Br6XT64sM5G09Pq0mjW6HZqdDmKTEjZR5lrG1ucp3fMe3EScBtszR0qGFx5uSWZ5jrUcpdZJ1ms/nJ4RHCEEURfdYUvDqam+vtX6p9rbEEkssscTXIu6Z/EynU5599tmT588//zyf/vSn6ff7nD9/nr/+1/86P/7jP86DDz54InW9vb194gX06KOP8v73v5+//Jf/Mj/7sz9LVVX84A/+IB/60IfuWenttHXVrx1Tz/6KY0bwB95eDXHHtl5rMHFnKcrdBiGvVI9/NzGEuxGlkwcCiUB6SyA9xliyaYZwJamK0GhwnslgQCTbYBxSAtYRak272UBrRRQovDUEUtJpNfC+RWGHrG+tYH1Fp9sgbUYUucFSIbRHWnBUVNZRucXfgcNYi3MGh0NIMF5QOUvlNK7UOOuZTA1FWWFMhvMTEJLhYIRQAVmeM5tnZGVJtfCOmWcZk/EUpGQ6LhmOp+Slpd1fYzaWDAYVUdxgc2uLappxcPOA1soG/a1zWA8v7M6QSiPSFulKn7DTxMUK2QoJuhEqCMjJcKIgjKHViTk6MliXoZRCCIsQljyfo5Wqpbe9QssY4QOqAsochE9QokEcdEgjTxxOOZwMcWhwIYqYQAl67TUCkSC8wxjJ7tWbUOUorVDaIbWg313DUVEUBXlWLghF/Xl67xHIui9f1KTC2bqYS4a1cplzFmcrkqTBfD4nCAKiqM7SzGYzer3eQrbesXPjClLVQgdBEJAkEc6DDutBvAACLbDO46wBAXGcMhwNkMIvSsk8G2ubSGFpNBKCIGA2m5LEtbx2WVZMJnMODw+5/76HGA5HHOwfMhyOubvs9UvP++PeL7+w+LxVQnfc8SPAC5w99iaVi/9DfU9wi+vKeYcxNemRQp2QKY7rjL2HQNNot+j0ezTaHaRS5GXO9uYa58+f48z2FqacorUDZ3HU/WneO+SxUMJd7gm3X7unvf/cGfdKgilLLLHEEkss8ScJ90x+fu/3fo93v/vdJ8+Py9G+7/u+j3/6T/8pP/zDP8xsNuPDH/4ww+GQb/7mb+ajH/3oiccPwD//5/+cH/zBH+Q973nPicnpT//0T38F/pyX43QDhdtnU79SM53+JVt6tRnVVzrGV8vq3E296dX6gO72kIArc5TwIEpGkyO0dBC3CVVIoDVxIEijgLAZEShJFGiiIEC3mxhbYU2Jkp5QK1wYkEcBQRjQX29TWUPSSLDe4vHM8zleemSgqCqDMQbrPdYZjKmYZ3PCIKizIlLUGaXSUlYGnMRUntGoZDqbM51Nmc0yZvM508mMvDJkWUFWlFTWEoQxYRxhrSObWzbPrCPDBrkRZJXj0fPvYOfmIVnxAnGjz/a5t3LtxnXGL0xQ8Tr99fsYTyfIqIkMFLqRohsJqhEiEoGPLC4sKUXF3A5wYkacOPr9mJ3rFuvmIDTeF3hXMRmPMaVBhiE4hSJGuIQq05RzjfRtqFpg2kjnkK6Nm09Ah7giBBMRyoBuY4NsYihLhVQtXG4QRiGlRnqPco5L589TmTn7Bwcc5oeEzTY67uKtQyJRQVSbk+r68nfOYauKKElxzlEUc7LZmIsPP8rh4RFBEJyUYB0c7HP+/Hl6vR5CePL5EUEcEUUJjUaD1dU+VVWRpAlKSZyzRFHEYDBAa0UcJzSbDV588flFRgm0Vtx36QHSRszqSp80jjk8PKLX7eO9Zzyesrt7kyeffJJ3vetdXLlylc9//gsL8nM3EYSXkiHn3QnJeakF8K3r/vZsVp06qycEuI0y4aEyFYHwBEJjfL5YXSu8CQEiDGh22nR6XeJmk9l8hjOWS/dd4MEHH0ArxbTISXRYZ5lcSRRptJbgFa/WJn6c9TmN388rTQy9EuFZZniWWGKJJZb4k4J7Jj/vete7XvWLUgjBj/3Yj/FjP/ZjrxjT7/f/BBia1sOoO8cadytxe7VByquZEb7W8qvDg3AUxYh2GhFKy2F5xMpanzCocHZCZRy9bkIYeJJEk8QhSRKSpLoun8pmTCZzSlNy7foLjKYjCOD8pftwAu57oE8YRuzeHCFlQHE0RakAqepBnrWeldU+h0eH7OzdJIoCbu7vs7O3Q5bXmZPn/v/s/WmwZGl61wn+3u0svly/W0RGRkRmVWZVqUpSlapUQkuJNrSgllq90LSEMQOGGRgYxgdJQIkPIAbMBMxYCcMavrTQJ0yMtZlaNjCoYQTNGFqQDJDUqhJFqVSqNbNyiT3iLr6d5d3mw3vOuX4jIjNvDCmpQvg/7Wa4H3/9+PGz+fN/n+f/f166ydFRxDuDkjkmzzg+OmVnZyfZNDct89MFB5efwYxnKNXwpS98if/hf/jDfPnVVzi5d5/AmPe9/yP83M/9PE0cs3t4yLNXv5rXb30KrS8xKi8xKp/BtvfJi3329q5xeOk6jX+d1brm2vVrXLp0md29Hdp2jbVrtAmMxhopJEI5RiPFeKTJMxiNM8ZlTgh0ttmGspjS1BEtR4zyA1ydIf2UnfIa7axA+PssTgxt1XJyYlmdKGAKJyvuvHyH9ema4FvuvXoPGTPsCtwqQguT2VXq6j51dUqWRf7wt/1hTudH/Mff+CT13PPf/3ffx3pVs3+wx3gyxhgDRIqi7MhOw2KxYDqdMhqN+Nznfpt/+f/53/mxH/t/cP/+fV555RVOT0/50Ic+xHq95uTkBICd2YT/+ru/DedbrLUIITg8PEDr1ANosZhz48br3L17l5df/hIf+Lr387Vf+zUsl0u+7oNfzWc+8xmuXr3Kd37nd3Ljxg2Ojo5YL9Y0teXFF96Fc57T0zllOeId73gHRw+OqaqKK1euYK3nM7/1Wd6K+JxfzkOvPY5E9L1/+tf7x2F41cWQ3PuI5EaD0OisoJjtk+3uMZlMUFpibc26WvKHv/Pb+MDXvo9nLu1BcCgB6+WC3AiKTCEAGQUXL2h7+3GRMrgttthiiy22+P2Ap8Lt7XceYoOk/O7/0F+0f88bvfdxy96MNAnRf19HWTqkbKmqU+4dfZGbtyre8+ILXL/6LNPxiKp+wHu+6v0cHz3g7oM7FEWGFwcIKRAS8olhko/I85KD9pCoDZP9Sxydzpnt7PHgwREvffk2ZTnhzv0HeBe7RpIVd+8+wHqLcw7rLMv1krZpkFrS2obT0xOuXnuB07rCOkuWGa49c8DRjbtcen6P6c6Mk5M5dxcV1971Hpq2pbp1BzOZcHj1Oq8/OCLOV2QmZ7J3mWw8Q1soJmOuX7vCv/2FX8Q1axSBXAmq+TF2vcBVS3y1xq8WhKqmkIJCCETT4lZrMh+RjSOsanyM5FGidY5rPPfuHFEtW8bFDO9AxZJ6FVBMKHMDXvDgXsPJ8Q2Oj+bUjWW9UqyONZ9d3kZJSVNVVOuG6fgKy8VN5kdr1quK0DY0i5ZRUaCiQiuNIzIyY1TwtEiQa+7cuseDB3c5PjpGS8EHvvbrEEIw2xuDDBwdP+Dk5IS9gxHT6ZQsy1gtlykD5D3vUy+Sl/8T/+x//9+4fPky4/GY2V7Bz//Cv8Q6x+XLlxFC8LnPHzPbnSGEpG2b1C/otz/DvXv3gIhSEmMMs9mMw0sHfPnLL3PjxutcvXqVz33ut9nZ2eELX/g8/+v/+v9kNptxfHyKa1qMMly6fI3jo2PqekWWFYzGO9y5fYN/9+9+mTyfdFmSN0NyTzvD48jPY68QEul5nK1wygJ5UpY1L2ZgCpQ25JMph1cuc/WFF5F5TuuTdupr3/tu/tB/9fVMyhEieFxTs7szYz0/QguBEgrbOBDZozMlW2yxxRZbbLHF247f9+TnopmQs2FvXwAiuJhBwVuVrD123RcYf76vz+M0QBGlA0274M791/hPv/nr7O/OeOGdz+JCS2Xh8Mohr9x4jdlsh6vPX0drzeHlS6yq1Og0isCqaTitT1mua9aNp/nyfU4XFVpqbt+5y82bt5lOdwkIMpMyIuvVGiE1N27dZjKZMpvtce/BA8qiYG+2h7INR8cN73nf11N/9iWW64YsL9m78gzus58lm0wod3Y4XVcs6gozGuEAL8GMSkyZIbRCaIXOM6ICU2Qoo0B4rFuyOL1LU63xbh+JpSw0o0KjZUBGx2Q0IlOaZlVzcu8YjUS0MNYT3NJzdPMY5xx5LIghMD9t+PJLtzg+miNFCVoSguH0uMJZRZ5NAUmMgvWqwbaCGAxClhgzwXnf9QVSyFGOUQa0SZbuLkIQGJ2RaQPRIE2ksZ758ohMC5RWNLZmsVgipOAdz7+DZ5+5yi/90i/hXWDvYAedSebLOacnJ4wnY5RUOGc5OX5ADJEQI94HGmtp6obMaIxJmZx13eK6fk4xOJqmYTrbByKttbRti2tr1usVSInWhizLmEzGHJ8c09QVMXhef+XLVG3L3bv3qOua+XzOar4EmXpIrb2laW52JgOOukqliyEo6jrgXI0Uire+VuND/z5yFT1mHWfOb48nQAKkISpNNBneeWb7+8wOLrGzu8t4UlK1LUWu2d3b4w98+IMc7pesFhXtukFFz2RS4I1BC1BCJTolxJmPw+8RtlbXW2yxxRZb/JeAp5r8vFmGY3PMW6P/kYe3l/y8eeDwpMTmomPeuK/PozCZwraWgGNnb8rewR75uCBKsN4zOzjglVdeZSoVKh8RiBwtKu4fHbOqVjRtQ+sc66qisYHTRc3rN44oxrvY2rJYrliu1hSnntnuPlmWnLOOj1ZcefYqyzWMpyNGk8tY/yq7owPy0R6xXiPUCfuXrpG/do86CnSRU0zHeAkyN6giIyioXIMwgqjB4UGBNKm3TCCATA5fAYeQAYTDuiVKtxhjEaLB2gVaB7QKod6uqgABAABJREFUVKs5R/fvUdU1pSlo1y3Hd08ILQirmZgZvhIc316m3ithhPWO1SLQVqepMWoxQgiF94rF0uKdJC8LYhQ0jaVap2aoLgR88ugm+pB0MEqlxoPBI5QCPCIm8b3UMjUaFCCVJLV8ccQo6JuDvv76Kzx79TKz3RmrVcUnPvHreCeY7Iwxmaa1jvV6hTEG5xxVVTE/eYDWGiEUQkqElIQQ8c4SQzIqKEc7SKlo6hXONsToKcZHhODwznX9lDxKCZAKIRVSCLQWtK0l+NRE9MG9+5STCU3TJKG/1DRVRVYaIDVMXa/rrjGqIoZI07TJeEJADAL/SGZnExelEI8jP48bE88/VwZhJD4msj2Zzdi/fMhoZwfnW8CzN9vjhRee493veh4jIsE2uLbpDC8iUkikEAg0UklCmip5SJP0n4cnISmP0yNuS9622GKLLbb4/YinmvxwAfKThl0kwHn7q07EuXK6J9PmvFnp20UJ1ZubHkQQkI8KWptx7fnn+MZv/mYWp6lZqA8QAohszMGV5zhdV9w5vkHdtnzppS9z7+g+d+7d4+jklOfe8TzrumY2O2A+X/Mf/sMn+Pbv+F6q1Zq9vQNeePd7WC3XXLpyFds6Hjw45uj0Hs9enyLUDFMcUk6voLN9dg+u4WNgXTcEMeZ06Wicp40eoqMNnuQb57BYnPAEGfDCdX+W2lZE4XChwdo1zgl8qKmqOT6sUabA+lOuvmOX5cKQl57j05s4N8c2S1575SVOjo9orWdSTmhqx/HdOfXcI+2IaT6B2jCvHatVQ57PsL6lcZ61C3ivMVkJSHwAa8FHjUfT2pbTxYLFcpE0V21D09TUbZVIBIIYAsF5VAQhQ7ICJxELYsC1FcF5vNcIKTnce4b5/B5N22Lykl//9X/Pf/PffS+rasnLL7/C7Tuvo9SU+0dHJLvqEQDGJFF86gq9x2i0g9YaaxsWiyMgJ8938L7BuYb1UnJ4eABhDLHG2gpnwVvXuZ4JkDnFaIwQqelp0zS01QqERmmDVFkqe1y3EAJCKoQ0gKetasCQbkuRPEtub9Y2NO0KHwJSmK7HaV+e9jDeLFh/o2tucz295qdf/6MkSyiFNAa/WiIP9pgeXmL/8mXyUcmrN17l0uEhL7zzOt/woQ9wsDdieVohXKTQCqOgXq07aVKyDzfG0Dp/IdrzO0VG3qgR6pPY52+xxRZbbLHF04Cnm/xcABf7oX77NT8Pmx28VabmopqfJyU+b5wdS8Hdb332S0hRU63m/Oz/8W958OCIF9/5Ik1juXXzNvWqYblcUTeWLC+5eu05Xn7tBu9613vI6hF2cYP3feg7+U+f+hSzZ55Dj9eI7Eu8671fy3/8jU8SdcFousdv/vaXUMUuWhuCysnGuxSTPdatR5iC6f4lGi/AjMi0JncCmS3Q5RR0iVAeZMaisoxnhwQyrJOYbMzB4bM4L1mtLG0TOTy4xOc++0Xqqkm9WqLis5/5LEoalMx48OCE/+Pf/BwxRjyC48WS+ec/D0j2Lj1DjJJVZXEusr83xntLCIKmEcSYkWUFUmpCiMgYCc6gpEIVAtFZFccIzqcmqybLkUDrWmyw6MKQx4zRqGC5msPKEbTCe49zFls3uNYyMhMyUxBD3dlPB2IbcaFFBomMBqkMN2/foyglphhT1ysuP/sC//5XP4F1Ftc6QDDd3adeO5wNKKlp2grnQsr0IBEoqrXD+wVaK3Zn1zk5PaJtIuk2IQDP/fv3EBi01oxGe4RYk5kiZWg6K+zVPDU6FVKidEGxs0PbNjjb4K0FQGcTUBCDxzUtIEGUCDRKaIzJcTZirQUkWu4A4EKFRCKF6rI/b4U3up4lZ5bXTxDMC0G0PhXEHVzi/d/wYfIio3YWI3LKsuDDX/8BPvSh9/HOd+xxdP+E5ckJO5Mp2SgnOEu1XrMzmSJFaqa6WtXoTG01P7+PEGMcLNLfDE9yxB9unfBmeBLzjCf5xXsS7i3lW+nyziDs/OLbUFcXHnvqHlx47K//5smFx7525/jCY+8etRcee//EXXhsa0YXHlut3nnhsS/dtxceC3B8963H9Li+U1547OFB8daD+vU+d/FtbtqLn2sH+5cvPPaVl+9feGxVXXx7nbv4+fPsV7/nwmP/+P/1f7zwWC0vfqdyb+JY+jAuPpJUxfMWEE+wnVvyM4wbHr3Nn//47Xmz7XqSsrcnrcffJEMRxeHl58gM2LbG+in3fvXXmK8kxBKpD3n5td/mgx/6Bh4cnWBdIB8/hxMVddjheDXnxl3PnWPJa3cd2VQQnMYLTVYUSKPJyoLxbIrOs9RHRiqiFAQJpsyJUhIERClwMbCsKsbjEV6AjYF11VI3krbN8MFw++YKEXd4cL9luViyXjtEmPD6qyfJFMCOuHx4yJc+fwetM8psn+AjL3/xNnk+w2nDuqqoGsHO/i5KKFxrWa8rtM4weUbbWNq6JUpBHQwiz9BCIVFU6wZvHblMmQxdjmhdDdKjjMBkEoSkrhqiiAipUHnKHrjGoWQkzxRtBF0AtcNR40SDFw0WS8CCCAiZo7XBtuB9SGQLSQia6HOCzxBRI9QY6x3YBuciR0cV3q2TjkQXFLPLLCuHbytE9EiVkeUSrRXBR6xrCG6N1JJiVCQSsz5CKYcQgaEjLoqyzBEi6YTq6ghjJjTWoWRIJD4oynKMc5YYIxLFetUSg0DKApON0FpRVwtSOCcRcsRoVFLVDSIIlNQYnbNcHxNiIDM5ZZHK5Hzb4n0k4Dm7Vi8QkZ2rXnv4GnnYGKFvrvoY5zghIMvQOzs8+76v4spz11nMT2ispXSWD3/oA7z//V/N/u4e1bKmXi1QeCQeEQShb9CbFRAjzjY0TYvuA5m36fbz/092ps/0vFEvsS222GKLLbb4/YCnnPwEzouaNyMcMSzboBI8GiilZZtyn8dJoN9s2RuZ6w5zyuL8sr5Jfb88xniOJJ2NEY9ZsXjD9WwuH56LsyzU2eK+nEUgZEYEtMl47vmv4nTuuHvnAXXdEsSIYnwJle2BCnjnsIyQekbVGqrW0PicZQU25Ag5QhlNVk6IUhJF0jKEKJEmR5s8lTnpFiE1x6dzhNJUTcv9B8foLMeHyOl8wbpaI5Xmxs3bOAuSArxmtXRkZkpbC3zr8EGRZzss5y3eCpQo8FbRVAFZZigpcdZiGwE+QMzQWlI7h3UGmRVE5QgSosgIQuNCamyZZTnWgdYGpZOtdaDBOovQikxJUALvAlG4FC7HgIwKLxyi0+RE6RBCojNBJGVIWAZi9DjX4tqWYB3Re2SMICRKSaIN4CHYiLcRgkRgCF4QXQBnITqybNRlp0DpEbat6UvHYgx44REyIy9zCLbT8aSMmzYSIQWV83hf4axOjmbBobQkuJYY0yxuluU4VyEQ+BCG9QfviSEmLRK+I2ohNVCNkeD7ay5lmYIXSJURvCd1W5XJGU9ogvD4kNz/+pnzGME7j/ctShrC0MPmYdLyxohnV+NjrqaH19F39hEPjUxLy8mU2dVrXHrmWSISk+WoIJFS8e53v4v93RlCwHq5wjY14zxDCSAEog+JcFs38KvcZN21Hnmr7/Fw/7A3R3+DuejoR+9yMT56H9qWvW2xxRZbbPE046kmP5KApA+gHp6xTfX6MvY/3GfLzlhOhChBxE5u3K03plX2Q4I4W/Pmsk3yIzeWiW6g3BxAHzRshFVDUBIfM0akMoeHtNZ9zuYcCTp7+VEixAYBAgShk1Wn/eSagBOQmYyDgwM++KEpv/Dzv8S6aggxY/fgGjZkNM7QekHjNagRtZW0XiFkgXWCophishEETVZMWNctSIN1sFg1GFMSoyIEAWiUKrh9+wiTjWht5N79YyaTGSBZVxXWeqaTGa+9fgtBgZGGiKRtWwozJvqAdxEpNWVucK1HojHSUK1alCwg6mSt7QTGjGjWNTrLyLOCJlas174jnRopC3wQRCfSNgpDlpVY5wgxBc9CKgIRFxzWO4RPWZ4oUyYixID3FkLq2aKEIQqPCyGde92h9d5hm4boLdViTbOscbZNBgcCdJQQJW7VIAP4tiV2DTcREH0gOgvOAR4pclxoiSFg8hHetqAKiBacx7oV5awgNyXBC9a2wrkK6SAzOVoJEAJna5xN2yplMhcIoe5KXVKfpcVi3p1TGqVzYrDE6CAKggCwtC3QZWYEqadQ72UWQiAGj84KbEiGBzFCXVdd/yGPD57QekS3z0KING2N9RWZnkCMqQwwhu48P3+hDcF57Mp/hDjb/5vX43CldCRrmEzZ/OsvvJSgl0Yz3d3jyrXr7O3uUVcr8iyjKMbszsa8+M7nyYzBtjVtXSO8J88zlJDE0FMwSVs3iFTAx6gs8dF1tOatSNxFyc/mneHR++JDd69zy2K3LBLO7jLdvkY8WanCFltsscUWW3yl4akmPyLY9CdEV4wsk5AfEOLsB/+MMKRlQ9ZDxDOmEgP4DWIihp991NlS+tlQ+ZgIRD4cVG2MSdu48Xjj33PoS054eEzo3t8FMWJjzLnc1kPr7GZuZR+8IdnsdK+CYDQao7Xh+N4pVW2R5EhZ0jSe49OaZ66OCczxUVCOdllVLzHd0wjAu4bpKOdgNqZdL5kvTpmfrvlPn/oC+7NncF7zpZduMR5f5sbNE5qmRSApy31WqxXXnn0XOzsTijJjlE+5c/c2L77jvcxmU7xv+dRv/hZK5R1xikhpCC6cleKkqWmM1KjOXSzGmLRFIZVsFaXBe890VhBFKrG7NJ5w++59fBbIjKHQOYv5nDzPKU0GOmLritlsxny+JFqLGqUMS1FkSCWIwgMeYyROaGSq6mM5XxGBZrWEKJhMpsznS5qqZr2uWS8qXN1Qr2r8uiLULbRtd/51gXYU0Gw22EzH39KkMbHXq8B6fWMY01QdSfKQzAMMIKhOT6hoAdeN1bR1CtA3s6T954WQSv/6ayZ4x2JxQk+hYww4e1Z7H4dTVwB2Y7kf/vU+XU1aGoJ3aKWIUuJDIMSItSuUkmgj8L5Gq2SVHWMyT8BHWleRZyXG5FT1ujvj5bmJhTzP0zYHT922INTZPu03sdvoswAfYuxrq1W3S9K2S6XRZU5br5g98yy7h5eZFiWlkDStRWnFO68+x/d897fzzneMeO3VI6KLTMox5FmaLLHpWBqpz66/2FFC71EipFK+t0qqiAtmXmJ/5zpTipyVr6mNx6K7V3Z3yeEYQoxq2KeJDJ2/N22xxRZbbLHF04inmvwkxLd4vDnLGR56XTz0nif8uN9VPDRt/TZhb7aLkpoYBeNygm1XKFWQZxOUkezuSh4cL5FZyaScUreOg0uXqaqazGRcv3qNowf30UJQr1eIEHj/136AS4dX0drgPal8C4WSEiUl3kfqKnB8tOIbvuGbef75a5Sl4fUbN7l79x57u/tcunTAarXENh5ZJJ1SR13pAzohUsZCSYmUEu891vshsNvULoTQaVLo4kLh0ULiW0vjAzEERqMRwTliCEghKLIc11qMUUiZZsfzwlDVFVJKQgicnp7SupZVPSfgEVKwXq2JgLXJbGA8mrBcrvF1i4wSrTJcY3HLllhZaBy0EUJH0EXK0J0r6TyXBIwkErN5jvfLH3d+PDz+7cIbfZ7Y+Pf8Y9mnPGO6LmOIXcQdgYD3LmWH8BAcrU0lg70NdMTStH3/nZSlimQI+mNE6j/VZYfOJj0ednR79HsIoZBSIKXA2jXgKMY7CKmoVwt2rzzDBz70AQ4uX0Zkmtdv3+D6tWf5lm/5Rt71rhfIcs2rrx0xHo1YzE85OjpmfzcZNUQZunmWDeK6MSHyZBL1iyAO++fcefTYffC4/fG45eKhf7fYYostttji6cNTTX4CgiDk2U+xeEwuRJyfp+wD4MeVjW2OOff8XC3ZW//wPzrTeraGs3W/8fzp48f0s9aJsD1uzBu6w4muh4gQRJFmyXsK8dKXX2G1WOF9pBzvYLIRTdMmzUues3dwSNW0jLIcpTUhRmazGavVAq0PuHRpn7IsmE5GWNvSti1SG0KI1HWDd5EQACRKZmSZSIL1EFA6BYExQoyS0WiEEJKmaVgslpyenhBC0hoh4jkHJSFFchOTCq1TE07hLEN8GTapQkQpCTHNXYcQu9K61JgzhKRRGZUlx0fHEEIiakqzWq0wRqO0RgiBJzX0HI/HZFmGlJJyVLKoTmlbi5CkfwV4FxBC4qzrrKnT5wQbCa0jWgveJ0/xje0l9qfZGbmIbM7h96VJm2fbw3h8MN0f+cfbOPfLeOj1fpLgce95I7L1UDZJdPkO0Tkrdscixk3yE4HUCwgiUmkQgRADwceuLC29Pwnz+28UESJ2WV+B935DF6TSdg8ZjcdMenTZQ626DFKX0UMZrK1RWjPem7G7t8vu7g5CR2q75NKVXf7AN32Id7xwleksRwhPZjRVu0BkjuleSRDtsAdTolkgY0fmupLciEgZyTc5mueP4UUGRRABoieKOHzt4Z4kUgZ7M4N8bjmcvQ9IJFMTERu5si222GKLLbZ4+vBUk58kqJdslpENdOOcY9rw6FxJW1rCRkwUH3nv455fePs2QplhHeLNycobjzkLWvotF2Lz34cfbyzrZplFXyI0hMCB+/ePuXP7Ns4Grly9zvXndkEIQl9CVOTU1mGyDG1MZwSQ4VxBWeRkmUKqRC5CDBhAaQOkGXjvAzGmgFRJhgxKCJE8z1gs5ty9ayjLHB8s3ntOTk6p64rT09Ou51AqXwshDkSld6aSXdZHSom1FmvtuUwPQAhhyNT0e886cF1jzn59Ic+p6goRQWuNCp7WtiijIIS0LTHQtG3XEDR9jhGa4APOOiIBb90QnAsRUx+c0GVvfMR7B853BgxDLeRwvGR3rGJ8g2zAELu/Raj8cP1lfPiFzcxMj80MyeNe31x28eypFP11era+GJOCZeMq6chRl+OTad0xekLoy/UkCNVlaVQaG7t1xUCMqYyun+CQQhMG3R9d2u+sFFbE7vGQJaT73NS3yPtEaHWRce36VUJ0VFVLzAVf94EP8O6vegfjcUGUDqU6PVeoyLLk6LZeLpGbaTuRDEAG4hPThEREEc8dl4f37dmy+Miyx7ynJ4OiKxHtk0ybWVHR75L+QRxW1Y+NG4c6HSuB3xoebLHFFlts8RTjqSY/QSiiUMOPd09sBBs/6B3EG/z/bMC5EOxswrpb56PrenP08/XD3PdjtvGNskiPHxMeHTPM2b7x9xL0c+OyKx07U/zIbnndWNrWIrXm6nPXKT/zBU5XNU3TEERy/jIChJTIGGltS1HkhOCTy1gMrFYNITiM0Ux3ZtRVDVHhZSI6McZkBkDK/HjvKYqC115/ldu3b2CMZmc2Zb1ec/NGSySwXi+p6hplRimT4gNN09A0Ddbajlz5LvCNA5npG2xqrYflxhicS45sWV5w+fKzhKZBytRkMvWtGTGZTMjznKIo8N5z7eo18rIkxEBVVRwfHxNCGD6/rmtEFamrmrrp+vG0FmQqtQpCElxyK8O6dBi9TMQHAUImvqHoqKlCCpAidmVzZ2fTm51pF88ZnLPueOSMenT8w48fIuMXRF+S1kfW6ZgxBNX9mapUhtKCGF3KAMWYDBVoSKV7ghgNyIwsTw58zqZzw/t+fR5QSKExuqDxdmNzk7kJMdGI3vgDAs4FskxjtKImQHTQ2bIHb/mar3kvn/7cp4mZ4B3veSf/9fd8J95Z1tWCNkRm0zGL+SlGC0yeYUyXuWKDUsbYZWW6zJXY3IreduWhrNlm1i0+ZtnDZFSEgfj0ROhRMrNJOh89lmfkqM8QyZShBS7WjnWLLbbYYostvjLxVJOfVIIhN376e0+px5m2bj7ZyJoMC3sHtEScziaKH1rXE8x6xhTlPXZ9j6z33OY9bsxmw7jw2DGPW2fsyt5EH2QJOXyHEAOL1RrnAyYrKEYTdmYSHyx13RBRNL4hAOtqjbIWpTXeO6bTET442iZlhULwGFMihGC9rlJZm1HoTrBuW4f3qQxMakmmDK+//noiJPHMNlnIiNYKKSEEz+npgqPj5SDK7rM8xhiKoiDLMrIsG5psAiilqOuaPM+JMdI0DWVZ0jRN2hdSAYr5YsFoNKIsS7Isw1rLdGeHyWRCURQsl0tu3rpFlucYY5BSUjcNEVgul7RtixCCql4Ro0cECK4zpvARqVIWxzufzAwiifTY7vkg69nMTHRamIfj0XMlSPBokdSTkJG3I3jt1+HfdNTDiF0EPZCfjTykEAalQOBomjmD0YOQCJXc0kxuKMsCgeD0+B7leJcodKIvMZHHodQNiUAjou9K5oZ4fqCBCelA5EbifcNy1VKMxtjoCMGzt7/D1/+Br+eVV7/I5SsHfODDX8cHv/HD3L9/n2cuX6JpFXW14n5dMZmOefDgDnVVMR6VG5/yKNXoJyXSkUxZ7LPM2qZep18mH3OUH87OiUSQRPKSS5mfLoO2kSnafHx+u7rjcy7T1N0v0g3nCWnvFltsscUWW3xl4akmP2c//P0P9easdnp8FkTGDQe4viSp+5GPsUv8SM5bZpN+7EVPk86v+43Lf7rgJW4GJf17Ht3GR9fTP+2D4r6UZXNMv62k7MEw67u5bzYDp81wLz2PAqqmRWcF49EYkxU8OHK4IDB5jslLtIuECI1NvVess/hgaZo1rW2oqzXONdi2GbIzVV2T5yV5XqC1QcrUTLOua4ToiUvJzs4OIXiUSn1trLWUoxzfTeFLKZhMZ0wmM4SQhJAyRs4lUfwmHn6+aXrQv7bpENeXlEkpiTFt23w+pyxLqqqiqmuqpmYynRJjRCk1ZIdijKzXa2KMTCYTEBGlUhldUzcQU8BpjOk0TC0yQNARt66x7TpxhkAiQT5CSnJ0i8/yAOcwHNuHLZnPffPHLHtkBW8DniwEHo5P3JQ3pYkLKbrSRRWJse30YDlKgTYCIWOnAxJMdybMZjt45zk9vkuWCwiKtgl4H5BCEoNKeyEKvOuzPGfX5/krod+YgDEZwjuc9WidMpQHlw649tw1Ll/e59adW3z3f/VdvPDe9zDb3WPV1Ny7c4+iyBgVU5pqzYN7p+zuHBC8pVq2FHneEdeHyGvc3AKZjuhGVobewfLcsrQDz25pm/eE88sEqsv2cC7Lc+4a2HhP3Lh9RR7e1p4MDSt87DHeYosttthii6cBTzn52QwQN4tH0vOH5y+HOptNjvDwDGjs1rOprXlMcPHorPv5UpXNOdazPkRJY5BefOP1iEfIVL+eje/VB1Sb+2Jwjzp7v+hma4lngvAhQIo9iZK4EDk6PmH1W5/j3v0j5ss1qm6prcMHcC6VryUdRJuacHYZmzwvMDplppzzRASj0aQjPhIhJTEImt5cICazA+dCqvqSIjURVQqTGULTJF1MFORFgda6285EC2QIXdlQT/6S+cEQYAuRjBGGjFcq2dukltZaiqLoestA27b4EBhNxrRtS9M0aGPw1tI0yQLZZAZl9KATEkIwHo3QWlJVa6y3Se9D+nwlIgKPqxpkFETfWR4PvEWcnYIbAXLfb+bRJOObBZ2PI0q/00HqE2RBN8hoHK6RNCEhpUymFSqS5RlZLskygcmSu1uMqZeQ0pHRqCQvcqxt2TvY4cqzl2hqwfy0wrbr5NSH6UT5CtE1Vj3L/JxX1nRbByJpsaSSlKqkbdaITHN4aZ/9wz3W9Ypv+pY/wPPveI7xaIxtHDIqjMiINvU40iJnlEnwGi00JisS0xNpcmXzPpKuvTP7iXTpnpGzN5xaGcwhzm4jw2PRL+vXnQwKCHEwlhOhJzppm6Kg28b+lOmKEOMGzRrmVWIyQXjbnel+/0GJgBZvvZ+kunjXJPkEHZaeZJpDyYuPfpKx5gmii9XavfWgDv/8l25eeOy8vfi5urNzeOGxp83F90Ow2YXHNo1660EdnL34/f1oubzw2LufP7nwWID61vrCY794+/6Fx3rfvvWgDm+oj/3PHBu8fetB/Xqf6Pq8+DkhVHnhsf/9H/8jFx77wuXdC4+1zcX3gxYXPy/jE9xPwgX2r5YXPwZPNfmRsfMeiqn2XWzMloqYfqRjPGvoCXSkoSsFG8hD91rk/Hronm9mbARDocoZHjcL30m5Yx/89NvIWTARu7Kec2FOHyRtbqN8aP0bfksb6zkXzA3jEmkQ3ey36IwCRJRDcU3TOqp6xaK6wcl8wb0HJ7TWE4Wkai0BiRQKIRVCStp6zWhUorVCa8P+/h7eNZ2uJ9Baz2g8GYwE0n5XOO9o2zZlfsqC+XzebWXEB4/WOrm7eZ9IVHRkWUbbJhc33xkepMxQ9/U70wMhk5tbb2rQ947pH/f/SikRIWl1JpMJSmvatqWqKgKR0XhMVdesViv2Dg+oqjXL9YoQAlmWsbe3R9MmzZEUojM+KKlWa2xraWuLlClrIHw6cna5BlRXxRVBqjOKPPSaCilAD31EunEunXv68I1l4xx+LJl+GG9n9ufiCMMPzmZYL4fjlzJrMJtN2d2bMplkaAPWrYnRonRkPMkQItK0DVUlef6F53j+uRc4OaqQ4ojloqGpPQqBQIHQSKnBtxuE5+Hvf3ZdOWfJTYbJM44eHDPbucx4XFIUGiEj3/Yd30aWl1gfaJsWbXJGekxVrwkxpDLMYsJquSTLc0ZlwWq5pJ+EOXcfimcZaykiET/cVzb4yHAIZbesJz+PTrcwnAKxV/bFNGkg4lkGXITYla+dEZt+mRjW0WfCN8lPAJFMJ8QTBA9bbLHFFlts8ZWGp5r8CAIyBkQ/wxbP5pRFNzs5WCOnZ90PuUg/7iKF/0MothFgnpGLPpty1k3+8VXvjwkIYu/mdbY9Z+sWnK2TjQgmlcv1GZs0+7+57o3vOox5aFn/2cPnJe0JMSKj3CgBEpycznn99VssFytciNw7PuHqtefIihIfIjvliGI8QSk9NEp95eWXyfMilfZUFcY8w4N792idRQhJUZSpBKxpBgOCshwPJWipCanGGMN4nJZbawcjgbJM2qG6rmlbR6ATW8d4zuCgD5z7jE/TNLRti7WW5XI5uLEtl0u0TrbVSXgvWCzW7O7u0rYtx8fH3L59G1Pk7O7v8frLL3Hn1k2effe7kVKyXK+SQYMvuHLlCqvVmuV8Dh2Z8q3FGIORGUbZ7rTxGKG7hJ9MJDRGpFQoJZEBhE6z8jFEgk/ub8GlkrwQPdG7c9P752esNsnww8Tn4X/PnZR0c/iPIQKb2Ye3myQ9PDlwhp78KA2TyYT9vX3yQuFDRZYLdncnXH/uCu9693McHd/j5Zdf4uTklEuHV3j2ynN8+eXbtBZu3z6iri2BgCRDiZw8y2mrfmZyM+dzti19Ak5phY8BX9eA5D3vfQ9f/vzn8M2S/9vH/u+YLMN6hxSGcV4AkpOTY7TWFHnJuCip1mtyNCZqcAIV1blszea13OdnUhesSOgnTHjUc69f1k+obC57dJxApsRnN+mSJoP6zJGKZ1mkR5YRkfEsM9cfORETORfRI8PFZwG32GKLLbbY4isNTzX5ybu/M/QzlRuBzSPKcd4oBrsQInBh04PNz96wuj4HIVAqleacLRpSQ+eDUHGWYTqzzj4fqPaLne/LCNKUbvB0fWq6ZUAUmt3ZHvNFQ+sEi5MTQpQ8OD5mPPVMdnYweU6IAUnEesvJyQl1p+9RWqO86wiQQWkFHSFpGstkssNqtWK5XHJwcMDRkUvucEESguPGjdd55zvfkUwDqnVHXhwhRLQ21HXLgwcPGE+mnC4WrNcrXnjxRWxrefDgAQI4ODgkz3N8DORlQV4WrNdrXPApG0Skbhvu3L3LzmyH4D3r1Zrj4xMODg5ACKxzrJua973rBRrboqYTdsRVlDE0TYMwGiFgXVd8+jO/RRQwmk4J3rNarfCtxVufygJDRIQUnFb1GiJIoREhBaWhdbRdGR2hI9YxnglhzvW8CRskdhNvNvP+Zid3F1gLgY81Ro9BSGIIuCGblrQ1QmhkV1rYX0Nap35Hsbf99vYJLiXx0F/3acHjG0/TNkAgywwxeJCB8VhzcLiDyXKcC7zyyqvMF8dUVY0Ukqqq+PSnf4tf+7VP8uDekuANEDBaE0MiHdZaBIKyHOGDp21qlEpZSKNUItmuRgmJyjK8qwmh5d0feD+//YXPUVdLZk3Dpz79ab7pD36Eer3GKEOZBUQU7IxMd7hamqVFhDSZ4tua4Go0khDPLNVDCCBCIsFdQ1UtBY2zXUlZT3Q37mFpwYX3NCSDh3QveHw50UAD4ybhfSNEwGN9C3jYkp8ttthiiy2eYjzV5Ce12wtvGu/FEIgXCNF60fUFPvTic+JDPWNvW71BVMTZKzH6FPCd+4zHkZuzEqlzPYIeIkBp6OZ3FmeLurERCFFSjsa4EKlby3Q6I6ARWuJjMkOoWksIgqIo0uy8UhRlQRQC7xyu+wOQUmF9YD6fI6QcrKDX6zWnp6dJV+M9zlnqet2RPIYAu8/m9Fke6DyvtEoEJyRr6z5TEELAOkuWZ9jWDs1OvffkeZ7q6QXkeY4QIq3DOUCyM5nhWkteFuzt7qIyTZ7nHM9PiQKK8YjG2658LuB7guCTv6AQKZuWSpFEysD1zsII6Ev+AshAZ23d/dv1/ElfVLxBYPtwpuRxmZOHsj9vUfJmtEnEx1uIEh+6Zp5EjNZY15DKsCRaKSDifCB2Y5yP+Fh3q04mFe6CZm8PtRp+9Nt2pO/4+IjV+hSIFKXixo2AySDLBEp6ZCY6N0CJc5Hj+6fcvzfHWtVlJnV3/oSBdAiRev/4kPowaZ3hg02TAl0mTBlN2zR43yKE53SxoK5qxjs7HF59lt2DA8pRSV1XhGjxvhpkgWeHL5HFXt8jgkBqTYiO2BGS/iRJz2WXB077Mm7USm8aEzz+aL4JYr+33blz67H3LfGYCaJHBkaiCJju/mjUxXUJW2yxxRZbbPGVhqeb/HSC9rccc4F1SSlT5uIin3th+vNwUHHWl2dzs70/m11/qCJn80PTC32fkDcc082ty7MCwPOviQ0CJJnNdkFI6tYy252g6hYfU6AfmjaNFYpYR4wxnbW0IUSP9y7paTpNQW+4YJ1Hyoh1Lmk9BFR1jVQKTSIzPnpk8jXe2GiBVBuKKiFQSqeyolGJUBLrHForTJbhvcN1ZXBN2+K8RylF07ZkWUaIER8CSutOUJ8Ik9aKSTEZNEdZljHTM4wxWOcQQqKNompqfPC47s+HMDTF7IXzfUNSgTwzoeiITQyxs7SORB/Plm0md94Sb0SMzh/zNy51O3uulEQKcN4jhUJr2WmokhlGxFOWI6TQ2DbpO+KGTXTSMtnuca+nuch3uDja1uJcOu/aNtLaJcHXpD4/lnLa9WIqCrwP3Hr1NkLkSKkRUqFkOjeJMqmoYiTrMj0hOKKISfclUlPeNDEiEVJh2wqlFePplP3DQ649d41LVy/znve9h8tXniUgEEpCcATaM+Ppgb8+bFXSXWvSpYkacZbJk5L0XMruGuubu6Y3D0Soy8w8URFi7DN2ljfK/JwffpETsTthzyfutthiiy222OKpw1NNfrQ2aG3edMxZP5E3h1Qpm/B2YlOYD2wQtfPpIyH76Ok8KWKTuHXC+DPzhUczQ33vIgSozSzWxno2t0GgufzMVbLis7QuYGOkatpUMqYUJksi7rzMsdbSupZiVCCUoLUtwbtBd9NXa0mlGI/HCKXIywKTZ6nXj4hMZzvE6LuSOYkyiijS8QkAUiClIopOqyWSC5g2BtU5rTVNg0SRFTnOKXwI2OBpbEtsU+ZotVpxaXSJuk2ao0BEaoULHusdrrXM23nSC/mQ9Em2ZbQzITOGNvik/QiB1tmueaojet+RH7l5BIbmscMBCTHFuB6ih+hCykB2+h4RBvXGWxCg8NCADYJzTuPz8OsPQZy9L0ZPCDWZmTIej7Bt6unkuga0h4eHCASvv3YzWUx3wbMSmjLPWVXJeU0QkQp4Aseht4bE6ByTaaQMhNhgXQai25GAbSS1iiglme3sc0eeIGWB0iO0ypFo6rbtYvSUvUKqrp+UTwRVJs1TiP3+VYO6ZWfvgBfe+1V85A99hA9++ENcuXaF0XREiJ7TxRyhJEpLBA4RLb3qRpB4Ta/tSpepRGiRjFn6OYvuQknkJ13vQgDeMDCLDZ3XWdL3CfazSI1hfUwE9u2BxLt097H2bWa8W2yxxRZbbPG7iCcmP7/8y7/M3/t7f49PfOIT3Lp1i5/5mZ/hj/7RPwok++C/8Tf+Bv/qX/0rXnrpJWazGd/1Xd/Fj/3Yj3H16tVhHe985zt55ZVXzq33Yx/7GH/tr/21J9qWxkWUe/OgoA8w3grOxyQwfxtRluWwDZvb8/D22brqNBfxoXEb2p6NmdfHyIYeeSzP7Zbz60n2z2k+34zGHBxeYf/wmKZtEVohfMQFT71quffgATFG9vb2mM1mgzOaUqrr1zMaStxSY0/NeLyD1Gowa9BacXJyTFnmgMR5x2pVkeWaiO+yRymgUkoRfOi8IgQ6y0FJpBCo3mCgy/BorYkxDs1GvfeJpLUtWieiZK0dyhnbtqWtG6KPzGa7xBhRxhDamrZNOpxyMqY+PWG+WLCq1kOT0t6QQLFhfdFrOEJnG9yb9/UNe1zoTAwcdAQoZYvOZvgfpjdvjQsSnsdBBJRSlHJKCJHjkzvEGJBSM53sUlUVN268DAiyvERKSVVbYgxEAUrDqCyom6ozp7i4FelF4ZzHeYcPDSnb4wCNkDtIGXFtw6Jd41vY3XmWy8+8g9OTJU3jaUKNEjnQoqRCqxylDY13RBG6LIqksi0+OPqSPwi0tUNPdvjwR/4gf+z/8sd4z/u+igfzI9atY3WyAAVFMcHoQLQL2rZCYlPZIjLZS3dsNvb1pT5iIV1psTMzECkTSjgzUAHFuJgAmtT/R3TXgzy/vqHxKd12b6aJN14XARFbCA3Joe0/FwKiwguRtk+/vffJLbbYYosttvjdxBOTn9VqxQc/+EH+7J/9s3zf933fudfW6zW/8Ru/wd/8m3+TD37wgxwfH/OX/tJf4o/8kT/Cxz/+8XNj//bf/tv8+T//54fn0+n0iTc+qpyo8jcdIztR85uuZ7P06kIf/NYBZwSWbT9D+iYZHQCZIbLzrz/2cUeA4sPvf8hMIQJu0+VO9Jmhh1lTRgiKK9euMV/X/OZvfRohNXmWU+pUknZ6eoKzFqESaVnXFdZ7jDFJAK8UdV1jrSPrdDaNbRFB4r1DqfSZ66qiHBcIAda2rKoVmclw3uFcSGVlMaKlwLo00y9Vp+HpAuK2K2erqoosy5LDmjHcv38/GS4oNRCdLMtommZwltOdpbUQAm0UOzs7fOpTn2K2t4cpMrI84+69+zgRaJyltS22rtGd1igED8ET4sax3LDejkFAANE1LA0+lbpFF1PSwnddTDeOXYydhbFgKC27UE2c4DFjHh7/qDNc01a0XSAuhIIoUcqgpGK5XJBlGUqdEXZjNM4ZrGsIoWW5PCXGJOBPGqCNzXmbkCYrUgbWDwF9r6MRaJ0DAWsFr375DteuPcf8tCWEdXqHEF3ZlyfGlhADzodkfqEUxIC39UP7RwCeq9ev844X3sWzV69jCoGfJwt1oRWRSN14ThdLcuMpizExtoBMn0dHDKLcdJHGh9QbZzjqMnaZrLDh3qeIDV3GaOM49oSJPnsdN7a7zwD3Vvmb540n9cSKj86UPHafv+WItGkyI0aFk1vys8UWW2yxxdOLJyY/3/u938v3fu/3Pva12WzGv/k3/+bcsv/lf/lf+KZv+iZeffVVnn/++WH5dDrlypUrT/rx5+CFwYs3L3tDJteqN0MUqfTsrUgS9JO7F5ttDw/V25/LAKUF55+fDRxeP788rbVv3NkvPKtkOzOxDp3AfiiFe+jzU3WNJssVz1y5zKqu+fyXvoSLIVnudoG670rFrLW0WqNCyh5oY4aysapp8SHZOEupcG0DXtLaBmMUWiuEFF2WQQ77WkiB834wTeibMzqXnNMMSZvhnB9665Rlec4coe8NpLXuHMgSMXPODbbaIYSudC3pg3wInJycdO9xuMpT25Y2BsqdCc4lopVE88mCuA9M49AnhUR+us/EiT7mRPhI9KHT98QzgwO66sX+GESG/rexP0ybib4L4a1I0ubQFEzHmGiFVMlo2QePD4mEmiyDCNZWhNgkgiYFIYguW7K58j7wflvpT6ef0p09c2cQECOpt608M8PwMCpnlMUCZ8E512n8UgNeH9p0HXRpq2SmIcAFZJZ1pYhduk7lfOjDf4D3vu995GXBau1QJscUCiRUrSNG0FmJ0IEgAyIq+hLU2BGfRH5EL/vCRbeh6aE7AZKOKnZufjFKpMxTX554dgKc3WY2yc/mCSLeYFnqcRTRiWi96d6G+Jb3vW6dZOn7qm3Z2xZbbLHFFk8vfsc1P6enpwgh2N3dPbf8x37sx/g7f+fv8Pzzz/Mn/+Sf5KMf/ShaP35zmqahaZrheS9UP15V1PHNv4K6QOYHkuZHKnWhmPOx9tmPQe+C1uNxJW+PXd9jNTqQyt5iP6Qf8cjjGBl637wh+QEElswIlJZMJhOK0Yg2OOq2xoVUJuS8x3pPa1uklBhjKPMiNfdEYJ3F1g1aGaRMVtfOOUIUXebFJDtfrdNMt0j2vv1x8d7hnMU5CyhijB1RiUiRMku2dbStxXcaIyHlkHHpCY7obJlDCIPux1o7EKUQkoaHmAjLvXv3uH79Ouu64mQ+5+TkhKAlxWSMdw7bNkm+0zOTPpoNXTgeI/hI6EviHAgviCGVw8Xe6KAjQJvJxV7SMSRwxFkY+yiepCjucWPP9D69QUjsmqhKCSF4pBRcvXq1syzPsbbl6GiJrVukLLuMmu4az1pAd+fZ4wLw/1yI4U+iSI5oHdnpiUr3eVoaCIZRuYOzsFqt+1kFIiE1Co2QSsFUZ6yXzsF8PMFai7MtRI8ZF7z3a76Wy88+y6qqWKxbKCS5kAQRWKwcSIHJBcJ5VpWFoTStK30LuiOYaR+HCK11SElH+jkjPzF0+qsAAcaZRcZEJvv7wTm76yeyuk4Zooi/EPl569SP6EoGWyKCalU/wbZsscUWW2yxxVcWfkfJT13X/NW/+lf5E3/iT7CzszMs/4t/8S/y4Q9/mP39ff7Df/gP/MiP/Ai3bt3i7//9v//Y9XzsYx/jb/2tv/XI8l/85V/B5KM33YaLGh4IJZOT0wVw0UCkrs8HCW+k/dFadz1putfSgMcEJn3ZSxxIzSa5GYY/lDE6Z3JwLvmjWC8a8jxP+ylEptMpqlZDJsK5Ft3UxOBpXYOQEWOmqVCo09gAnbtawNuAc4loVFWFDyn4U0pRVTXGK2IMab1aYm1qbJqIYiIqKSj1KNmRn64BqpAS12V2vPc0bTu4uVnnaNqWumlQSjG/f588z1FKDcdLKdXZ9AqqtuZ/+h//KJ/89Kf49Gc+w53794hCYZ3Dty20LWQm7dCepXTZHx89IkTwgWgttB6sIAYJQQzER4SI6MTvApVMAuhn23lrXtN7Zz8R4vmHG9seYo1Syba8aSzWrpFSc/36u/if/+e/x//5f36co6MHfPnLX+bjH/84R0e3CKEiy8bkeYm1nqaJyeUNur41cSNb8fB2PO5LPqxTiedeizEZESSCplFSDqTNOYcn9ZoRSKTI+OIXv8zBwR55NmKxWBFCgxRJbyZVRBmNb0Oyku/LyrKMS5cvs1gsWK6WRALXnn+OL79+g1XbJOv0GFjZChscCIHKM9BwfHyMEIIs78ttVcr0RAlRd9qfdJR9jDhnEUKgtEJKgVCpLC1ER+is2wkR3Vmln7vaH0OCLopE9t86Q3Mx8pNgOwMX11ZPvD3/xUGKjVYHb4aLTxoIeXFDnotM+PV4Ei/BeMHfSCCJBC+IG3cvTqhP24uXyKfeVBfD8fziY6v64qWf9qL9AEg65ovi3v27Fx772hdeuvBY9+riwmPTGy5+7DzNWw8acHGzFvEEtqNP0sD70jNvHl9uQl7oek+4fevi2/vur3r2wmP/2+/9tguPDeHixyI+wXd7ovvJY2OHxyNc4HwIT3Df+x0jP9Za/vgf/+PEGPmJn/iJc6/98A//8PD4677u68iyjL/wF/4CH/vYx8jzRzU8P/IjP3LuPfP5nOeeew5Ulv7eBM7ajdr6xyNCsiT2/vFx3EOjQ7jYDUpnxbnn/Q/S4wKOc+qNvnxNPO5CFef+TZX/G2VwUaRgrXNNS3PogijSuM0KGSEE+wdjvAsIIbl8+TLHxw94/dZN1utVKkWzHiNS2C5iRLiA8o7gHTEEdAyUZcGozFhVNdZFxuMRTWtpbY1SeiAdy+V8mL13LomzvUtEJ7juGMVI6BzWgs+ImBR0SYU2mtZ58izHNw110+DXFeVoRNu2OJfE+1mWc3Jyymg0Is8LQoiE4BiNxuRZTvSB+ekCVWT4EMiKnGevXeXzX/oijbfJqW66gwsBhaQzKj47BCGVteF9Eq47l8reQtJ/9GVuqedLn35IKble5t4fqgsofJ4Qm5mYXnySMhNFMQXhqao1xuTs7F6mqddYu2RdV7z62su8933v48V3v8D1567xT//f/5Tl/BjrbMrABPA+IETsbJl7zcmb4eFv1mtV4Kxs7gw+OgQCJbLBybEvWwwEFElXpo2mLEuOT27x4t47mYYpjWs4PX2A0jqV8XlHoAFhwLUQA0hBXu5zePkZglTUIWmurjz/bqYHl1nawNH9O5TjktnBDNvUNLYh1jXFKKeczFKrptBTWUkgaX4kEk/KfhJFt9uzNKmiZQqGBSRDAg84RN+QVHaucN0uCkRkhMHmeqNEsj+k4g2WIUQyDWkvYHPNxQNlXaQPiPKpNgndYostttjiv3D8jvyK9cTnlVde4Rd+4RfOZX0eh2/+5m/GOceXv/xl3vve9z7yep7njyVFShsCSd+ilGK9XqGNSc0clUzWwgiikEMT06T58Om1GNFGY7QZMihSSZq6JsSIFIIsSwFy27YQk5vZaFxg2xbZCeyFEENZXq8vatoWJfVQdjX0wgGElKnDu0r/LheLVCIGXL50idBlP0II5EWBlJIsyxCkmWQfAsH5TnYSaOsGoSST0RgpJdY7gvOU4xHOWrxzSKWo1lUKPaVAq9TUM/qQnOFiYD1fMi5L9qczQtNydDLHSBjpDOsbQojkRkLd4H2y0ZVCEENg3VTUtaV2ASsXCJ0RQqCq1qzXiy5zA5kxKCkIUXB6vEBLTV/iZK3l5OgBMQRyozAKYnC01tE6D6KhHI1AGFobaWxMn9kuCK537opUdYPWOet1TV23CKGoqiVN7SiLlOVa1hU//U//Xzw4esBytaSxFm0UBD+QZREjRqnUGLVtoO2sjSPgXSI9wYMWvWtByix0pgJAErvLNGsrkUTvUx8buplhIZLmQsgNLVdExEC0Kctxhp48n9XJ9dRCSplILhGlxFD6GIbZf4/3Km2HznEusFoukFLgAvzcz/8c5ajAeYvyktnulOeev84XP7+kbVo8kBc7IFMz0eA9IbQIqZN2ZrC668nQWTkYiHMNhEN8tDGx6L5/atApURqEDHjX9ZISEa1VKjuMLc5ZrEvrf/3GDXZmO1x59hmW1TJp1roJgeAseVHQetv5TRiEkJTTGfHWPdpljZhOuPzOdxOLHaxtYOTIdmfcPj1BypRldc7j6xqhNAiNUAaBxLYOnWXJmMMGjNZU62YoO9UqQ6r0/aUUCJlmu9IESspCCpG0cLZt07kWIjrLMDqV0aX7VSJubdOmazp2LoNKYbTGaI0yujvukYhCmkdLfvty0f4vxkjR3WM29XFSyiFzCume7kn3iRCfzianH/vYx/hn/+yf8dnPfpayLPnWb/1W/u7f/bvnfnPquuav/JW/wk//9E/TNA3f8z3fwz/8h/+QZ5555vdwy7fYYosttng78baTn574fOELX+AXf/EXOTg4eMv3fPKTn0TKlHl4EvgQCCGJ5YuiSM01lU7NLW0S6fdWx1rr1KFcpGaCUYQuMOi6snfBlxRJZC+JnZ1zhgqB4JOtsZIKJRWWNFbJRIBakr1ycsxSZJ11cujskPs/6OLiSBfopd42QsgU1Pi0XcmqVzMqR3jvkULinMO2DmMMQnXaAJ+CbiU1eVaASA5TCFBCEUQyMBDdzL2QKbgkCtbLFZPRCNURGO+Ti9V0NKIZjajnc7y3SB/IECAlBsA2Kfjvyu9C9MldyyV3s3W7QpVjFILgLNa2hBAoiowoZJeaDNimQWZZ2ucxENoaH0NqpKoEKlp869F4Wt/SOo8iYqXAO5fIgWvxLhJDGJp4tk1FYfIUTEIqi1svsUIgXQMiIrF84fO/2SVpIjEGxnkqySP2hg+RTASUgqAFoAhEbOvwvia0DbQOkIhg6Hu8JGe4s4xI0oC4rhTGI2UiJLE/H2EjE9hpuggo1W1HjMPSlL3rKVIcSLogdBmHgBAKyVkPmRgjAZ90VFEkgi4E0VuEVLRNzSf/46/zNV/9PpaLIwQ7zGZjnr1yyOuvaGxTE6NDyc6BLcbOTc2ihSLKsHlSd+d4SFVmyS4ilf1131EO3O0sQxY3yjcjssuaaaQICBlBCrRONufRtYQu8RZxnJzexWSR3d0rZCa5EhLp+ip5FAEtIl6kbIwxmrpu0qRBhJ39Q6aHl/HdvUOPppjRlHZxiiHtr4BNLodSD01SY5BJVyS6XlcqICXE6IaSMykFBJX2Q5Tp+EWxeTS7Yy+Ty52AiCdEOmfBXouYrmOpIioKgk/XHMhOF6UIUUIMuBA67i27c0B0171IjX5jKs0MXS+rELt7UEzlIwFP8BHpQ8r4CoFHEDo9k3+CUoWvJPzSL/0SP/ADP8A3fuM34pzjr//1v853f/d385nPfIbxeAzARz/6Uf7lv/yX/JN/8k+YzWb84A/+IN/3fd/Hv//3//73eOu32GKLLbZ4u/DE5Ge5XPLFL35xeP7yyy/zyU9+kv39fZ599ln+2B/7Y/zGb/wGP/uzP4v3ntu3bwOwv79PlmX8yq/8Cr/2a7/Gd3zHdzCdTvmVX/kVPvrRj/Kn/tSfYm9v74m2pa4qokzOXsaYwf4YoKoq1us11lq01hRFkUhFl63pZ6JDCNR1PRCk5DqWusD3ovy+p00/U1rXNU3TDP1mlFKEEDDGMB6PKcsSIQQnJyfDDGvvaNYL9PvHzrlkNlAULBYL5vM5WZZRliWj0YiyLFkul8znc9arNU1d88wzz3Tbn+a3jckZj8ZkWZ7W6wJZlqdyNiTGZMQYGXWZoX57v3zjdaYvvgAxOU/lmcE7S6YlezsTVDzk9s0btFXFqCzIswzvLASPFiBEKvyJvkVJGOcGpSLrpka0a7RSZEogtB4+N9lDe7x3GAkyWIiJeBnXIJUiFxKDQDlPcJ6dvMBEz9pXyKZBKIuJERU8hfYoKfHBY1Ry9jNtiwoOQ5rBzlREGUdBhfINKEE2TkL22JHfGEAEcY6YRiJSekSmkSQnLmtrTk9a1k2F9SuwDcJHVDZJWYEY8NHjYypn6kvQhE/ZIa0UukyX3fmsYBwIcme0x6go8KErYRoIrUyVdZ3TnIuerCf8Xb+kaFVXbiiIEoL3tMESQpdVEIbRqETIHOdb6tURr3xpQa4swb4D/dxzXL16nb1pRpkrGk0KtP2a0NiB1AgsOqQAXyox2FRvfhfvPZ5UPihRqO46k0ql8q5ujPMOL3qSB1BhYonOdJdhBfA0zmJFMrIwErRcJ7JgNe06Y5R72tYRZPf5IqBijdQSGwKBlp1pwc0br7BcnVDujHjxa95HlmfUriUIiSlKUIrZzi7et3jfojryZ7QBoQgxaWB6jZKMKbOTjDs8gnQcna0JpD5VUiqUVhilU2Nj0ZXKRddJkQqyLGnpkl7Qp4kAYxBC0LbtcA0/fD85M/WIeJ/OBd/1Leuvvd6aXmnTkav050NEk1wYpZBonTIgdlWle6VSXd+uVN4XwtNJfv71v/7X557/43/8j7l8+TKf+MQn+EN/6A9xenrKP/pH/4if+qmf4ju/8zsB+Mmf/Em++qu/ml/91V/lW77lW34vNnuLLbbYYou3GU9Mfj7+8Y/zHd/xHcPzXovzp//0n+ZHf/RH+Rf/4l8A8KEPfejc+37xF3+Rb//2byfPc376p3+aH/3RH6VpGl544QU++tGPntP0XBR5UVCMpkPpRtM0CCG6LEPBbDYjz/NkKCAE1lrW63X64lozGo2QUtI0TWqA2f0BQ7CxWq0GYX9f2vbcc8/hvR9mfPt+MwBHR0es1+vBSrkXaw/Zp25s3yen7z8DsLe3x3K5ZLFYcPfuXeo6Nd/c3d1lPB6zs7PD1WefJcbIzZs3B9K2t7dHURT0DT+XyyU3b97kxRdfZDxOwVLbtly7do35POluijznW7/1W3nly19ktTjFO0dmDHfu3MJZS6Y1mTFEHJNpyc5kTJ4ZbNugpWA0LsmMRskkRM+0pMgLiJHF6RIgfUej0VqiSPvTWkcIKdi7euVKl7mzuNbStvVAYlN/H8dqtaCp14DEmBl7e3uMRiPqqqKpK5qm6coHE5lw1rJcGhQCpQuKPGc8HuP8LkZlCCkIBFprCfjB+SzGQPQpqGdwCQs0tUUr2RlSCGybI+IeWW4oioLxaMIoy3lw+z7NqiI4T9u2XYNVh/ducKUDhiaxvVlA6ErG0vPexlngo2RVRyobkiYqJDW8URqEGAh107as2weJqCHQdH1mHIBECUkmFZNc0NqKECw6SsrYoIWgjTV1u2ZdV3zq11/iS785QgpJXTc0sQEkhSkpsxFaAnFJUo8JlBAoapQgZURVT7oGWwdC16z28NJhKuMSKZPSn/tKaYxJ14VUCt2V7/lOf9e7+Hmfmqpa70H0paMyWbA72zXc1Tw7m3H//n1CEAiZIWRGXoy4c/8U60GXBQd7kpVzrOSa2XTMN379e3j51S9QjKfoPENIydHpMcYoIBH9Qo+ZTgqU1jTWsapb2rpCCYFvQZpAZgzrdQXeJzWQ0UxHY6xP2TshUubFqGSs0dTpXKiqFbPpTtoHsm9s6mnbRFhD6PVPgcXi9NzkDJyRaCHAGEWeZ6l/kzYbNvJ9s1QGotS7JPYTL/2ETpZlTKfTVGrb3U9tOO+s+PsBp6enQJqYA/jEJz6BtZbv+q7vGsa8733v4/nnn+dXfuVXHkt+3siJdIsttthii69cPDH5+fZv//Y3dR96K2eiD3/4w/zqr/7qk37sYzEqS4rRaPhB3iQaRVFweHjIYpH0JnmeD4Sj19AURUFd1yyXy4HMWGuHbE8KujxaJ3G1Ugrv/dBksy9xgzRT2jfUPDg44PLly9y9e3cIeuEskLPWniNPo9GIokj20ScnJ10gl+rwvffs7e2RZRnESFVVTKdTDg8Pz33vO3fuDH1vZrMZL7zwArdv32a1WmGMYWdnh5OTE46PjwHI84yXvnQfrQJSCTKTsgFSPUPwNpVSCYHSSc7tg2NZ1di2JnrHfJkUJiGE1ARVQKYVudbk2uCaqtM1pD/XOqoqEU+lFHlumD+4idZyKIOCSFmWjMcjMpMlzZVoaO2C3Chm5ZSr+yNG4xHLuWcpGyoRUSploWLwOBEwBUTvUTKiCMjGEtsG22llIjEFevQlZV1g6PsA8awcq61rlEzlSCEE2qZFSUmjNCspuOM86/WavemMTKVeQ846QpchI/pUmNRJXmQeyHRyBwtdjxei7FQqycY72TIboixYt2l9SfMhyY0BmTQ3PfkpihzvE4mSQlC3bdKD9HVvIWC0wrU1BI9REq1lKv+ToJREZTKJ+5u6I6kWZQxlPqIoRhiT4VvPyWKJlprc5BRFQdusoMtcdHeAVHanBKrTtkkpyPNiOP+TBgiMSddQnmeU5RhjFEYrBFDVK5rWEaLviI9jvXb4EFFKkhWG6XTGaFyk/UUqffQh8vrrkjwvGI8njCc7rFpLwFC7iNA53/k9/y3/+H/7J4wmz7N36VmmpeDaM7sU4x2E1LTec+xaCmPI8nEq+7ItJhpOj+YEmdzbCA6pNIk1K7QUEBJZptf4AMG1yc0wgjIaU5QYLRG5RsQMQdL89PcKpRSz2SyVuXZOiDGma6O/d6RrKB/ISf/XE9Beb9eX9W7el5VSTCaTIQveE6DNMVVVUdc1SilGoxGXD/a5detWKsF9Auefr1SEEPjLf/kv8wf/4B/k/e9/PwC3b98my7JH2jI888wzQwXDw3gjJ9Ittthiiy2+cvFU2/ZYZ4nVmrZtzxEXSNqjVNufbBjruhoyP8YYRqMRe3t7ybY2M2itCCEFxZvBRG/lbLrSEyHEkLnZFHH3mZ+e0CilmE4njzTa3CxXOQtYZPf5nrZtyLKMyWQ8BDtZZpLRgXMEH1itlqxWq6Qt6kiY930ZXXK3WyzmSCm62WOPc2W3HSlojsGzu7sDWLyt8a5luTrtvkunz4iRndkEZ1O2RwLBl1jb4q0dPjPPTaeXimghkGnCHBEZygJNYfAyBXM+OprgiU0gj52Ggi5rUy84XRqUVggErqlxtiVTinVd0XpPnmesVyuausH5NOsfo0/Cb6VwnZlFiMlVrmqaRE5DQOoU7LXOnpGfXlcTNh53FtXESBACEZOxhgtJw4IM4KFpGxbrJVLpruFq2sehGyekQOgzEiB8IHqXmqVuzKbTaUukStqPRCCS6YMynXOckmTaIFTqKeO9Rtu0LNl+R7RURG1SeZ3WKK1o6wYjBbaOEDy5Sbbb1rUIEVEqUuSaUT7BulQiqZVKGiuhkEojhCJImFIiYirfy3LBZDwlBjtksULwScvW9bbpvzfRJ4LXO9+R9qdtLTHUeNcgFZRFhtaSpq2SRkkJUoWcRxuXSgw7bZe18+6a03hvadsGqQw+rNP+khnaWEK9BJl1GbYGpWq0ajm8NOHg8g7RrdAiMM5l0mHVDhUDtq7JOrdCZwP5KMMITVQCmWmKPEtlcIA2ijwzaftlskiXUjIejUBEmqrrQUVECtCZIdOa3BjyPKeq6mEyoy/T7e89qeHuWXnk5j2mJ03nyY/CeYGUfpjw6e9Bfe+r1GtLDr3VrG2T7TZ0n59jbbq/ee9YLhdonUhtfIveak8DfuAHfoBPf/rT/Lt/9+/+s9bzhk6kW2yxxRZbfMXiqf4V897hm5qqqoYZ0N61qK7rzqUp1b3HGFmv1ywWC7IsY2dnBykF0+m0Ix4S5/wwO73pitSXr/WzpP1npVlQOcyOpm1K72nblvF4PJQ0ee+78ohUYuWcH2ZxrW2x1nTBjKAocsbjpPfpS/HW6xXBe7TS1HVgvV51hKsLBmXSq8QYaNuGu3fXTCaTRJq8p6ryrgQwifpD9Ozs7NG2C6xwVL5muVownU7IcoPo9u+onLBeRXKTyuCUSmVuTVXhfSJamT4bH6NP5gU6za5qnQiaURozyVM5mLOETpQuii57FlP/nLZuWLuW3t/Xtw4tFLULrFxkaVMA3XYkVSlFWZQ431IWBWWhiKhkja1SYNjYhroNhBjQSJQWNL7zUdvwmw6h6wnVLYtEcpMTu+0L0dPiiT6mhpRCYIOgRuOqBiFtEoV3M+h9aZYW6U9KRYge6wOegAvgXafzISZHQi8RMiCFR7qA6/U+nWmFxSNDyhRFH3B4qqqhbmpCDBRZjo+BXOcoY8AovCURUp10Tej0/bxPbmq4gBOOsiiQWUaWGYq8YL5Y4KzDeQs4pFCYIsNZhw2O6CJlOYKoun0nkwV0l0DoE0+IOGQveg3UZpZBiCT+RwbKIsNkGucbpNBkeZpkCAKEicl9TUW8sMxXNdJEkJKmbajrirwYsaznuNgSVcArx2K5pA2RxgaiyvjCFz4FsWI2nTGb5URfEazH2xUBjWsdWkSapkUUJVKoZPmuDJlO/X6k0YzKAi0lPnbmKFoxGhUYaUi1eYJRkWNdS3Rp0iGV/YGWEqkkdOV/VXWmO+y1i2eZMjZIMhv77SzTvbks3e9SJtB0luD9vamq6JoPh057l+6RvbW9lJKyLLvMc5pQatqGdZOy3cjzvcKeRvzgD/4gP/uzP8sv//Ivc/369WH5lStXaNuWk5OTc9mfO3fucOXKlceu642cSLfYYosttvjKxVNNfvb391GmoG1bpJQd4RED0ciyjJs3bw517L11q+lmW733zOenVFVN07Q0TUtd10NQ3Qci0+mUsiwH7cwrr7wyzKgWRcHu7i6z2QylFHVds16vOz1OLwA/W1dZludMELz3g7FB3ulT+lK6/nv0Ga2efF26dInDw8NBWzKfz2mahtlsNpgnzOdzHjx4wHw+H0pm1us1BwcHnS34mo9//ONMpxnTcU5eGA4ODnjHO5+nyHKapma1WCAB7y2r5YLFasnOeEJRZig5RghQUpJlGmvtQEJ3dmc0N25w794d6qZBCNjdmbG7u8v0Up6syIXg7t277EwmFEUqSQyh6x3UBYTaKIiSalkRA50+JMPamrpqiDGS5xnT6QTvHdW6omlqtE5ko8gzYojodUXmW2IIXQAnuX/0AIlPTUljTAL+QFfCRCJmBBpPctCyjrZtOD6tWSxWOGcJMaCkTo7Fsk0O2B3R3QxWk9tWEr0rrdFd49a6abBdiZnz/kwXImXS00iDFnKzNVMqjdokF1JSdxqiPM/Z29vDeY9gPQTR6/Wa2WTMJMvJlKQODiMVqsiJ1tLWNUfzOdm6IR8VsIzU65rGWiblGJNl6MxQZgU6K3BVTXCOFrh9corSEqPTOa7zAi1VV75HMrggkmtDbzPvbXJDE7HLjCmFlgqlBD56bHD4KBAx0jjf2U1LhMlRhUHqFOy71lIrSds6GutoQ7KiF+UIJxVL76nmp0wmBYuTU9Aak0n+zc/9fzm88jzlyJBlip2dEafLIz73uc/ggiQvJjxz+VmKvGB3Z4pE0lZrfNOmckYAFzFaEL0nBp9IbSPJtU46oBBx3nF68oDGOoK3qU+WlITQ0qxTOZ9zyco9maVMyPNiMFfp9W+QCEpVVUOmpy/JhTPNTz/pArBcrjg+OWV3d5e9vT3yPB8manrDE+ccTdPwxS9+kZ2dHabTKaPRiCzLqOs0qTRkg/KMo6Ojzklz/Tt0R/+dRYyRH/qhH+JnfuZn+Lf/9t/ywgsvnHv9G77hGzDG8PM///N8//d/PwCf+9znePXVV/nIRz7ye7HJW2yxxRZb/A7gqSY/r7/2KjpPs5pZlrFcLoeZuDw3lGXBO9/5PMCQrenL2tKypNGZTqfs7uo0M9+5v/U/+kopnHOcnp4Obm+XLl3i0qVLXcCexr/yyitUVTVsy8HBQWdFC0p1Tk8dqdkMXkJIDUatbTk9TXqcniilDNWk0yRZqo5YzRcn52Zox5MSpQXWtdy+c5PlcoX3jmeeeQalZ1RVzb37d1JQ01QolUjU5cuXqapTfBSpL4jUvPbqTbxNNtZaS6aTKbPZAVrnONsm62+jUVkqi/PesVq1VNWaqrW03nPjqMZkYw6vfw15npFnOaMyEU/rHG3TUNU108MXKMsCY3Tn2BY6i+dUzuNjpLKO104ropCUo5JZuYOjZdWscdYhG8gjNLWjKCaMZpcIIlI7RxiVEKGSFSH4NLuuJCbLmL7zWnJG61zdesOD5HxHl/kJ3LtzH6VSqeNEZxxKaJtkfmG7UjOhYFGtaFwiMX22rie3foMIFUWBHo+J1qKqCt80SGsRXYZSdoYAkkhoWqRRXTYzlSatV2taa4GYMjHaIHameO+wxmDH+x2B96mvUBt5cLwmWzlymSzFXdsihSAvz7JuVR2Snotlcm8TitZZRpXEhxXWOQiCvCjwziO7nk3V6QnGJNOPzBiyIqfIcpRWnW186mfUVE3Xm8fR1g02OKRI78uLnMloTJFnCJmIaPCepqm78rd0jWSFIcsKpBL4GKjWNfkox9nkqqe0ZBYcVShRUiOdIDY1z+aSy9dfIMuLlBXMT/mtz79EefuYnb37TF+7zXh6yHgywjqom4abt25w89ZtpEiW81pprl65ws7uDqqzmp/mI5qqRrqYnNO8Y293H0LEWsdqveb23dsImbKmicwYiizrnAEhhoDzEZMXibhJOZiApEyQ6e4HGiEiRZF3WZ0zwuNcIuZ9ZrtpGh48eMDNm7coRmP29/eYzWZMpzvMZjuMx2NylSNkIv7vevcLG1ntSIiO0bigKPN0zq3XnM5PKMsRQgpc++a6zq9U/MAP/AA/9VM/xT//5/+c6XQ66HhmsxllWTKbzfhzf+7P8cM//MPs7++zs7PDD/3QD/GRj3xk6/S2xRZbbPH7CE81+bl56yY+ppnQ6XQKwMHBAZPJZHA52yQko9GI0Wg0ZF76sjMIrFYrqqpJjT8744I8zxmNRoQQWK/X56yuV6sVwLmgFpJQeLlcUlXrLoARaH2Wbdp0gOvfr7WmaVLwMplMgDTT2xsvrNdrVqvV0LNosVgMBKm3r/Xed3beO+zvpxKjftubpmGxWAx9j4xJ2SqjFQ/uJQ0CpCzLrVu3aJuWPM8Yj0ecnCwRXYZFKcFicYq1KesSO42Hszb1PDIZSI1HM5tcSsegy8TNFy1GC4zJKfIRZQGr5RIfNFiJExCiJNMKge5sgh3V2mLKGVEqRJ7jTYEwOaVKGiYlJc61VOsWbyFoiMFjnUcUKpXqlYZCa6JZDZmGNnpiVBt9ZnqdT9efRqTSIa8yatsS6hopmkRepCLoImlKAKUVk2JMERPRsc7i3WOyPyIJ5bXW2NZSNzW2tQNJGmbmpUwZt6al7Ew1YozUVcXx8QlVXUGMKK3Js5wszzg9PU3ZKVlQzKYcHB6ys7ODUoovffGLrJYLyjxPpYDOJmLRNNjOJUwXU3RPyLsmpLGu8UWRjCt8QGtDMR53GQFHIyK2sFgiIghEA8K2KOUHO/n+r7/WvPd4l1zgBBHpPNq1nLQSbVpk1ztKKYl1nroJKStGILcSqeqUXXMWt67Q0zExABKkUtxePsC2LUrrVArqau7ePcKo18iyHJMV1A5Olg0PlvcxJ2smx0ucfxVpCnwA52EynrFarYhRoJQmzzJu3HyNclxgigxTZhSTEavFOh1vHxAIrl2/hneBpmkHm/0Qk6d0BBCgpSHLczKTMnM6y5lMd6mblqYjzr32Z9Oav7/O+0mT/n7UE6CqqlgsFqzXa0bjMd/4zd88OLgle+ykeew1h/26ejOYfoKov/f0bm/GmK6E1hF8HEqJnzb8xE/8BJBMezbxkz/5k/yZP/NnAPgH/+AfIKXk+7//+881OX1S9D3P3gqB8JZjBjzBr/Vb+A6dw5O497lw8WMvxMU34ubRxV3yXr1788Jj93ZmFx5r64tnNFt/8X3WT6ReBIuqvfDY12/dvfg23LUXHou7+PZ2b7jwSCEvfk7k2cVP+Lq++DY8ydTNanXx0Vn2JGu++PnzHX/kv7nw2ORQejHM181bD+oghbnw2Bgufv6EePGxF9m7jb349fNUk58UKCY71+VyycHBwTlXtz446H/QIZEga+2Q/elnPEMItG07uK4BQxlJbyzQoy896dffByZ9bX0KSGy3Xo+1YViedEBn21TXNTs7O+e+V29Z3btubQqZZReU9MurqhqyU71LXF+i1+sserc37z3L5fLM9U4pdmf7qYQrpLIrrXJkYTpiVdA0VWp4KDNMliHJkCpLDVmdI0aH7j43z0sQmnUTMKJEkxykorO42pKNDJkakWcZQkI1bxBBA6lESoSAlBoZs65iSiKCJQabsgG9c16kO0bpcshkxngy7hq1pqxVkRdoY9LsdgipD5A2SbMgBYRI3SYyKWQyNJBK4AdBfXJjm04nKYB0HikE4/GYTGtcR557Ufq4GCNU0nkkUwlPbz+8SXT7ZrpN0zDxI5zzgx221oY8z1LDSQTOBowyG+dnQzbZO5e9TMYaU/LJyVDqOZlMuHTpEqPRCCEE+8sGszilyFPPGNlpcPqyphhjZ099plnz3jPuzqlkZhA7/ciIoq5o24bgLCovOxKcagXPshWpGbCQqdHmSMih7M22lrr/bCBKgZWKtjNaMFojjEHloE0LnbFGUIrQZSuCdERvWIck5pcotNS4KIk6w0kJnV20DQ7fVAhZoU2O0BmNkzTOQ1tRxQXWQUASSKWqTaf/66/h6APr1YpFq8iKjLzKkXNFtW6GkkYhBPfuapwLnX4Qdnf38Z1rW79fhVAUeU6eF+RFQR4CSmc01mGdIwQ/OLYlU5HU40l3/YGkkIO2EdKxdN4hpOiuw5xyNGZvf3+4r22aKfTLNp3j+pLVTfe3YQKmc7tcLpfdcX468VZOpJAmsX78x3+cH//xH/9d2KIttthiiy1+L/BUk5+rV68yne1jreXzn/88169fH3Q9PYHo69vruh5srvveDCGEQWOTnIT1oImZz+esVitOT0+ZTCZMJpPh/bPZbNDSbDYwLctycGpLJgSS9XqF7dhon6HyPtkjt23L3bt3B6vroigGC+yqSj1spJQcdrP4kMpkdnd3uX//PkdHR9y9e3foH1TXNePxmNlsxmg0Gr4DwOHhIaPRiDxPpgNVVeGc4+rlK9hOLG6blueeexFjNNATN4cAtJbkWcZkPCHLDFW1pmlqnLVopSnKAi0zmsZx984RsZW42Nl5R0VGzqzcYzwqh4ycDJqMDIVCIvB4VFDoYLrZbs3YBO4+uIsXARFHqFHWabxEyvC0lt29PXavXma1WLJaLjBacelwb9iPy9UJznkmkzGSVI5VFpp6VWHyHKV0+o5CUjeWIjOdg57nYHKI92EgnZPpFBECy+WK+XzOyckJdV0zK0uKskCZtK6mbc8RFO9c0mN0AWYlPVoVZ+WYbUuR54zGI4TQhCiJIqexKfPRk5T9S0lX1NsgN03D/t4eB89cG86dyWSStqFJJUvFZJd8PE0NNrs+MKNx6ufTk/CebPdudda67jxInxc7M5F+UsG2LU21plmvkntdpLOYz5lOd4brEDrjjPGkywI6lqs19+7dpVqfaUpCTCYWRTGiLMqNCYxeF9NiO0G+1hoE1G3L8fEREdB9ZlVpTJERQsQ2NcuTY8rgaes11jrqEBHB4JVEKEAqnMgoZxPa1iZbCWMQuaboDEKkSuSmmKassMkyjNbM53OUlkkr09mz13WNipI8z8jynPFo1JFk3RFdP2RVjE7lnjFGVqslWVGyszMd9l2v6euPTVWvGY/HjMYlk8lkCOaPj48Jc09ZFuzv77G7u0dV1dy6fYdLly6xu7t7NnkiJaenpx3hVQPBu3s3zSKPRiMODg64dOkSDx48GNzhyi6THuGcwcIWW2yxxRZbPG14qslPXdcs17dYLBZdALEaGmT2pSOr1Yr1ep2aIXZi4L4PUD/T2dtiG2OG8rC+F0Zvhw0MwWxd18Os6OZsaU+OhCjIc8NLL30RYBDwW2u5c+fOULZSFAUvvPDCUKvfu8b1ZKaf1S+KgtVqxfHxMffv3ePo6GiYne1J2cPNW1988UVee+01bt++zWKx4PT09FwT1zzPKcuSj3/8E4zKEbOdHSajMfPTFNS3XfDeb8d4MmI0KlnXqRmqQCClISsKsiwnhMCytjjnme7uUhYpw1VVa1brJUnJ4WlsmwLgxZxiVCQL6Zj6swiRSsiQSdPRWkvTVHz4g1+HyhUuOKrVmpVIWQtCZFrmTHLN7s6Uy7MdbNtw//49Hty9jXcO75Jb2Wg0olACH1qEkBzuHZCp832dqqpC46lXpyxPHdEHrl69SgxJ22RXDUfLeSK7Nq17pBXj6ZjpuMBkKUvTWkvbpGaXAEJrjBAIAnVVs6prRqMxB7s7w3nYZ5FijPgYCQiy0YRl1VDXDQSPC6m0qjAGmaUeLxGo1hWlydEjjUSw7ohsBHJtKGd7qV+OCPT/LVerpIuRXQAsDT5Y2jZlsvJiNDRk7Xu77OzsMJ1Nu35HDdokkwzflVFBInqb2dMQAtE5FutqKN8yRckzV5PLVn/9hBDwLlBVLdZ6irwcSkl7i+a6Pct4AZREDi5fR+pUDlbXNScnxzTrVAI63pmyv3+V+d0HzC6lbRJK4kNya8vyHJ0lW+q6bRJx7csd8YN1d+o15DrXPWhcctczeUb0MF8umC8W5FnG7v4e47xIZM62LO/cSdkaqQbdX2YM2phu/yfyc+P115A6Q3cmB/0ETv/XE5f79+9zeno66FT6/mN9uW4/qeFDQCkxGJ/0pKssy6HErS+jizEOZKonR8BQMmyMoe4aPifDg+rtvI1vscUWW2yxxe8qnmry89zz17l7/5gHR/dx3vHbv/0Zdvd2O0JgODw8IHYNOtfViqpeY117Tnvjvada1zjnAcFoNGF/f58sywghMJ/PuX//fiIA4zFFUXByckLbtkOA17btYImdgpWw0TsoOVt5H8jzbCA2uc4IPlA3NZGAlIIQ/aDnCDEAgtVqiXWW4+NjqqoiOM/x8RFa6yEjNZvNGI+T1bbWiuVyycc//nFu3brJ3bv3WK9XjEYjZrNU/9xrmbIs58UX3oWUCoi01hGEYO8gZYl657gQI3Vd4Z1PAX5Iuqe2ddS1oygTEcsKgxHJElrlgqqqqZs1tVgjjaCWNUGmpqr5Xp5czpo2fX8lGU9Kxjtl180+Ym1G3mqC8IgQ0UpQ5Bk70yssFotEcGPk6P49To4eDFW0QkQO9w8Yj0pUZ3dNjASf3K1W1ZovfPZzWN9SVykjuLMzRWnNbDpN+iUlmY4nvPbaaxSdPkPrVG4oCGQ6x5gJ405H1pfu9ZowGQR1XSdCYyPWW9qmRRvNlcMr7OzspPd1zVNVVASbLK+N1iidgwyoQjM1ghgLkIJMaWL3Hu88rbPsmBFZr9uIsFgLbKNAJL2KkpI2tNjgcN1f8F1zU5n6CUmpmBb5oD8KISDKAj8ddaWEySlvWmZIJYmhwO+MiB7Chk6obyDcZwdCPNOWbPa5isHjfOpb1QfgQkoyaSjLdA7k+uy7agFGiqSfEV2j3FE5ZL+clBRac3lvjxBTI2HbOpyDZ6+/B6UzIinztKrW+BixKEJQICM2ymSmIAU+WJxr8dETpQCRMmbKpFK+Zt1ia8vh/iFFntO0Lc46BJLJdELwkaqusS6VMtKVqgkpQQqcj7jQAi1EQRSCvCxRSnd9niJtW3fXmO1KdhPxmk6nxFhyenrMcjlnOt3p9rnunP3E4AiYHCsleT4a7plCSIzRtG2kaerOAXIfrfdTqWKXIbp06RIxpr5ny+WS12/d7M5XgWue3tK3LbbYYosttniqyc9yuaRtW7IsY39/n+VymcpCRqNBh5NIQRwMDnoB7+bs9KgcD3bXSqkUIK9WVFXF6ekpi8WC0Wg0BAZ9XX3qhSHPZZVSoJdKhrRWRFLj0aZpBq0HdIGJ0Uy6dfTbl9zfzrq29/qg/vPKvBiyNn1GabPhYT9jPJ+fpiaL4xFZZphOp4zH44Gk5V25VwqmIs55pEzfrTdnyLI0E90bMljXIDt3sNal0ifvAy6GNJuuBVFGvLQIBFVTUfuKViab31fvvkbbtITg0Voym+5Q12uC9wgpGTUFx+vjLtOS9FbBp4Y8yXErlVHt7s2S4F8qTG4ofRcQS4mWEiEhywpa67Hrirqq0zHRSTOBUCidUYxGFIXtbIbHKcMnJHXTELwnRolSGUrnKG1S8EpEqc6Rz2QYUxCQrFYVMcRu/wuMKZEyG7QWva0wiE6LZFhX7UA0AGJMxzDPUzZtPl8REaiu+anWGqN10s34gHctvq5TJs5ZfEi6pFIrRjoFqkKQ7L6DpvEBFyQBTfB0PYk80Qa88Cgk2uikrfGevChQCnzwqS+TiORGoSSpp480SBTeh67PT9ePSMju+yShv4iRnU4wn4wA2kEzZ21yNgNBZjIEGhEVSmm00aR8WcQb05GsZBwQYqBZV4lweo8MMRlPjMcdWa9R0hK8YjQ+wAaRTCiEIxtpfHApGylSw89ipFNJowTrGkSzBpvKTBFJE5XlBq0MuSkIo0BRlsn8InWzJfqIC4m8TqZTRuMJwQWiSPJWgSBKgYySKEGm/ClRCFrrh4mRPjNjrT0jiw81Nz0zQhCDe2M6d1LJX1EIhNSDZX9/f2nbdpj8GI9HVFVFnufD/aYfV1Wpr0/SaSWN0HQ6RSqFCBcXv26xxRZbbLHFVxqeavJzfHxM6+LQ3yTPMyaTKWVZDNqF/sffGHMuiOhLRbTWiLGkLBvW65oYU1nbfD5nsViwWCwAKMtyICN7e3tIKQdCZK2lruuORKRgJctS13khz3p0ACwWiyHg3Qy6UxkdOOe7jFHsDBEqIA59gKbjPtOTysrSzHeN1slGF8RgfnBwsM9stoMQkp2dKVqbbn29YUAK6LwL3TI1ELr+u/Td4FNDRId1KZPSuhbrXWr4GTzaJcMEJy11rAjSdxoKDyZCjNy7/4CT42Ns21IUOdfUszR1sqEWQlCFnOOVpGnSjLe1FiUUKhi0MKlRqsmIUqeMS5mj85KxLonRDzbRELDOs16nme31akkIIWmeyhyTGUbT3cENr3dh885xejpnuVhg25bxumVcjmi9wHpPDEkknpkMrXKEznFBsVzWnJ4siUCRF+RFjszGmD5Q7cqy+p5N3nkcmnWVdF9EyPIMJTOk1ihTYrIc4hLZNT9VgBIR2bnSiRhIDMYlAuI8McQkes9zTJYl4hACbWiRBIwEJRVRKoKPNG0q33PO42MkU4nsGqWQWjEalWSm6wkTHNHbrsdOSBkb0WU0kAQR6Rv6bpL2/rHRGVIoiALdZZqS3iiV2gkhyPMCbwPexlQipjVSiKEPbQhhsA231naNfjMkIpEJ0U0CxNRclygQeU5WjvGNw8dE8EeqIESXsjvBg4SiNEymOwgZaVuDlCBkIn6IZPueZTlGa2ShkEEkwhcEyiTram8trXUopSmLApNl2MYSkm96ctATAhmTyYNEpgaqQqBaO0w69BMzm+YTvb4nOdDFoQeQMWZ4LXR9rJTqjSbSfk49zdww8ZKIzxiIG73NPE3TDiWG8/l8uI/GjckXKSWteFI3qC222GKLLbb4ysFTTX6MVvjocS7w4MG9zjZaDRabvYi31y4kUlMO5Wt9AFEUJZPJjL29vSEAyPP8nN103wBwNBoN2ZK+s/dZ9/oE0c3UG5MjlSDGQJ6bLuOUDWOapubBg3scHx8PgUlP1PogpNcgGWOIIdA2LWWZBM99dqYsS3Z2dobZ4rZt2d3dHfRAvQ6obVsWi0XnHqcRQhJtgNgO1qhSRsAn3UPwqdlkG8nLHJ1p2rZlNV8mjYTSjEdjdg92GRUjXHTM6zn3Hzwg5hGhwXSW3EVRQCnZXe9BjBRlgW8t+axIIvXMMBqNuu9YpyyGlEzKXQo1RUaNRDMuRyilGY1KECRN0WLJ6fyU1XJJWzdkef+ZOeXuJfaeeQ4hZNeYNJVoRedYtJG6SVqG+XxOdJ779+8P2ogDWXC8PE1Na6uKpqoxxnD9+nUuXyoRWUbtAg+OK5A5JssJ5YjY6XhQiiglUSmCcwTRoApSOVeMhHBKkEmbprpsZescwQuchSvXr2GbCmvb7hwLRBHQhcYUmtG0xIcZTdeYt/9z0SWr3Y6AtG1LXa+ZzKaYIkuGCY3DWY+LMbmROU8UAecC49GYvf09pE59gQJ0+q4cnWucbWialpWtOTmdDw52Kb8Ru3Opvx6SLm4+Xw4Zrr6hZ192mnoieYzOqEJNaxsigRj84LwnRdLNRJ+c54oy5+DSi8QYOV3MqYbeXPHsWlQCqRRBgM6SpXQi+BkQaNqK1jZ4b1FKkJsMKSNKgIiJFPuQXNtk1+tJaw1BEFxEkAh12R27uqq5ffcui+WKdd2QFzm5Kc4sOiMDmXDBE3wcdER937B+4qHXKvb3rb60tq5rsixjb2+PK1euAAwZmxACe3t7TKdTlqsVN27coixLLl++TFmm+16vIdRaD5bXMWbDPaefqFmtVjjn0Fqzuzvj8JlLg9FEUy3frlv4FltsscUWW/yu46kmP889/xzFaIpSitVqhTFmEAHnec7NmzdZrVbnLK+Lohg0CX1ZyWg0BhTOJaODZ599lne84x0ANE3DyclJNzOdD1qYqqoGR7k+SNnsvh6DZro7GxoW9pqh3d3d4X13797l6OgI7z07OztcvnyZw8PDs5KzTpfUmw+slivu37vH6WkKyLMsG9zdIAmU+9K509NTmqYZBNO981lVVQMZUkqRa9M1K02ZibZpMdmZZbYQhuUyBbgIsMERRArCA442JF1PjB4XPS5YZpMpk90pwTtsZ7Lg15b98T6+mOKsxdqWYjLCaIPuSgS99yyWc5p1g3UWKSDWkhWeZu2o1ilzcnp6ynhUpgyZT459zjbs7EzZ3d8n+qSdcjbgbESIjMxI2jYJwX3wVG1FXhZcOrzCs1c0zjsIkZdfeon1ao33jrq2XHnmCrOZT5mVGCm6wHM8HiddmPcEYZgv19gIwXoqu0pub52VsxQC1828a5VKDtfVmqOj44G4qM4QY7VaYZua4Fpy5QmuhphKmooy5/DgMvsHe0wnqYwxyw1rB6PxmNwYXOu4dfcmbW3J8tTbyoxS9q8JgrZqaVtLVdU4lxrkaDPG5JLgU4ncqnI0d47JMpWOuW1xrgVccvXTsstWprFSmc7oA0KE/x97fxpsa1qWh+PXM7zjGvd49jk90N0YUcJgiaZDTCwIlIDGKgL5QCRVTgUmBaaEaBQrUdFUkWjyK2NiyZdEqIpEY5Voaf6SIhogli3RTlGoQIduhh7OvPea1zs9w//D89zPetfpxl5bpbsPvnfXrj5n73ev9Y7r3NdzX4NuFIy3+eaMg0uBnnDaF4DBgGNdw2UZGQalBKwBmsZgMD7AYZKgqAuUqxLaaueQJyJkWYw4zvyCgkVVNyiqAixOEHGBiFnkeR+ARVTXqGuFurEA00jzHEIKt4+q9ro8gSTOoXWDslqjrgow7gwPBJPopflWtgBjDMxyZ1aQClSqcSDw7AxKaxilAc4xGA0RxY4qaRoFEUeIROTAGwNUpbBcr1A3BYr1OliUU64PYyx8XtHCQRzHbvI7GARaHBmdkE6Lnu+yLGEs0O/3sVgs8NnPfjYs4kRRFCbHRGu7fPlymCARgJ5MJlsTpzhLcfHiRQgpUJerZ+wzvquuuuqqq67+suu2Bj9N04B5KtETTzyBsiyRJAl6vR729/dRVRXKsgSALVtXcjADEJyUIpkA4FivSywWiy1uPdlh0xSlbUNNoIh0QNQ8RJEA54CUMZLETXtoBZcmRePxGEdHR1itVuCcYzgcupXs2Sw4zGmtA4DjjEEKiaOjo62pVBRFIaNob28P/X4fN2/eDLbeBIho9Zj2xViFigv0+z0MBj0cHe+jKksUlVtFL2sX8qh9UyekRJplGA57MH6F37m+OXe9qnQi7aosMRA9DLMeIHMopgDrqHtaNVibFSbzCcrpCixNIZIELLIQ1iJrIiR8ACROwyOiBCLqQaeAGrpmrLlw5PQ7DGEiouoEeZYhTxMIzpBFrnGP4wj9zFGBIm7BmRPNT+baUa7WK/AkQRJFEHGE591xB6x1rmqMM/TyHrS3KDZaw2r3e5Mb190xFyWKpsFsXcIwhtjTnRgclS6S0mt4YnB/7yWpyz/a38NWg+lAcYWqrqBUjUEvQ6NqGO3DUjmDjDOsrUC5KnFzVUFbjXJVoj90dE9mGa7PSzDL0E8ipGkPcT6Ajp1+h1kL3jTgSQNrGTiT4DwCZxLGAFq7PKH1ao046kFKDsMrNFihLFdoSo0kFY5uFktEvQhMROAgqmSDui7cBMsacABMA6WqAeYylTgYLKud5oUzMM4hwGCYxXR1E3VdYVWssFqsoHQDxt0UtdfLkKY5hOTQ3m48SiOk3hpbSIlFrZwOJkqRphIZ51jMS3CuwJjxQL+GYBaSR5BCgMURJE/h9EoMXEjw2Od/USaX1qiaBkprzGZLrMsCMnJmEoxxP+mNkcaOhud0R85SPk4SZEmOOHZ6rygWSK0F4KhpQrrJJ2Uj0efK5vmW3go/c5PX1TLQbEnDkyQxosgFuzqTBBf0Sws8BK7iOMZyucRyuQyfaaPRKEyFl8slqqrCZDIJMQFKKUC4cGUuOFTdub111VVXXXV1+9ZtDX5opdLx4g2KokRRlFivCxTFhgbjhMEC1m6S14WQng5Uoq4UkiSFlLFr9n0OD4EU4siTNexyuUTTNEEzRE1FkiSBduac4maQUiCKnR5nvS5a5ggWw+EIURQjjpV/z01CO/f2uNTgRJET2LOEhRBT47NXKImd7GyJSsQYC4CLBNFErQHcVCtKUzed0g2MiRAnESxzNr1N00A3ChYuZDWKpVv1F8w1tcydVykELHN20Mwk6MkUPZEiQwJrDWoN1HUFzgEOgdTESE0MVRXggkFwBmFd85whhYg98OQCGgCTMQxj0JGBahqkfkpkjIYAUNUVrNLQTQ1Vc/BIAlaDg0EwQAoGKRiYcfob57DWw2Q+RbFcQFcVsjxzZgGJ0xYRWBZSojQFdKOgmxowFrppoOoKTVl6ip5zouMyRpwmyNIsaH0iGSFOYsA6+qWFc52DNcjSZFtfBYskjhDVEnUTIR8OoYx2ons3QkIkImcarg2aRqFWDYpGwxY1assgwNGAu3slSgGZwIgIhjuqF2BhOQeXElpbaMugFGCMgjFu8lPVButaQ9QGwgB1rVFWGutSgVUKslIQogLjEhYJBOM+0JTBnXALzhQ4NsYeqnEZPVxKCMagjIHzCeBg3qSjUTWqRqOqa1RKQ4MBMnK/E8ewIkJtLNB4G2ouUCkDri0gmXNOs3CaIhk5bZMxkJFwyeJWg8FASgDGQDUVVONpaD43iTMeAGocuQmxYRbWKEcB1NpP4oQTBYF7YwkBLqQLJ9U6gI8oiv1XhCh2ejMOASYkpIwRxwnqOkGSpoiEcA583swAQJjwuKkQ96G5aH0+GG+uIv0ESKGuKzRKwzjDyPD5lGYZkjjGdDZDU9cQ0mnnpJRgfgFDKQXGObKyRJIm/n6ooYz2NFgDrXZPU++qq6666qqr51rd1uCHc4koSiBEhJOTi8iy3Okzygo3rt/EcrVEr9f34n4bnOHyvAcpBcqywmq1RJbmSNMMWdbDhQsnSJIEy+USk8kEs9kMg8EAx8fHGA6HkFJiMpls0eiIhrLhyy9RVSWuXbsCKQWy3Gl0CDAZYz19a4HFYgmAoalrzBcLXLt2FUqpQDsj2stw6IJTqUFxaesm8P/zXo6z0zNMJhOUfgLDOINqHICj1wsWxEZjvbbI+z0orXA2mWAymWA4HjvqoHSr6cW6hDYGWZ4jimMopTD3lJgocjqddDTCIBoglTEkEzgY7qNYr6EqhaJeo1o5A4mmcEGejDFkcQ6bGuRxikhGwfFORtJZggsnWK9Ug0Zr5/ilFRbTmQOgqyW00hBSoKwKCDCkaYKqdBM4rZzjHuOA1jkEZ4AxzuJZCoyHI6yWC8yWM5RsDaVqNFWNvb09mCgCZ+TsJjCdTrFcLlEUJTI/WczSBFmaQKkeFBhkmiHOcqR5D1na0nn4CVlZligKhtVqjeVqhaZx2UORcMGRunEueNYYN11qFNbrEuDMTcCEdMAqTsCc3Zpz2tMKi2jhs2Q4rAV6vSHSxIXmWuummUVRwhpnSsHhxPpVVaMqa5RVjbKsYbQFgmE4b5lw1B4M1zBWQzU1GtWgVgYHB5eQJA2iOIb01zFKEiQ8c3qvJPbP0wpSCh/uGTkjAf92DAxVXYOtl4hjieFoAMsspBCI4jgI+w04qrJEVddukpjnuHF60y9SAMY6oBCnKcDcay5nCxzu7ztKmjFgDEiSGE1dYb1cYb1aoywLdz7Kyrk5ZhmGA0cNkzIOeiYBCcEM9sb7SDJncV3VlVtksQ6oqGZj6Q0AB4eHiGTkAJB00ykGt2DhtmscLZY5I4hIikB3JTqb1ibYpidJEvR9WZZhvV4H8LxYLNE0NYqigrFwNudRBMkFkixFnMSQQnrQyRAnMbJ+D1VVIe/3sXewj9F4DMuAxXQfSZ7BGoOqrFDWlactArou8NAz8gl/+9b/74FPI2pZjH/pYk+/iS+zRcL8s0uI3YNotTZPv5GvONrd6U9KsfO2dbn7NDHnzc7bqsWNnbeF3d3II5fxztvqptx9F9Tu5+GEzXbetkl2p6o22H1/AaDWu18PznZfOLn3ntHO2z72hcXO28pzXLs02f0eZnL3Z3n81w533rYe3Lnztr/yv/7fztuqZvf9hdr92TDn+DxRevf7YZdPv6ba/T6/rcEPIKAaZ9OsGouqVFgtS6xWq2CD3e+NkGd9ZJmzDyaL6LqucePGDaxXp1ivKgyHBkLEeOKJJzAcDjEajXBycgLGWJjGEBVkPB6HSRBNZubzebCIJQF901RI0xR6UWA2XaLf7+Pw4IITR5eOXjfeO4DWGrPZDGVR4+TCHS5U0E9sOIugFXDt6g1o3Tjb3UhivL8XwBEBmpNLF4MomsTl1EiRnoToLwCQJC4klVa9mbVgPEHdwNP3ABnnGOa5O1frm874IettUe6scfStqlZYqwpFWaHf64EnApzFkCxFHrl9MRQIG+fY2xsA2mC1WmExm6JpGuzv70MZAcldRs1wbx9PXLkCGQkMhn0MRwPM53McHB8gTVMMBgNorTE5PQ1UQDovxjjg12gDMI3GGNRFAaMVev0c49EeDvYPw/lzNr81Ku8058I9OQaDEQ6PTxDHMXTdBPpgsOOuK5e5U1UALKxuWkJ+FQw0sjRFlsTYGw3AOQ/210opxANnwkF0TKU8+AGC9XejGqhqiSiJkaUZeoM+8n4PxWoNxl3gqVEaq2KNqiyhigKrxRJNXaOoSvT7fUQyQtU4OhQASMYwyFIMsjQ07UJIZJnTwjia6NBTOx2tc71ehy/DmHN+K1cozSazB9gEmHLOcXh4CNRw1DlPJaVFA8YYRnkf+R2HWCzmKKsSg6ELgG1nAxkLl2fEgHVR4ObVK8h7ObLROABopQwq5WieEST2x/sYD8aoywp17QCcaoAo6mFvr4fRyITFAgo3Js2dUgrrxRKNUjBwGpq9/QNwzgDmHOz6eX/LJrquFRo0kMy5tc0n8/CsbOypn9yYjof0Dz0H5zI8l6vVKnz+AHDn0QPTyWQW9rvtCscFh9YG66pEkmZojMFqMnXPB4D+YIDewC3kVHXjXA6vXXPnWGtoY1Cs15gvFu4+UgpCStx5551IswxCdlbXXXXVVVdd3b51W4Of2XQBy5zAd7Vaoa4rABzD4RhHRxeQZWlYjeaceQoJCYsljo4uYDQaB9qYWw13Gpk2tS1JkpCoTroeZ7W79iv6brUmjmOMRs41jhqi/f09Z+GrNdbrlXeIc2Gqo9EehsOhn0il4FwGQTNR7vr9HqSMoJSbDIBppGkSuPx07NPpNFCotNZIkiSEoNJ0qm2PXRQFzqYTLJcrkCNXEsfI+0Ps7Y3Dfi4Wc0ynM+R5H4PByOcDibB/xgCq2TiNgQFMCqzryrlbWQMIgSh1znjMa6ki4cJYpRDgaYwEPdiyRKEbrBZVaObySQqrNcpJgaJwq9yDwSAYQazXa2it0ctzd5xxjOVqhbKqUBYFGtXAGIvY67wYnAV6VZTeiS4KuUn9fj+4+ZGzl7P8zUKA7XQ+w+npKcqqcvQfb8X8mYc+i+VqDRnHGA2HODk5wf7+PgaDAbI0Q1PXOF3cDGCIziE1rkIImMEASZK4PCFrkXudkPNQgw+/tUGPJhlg6xq9NAlAi1uLca+HJo6dBquqYOMIJxeOkKR5WPXa2KRX4UspASDx17VBHEVI0gSxPxeMMWilIDhH4vctjmPHw7KAhXMv08bT0vTmvji7eQ1SSqRJCpEmqIsVoP1UJ47BrMJiOoWUAsNeDlVXmKxWoPGQtUBNz1zlJjT33H03jDbOsc5YqKZxkz3rLLitX9hStYYQEbIsQpblbkpktHOlsxZRkmI4ZmBgnsLmznhV1ZBR5cCPMVsOaVprp1cCI5M7d/8bC2Zdho8BQ1U4AMu5CzkV3OU1yUhCenol96CoLEtUlbv349hdp9obhhAw+9znPhdADhmZELgKuV9SIE9SDKMEwpso0FfkV+7pc4uMWiinTEiJfpbh8PBwK1soSRKAcWfbXp9vZbirrrrqqquunkt1W4OfXp7D8ijYQ1NRQ0B8eaKoMZ8DwjxHv00tAxCoXERZocaUJidN0yBNU/R6vZAPQ00yNRfk1ERUFN4SMAMMy+VqK+1+MpkErRBpeNr77yyalXPn0jUAg6oqQ2CrMQbL5RLXr18PdrfUHPX7/XB87RVt0gUJn7dCwYp07I4+ozzdKEa/3w/ntT2xaBsoKKWCtmgwGIT9I71BcMIzxjWYvuESWYYojiGkRJy4xrssSyitobRGWVfoZ5kLmYzdNc6yDAC8CDwNf26Dv9gbWbQnEZxzCM5gjQazQOopWW3DCqLfGWNQ+SabzCeMMQ58CEffYkkCGUXgguPOO+9EWdWI4hjD4TBMB+nYKSuFqJG0v4mnAcZxjMFgEO5Fay2Ev04ORLiATwEKutzcy3Xt3MvoHqYpAecc/X4P1rrxstEGVtitZpi+KFeG7g1nHhK7zKAW+CHgFUVReF6ogtV2oGvpcC6FcMdG96KbTLpsIGsNYBywYhywYCiLAoU3FYGn6dU+VDeOYshIoqnd86nshq4nhAS31mlUlMsw4pZvWYHT80lftI/0bLR/Rs9h242Nnv32s0rXrG07rZQz+niqyc/mMwEwemNMYD24zTJHO6WFivl8jqIoAs2NnB7zPA8GLnTttDUQMkKS5mAEtnwYMgUt0/uQWQp99tDnRJ7nT8pqWq2WMNai6dzeuuqqq666uo3rtgY/aZbBQIR/yAkM0GSmqqrQ1JHjUbuZpaaG/uGXUm6CT1sNLwEVytig5pDelxpoAGFlmL7W63VYVS3LMvydXrNpGgyHw62mm0AXvZ6jyDkaHeMWQrDtQMMtsOSastVqBSEEqqoK3x8Oh1vNUq/XAwwLoIhWn8mUIffTlDRNQ3NmzIYmFEI7fZPbNE24DmVZgjGGNE1Bga5tMCmEwGw2C5Qwl4GUBrreBrz6MFnuNDh0ndrXmr5X13VYOacJ1a2BrYIzMFiowRBxJENTS0YQbQqT1jqE27ZBJdHTCNhZBmR5HxbOzYtyVKiRbrtt0fWlKWLbiCL3eTFau8adLMjpvNF5FNJPC/zxmcY39LBoVIN1sXbalTSF9OCkXnnLcWPDfrfDfgko0j0HYOtZARD2k64P/b0dstkGBgQUKGC2fd2Idke/R+fTGoPau5TRvQDAmTNoDRm5XCsZRVDaPT+N9uYJjEFwty+NatB4QK5qFaYnbZfE9r5UVRWOjYAPnSf6cvuht8ARHeetzyDdl3TeCDhtNHcbkESAtWma8L5RFKHf77tjlhJVVblJaSu3azweYzgchueZ7K7rpgHz15UmhbTvBL7pOUzTFFVVhevWniLR9qWnvk2mM9RNg7rL+emqq6666uo2rtsa/Mznc6zLBhMv1qfJA/0DTo0kNemUs0NFTQSA8A9+lmUYjUYhRLTdVFPj8KlPfQrL5RKUtD4YDDAcDrdWdqmBmc1mXkchwmSFmo7BYIAsy0JjprV2mTV+5Zy2s9aiqmLnliYAKXlozLMsw9HREe64446tScN6vUae56GBaZoG0mfJEJVGCIHJ6SToN2hFmahycRwHrdBkMkFRFOE8CT/9yPM8gDAAoQEDEAAepdLP53OsVqugZ1qv1xgOh+GL8kfaYJJzoJ/l0MplA7nQxXEAlpPJBMaYoP1pa2wI6NFqt1IKUgjEkUSWJP41mwBw6ZgIDEZRhGvXroXGlEArnXeafiyWKwyGI4BzJ7JfLremgm0ANhwOceeddwbQQBO02v8eUdDKokDtf0ZghGiVdK/R1/7+PqbTaQDWBwcHABzYnk6niKIIR0dHWCwLFF77UhTF1v4JIcIxOp3TAEVRhPucXAWDrbnfN5cFtZlstIFVGziRhobAKV0XAOH1B4MBluslmqJx4b29ntenMW/BXSOK/ZQudVO3s7Mz3DybuHtruUJdq+DSx4VzI1T1Ysvyne7x9kKHMWYrJ4vOOT3PbeBC+0zP9K3TXyqa4LR1Pu3pED3nZGBSFEXLKXKOo6OjMCGkIOP9/f0w7aRzTNeNJlVxHLkPCgBVWaL2x0SLNjTBpsUNWoQg/SJ9FtE0lyIDCr/oUSx3F1p31VVXXXXV1XOtzg1+Pvaxj+FnfuZn8OCDD+LKlSv44Ac/iNe//vXh59/1Xd+F97///Vu/85rXvAYf+tCHwt/Pzs7w/d///fjN3/xNcM7xxje+Ef/+3//7QK/atS5evIgk6wdxeelT3tuNCYEXavayLAur+o4W1A/UIfp9ahpppbhNb4njGF/3dV+Hs7OzYKqgtcZ0OsVqtQpNNjV2aZpif38fd999N46Pj7d+jxqyfr+POI7D7y4Wi0AbI/BWliWyLMHR0SGSNHZic08dcmGVQFU1KIoqNJh1rbZWnzmXMKZBXTsxvRACz3/+VwFAWPXv+YaTzgOJrY+OjgJQpHNBUwkCTwQ8AGxlKVEW0uHhYWgsi6LA9evXQ1NNkxcCjgQYmqbCF7/4BYxHI5ycXECWZSHTiYBQVVV49NFHA3jgnGM0GgXNDdHZ0jRFJCVgDK5fvx5AVpZvqIHUnJZVjdW6QO3pf2mWwVqEVXNtLIQFsryHXn+AxXKFpq5h/bHS65AujIBJmqYBDJI5BtGQCKxxzhHFMS6enIRmlJpTxligQdE9BCBo0uI4xuc//3mXL+Ob/CiKcPXqVXARA4yHqUV7UgNgC9hmWRbASps2SCG/dM8sFostvQnt/63vQX8ngEBTL7qHiN61XC6xXrvAYuGfUcYc9a1pGly7fgPz+RzzxRyz+dyBj8RNuKSMIIUDI3ES++9JLOerMN1q7+fGQtrtEwEPmti1z3kbzNJnxa0Arz0xpPv87OxsY9jQmlTSPU9fBMbo/fv9/tazSDpEWjChSWn752S0si4L9PoDHF+4iLUHVAQw8zzfovXS5+hsNgvTbAJTdB/QAszd92RuP2Zn+Pyvneujuquuuuqqq66eM3Vu8LNarfDSl74U3/M934M3vOENT7nNa1/7WvziL/5i+Dut4lO9+c1vxpUrV/DhD38YTdPgu7/7u/HWt74VH/jAB861L+3mUikVmhlqXlwg4Cqsngf9RauxoWaDVrJpIjMYDMJqPb0Opac/+uijABCaFhLEt+lJBKiIftTr9bBer1EURWhuBoNBoN0EwbqnEhF4IMerJHEr51evXsXe/jjoadpNEIWaApsVZmq6yDqX3oOmOwS4aJu2i1m7KQcQJjp0ntt0p+A05WmANElonxNq+ADnnDUcDrec6TjnQYC9ub5LTM8mmE2nuH79GgaDQZg+1HWNxx57LDRztO+z2QxPPPFEaFizLMPBwQEuXLiAvb09DPp9XLrjElSjwgSKwO6ttLu77roL0+kU165dx9nZGYqiCBMqIQSKosDV69cwmy/BhQir83Q/0BddV5os0b0VRVE4f+0JgTEGN29uDBLaDmqkU6GmN4oinJ6etvQ1IkwHiqKAMcZNFLUCY5vppDFma2LQpoO1gX37/NLzTMdCjXGbDtmeBAU6m5+S0nkhq3a67oAT9zN/byRJAuufIa1drhGBJzex7aHvnx9lLJTWqOsKhSrdNTc5cn/925q1J5kDtChhN27cCNfq1q+2timKovCZ1tYN0UJF+x6iiREB6zYAbAOv8XgcPmto0aEoii23RiEEbty4gRs3bmy9560aJjCG07MJHn3sCWd40aLwJS0NF7k+TiZuckbPIrlltj9HGGOIU0cBLVfzc31Od9VVV1111dVzqc4Nfl73utfhda973Z+5TZIkODk5ecqfffrTn8aHPvQh/OEf/iG+4Ru+AQDwH/7Df8C3fuu34t/+23+LS5cu7bwvk8kE2vIAMsjNjKYnRImif7xJu0JNz62idmrobm1ICWRsHM5M0MJQM0Fg5NZpB/25aZpA92qDG1rxvlV0TO+ZJIn/HQGtXYghZxwWFgzO1Yox5ly2rIFW2uffyPB+WikYa1DXDaqqhFIu7yWKI6h6o+UhUES0JQBPWsWnJpamKdRAU2NMBgykb2mDQXKxosaLQFt7YkSr0XQ+pZRIswywJtCTgvOYbzattUFDk+d5uCaktaL9oikV5xxS9FE3DcqW21ld1S5/Bi57hnGGq9euYblYYjafYTaboygLaGNQ1TXiKPb5N25CArax/07TdGtiQPcRTUs450Hj0b53bp06GP9lvdkCgSD4JjfyAKQsXR4TURfTLINoTSy5EAATAfwQGG430G0aXHsK16Zq0fmm60BTxvZ0o00fJCBMv0dUv8ViEbYl+pnT9EhEZCwAhOdZ+ZwBKaUT+vd6yHI3xa0ahcqDhqr0Rhv+OTTGIE2yJ4HIWxdKCFy0F0W2AIW/Jwmwtml79DM6XwCCBudWkwM697e+dhsg37o406YSEiht6wpvfX8mXN5TYxCANrChodL+0WeNECK4JtIzRvdG+/NzuS7c9ajWO39Gd9VVV1111dVzrb4smp+PfOQjOD4+xt7eHv7u3/27+Ff/6l8FHcIDDzyA8XgcgA8AvPrVrwbnHB//+Mfx9//+33/S61FzSjWfu5XHxx57DCJynPjhcBi2nc/nePTRR/H5z38+aFdIUF6WZXDVouYjTdOgpSBaEXHwqdkhMEO219TcKqUwnU6xWCy2xNREMaEiEEHApk1fausRaHJC+7yh7yUeELkGebVawTlgNVBq05TSynGWZZjNZmGy0zQNbty4gcnEaXzo+5wxONtf1/yenJzg5OQk0Ki01luhrgRg2noamh4QJej69eth/wnE0fHSeSQNCLChWwEIon7XPMfo9TKM+wNEkUSaunNAmhoCtNRUkmsbNextChI10aSnWfp7KEyvLCCiCNAtZzCl8Yd/9OAmbDbPYYBAhyPR+dHxBZyenaFsrfrT9afGniaL6/Uap6enATw+VTNOzWbuwTyd97YjWHu6kqYp+n5S2daO9Xq9QF+bTqcQIgbnIgBBmjS07ZsJlLYDcYMJQ0tTRffbfD7fOscAghaqDSCm02n4HtH9aFvaT3c+KC+nhsFmmkdAMfJZXU4TlLtjMQZKaTSNQl35KapW0P46kq34rRO2W8NEj4+PA5gnCmzbHIXOFT2T7ekNgRq65+m43dQ2CeCcFkTaWpq6rjGZTJDnedD2ED2t/R7tZ4wA0VOBZm00mJCI4hSiNWmbz+eYTCbBxp8WLA4ODramQ5TB1DYzYYxhcTZxTo1m98C7rrrqqquuunqu1V86+Hnta1+LN7zhDbj33nvxyCOP4Ed/9Efxute9Dg888ACEELh69SqOj4+3d0JK7O/v4+rVq0/5mu95z3vw7ne/+0nfN8Yg9avscRyHCYSUEhcvXsR4PA5UjjYNjlZTqVEdjUZBg0ErpdToEG2pnYtRliUODw+dC1lrtZjocsPhEFmWbTW2aeoCRalxpH2lhovE+/T/yWQSGq+qqtDvb8CGMW4Fl5pGALh69WoAbKRvms1mQV9AblsHBwc4Pj4OmgvVbCZRRCez1obXon0jwEQ0q3Z+EIDQ4HHOsbe3FyZxJKomR6v5fB4mA+QY117xpp/TFAcwkGAhoBJAuB5tI4t+v78lSL91IkUmBVq7qVfm96ndpLebV/o6PDwME65bnbIIbFy+fHmTX9TScdAxt1fSB4MB7rvvvnDftGmHBACp2SdLbKJVtmmJwIZWRdeZzDfonjn1wa8EMBjbGIDQfgkhAkgjWmhRFPjiF7+4lS/Tbopp/+gZaU/x2iYjZM9cliXuu+++MO0SQoRnLjiUecppX/YAOLqehXN07PX6YMztFwFMB47cFKlqFIx1dtdxlLiFEO7NFIwFZ+JJrn0EcNqUzfb+lGUZzg3d5wSeKQuKrkH7d+kzoz0pa9tj36o7os+t/f39cJ211rh+/XpwoIvjGIeHh8EYpK03altmh2LAfLnC9RuniPwiD0289/f3MR6PsVgssFwusVgscOPGDQAbOl9ZluE60mdYkiTgBPrYbe2T01VXXXXV1V/x+kv/V+xNb3pT+POLX/xivOQlL8Hzn/98fOQjH8GrXvWqP9drvutd78I73/nO8Pf5fI677roLL3jBCzDaO3xSPgetdM5ms0CjIsG7awJZEAiTHTY18WdnZ1s6HHLPOj4+DuBpvV6HlVjOOXq9HoY+kZ4a5dlshitXroTGczQaBbBFQIqamM9+9rNhukLNBjVJ1PxSmGlRFMiyBHt7e2CMBUAxn883ds5+JXi9XofmaTAYQEoXokpi6rIssVxswAhR7Mgem1a3icbGOQ9NfNtQgqYVdO7X63X4PjVXVVVhb28v2FnfvHlzi3ZIdsIEPKuqwtnZGabTM+yPRhj0+8jzLAApmvTQFKA9daOJW5uKBWwa1bIocHrzZtgX2ndytyPQFEURjo+Pw0o+acPaUyYCA4WnnbUnMm2aE1WbwtQ2EyA6F92b1lr8tRd8dch2qcoKVeOAaSTlVnhlUTmhumWAMm4y109cc260Qd3UqJoaDBqU/En0O3o+aDIBIBxrW8BPjTBNQAh4npycbFE16XgpC6sNOGi62KZVBhqfvz6DwQD9QR+r1QqL1cpfa404ds6MjdJBx8elo42meS8060SBtbBg3iXtxrWbW1o2Mp8gumGWZWHSQhM70jLRdabcG1pY4JxjNpuFCSfR+WiiRCYrFJhbVVX4vKF7iyZ/RM+8lR7XtkefTCbh86z9Rc8Q6a2EEEiz1GUl1W76RftEn3N1XYcA5IsXL27d/7QAQiCI7k1rLRLjrr+uiz/X5/hfpZovF5DN00/I0iTd+TWbxjz9Rr6SJN55W2PUOfahfvqNfHHwp9/IF7PV02/k63l3Xdx5W6uap9/IV57s3g5xbp9+I18Cu5/fst49Q2t9IX/6jXxNXjDdfR/K3a8xABSr3Y+P293vYVUvdt723r3n7bxtGu1+Xwqx+7bqHNcZcfT02/j6wiOf3nnbdDTaeVsZ9XbeNsmGO29blLs/y9rs/hztsqWqdr8GX/YlvPvuuw+Hh4d4+OGH8apXvQonJye4fv361jbkivSldEJtuki7bty4gXXZbK04twXDi8ViS+Tc6/Wwt7cXXqvdDJF4G9iImKkBaVOskiTB0dFRaGLamo72lGi1WuH09DS8xvXr1wNVrg1wSBMRx3EAVm0qDQGYJKEV3BrrtQwruQDCSi3tB4DQoFPTQ01SezpC1svUsN7aqNO+U/PXDl0kYEH6g1spWW3xftvd6qkE+wQ4qMmi43dN5QiDwRCRFFvApN2Mk5kCgQG6JnmegzEWrkebGtSmC7UpiW1NEecuL6mtb7q1aLuez2QhKh9NQgBsnRsqOmdtnRc1oTTZIXBE541xdyxlVcF64HyrloTOB+1rm4pmtQvaFUKg3+8HzRlNgGiyVBQFZrNZuL/p2rX/T4Bzb28vTM/o+Gm/CDwLIUIj3dY33brfACAk36JD0jHQPvZ6/j5UCo1yz1qcxGGqxZlr8MuqROMnV4wzSCafdE/SPUQUt+FwGO6j9j1A009y7aPjd1RCERZOyAadrheZbdB5pWNsu0HScdL92b4/2hOpW80TaDGHABIBl6Zx+UbaWDSN3ppI0ja0P23dkZQyfBa1r00bAFvmzp3S5/hHvquuuuqqq66eY/VlBz+PP/44Tk9PcfGiW615+ctfjul0igcffBAve9nLAAC/+7u/C2MM7r///nO99nw+R1lvphBES6LVchIRtw0L2m5OVERLapoGSZIEm+l240cNPNGxiBZGzWPbJnu9XmOxWIRJSFVVmM1cNgbtK70O0cTSNMXp6WlodqnxIEqQo/OJsMI8ny8gpQBj3Lt55SGw1TWNDOPx2AOrJFj5FkUJY2xY5U6TeKtZblOZqFFta5AABOBH1DOaAhDFajweB+oXHQ+BCwJM7e+3jSSosSTQlucpEhlBK2fWQNevfe1IR0RNG01OgI3WivJqgpmEELAAOAEg1hb5R63z4SeHgnKMDBhz/2+UAvOvL1tC9nbjTwCb7K3pXqSJS9seuu2MBzhDDxlFXpdloI3BulijLCtYY8A4RxRJSOEtm8lwg4wmrAXsxvbdArB2I4ynKVpbV9QGtdTAt13qiBZK+0kggp4fauzbIIJAODXxBCpudYTjnGO1XmJdrMN1pX0joxAhJHo9FzS8WC3dcyEkmL92gjvg0SgVRPz9fACwjdsbgVmaYtJ7tE0D2s6Qbcqmm7y6SVHbpIT2tT3RovuxvUhC08U23ZHu0zZ4pXumDZDbGVQ0dSSqqTEu22q1WqFWzs6ecbv1/LYBf9vsog326JlvU4PpWdLWg2m7+2pdV1111VVXXT3X6tzgZ7lc4uGHHw5///znP49PfOIT2N/fx/7+Pt797nfjjW98I05OTvDII4/gn//zf46v+qqvwmte8xoAwNd+7dfita99Ld7ylrfgve99L5qmwdvf/na86U1vOpfTGwB81Vd9FeK0FyYobb59mqbY29vDcrlEkiQYj8dBAzSbzULgJuAAyWKxwHw+D1OhPM8xHA5xfHwMrTXm83loQNp6IAoNpAaBVlKzLMOdd94Zml9qdml6RM0gUVAAYH9/P9BPKFmdhOJODyAAOEBFzRkBJABIkmyriRmP97ZWfYFNQj3gAkQvX74cGh1qqMitjChydHztFWI6fjpmau56vR5OTk6CBqc9XZvNZgEwMsZw8eLF0GDSayRJsjXB09ri9OZNcM6QpgkODg5CeCuBtr29PRwfH6MoCpydneHGjRtBO0RAiTJMyGr5rKgCZdFRviQMGJiIIMVmMtMfjgI4dvSiyjtqGUjLwLgEZwzXr1+H1s4EYTQahanKer3G2dkZJpMJlFKBelmWZdBO0YSDwAPgGvXZbAYDhAkHTTPbVMus18NnPvMZDxSdFoVANRhgrIVSbhoQywSciQBQ6FrSNSDAqZTCHXfcsTVpo+tD4JPusYceeijsLwEHmn7Q9xlj4T6i4yDtHU09iWqmdINGbe4rcnojq2vGRQAuZ9MJpJToMw7pgXRdOeC2XC1ReE2P5FGghpEVNS0+EP2LLOUJuFJ4L4F8osAJIYL2pt/vh/u5DVrbuUzT6TRQ8WjRo6oqTCaTQINjjOH5z39+uBZ0v5LmTkoZrOHp53R/0sIDgAA4G61Q1Q2S2oHztoNfe0GHrmm/3w86sLaxzGg02pr2Xb95E0ppqGp3ykZXXXXVVVddPdfq3ODnj/7oj/DKV74y/J20ON/5nd+JX/iFX8AnP/lJvP/978d0OsWlS5fwLd/yLfipn/qpLdraL/3SL+Htb387XvWqV4FzF3L6cz/3c+fe+civTBZFgclksuWaJoTAtWvXwgosTR0Wi0UwRRgMBjg4ONjat9lsFgBBHMcYjUahASJnLaLH0AowrXwTFSXP82C7favrWNspCnCN0rVr11DXdWjG2jqAvb29sPJb11VwaiLXOVqBJrMG0igQ3YvyQpqmwd7e3hb1LI5j7O/tQeuNDTCBlMlkguvXr6PXc7xQaozbK/W06tymBjLGcHp6GnRRBKQoY4dWmimstO3MRiCDVtknkzNUVYnn33Mv8iyFEHyrWSZL6/l8jocffniLVkYglUTdi8UC+/v7ODo6wnA4QtMoLJduckC5JhQMSuCU9oWAAmmASD8FIJxjoiYKIXB2dobVahXOzXA4RJIkODs7C1OENtDRWm/l5YAxWLhrEWdpAFR33HFHmCa2tTh/+2//7RY4K7eeAQLJABCxCLAsXIO2Ro2AAU0GqEkmAX7b6a1tuHDp0qUnUe/omAjsaK1xeHgYwGi/3w/PDX3RvoNZgPkJg3/NNI0AuP0uKweKG9UEwJdmKaLIgfuycGCNBPoAYGHD8dIxtTU3k8kkAAm61/v9fgCxVIeHhwHw0DUfjUZbVMC2/o3Oazv8eLlchgnp3t7elq6vPZ2hcNF2BpczPukHYElUUbrOFNhcVhW4lEjSHAtvjU2fRW3TFwJ6tN9tmiNlp02nU5ydnWGxWOAlL/065HkPTbk5J1111VVXXXV1u9W5wc8rXvGKrSbz1vof/+N/PO1r7O/vnzvQ9KlqtV5Dxs7tLE1T7O/vb1GI2qv91MySoJcaWqLKxXEcxO0kbm4Dl/F4vKVVSNM00JrIsnq9XgewRQ0FuYyRkxOtPLdB2a26m7ZJAxkrOHBgIUQErZ21b1lWsJbBWvf3opj5LJ8qHKNruhoIIWEtvDucs7eOIoksjbFer7FaOSvc69evYzqdgnOO8XiMr/7qr8bJyUkQiRMliKY/ZJJADRqA0IiTMxz9nyiJWjtRPukoaMrTNE1oit05YMjzPKyotw0YTk9Pw3vSKjiBFjKq4JxjNBphf38/3DOcczSqQRQnSNLMXQMuAMYgZQwhRUs7VaNuanDGAXAwLgDGsS7K1kSrQFGsoHWDPMsCwOp7DRCA0NS2XQRpwtUGQ2E6ZwyUdpO1dVVuOdJRs9zOmSIQR9sRuG3ba5dlieVsBVW7xvvg4ACHh4cBKBNVtH3/tl316LWoaabGmdwK2/SoNhAmoEHPDrDR8NxKtdNaw8I4swLGWlMLR+90184BN8Y5ch80a40NJgKDwQC9Xg+NVmE62e8NUFf11gS2nWkEYAuwtO9luj/JGIXOEdlQ0zNK92FbB0efSzTJJYBF0zQ6/qIocP369bBw0ev1wucLsNEm0ucM7TO9F7Ax0nBTrxWiJMF47wC1d0Mk63qyor958+bW7xKgItoqnRN6louiwKc/8xn3mdcZHnTVVVdddXUb123tWbpYLJDmCI0KTWs45yFIsc2Vb6/KtkXUBExIrzEajcKKN63gEz2Jmkqil1GzSHSxduNEdLS2OLlNgyPTAtLqtBtYWgmnUEPi6RdF4VesAaU0kqQM0xXGeMj8oUmQK/e7q9UaVVWHfeAciKRAXVeo62prouC2X2E6nSJJkgB+aLLVntjQpIGqrX+gRrltj0yggBqu9uQA2Ba6C8EAWO9mVQQ9RHv6QM0ngV2aalFTR6ApvL9SPvDT6XvamS3UzLr9Esh7vS19CoHnNhjI8gzMpsiydMvogBz9AAQqGAFuAOE12uGgAIKYP4pjwGzOXxt40Bdpudq6mzbFi5rmpmlQFw1gECaZ5DZI+9vWZtH9334fAvQEZIg2127kaXrQBgZtC+9bp0i3giZgE67LW+5xVPRaABB5R6tGb/J7GHwejthk32ilw3HRvhFFjO65W7VPbdOTtj112zCBrldb70Tnve1uRxbhRA2l9yXwslqtwkSH9DltWmubXtoGVvS+bQ2PMzxoYOAoymuvGaTfresa0+k0uEPSsbVNLwjstkFelmWwxkADIQi4q6666qqrrm7Huq3Bz2q5hMEm9JMaTWrKaaJDq6kU+EgTIGst9vb2kOc5qrLEZDrFbDZDr9fbAAffSPd8E9wW51PDwRjDaDTCeDzeahZv3ry5Jf4mC+aicEnp7f8TGCLAQPSzq1evBkqc1s6eeOTtDKuqChQwMhmg/c6yLNgNk80uTVdIT2CtRl05MJVlKQ4ODrC3t4fxeBz4/9evX8fZ2VkAM+2AU2pM24CS9FekZyEqHp0veg1a5d7oOjYAoE2ZUqoGwLwmaxYaRcpSooacc2c9vFwuQ2AtsHHNaje1zqyg2tp3cvNrgzApJUaj0VbzfesEJMsy7O2PEMsIgNPXzOdz3Lx5E6enp8FO+vj4GCcnJ1uW0m1ntrbzFtEQe4P+Ft0Q8ADCGFj/O44qtpk6UE4UBdwSxS1JEuwfHCCNknANCATTRIlyq6jpJmpnW5QvbwEk7eb7Voe5Nggi2hdNEqi5boMRBxA4OPfgJwCYbdc6mpBZ5rZTZQVtDOqqRml8EKmU4MI9r6c3zjZGFx4MEzBqg4a2Ho7ALk3Y6L1pgaMN3ghskpapPc0qigJHR0cYj8eBqkkTO/pdAFv6Nyr6nKF7gBYhnspVse0c6WdnUAZYLJeYTqfBRbKu65D/RNecrju9N00K6fnp9XoYDAYbS/G6wOf+XJ/YXXXVVVdddfXs120Nfu64805kvSGstSG9nGhlvV4Px8fHoUlv63HIuvbq1av4+Mc/jpvXr2M0GuHY07vm87mbuFQVYC0GwyH29veRJAl6vR5e+MIXhiaYVu4BbDUjnHPccccdIYPn9PQU169fDyJ4WnXf398PVB3SGkRRhMVigdPT00Af2tvbw3A4xGAwCI0nucqdnZ3hU5/6VMguKooC9913X9CxrFYrzOfzoHPq9XrY399HkkRYrxZ+suQsxfv9/lbDS0BmsVhgvV5vHWfbCaztItXWFBC4I2BCUzIyeiAhOb0WrZ6T2Hu1WiCRUdBfkd6KAApR5QaDAU5OTrbsuGkaQNOC2WyG6XQKpRQOj05Q13UAKu28oXa2yx//8R+HFfs2oKTmmXRF165exc0bN3B6ehNFUeD4+BhHR0e4cOFCAHl0fghc0LG3LYaNMZCRhPE/A2cO3MBnWGmnG6EvMu1o7/d4fw+Hx0eh4Y/jGGmcoFxVKIvK5RydnuILX/hCCPpsB+HmeY79/f1w7toTq7OzM5+/NA3PSdshjc4RgTy6tm3KZJ7nODg42AIhBD6q2ul5OHcpIe64YkQRmQEwZ+KgNYrShcBazlHXTcj3ms/niJMY0k8W9/b2wkRsOp3i8ccfD/dX29GOqGbtKR+BMspzWi6XAUjXdf2kbKokScIzSmYCdIy0KEPPaNt97pFHHtmiAtJkk0APBQbTJKjtZkgg6/T01P0eZ0iSFFlvECaRBG4ITNHiys2bN3HvvfcGkExfBwcHW5bXWmvUyu2T4rtndXTVVVddddXVc61ua/DzRw/+EQyTsN69SXiqjvJTFAvXqGulHRXE/8NvjYHSGk1dA4zh+NJFCM5R1hXuuvtugCEYBahGoaoraGvC1+e+8PlgajAcDYPYWptWLgcc7QRAmFKkaYpr164Fp7ler4ejo6OtBoX0FySCv+uuuzZ2wULCaoPrN68jkjGGwwGed9ddeP6996GuS6cF0hraKN8sOmqco3tVSNM8hN9VVY35fIp+L8NyuQyUMgChGW+7gZEeiuhSNC2ghpcaWcDRcSaTCcgW2k3Gxtg/PIDgAsZaVGWJs8kkUAOljJDkCWCZa3bTBMe9HgbDAbIsgVY+f2Y6xXQ+d02rf/+ymePK9RuOeqQ1rDHgfqIgpYAUEmAIDbLWBqt1hSiJfRaMgoFFLATKusLS21JHSYyTo2Ms1yusi8IBjmKNNIqhjUGjGjRVjbMzQOkGWS/H3YPnIUlS9Ps9JEnqAY1GUThqodOxRKjrElJEyHs58ixDmmYwRkMbd++AWZRNjdlkjtV6FVbqx+NxCKnd39/HarXClStXUJU1los16rryTf0t+T8AJJOIPM1PCoH9/X0IKZHEMXr9PlI/jWCcI5ISBVHnvGar3+vhwskJjo+PA2VrsVgAjIF7jY4QAokHDLJFOZzPZgCBSE8BJRBIE0FjbbCsrusautoci5ROg3Q2mTogXhTQPtC1qGqwQC11E8w0yyAjr/+qnE12mqQ4GO9BWYO6KFErd7/AWIAzcLgsJc4FmLUwDEg8KErzHMxaFGUZwtZWqwXSNA/Alswx2gsBZ2dn7t6KY6RJiix3JiFlWaKpGxhtwIUDSe3PAHJfo2kU0era329TFmlxp9/vYzAcgguBWhnIKILRGrX/TBz0+zg4OHDnXmsorZEmCW74BQDjQdeen2LTdOxsMnHXB4Bpdg+O7KqrrrrqqqvnWt3W4EcDEP4ff2UNtFLgnEEmMWQSwwLo9/reTcpNWqI49uBIQWvltSFRWIVttLMjHgyHyL3TWexpSsI3kkVReFqNAJcSMo62mn/AhzlyjsViidI3ziR87vV6YUWZVo9vrfYUyVqLpq4hUo5BrwfBDsFFhDiOEEVuRVdwhkjEYIKE4jGUrlFVTtRsjDveprG+MWbo9XKkaYIkTVCWFbRWkNKt8svINcrSU5GMtf6cGZRlhaquwTnzFC7mgCYYZCQxHDqqWFE6OlCxXuNsMkVZFYgip2eIkxiN0gADBBfQDJgul5hOZqiqAsqvMmvtGmNrNFSjwuuBbayasyQNDWNd12CcIeIC3CEvANgCpUII9Hp9sKqAbhztyZDDHmdgcM28tgbz5QJKazDhMpGyPIcAg9UK0k/LenkPZVWgaWo/bRIQMvIGCQIWBkxIiIj0YbFvzBXqRoHxGlzGUKrGalVAa3et5isHfAiwWWtx8+ZN75bWQ57lSJMMVVmjqhtYA0gZb4Wyam283bMDJUJIwFosVyusvCNfnmWwjKGuKhRVBWuNo/EJjixJEHsdChhDWVeQXEBGEZLcaeW0P6+cO8vpJI5hGWC0RlWWWFelM3FjzJk5NA0ao6GVglbaAxDnchfFElJ6d8amwWw2w+npGYxPghb+/szzHFVdhaZfepCSpd5lETYscGilIQUHlwJxJJFFEiZJUCsHCFTToNEakXBUOcY5mPUucVyAAWjqClYbqMYtmDAGcFho7Yw5yIqd8piiSCLNUgghXR6RsagaBV47muBq7e5xxjjyKEWWpuDMmZdorWFUA1gDztz9miYx0iTG0eEB6noQzApIr7ihKkZIsxzGMpR1DaXd+aZ8nqauUazXiKSElG6auT8au2n4aoWyrNx0cbEIhhORlDjc3/dUWYOGd5qfrrrqqquubt+6rcHPcG+EJHMUk8aLvoWUiCI3EZBCYjR2OS1VWQX6SllVaLxuQ0YRlDcekFzg9PQUIoqc2JzeZ+T0I9pPUSxjSLMMSZoiThJESYKola9DX5EQvlm3wTo2yzIMBoOwmjudTmGtDZQbMhKg1WTAWdpaYwBjkMURelkG7kXKTVWhrhtooyCEhJACIpKQQkA1Neq6QlWVKIo1lDLgHBCCqEzCC5olsmyTeO80JNYnxW8c1YhqU3vjAAAwxiKKYhi/z5GUEFwC4OBcAmCoG2e2MJ1NEMUx8ryH4WiA5bqAlM65SxuD+WqB69duYDaboiipOUSguMHCgSCveRDc0dRGwyHyLPfgztHKNN/OXQIAzjgEZ5BgUEZDNxrGgwoLC9tYyMg1hcI3lKeTs0DVyvIc/UEfqlEwNRy9KIoxGA/BVwJFUaAqCyhtUDUK2jIwKCjVODDHLJgFtHWajKKqYNYaQq5RVg2UqjGbLZz5hKqxWM3RNBWEcI5nAIJ18nA4gh4ZT8OzkEIiSuNwf8G6fKC6bmC0dU2xN/2o6wpFsUbd1GDKTTvypoZSDZarFZTSiKMIg9EQcZIgzRy4sEqjUQpWuAmNYAxxkqDR7npw5gAGFwLauilkUZWYLxbIksRZeFsLow2KqgzPrDMocE22kD0I4WiUSmssyhLz+QLLpTMeOTw6xt7enreydg1/xAWEb+ZJG1V5UxHVKAjGwKwBrIX1gIJH0l0PWFiv0UkT5/YHxhz4YQCMdTS7poZRPlvKGlj/1XgwBFgkSezBLwMXAkmaYjgaQcOiKEooo1GUTuNT1g2sBaR0LoLOalr5Z7beyvgRnEEKd+/ySILBumPgHMPhIExqSYfkJldAJCSapoRgHFmSIo5ilGCYzGbQvEGSWrf4EccY9PsQjCOWEWqtYJQGuAPNsYwwHo8wn89hrEZdbhZ5unrqslbB2qefkFm7+z/Bed7beVuXCbdb1eeY5Bm9O+Uxz9Odt+VInn4jX2l8YedtFVM7b1tX8523jcTu+5vEu+dipabcedv+Bf70G/k6ErvvA7Exdi3Odv88OI9ZyrLY/VwYvft11nr3kGbV7L6/5TmejVrt/nw2rHr6jXyparXztrHZ/bqZc1zjNM123pax3c/DYr3DsZ3jeb+twc89994LmTgTAZqeEI8/jmMMBoMgaAYQBL9tnYOUEovFAoN+H+PhCNeuXQvcftIPnE0ngQbHGMMLXvAC9IcDjEajIJJfrVabZHoAUkhURYEsSXFychLADTm4uRXtU5ydnTkxsf850enItpnsa6uyxHwywaOf/xz6eYbca4PaTmrabsT70jdiquUCpo1rANsAbbFYhMDH4XCIKIrCBKUdoNgOPj04OAh0G6LFkLh+UpR46DOfdZqPNHVgTEhcvOMSLlw8gbHOzFgphcefeNjpVtZrrMsCjZ/ExUmCrNeHEE7jceHCBedIRXkwReH+wfYAqNfroZdSToqA1u442wGvURS5htZoNE2F+Wy25fhFdKO28YAxBqdnZ8jzHIwx5F6XxTmH0ioYSSxWG6tputfquobSm4BXypZqO9ORXoe0JeRkZ60BYP3krkCv18d4vIejoyNw5nJclHLmF5PJBAf7h+j1+8iyHFmaBSG9c+GzEMJNU5IkhuAc1hrs+5V8eu9erxf0WnQtiZJJ1DQwF3zZ1pnEcQxmObRSaFSNsq6wbp3POE1xmCSByknXn4xIbtXYZEmMOHamAuAcjVIAGKTcONHRPUn6l1qVMGSIIN2UiksRDCkiKeHuJBaMReiY2l9iOEQcxVv3gOUWHIC1HNYD0NV6hfV65UwjoD2AA6RwuT/Cvwb8IsloNPIW6QWKqgQDRxQ5oMU5hzLaZQ1VpV+s2ASx0vNcFAWqqsJjjz2G1WoVLPLH43FwsgxGHDKCEBG4kFBKYzQaBWMXpRQuX76Muq49BTFzGj2lkcRxoCSSRoiejSxLEUcC1hpURRdy2lVXXXXV1e1btzX4eeihhyDiLCSyt22I2017e3JB7lZxHGM8HofgzWtXr2I2mWI+nQXLX/rHfzweIzs8AuMMdVXj//zBx3FwcIDhcOgspjlDsS5C1ghx763WyNMsOEYRTWswGGAwGGA8HuP69etYrVahKaOmmByhghmAFDg8PMBoMAD89IOOtawrVE295bJVNm4yY61buTZeo0LnhjQEF09O0NQNrl69is985jNYLBZBhE26ErL5BhDcpm6l+SVJEkJfe3mOOIndyn9RYLVaYrFaYblc4Gw6wdlkgrOzM5fTIl12TpYlkNrbUVcWsBpRnmMw6OMLn38EDAy5n2qMR870IPKUnDiOEXtNBxkeqGr7fBhroKqNOcWFCxdg1MZyGUAIbqVzH8cxvuYFX+OmbkAwRACANE6wNxqHcxWA0HKJ9WoVnOg45yirEmenZyiKApF01sczCyRRvAVgi6JAEsVgDBCSo9fLsFjMwBhHEiew2oBHEYb9ARjjsAbe5trR1JIoQuR1WQwIjWya5LDQLQ2Hm9y1RfBa62AcQdlDSinMvb6KaJhOy6VDU06Ofm1BP4GLtv05vRf9Hj0ndJ7pGdWNm3oopbD201J6jjXR2LSGjCL0+m6RgAkJ5qeD1q9mMc7BBYfkAtbretqOf7RPbetpsrGnc0JmIbRYcXZ25imvAlnudUuR9PcYh+AOGM8XS8wXC5RlieF4jAsXLiDv9Z0Op66hldmEsDJPqWtqKD+pUl6vGPbN66GMMRiNRhiNE6zWazx++Soe+uwjAfREUYQLFy44M4k4hsOPm5wwMt4g5z0C63meY+H3lxaFej5DiZ7xxYJDCj+JLtZ/8Q/vrrrqqquuunqW6rYGP9PpFCJ2vP+zs7PQQJHrWTObId/fdyvI3pKXHLWMMfjiF76ASHiaCxzVpSxLZFkWhOJta13S4Nx9990uWd4DGsaYa06tDdunaQpdN15nIUIjSW5fZEs9Go1wcHAAAGE1nVZ+Kaiz3+8jSxPAWiwWC0jOtvYvsSZsr7RCVTe4fOWymzR4m1wpZVgNJ0BlrcV0Mg0NYb/fDyn2BAKoOacGilyuiKJHK840RWAMsMagaRTmiznmizkWiyVq1XjXLtegHR8fuaZXeFE+52Bye/pijIE1FuPxCII5mhUYC1Q1oxSUtYiEAJMSdVmiLgtwLiAFCf19M8wYRJqBC+60FfCUuJY9MzXFBAzX6zWOjo42+2I3IZg0QSSbcgI6nDGMx+MwyWmaBlppZFmGfr8fgDBNO0izQa9H1EwpGaqywMULx0jTDJGMgqV1lmXgjKNpFE5PTzEYjJwZBrzBReWyjAzX0I3CelmgrkvkPQdKGWPBPax93O2MKillOLa2/TeZXdDEiP7+VCGn1LzTpKs9ZSF7aLqPQyOepUiTOID7zZe7JhYsvHeceIe7Xg4pIwDM6Z98cw8FKMZgtYZWTmMUpqCtnKi2eyFNOmi/6FqRsUdd16g8LZH0Rm5Sm0KKyB2TjJDluTMn8K6OjLNwboNZSJK4SWWaIAKD4E6LR+e6fU7DPewXIUbjMY6OjkJmGIF4mnI67V6EXq+/5VRHgLUN9j73uc+FiTOBdnKDIzOKPM8A656VptydWtFVV1111VVXz7W6rcGPFJv8E9LvpEkCZBmyJEXJBWwUodGOimaNBZeOj68BqLqBMgYycgBF+MZnMBiE5pQsjgm0kOMWNXYAtgImKbSQc46IbTdSZItNLk1tgEHuUBRQSroWCjiFMZ5yUiASvlHztDCix1kAUAwGcJlDLTpRG/xQMcZgvB00CfGdBsA55znaGZx+pGlQNzW0MW4V2ppAo1sXayyXKxijnWOZbzLrpoZSGlEkkOZukpRmGSIPCKuqAvP7KL1WyZkruNfWSkNrBcEFuJNVbKhhntrGvRg8S5LQWEvGEFMOEVxsJmPcG0REYB4M0zkAKBvKON2F8sehNaw1/to67Y4x1gM048ECAk2Nvuf66sgL9wmkSu9aJgFs57fEnhPOGDyodhqyYrVElifOTdAylFUJoxSkd4wTXCKOYqfvCgGnboLAvG7FUf0sBGNYLd0Ug/kGu91YUy4TTWG01gGYtYFfO1dJCIHlcrn1OmSNTc8F3fME6GmbdhGYIlc6Aib0/DkGmQM8ZHggvKaBMQbOCCxsAn6NNe7ZEAJpHIN7Ewt6HwILbaBNeVD07LXBLmMs2Hf3bA7jr7VM3EJHJCMYHyDLgEDfHO3tOfv62GmeOOdgGXfZOkGXYcEMZRhtrOPb0zMCPu39bucJtfefQL+Um9yvduBuO6OJbPDJkIWmzbQQQ7baURShl+fgjKGpuslPV1111VVXt2/d1uBnPByCR5sMlV6vF1bXqbm+efNm+EecAAytRlMDmue5a6y9LmM8Hm+DBs63bGxvTXcnytJsNguTG601hr1+0NhIKUPSO4EaWumnpgXYhHIGcwFPaSnWK0ghIBhglHMiIw1JmCDEcbDbvueeewJVJuSH2A0NiVa8Dw8PQ7NFegrS/FDjI4QAExxM8M3EBIDSruFerlaYL+ZQukFdVVgtF76R72E4HGI0HmE4GjlzA+amPOAM165dQyS5NxmQm6bUGk8nk5AyQ7lcAcYBnTiKkcaRO69gEIIjSVKkceysrOsGsTct2AY/LFg8O4rUtvZpc+7lVoBl09RhSkH3EeXpuAlfDK2d7sxtV3hgZcMELctSLJdLH+7pfr5YzLxeDNA6Ce9nrQPqgnPkaQrAoq4qNLUKr6GVRppm4EzAKI35bI6iKFBXDmzS/gk/sYllhCjOcfXaVczmczRGhWtMU4jRaIQ777wzTD0Bp++he5sCeUkXBrjmmQJwb52YaK/PWiwWmM1mAeQT9bO9LYGcKIpQrFeoyiKEdrrtNbR2+9kfDLwtuMHV69fCfpjaORvOpnNH++MMQkqkcYJBrwcWMW94sAE67S96/toBuwTY6BmgBY9Br48s94HJ3p2tqRus16Wb7nrTgbzXw/Puucd99hgHxpy7ngsLbZRCWbmJWFXW0DqCMUk4l22QSICTPnPa+9gOiyUKJedmy0q8KIpAZaRne71eh+ytGzduYLlcomkaF9y7txeAL/3OXXfe5YB23YGfrrrqqquubt+6rcEPNa4ELLLMuUwQLStNU9x3330BqJDJQDshnRqh4WCAvfFeaCLKsgzaGGttSEgnu+p2Nk+aptjzK7z0+7GUjn7kJytpmmJ/f9+JpPVGa0I0OdoX+l6gqpFlsWoQCYEsTVEVaxS+aaLmVcQb7QIYCwAsfFkDAYTXbU+uCGgF62g/6aKmv2kajEajYL5ATRe9x2AwwNHREbIsRV1XePSLX8DlK4/j2vUruHL1CTflyvNw3QhULtYrDAYDZFnmsmCWC1y7dg3r9TrQ/Q4ODnAw2kPfA9vxaIietyDX2lG8Kg+4elmO8f440JqY1c7hjcwMmhpFqaGMgbGAueVeagdK0vkhQwj6GbncAQiAaD6fb1HDiDK2XC5D40i6tHYI7JYTndernZ6e4hQWzGjouvLidok4TgJN7frVq6jrBmXhwMXFi3eEhthawCiF0pssaG0QyRi9QQ+j8RiHx0ewzGm3zs7OsFgssFqtcO3aNVy7dg2cu6nE4eFh0OkQwKfFAro/hRDY29sL9zIBTGAzVZjNZrhx4wYmk0mYdg6HQ+R5vhWSm+c5sizDfD7HerV0r0M6HufS7CeVm0WCEFQqCiitUZUVZrOFp545sFJGMT770EMQXHh7ZxlABT37dL8Mh8MnTVziOA6UN9I3rYs1Vuulu0+Ey+zRymUOXbhwATKKg8X6cunMMEQUIc97GI1G6PcGLoi3LMEFd65sUQHmATl9fpGRAdHTqqoCWbrPZjM89thjOD09BblFHh4e+vDYGEkiAy2xJidMfz0p/Jie5eVyiSRJcMcddwQNFoU90+dfkiQo1o5SquvdXZi66qqrrrrq6rlWtzX4efGLXozYr6IKIbBerTGd+RDE1TqsVA+HQwyGAxwdHmJ/vOeExn76cuPGDS8QZ6jKElIIaMZQFQUaPyninENyl3mSpimmsxkWs5lrfr1BwXw2C2CAGlpdlBiMxxjv7WF/fx8zvw3gmqrj42McHBwEQwGisAAbakqg1FUVKmtRrNdQyrs60Wp7JIMDl/ZNdb/fR00GB3qz0q+tCeGv1PBrT+uqG/e6sDbksazWa6fXaBQsbJjQ0CRNKQXuX0cKAcCgrgrM51NUlWuShJBgzFliM85gLKB0jV6WoFyvMJ+eoaprFCRw95Se+XSC+XSCLxgbQir7XmvFfY6PYG6FX3pdRuSDbo21iHzDG/nvWy96N7CAkIHmQz9vjEK5XqLxx6WVxnA4AJgPym1csxjHMfJeD/1+jsP9PaiTYyRx4iY6S3fvJUnsaVrSUbm8C+ByuUJdriEzF0JrdAOtOJI4huQuR6duajAAJ4cH0I2j4elGoSqroFHKkhSjwQh33nEHrly+Fu4bzgVgLEQkkXg6ZxQliBKJOHIW3sbT7siYII5jDIcOVJL2JcsyzGYzaK23BPA0aSDt2N7eHlarVZh4lmUZANJ4PMZ4PMY999yD+Xzu7wURXBZvLWOcC93x0SGstWgCrUv7L4XZfI7ZfA4hhAfcGaSnlGmtsVq6/bDMWbAKLnDfPfd4m/MNEL6VqtoGpQTON/orGUAa5xxxEmE0dsHFENw/Ww2a2l2DWinUdYOiKDA5O3PHLSOs1w4okzEC2Yjv7+9DN40LGDXu+eScw1j4Z7PBeu2mb9PpBE2jEEUSh0cXcHBwBBk5YN7vDyClDOfsxo0b4TOpPU2iSS8BvnvvvTeAHFq8aZtfEKhllgHgUPXu9qRdddVVV1119Vyr2xr8LBcLZNaBE0clcqvY6/Ua6/UaVVWFZocoPgACnYNWvznn6Pd6yFvUHGstuKeclWWJ2WyGxWIReP9BOK0UBOcYjUYt3YVbpe2Px0j8NGq1WqEsy9CAKKVw/fp13LhxI7jGtR2wwhQHbjIjpHTaErOxljbWgHGOuHY8fdbafrVeoaHmrqldoKPWXgvhiix0Ay2upSGgL1o1Ztw1kjSJoskFNVXaGNR1BWM0ODMYDPoYDgdb5zxNU6dT8qvZaZpuidp7XlxPoITMAZbTeQhUzbN8Y1ttLeAnDpxz5F5DZbRGXbumtqm8TXjpsp2014YdnZxsJn9KhZBOAn+cMTApMPOW2HQtiJq38q5uJCSXUjoK4HKJ9Xq9NR2h/bt14kDW6UmSBDqZtQaR158RBSmKYheMKiWqqvLAI0WW5Q68ycRPZmyYWNAKvqNVWhTV2pkgABCRCPbmNP2j4F2X+yR8M93fMgpJ0xR5nm/dJ/P5PDTXNHkN+h1/nY0xGI/HW/dd+/4OZh1Kudwd4+3bWwsJ9JqVn2RwISBj5+wH7qiMNAW13k6beRMBoj3SggKBftoP6QEzfbU1TbdSI93z5fIq5vM5lKdoMj9hdJofDyB6PfQGA2944PaRMQatvI6HOypeVVVo6irYcdM9RsCMvhxtVyBJRAiyJU2gtRsjBbffjtpGE8xbTS3atDmafLWBL52T9v2aZ31wxqHY7jkZXXXVVVdddfVcq9sa/MwXC9QaAaBQg0DTF6LsEN/9Vsc3EvvGcexEypHTkiRpCli3cqx9c0KNqjFmsyIK5tLs4Va0jdaoyAVsvcZwMNyi1iiltihVBL5IZEwr7Hmeh++laeobYAnundSUkl4L5BzPLBBWiwEPCppN4wnGIKONW1jIMIENNC5qfNoNKzW8tMrfnvrcKmAnjYc1CpFkyLNkQ9nzwWZxnPh9dJOlKIpggybJGQZEcYw8y5H3cgy9Jfjk9AwwFjKKEEceiNDvaeNcqBhDP+8hz3zOTVliuVxh6TUnVbmxMAYs0jjxTnMbhzkAkEK0AmudtbPLbmJgzFsuKzeFqSoXwDmZTlxT6CdsjW/OScAPMERxhDiKEMdJoD4uV0swMKRZisQDvjzPIcitzhoMh0NkWY44TrbAj6M2uWsTySQcm/JBvBvapEBV1ViX1pk1aA1wBComATKiWLW/6Nq3p5lJkoSmuGkazGaz8F5tquatDnlZlm3dW7fmKW2sshWMdtTVxlO1pIyCE1tV+4wfD1SqqkKtNCw8DbJ29DwuvC5PRmiUcpbXHhgQhe9WvQ+w0dZsbMFVeH4DVZQBxmo3EbXksBZDCrrfNzqh4WjkPhvgnPiqskKl3DPHuAsTNtr4qTMHh7O1rqsKqr2fxi10BPc5b2Rg/JTUGBcqa6x1YK+lwWofI10fOndKKSwWiy3gSJM5OudEr43jxC2AYPfgv6666qqrrrp6rtVtDX6iyFnLLhYLaK2xt7cXDAXI2YhWNduUDmruiM+/Xq9RFgUmp6eARbCvpRV/qw32RuMwmdkf70EcHAYwRA5vZVkiUwp2MAzvtV6vg2CcKD8EdPr9Pvb29jCbzbBcLjGdTkPODv3s4sWLuHjxIuLYaxUsIEcj9AaDlijf0dPaAZUXLp64CVLL5U0p5WhVfiW5aRpEcQTuXchoInZrs0S23NQ4UfPUXil3DaBEJAWSWGBdLINBADXL1rpGz/jJQVVVEFEcrgMBvTiKnQmCEBBc4Pjo2DW7jZ9ENY2nNHHEUYRERmEfqJmXwjmh9Xs97I3HKC9cCEGv1lqAC8A3iO2QTToPNBHYG48xm83CJDFNU/A48ToPN/Xr570t0EBTCjpmOp90rWbTqbMP9jqS4XCIg4ODEFhJIJbDnSv46WYURSFkVOsN0CnKEoK7MFn6/aIosFgsUNcNtDYAt0h7OZhwYZukH6Epw2QyCfSmKIq2JoIETEgrQucqSZKw6EBFgLmdn0P7Ts+eUiqECNNENs9zD/wYjFZh8kNTqDzvee1Yz7khao0kdflKy+Us3P/FunImJr3cURPzHmAMZJaHe7mu6/DM0fNCEzC61wmg0nSEjlEIgcFwgOHIadW4d55zjnPuuVCNo8M6GuQSWZahahrM507TdnrzDP1+H/sH+zg4OMTeeOzACzaAcrVaYTweo9/vo58k4Xmkz7WYwKpfyKFr13iHPXKcI5MDAtbj8ThMXGlRaDqdBgokfaaR+18bBAoeg4GB291TtLvqqquuuurquVa3NfiRUmIwGuLo6Cg0sFVVBdpbWZZhpbRN1aGmL0kSXLhwAcwbGqwWy0CHo0wMysSh7xVF4RqX/f1gcpCmaVgpB7BFmRmNRgF4PVVjbK3FnXfeGUwV5vN5WDWmSctjjz2GsiywWi6xmM8RJzKku4+8roLsuTnnKKrSBRYCiBkQceY1FCrsJ02gJqdnW5kn7X2nfbXW4ubNmyjLEoPBAIeHhxiNRlsrw2QLbbRCXVfI8zw4RhHthmiCzsJabwJJlUJTN2g8TU03aqNPEO5YtdYofL5P23Y4SRJwb8UNbLJRmmoD8Oiau0Ba18ytywpoHd/29GGjkTg9PQ0TQzItiCIXVDoej3Hp0qWtLKh2Pk07QLUNuAmgtIEW3aMuBNMFXZblGkkUI47TYIqxCad00zKtNWAZCh/g6sCODtqO8ThHlvWQpDFq3WC+WmE6d2DOTZWcuxsF7bbBeRsYtmlq7fv3Vsvw9v/b9/zNmze3TDhoIWA4HIaJg1IKRV3BaBeiuzceQ0bR1nRu0O9jNBoBAMq6Qr/fR2/QoPKBv9a4c0w28EZrLGYOHJHxBIHI4XC4de0pBJTCgwFgMBhgNBptURinswkef/xxyEiCea1eXTco1vTcbazEl+s1+v0+wBjKqvYLHA70lVWF2XyOPMtw3733BQc2em8AW59bVVUFqiJN4obD4RZFlIDnfDbD1ctXcHx8HED11j3m9T4AghFHO/y47RJJX4I5u/Y62lAAu3rq4iwGZ8nTbqfU7hTCweDpX4+KwPwuFSfxzttyZp5+I1/2HBNCwfjTb+QryXffX1btfq8yOdh5W9jdz0NR7r5YcDDe33lbWgjZpWq7+/mV0e7bAoDgu5/j6BzXmYvdz3F7Ae7pivHdnw2Z7N4iz9a7u2Bqvfs5U/Xu9w+T57h2dvd9SJPdP3u02f26NWb3zwi2w2faLttQ3dbgRzDX3JRFgZs3b+La1auO8hNF2Nvbw+HBQZgENUqhLEus/XQkTCSYy/+IpGto8yxHJKWjkJBwPopwsLcPpV2GTQAFxmAxm2M+m0NwjjRLkWcupyXLc6yLdVj5JpE1TUrI+YqE5Frr0FDTFCSKIhhjcHZ2htlsCqUcnanfdyu4FEiotcbZdIKyrrBcuyyXJ554AmkvDzS6rJdvTW+YcOGu/cHAN9QKSms3UZHSrWSzjeA67/XQ6/eRZimixFlqV+saVVlhuVyE5lkwhuEgRxSJLRqd1trlzQiatkiU68oBJuvDRg1gtIHSKuSowFo89tjjjk7oBfVCCvTSHFmWIk1SCMahjYaqG9R1FcT3cRyjl7vJz97efsjTsRY4kO53jPZaJ2/brRqFpqndz4wBjEYshXPliiIwGDR1CWssGGfIU+deVpSFXx0H0iRCHDmNlgNUlAXks2sI8HgzBGs0qqbaOHMpBySpqU2SDMJPtIr12jXyVY2mdgYXF08uOSDHOSxjiABEMoKQAoy7BYFVuQK4uwfzPN/SsUgpcXh4GBpfErzTFLCtl2tPcwj4UsPeBpl07Ykytre3hzzPAyBtW14zxsKEJY4iiNSZR0wmE1QBRHrdWJY7oMmAtbffrhqF2jfunLnpjtLeoKIocXx46KaNXkNDoHNbx2O3LKAXi0UIcCUAt6GDcohIOGqsp6JlaYbhYOTOoTbBZn7v4MA9o9airhv0ej1UB7VzVcxzZHnmXQQbVGWFptGQUYI870NGMYwFKg9o60Yh9dlNVeXpqkICjKNRGmeTqZ/6MCznc9y8cT041dFUlI6j7TQIIGSO0eSULPY3k7ccV5646s1XOqvrrrrqqquubt+6rcGPMQZN7UId4aclgc4WRaGRYx7gyNYKNjV/QghIIZBlOXpZHrYhDUQ704ea+KIoAGyvbrcbKmqiyrra0vMQmGmDnzzPg2EDre6Sa1ZbrBzHUQAO9JohHNXz90M+j2rAuMsmcgBMIE5iDAaDEDQaeyAkGIOF3WQCwekICLS0rZpl5GhxRFcqyzI0ikVRwGgNwRkWywxpEjtgQudOGxhrQtMsuHDaGO5duDh3GivtXOYaPw1SqkFZVe7vHqAwxrCO1oiJMhfF4Iyh9ufNetBktIU1DLAMxsCHeEaIIukd6AAN50rMuaPRKb+STyvuZVG4yY6nPBJtqtENVK29+5rdog21AS+ZOxjj/m+NC1JlDGB6c0854EX3MQdjAtoaaGuhrQF3Xs+wjDnhvBDgEmDWQMYRoJwuxDbY0Dw1gXSg0Qre5w7gG50WZV+1788AVn1zfCtIaIdpkn6OdGD0WvQzAK3J4Ma8gJ7f9rPMGPPBvE7Ir/z+ae0ycowxTgujVNC00JQuUDKZDHbv1utx3Hm3sNyGBQiarrSnU7SfNLUjBzTaZ/oskVGEJHWUWOld/aSMIEUUwJgzGnF0VHfiED6bBHfPfpImSPw9pWq30EKrZkprrKezcF7o88gF8FooRdM9B0yklH71cwWjNfJeDxf4hTDNKcty6xjoPJAmcjAYbGWkEfgJ5i/chQRLKSDY7Ul7e8973oNf+7Vfw2c+8xlkWYa/9bf+Fv7Nv/k3eMELXhC2ecUrXoGPfvSjW7/3fd/3fXjve9/7TO9uV1111VVXX6a6rcGPCzM0AEOgoQnuBMlaa5ydOpvZoAPxgIN0CdZapIkTm8dRDClE0M20aVW0Ak5Nw2KxCPqU9opp6W2vF4sFFosFZLzhzRPQaTeUpJ0BEHQQV65cCQJkole55kbAGI3VagWl6hC2yYWA0s6mt26cmxkTAofHY9y4eROTyRkWPm9mNBphf38f/cEAWe5W0NMkCdbW2gubAWegYFsOcNT4kw6i7apXliXAGAR3Av/pbIJ+3sPA56KQOxvRd7R2E5eqKCEjZ8EcS+eOZqyBbjaueXVdO/IE840qOLTSWDclClZBChdSmyYJmkbBGIt+7sJFtW/KzyZTzGZz7O3tYTgcoNfPocw2Ja19T7Sd7yaTSVg1p3NAdK+6roNWK00TCCF9Iy48uNrQwwhUtM0VjNGBukagLkxNOMfp5Ay8qQHGoY0N06IszxGnBta41+ZSglkLy9zIuayqAGA542BcgDOLoiphrEGUxFsTuZpAqAcrlKFDWh0CFgC2tF7W2kCfpHuD6IFtg4wkSbBcLrfufQL6VAQYjTGoveaHnhvOnekBYwx1o/yEjWP/4MADUWd44ezPHSDSfuoGY7GYzyHZJocpuCWa1jTOLyTQdWpnb9H9QRMUIQW48IsnsdcIRTGiyAGUsm7CBGk6m3kzAmeEoLWG4ETz04CfQqdJFoAYTaFu3LgRrs3+/j4Gg0HQatE+EhWTDCVoChcJgV6WYjqduglaS9tEiy30jBVFEe4DWphpG0IQeDrY34fgAnUZ/WV/lD8j9dGPfhRve9vb8I3f+I1QSuFHf/RH8S3f8i341Kc+FbLDAOAtb3kLfvInfzL8PW9llHXVVVdddXX7120Nfq5evow0dzbRyq/IE2Ws3++jn/e2jA6ATYJ7OyA0iiI0dYO6qrC3t4derxfc4J544gmcnTmB8ng8xnA4xPHx8VYzOJ/Pw2ox4Bq5vb09XLh4sqGZtSZCt64sU3NCK9iDwWDLaMDRgziGQxcmOp87YwSlFLhxK/97e3vgUkDGMebzOa5du4bpfBamMlpr1ErhbDoNTW9VVTg+Pg7aHWr2iPPfpvyQ7qPdCNM2ktyhpETkJ2nuWGJwLsGY+561DE2tUJcN6qrG4f5+aLDKokLTuEBIZuFc0hhDJGNcu3oFymhI32QzP8WLZIQolojTDP1ePzTcyutQiPKT5zl6aeavl4KxGoCCtSaAT625+5k3sKBJ2l133RnOyWw2dZoOvyKepgn29/cCPY3OX/v+coexPQ1qU8420xf39ySJIaMIIpI4SS+GzJZGK9TKHZcDU9abHigwLr0DWIo4ScP1dfeiQBwniCKBoiqxXC0xm83AGPNGGnGgViql3H3kp4a0721dVNshzRiD6XQKwJmExHGMqqowmUxw8+bN0EhHUYQLFy5sAUcyHCgKRxckMxGjFbRqHBUSNHGRkFL5a+8AGRhwdnbmAkGjGKlfrDDaLYpYIIj28zQFx+ac03G0Pxso0JaeYQIDpI+h72mt0ev3MN5zxhMGQN3UqOoas5n7fSY2tMY77rjDnS9rYSyZflhHzayrEIQbidhTWvs4OjrCaDTC6elpeH6piF6olMLVq1fx0EMPhfsLAKbTKWazGdIkxsnRUXh26TqkaRrylwg0ZVkWFjFo4kPnicDRbDbDo1/8gjt39WZ/bqf60Ic+tPX3973vfTg+PsaDDz6Ib/7mbw7fz/McJycnz/TuddVVV1119QzVucHPxz72MfzMz/wMHnzwQVy5cgUf/OAH8frXvz78vE2RaddP//RP44d+6IcAAPfccw+++MUvbv38Pe95D37kR37kXPuS5z3AZ13EcYyjo6PQhNZ1jdPTU8zn87CCTO5JT2W7m2cZpNg4ntV1jTzPcffdd+OrvuqrtrYny2pqHAuvOaLGKYoiZ5cNhIaCwiEJnA0GgyCeb4vtCRyRJokx5iYbaYK6rvDpT38ay+U8NE0AIP3qs/UUNiEEDg4Pkfd7YTqzXC5RtlZ2yWEN2Ky6A9jKFaH3F0IE/QOZPbRtkIui8BMpBVU3qHyzFkuJPMsxGPRxuH/ojBn6Q5e9whjyJHXHW9WoPdiwepMpFEURRBThec9/PrQ1ngpXo6qoQbMuvFIIlE0DRo5naQopXKhpVdZYLde4GrJ8nGU1WANrTVj1p0aQJhg0HVitVsHQoNfrBa0KTRObpsFqtQrUIFpZp3N7q9EFNZNt8NwWm69WK2dJDqBuGpRN7XNhGKJIoufvXxlFiBJHibx29TqkD4ElU4e6qZ2JRNM4+h8zPp+qcfk0HpzRszDzob3T6TRMYG41O2gbYAAI5iDtMNDcTxTbABoALl++HEAZHTOBDzr3SZIgiSPAGsznc9w8O/MTMZdrlOc5ZBR7OuHGzjlQS6MYpa49sKidLmi1wsHeHqrGaanouMjQoW1w0NYhtU0Y2s5os9kMT1x+AsvVwtFG48gH/EoI4c5DnKQuTNZa3Lh5E8YYxEmKNMscvaw3wHg8dhQ/6e6/Jx6/jKZ2OVfL5TI8/wTeab/a00rar/YiBU0i67oCh4X0ZhEEymnBhe7VOI7DxIeuNU16aDtynjw4GMMag7pc4k/O9Un93KzZbAbAsQba9Uu/9Ev4L//lv+Dk5ATf/u3fjn/5L//ll5z+0CIJFYX5dtVVV1119dytc4Of1WqFl770pfie7/kevOENb3jSz69cubL199/+7d/G937v9+KNb3zj1vd/8id/Em95y1vC3weDczit+Lpw4QIsk0G30KaRGWOQ53n4x76dKE8NGU0/mqbx2iGFLE3BGUejGhjtNCq9fi/QYKy1EIxDMO4aCynBwaBHY/Q8RSeKI2R5jrzf23JromaCGmJqXtranrbjGIGg5XLpJwMum0dGEQbDgdvvFpUszTMkfgV+uV6hP+iHHJCqqrDytrfWWjA/Zco8iKEiKkxbp0FhioBbFR2NRqG5JxpcWZaezqZhGkevSaONffWg13e5NIEKZiC5095EMkaWZj7hnuhazDl2CQHFHC1PGSdaTzMNC+t1XNIbCDgND4yb7pSVE35zziDjGHGSwigFoxUAgyRNvfbGTZF4S+PUNA2qskRRFEGvJaX0RhBsC+TA2kCXRKupDBMyv402Tm8T9ETedtvoVpaLcgYGlBVTNA0aT40D4Kh6sCirylHsmABgEaeObtVohcaD4mDrbayjgwkG7nVJdO3IipyeG6LxEUDLfLPe6/XChKAtmKdnie5TAiJt4TwtFpRlGZ7T9iSMwOdWGKd/bQJUUkZIEndfN0oHypqMo0DhMtb6fC0HWIuyhFINpmCw2plhECAjkEM01qIosFwuw4IABbzSpApAmMpYa5GkMeLELVponzHVfmanszkapWCsRZwk/jnVqIkquVi5eySSLtcqz8G5QJZFDhBxR1VMopg+sKC0Qd0ob2nuzC3SLEeaumvC/f04HI2xt7fnnCEXM5hGBfoofdYVRRGALpmskNaHvjbZPu58jMcjqKYHwKAubn8amDEGP/ADP4Bv+qZvwote9KLw/e/4ju/A8573PFy6dAmf/OQn8cM//MN46KGH8Gu/9mtP+Trvec978O53v/uZ2u2uuuqqq67+Eurc4Od1r3sdXve6133Jn99KF/iN3/gNvPKVr8R999239f3BYPAXphaMx2MYiK0AU2BjIZ2maWg2CWzQSn6b5tWe6FRFuVnd9k24cyKzLhSTseBEZoyGZBJJEmNvPHZhp5xDSAkZR4jiCOSn1F4tp0ZktVqhKIqtCRA1UNSwkHOZ1goyksh7GdI0QZxsbJvL0oEV4Sc6DAxlUSJO4hAQGScJkiRF3dQwRMfybmXt1fzgAOVpR9SMWrjQVxlFiKQMoZIh66bXA+cCgjNwcERSIomSjbMZ5871zIeZuv9bMC4QxwIMDIIxMOshnn9fBRd8yTiH5AycCXDhgCnAAt0r8a53Td3AKIumcY22ZBKRcNfIGgurHeVNSjjXNn+djbXOYto30et1gdV6hYt+2iOEAIMDLwxO20RUSubNFkinQtOjtj00nVtjjDNn8OJ9opCRxiqE4mqN5XoNJhgAf696EMXKygNEt6o/HI6glIZqnOVye3XfTSWcUN3458KZAGxoXMBmIYDuyaIovYmDDQDeGBNsuhlzAbF5nm9RsUir1jYWudUxjbRAW5MlRqAKIaNmOBy2aG9OZ6KNs3c11j2vNGWqarJM39ANldYo1wXyNIXxUx96f9pX0uYsl0sHitIEeeac7rYCQhnQy53+Lk4iD2pqlE0DrZ0pg1bu2hUt+ljsQ2GN0mGKBLtwrpFCIErcRDGSMfLcUTc5c7q2YE5grD/HGpGUDuh4bZWz9d7YcJOGMU1iSMmhqhrr9Tqce+1d8JaLZbjeWimMxiPkOem3ZJhqE/U2yzKYWAIwkHx3K9Pnar3tbW/Dn/zJn+D3fu/3tr7/1re+Nfz5xS9+MS5evIhXvepVeOSRR/D85z//Sa/zrne9C+985zvD3+fzOe66664v34531VVXXXX1F64vq+bn2rVr+O///b/j/e9//5N+9q//9b/GT/3UT+Huu+/Gd3zHd+Ad73jH1nSmXV+KWmCMQVHVmM/nMMZgMBgEgwIX8FgHRyiiZgFOn0ATDMrJGPQHyLMMp6enWC+WnkqWop/nsJxB142bPCiN9XLpaDRau5XRzPHoRRwBvlmslXN7ak8CGGMBpLX1IDRZoBV3WpEn7QjlulT1GvPFzAmvZeytfAvM5gtUVYEkSZ17VCxxejqB5bTq71aLkyRDlEaIYweEZCxw+fLlralUmrpjJqMCokClaQrBOcqqwuTsDIvFIqzAp2mKg/195H3XeDG46RiDhWpqlMUmX8npT5xQu1y7wEzm3d4Y54B2oNJpPzQqrWAFA4RziBOMoSxWWCxWqMoSSjfI0x56/QyCO4vuSHJvXuAa17IsYIzCcDBCL8/AuMX1K1dQ1TWM0eBCBEcxax1VcV0UWK3WKMoKAIMUfgKmnMV0423HrXWNKU0pCEQTlaitmSKnsDTLocwKjVo/iV5owcC4gNEap6dnSLJ061o0tYa1KmwvpcTly1ccONEG1iIYZRCVLIoccFBNg0a7SRL9btMoVFWJ+XweKFT9/gAXLpwEN7/lchka4b29PYxGI5ev0+vh4sXnYe4NPpaLBRaLJWazhZvCeRBLVLP2uXC24a6stZA+/yHKUiSpAz5MCGi9oYLWdR0miUopzBZzSBmHYM+ycNdhf3/fTYKqEtOzCQBHDZVCQAof+gsGZXQIAJZxDA5AeG1MWZa4cXoT08nEOaUJgefddTdOLl30xgvOmU9yCVgGaxQMc8Ay7/WDNfnZ2ZkDf/SfBaqqxGq5dECWC2RZisViicPDIwwHI2RJAstZoFmSE52jvTkr9qZ20y6aSAMO7CVxjCxLkaUx7rh0CcI7xJEF/GKxxHq1hFYG1jpQV6wLSB/UyhlDkiY4Ps5gvTujEBJKK6i6hjUa9TnyRZ6L9fa3vx2/9Vu/hY997GO48847/8xt77//fgDAww8//JTghyiXXXXVVVdd3T71ZQU/73//+zEYDJ5Ej/un//Sf4uu//uuxv7+P3//938e73vUuXLlyBf/f//f/PeXrfClqwXq1Qj5wwt3VaoXJZBJW3rMsQ7/fx3K5DE5ew+EQq9UKs9kM169fx2q1QpZlGI1GODw4xOHRIYbDIaI0QaMVVLFG3dQAZyg9ILEAxsMRHvn853B646YTI3MGyQUsA5I4Qb/Xw8HRIe68886gI0k8/WU6nWI6nQa62/7+fliBbZoGi8UiJLyTQ1ObFsQhvRUbw8HeIdKTBOvlGhYada2cbXee4q8976vRqBq1z+9RRoFxARk7qk2UpIhjifvuvgd1XaGqyqBL0kpD1TXK9TpQmQoPXjhj2Ov1sdfrA9hMM4wxqJYLVNZl4zjGlwSYgPXTsqbRzvXKB3TmuWugsyRBLAGjGqyXc9RVBWs0BONIkgRaw0+vJNIswzBPUe8RjUkjimIkSQwu3ATJAScDi42g3WUCZYjjCFxwpFkP125ex/TsDOuixHK9Rq9hPjeJw7IITMSYzBaoa+XzdhwNaVWUaOauERTeRlwKAW28M1ZrCsTYxsXM6ZY0mtpRkcqqDK5sUZQgy1II6QEnJFRjoFWB9aLwYMJNgbaKAZOzCQaDQdCRVVWFq/PZFsDW2mBv/wCDwQBpmiH1k8Y0BUbjPdxx591B4E4hoOTqF1z3tEYcO/DMRQSlDZ64fBVxEnsKVo7RmAJhJTh3uU1lWeKJJ56AUg4wMEv20W76yJkHv4ID1u1rWZYomxpCyKCTk1KiqtVmqpIm4Lz24DlCmtKkjUNKjlxIRFGCSLiFhbqssFyXWJcFuAWixFG6ev0h9vMMqq43tMNG4eDoAvb2Dt3ky2gwY3H9xikSHyZaNw2MIbfACMYA6/UaWlukqXO5Oz48AvhmykVTG8DlJLoprAEsfLitQlNVqJoaxXwarh/j7tgc5TRBLDj4LfS9dekm16qp0dQxVJ6iqgqoSiGOJfJeD3ffdReGvRyz6Rxnp2e4efMGmkYBSqFarWC1QtPE0AZQqgb32UoHyR7GowEE56iK3UMmn0tlrcX3f//344Mf/CA+8pGP4N57733a3/nEJz4BALh48eKXee+66qqrrrp6purLCn7+83/+z3jzm9+M1Iv/qdo0gZe85CWI4xjf933fh/e85z1PuYr2pagFo/EIeX8EIQTG43H4udY6gCGilY3HY3DO8cUvfhFCiEC76/f7gfozn8+dIHnQD65wTdOgLp3GIve208PhEGmeBbeqsiixXC6xWLpgxLPpBDfPTvH//t//C45jw+HQWXH7Jmg0GgXgRQ2mMQZZluHg4GBL/3MrNU9KASiLPHfWu3mSQUYSTVU7OpaUKMoScdzD0E9WIJ3+RPtQUWMNtNlkmljrxNFCCNhoI0wXjCFOEmRpikhKGGNhmo0eyLpZhdPCMMAaH4LIAeaBj7aA1hZgHGg0GDNQxmAym2FVFEijCEkkEcURIs6R5RkE54g8bYtRhgvnPk2aIUlclpO1xltgu/BHIRikiMGSbZvp1WqF2XTmgmqNhjZu5Z8JiXwwcPQ57yQnvM4kihPAGiyWa9w8PYNqnLHG3t4e+v0e0iSFFNwDVAkLd97KqvKWw3Vo1BmX4MKBIRFJ5FJApqm/xxSqWqGsF5BB5yJxxx13QeuNpkupjUNZO2h0PBoHS/QkSYK2A0C436yF+31wdy2gN+J5ZaCU8fdXg+VyjatXrwFeM0UgTogI1jLUtXINM4BGKXDhwJ1qXOCpVo0HSY5+FUURDg8P3evAwTcHmFUI0aVwV7ANPauqakhpAnUwyzL0B3GgKkZxDGOsA5RKh9c5Oztz11m7YxoO+sjzHP3Dfshpms1mPgfLGRnIhdccGQulN3lbLmjXgbQQHOtDX9u0MJrsjkajQBNzBhMqPEttpzwAbtGEAYxJqLpCFEmwOAbvCUpk8uG6MdI8R5qmKIrSBdwqBeOpotxP8YQUYBCQkUCWJej1MzAO2EY7J0NtUKyWKJYLrJcrrJYraA9IXRaWo7EqxVHXDYra0SurugZjFjeq0lE/y9sz5PRtb3sbPvCBD+A3fuM3MBgMcPXqVQAIn8WPPPIIPvCBD+Bbv/VbcXBwgE9+8pN4xzvegW/+5m/GS17ykmd577vqqquuuvrLqi8b+Pnf//t/46GHHsKv/MqvPO22999/P5RS+MIXvrAVOEf1pagFnPHgYkSWuUQBodBJakI4d1OEixcvot/vh+1pstI2QWhnYJDDE4AgAAfcJGI8HmMwGKAsSwxHw6DVoRXzs7OzoKVYLBYAEPQjREVy6e4b6hPx+NuUKdJOtLNRdFkjkpGj8STOMUtFdQBKdeOCTl3OC3fAgzFY5gT4MICLNLVgzGmVZCzCe1OjxuH0F3mabXRJbfDjz5sAA2MW1mrEArDcgjEBA+dcphUgjYFSGlpbaGsRRY4WKH3AqBDcHxOHJI0P57B8Y1FMzb87NwyMbW5hxrAFDrbuFc69lsiBPzAnEofX7wCONsTciwCMQcoI1qiQF1R5m2uyn1ZCoal96C3z+9WyAacvpRTAAW7cNSCnMm6dFbUQFlpsQK42BszTCR3dyZ1vKTf0OAJIpF9pGzO0ndpoG2uBdVGiaTaGIO6cbays3f0XB+ofYwBjm+kVUdfaVt2MG/9zBi6cGYdSDtBxxmGijcVyOLf+vFjj7zs/wbDWQggJC0f56rVCU8lwwVh3b1Z1jevXXQ6OMpY8EjbmCp7GyDlHsV651/Nf9HrkbNa2JbfMQmCT+9MOOaXpK1Ec21b5NN2jzyO6/9rP8q3ZXuEcMoaYM/+6LizVGINGE71RIs1z9Ho9WGNhNFl1Y/M6jAEWaFQDrRsUxRo3z26g38+RSvf5ZrQBN9a7PUaQoyH6/R4YY1j6ybPx+q44jiDiyDkvem1bXTuHRHWb0t5+4Rd+AYALMm3XL/7iL+K7vuu7EMcx/uf//J/42Z/9WaxWK9x111144xvfiH/xL/7Fud8rzXJEydMbQ7SDfp+u2tTvp6svRSF/qoqj3Sd5q3Nce2PPEYZLN/MORZ9hO+3DOc4v3ee7lGS77y/jT+2A+1S1LnY/v2RCtEuJaPdsriQ+X44Xuc7utB+3/Lv8Z9Y57h+G3a9HLHffh3NcOnC7+8ZlvfuxRed4Pomdskud59mw53g+d98SmPu+eJci46c/q1S1ewzDlw38/Kf/9J/wspe9DC996UufdttPfOIT4Jzj+Pj4XO9RVhUqZbFarXD16lUXLOqDTEejEXq9HkajUTAZiKII99xzD8qyxM2bN/G5z30Oy+USR0dHTjjsnaNIL0Tg5/r16yjLMmgpVqsVjo6OAiefKHbkhqW1xnK5xGOPPRZW/ulrsViE5qff74fmC0CrUd3Qlcg+uK3dAIBab7I4qEGUjAfheRRFQeBulFv5tQyw3DXozDulAdQEO+oRnQfjnci41yRFPgTW7ajbj3b2i1Ua1tN3ojQN4McyBgMGazgSAEZbN3mCm9C4lXXX7FurQXCEM/fB43RSChZ4UhN5q7NaO3yTNEwAgpbJCf1d3oq2DGVdOVpQ6xpwzt1qOtuAoiiKYJLEaZl8w7xcLh1VsXK6mLJyYCHyFC3uDR4CoKHXFw50uebWhoY/z92HlsG2kxqZFtA1JntiokJGURTs3Ok+J10ZGXpQo+xeC1BqI/wnQNO+/yjMk+7Z9vkk8EV/libassPWWmO1mHsAwJClSZiu0j1lvHkC5wj3HAE3R6mT7vnz54xe2xiD1doZMcznczzyyOd8wK6A9BOYjTMhAxcOVF2/djWE1PZ6vaBbci5rPDjWte+dNiDELffeZpq22Y4WTVarVQCfaZri8PBw6/xS3eqY10974TkTXLp7bO3t47Wj+hGIDYDVP/uMseAkuFyu0TQ1ZvMJrt+8hqOjA+wPRw5YCYksin1e2chNcz2Qe+LyZUwmE6x9JthoNEKcZeBiM4kzjTca0edoap9D9XT/gN9111346Ec/+gztTVddddVVV89WnRv8LJdLPPzww+Hvn//85/GJT3wC+/v7uPvuuwE4+tiv/uqv4t/9u3/3pN9/4IEH8PGPfxyvfOUrMRgM8MADD+Ad73gH/tE/+kfY29s717488fjjgIgDRaXf72M4HDrqWr+/tTJONsbz+TzQzl70oheBMYYsy7BYLDCZTIJlb7/fx/HxMXq9XsjqoUbx6tWrwQ6W9Dp1XYfmC3Ar50R/oVwdAFh4cTi5at28eXPL5pdWjtvOVDS9ajfBnAvnwmZtsLnlfrUaAA4PDyF8c8uFgOGAMhrrqkTp9SZVU+H6jetoGkfvEYwH5znOvfjZAwZYCyM8/QybaUHIbmkaaKNgdA3TVG7SISQYF4AQEDx2/xfOtMAyjqp051r6fdQaYNr4CYRA7s/fbLkEwLauZ/scJUmCPM+xXq+xWCy28mWoWW1fi7pR+OLjlwEAnNtAXaJrZ7WG9aAhku7apEmMpk5Rlo7iyJibViWx08fkTYa6qZ1Q/sYN7/a2mXqIyL8+wxYgcdvESFO3b9poKG8ZHkdPnhpsTV38/ymUl6ZM5GLWnkQ0jcL+/iHiJIVSG0BOr0ONfzBm8DSu9gSNjBzItlobjV6/HyaWNH1K48hn1dRbNtdCCERSou/vMQYLY3TYZrFYBPBTliVW3j6dAKAD/64ZH4/HePnLX+4zfbyuTSkv6nc6LZrY3X333eE4tNa4ceMGvvjFL4bjzfMc/X4fJycn4T6g46dz3F7AoPuLQBuds+DmxzehwDSNbl87uj5tGlyb1mqYDYsiyltmW08H5MyBfaU1hGTo9/uIkwSMc2fMwCXKsoDSNQbVIHxma39PS3CcnZ0hi5OtTCrKTOr1e4Dg7jyuVyFoNooip8sCAiWvq6666qqrrm7HOjf4+aM/+iO88pWvDH8nLc53fud34n3vex8A4Jd/+ZdhrcU//If/8Em/nyQJfvmXfxk/8RM/gaqqcO+99+Id73jHlqZn11quVsh6IlDiyrLElStX8NhjjwXnNEoyJ0vc1WrlHM18WGdVVWFqVNc1+v1+mOJQsCBZxRJtRinlGzUHaNq6kvZqLtHEjHENPWWmHB4eBsDm3LX64JwHrQZR36SU0Frj7OwM8/k8ZOmMRiMM815wZ2JwQuuIbwBUVVUo53Mn9G5qFE0NAwseSUj/+kmS4KVf91KopkFdOS0BsB1Um/vV8rqsNuGrnvbWpqEJmsawCNooWG7hhtEeODllOMC8UTRDcESDNYDWUKqGrmpPw2OI/ZQj6w+8M1kTmmQCnNbarSBIWl0PoMyvyNP5dk27BbiEiKRzpFMbN7EkSTAejbA3GuH4+BhGN5v8It3corlh4P58ceFoiYXfP6I+EQDi0gGZRjmnOPe9yE+HLJTXrDDhGk0Wx7D6S4+ltyhTrUDVNqWyHWyplEavP4AQEYqi3NAn9caCmbalKcutFDcAgT5K79kb9EMjT/czAA+g3QQvSZKgY1NNg9qfI5e5ZAPYSpIEvV4fcZKiqirEHjRtURmZmz4aa1H5cOMoSZ0WzRiMRiPn4MW41zkpGN2ERp/c+cjZjhYX2gDS2ceXYULbPudtGl6b7kZAheir7clbW7cXnpcWLZExhvnkzFN/GJgHeBaOMsP4JocpS/Ngu155uq82BtxPJN25FDg5uYi/9oKvgpQctvEgSmtEzC3sxHLjtkeGMWVVQWkFSOGm2kkMRbTd1RK9LHfn5Dx0pq666qqrrrp6jtW5wc8rXvGKp6UPvPWtb93KS2jX13/91+MP/uAPzvu2T1kXLlzAcHyAKIrCim+7WQKwNSHgnAftAGWxnJ2dYTKZBLoKaQ+ooaEGmpqZOI5xdHQEAGE1F0CgybWbG2p+qGmixosaTQJIRI2jLBWy56bt5/M5JpNJaFg550hEFDJ0Iv/+TEab/UwSRHGMft8FnSo4tzENG+hwGhpaudyPsqxQespLW+dg/Mo1OVFZa2Fvmay4Lw7GLKSMMMgTaGgYA2jr9D1GcxjGgu7GGgQwAqPBrIEQHHnmHNmkEJC+O9O+OVdKhekOTRMAhJBKsl9uZzhRY79arTYOetYiSXsuFDaWW7k01loU6zWsD2/t9zJ3nLDgbEPBcvulUdaVB00xhHSTjf39fX9fbACK8Vk9Smso7TKILBN+CkS6GR6aXVigrOot44un0vsIIZzmCBvaGulV2tqSOGZhckLUSro3AQTdG/1eURRhQtUGufT6tB80hQvZOkqB++kWAwPzfybNG4PLi0rT1IFebBt6XL12DWXptQ2tHKAw+fH3hNIa6/XaWZqDuxDc9pSFM7iMIhXomjTpIuDfBik0YSLef/vP7WvQvt8IALZt6dvaKPpZ+zmhKQrRzej4+h58UV6QM8ng4MIH6kZxoHoaD3YiuGvK/X5u9IrKTWGhkCQRmHGg02gN4XnpSRQH/v1qtYL2CybrosBs5WzseeSyyuI4hogkBoOB09+dhwjfVVddddVVV8+x+rK6vX25K29NZ7TWThDsQQ41qJRYTw3aYDAI2hwCE2SNDSDQ5tpBqESDoclCFEWbxh0b2lCbRiSE8DSUjS4FQNARVV7Mnef51ooz6Y4ItFHWCgEjMj4wRsNaEd6LJituddzrMuCbUK9zqesGZVOj8uCr1jVm0zNUpXOsq7yYlc5fFEVQPtWee0E1YwwcGzoUNXncAvCamH6/h8Y0aBrnwmW1dlofT/WycDqgKJL+uA0Y3Pv1+32kaQIpOOCbOWUslP9zWZbh3Ld1PaTbaFOOgI3mhrahfd40nhJSikDdcmDMTUwW8zmSWPrfAYQ3VAgURT81UUoBzCKy0RYVyjX0BDIcaBJSIrKRDzLd7A81xBabkNd2blB7ekAgrX3vUdG0sB2WSxQ8bZwOi1zQ2uemrWGhJvpW8NOmwNHvcym2pkTuz7Qw4PrkNtASreeBERD2lFQXUltjuVwGGieBhPBcSf9Mss11NmDBMpz2jVlA+4karNl6ltuaJbov2hNauvfb1E46F3RuiqIIOqH2VJH0WHSN2qCqrU9ra4U45+glG3opTeMYZxDWH7t0x7cu1mh8oCsT7v5gWrtJmN+Ppqnc9HVlkOcpYiH95NJAWHetmQUiP3WqqmozXWpcbtp0OgWEQJql6PV7yHo9rMsCjVJYrFfn/ajuqquuuuqqq+dM3Zbghxq2K088CvX446g9iOkP+s6tyhjM5nNcu3YV/f7A2RD7YdVydhYsq3u9HBeO9tHPYrcazzj29vYQ++kP4FftTQKtFJhpsJxPcOWJR7dyeIDNREBKiThyCfBXLl/GcDTC3t4ejg4PkeU56nKF5XyKpdem5L0eUj+lkVKCQ6AqCpRl4W1t/bHlCYAE1hgAGlZVMMwCAhAsgTENmOXgkLDGYnI6w3K1wnw+x2wxw+l0gsl0inVdeR2By8ER3K1Oa6XAAOS9HHmWI81S5FmOem8PTblG7JPlpZSIvcscc44EwYHKWAWrJaoIaEyNqtKomhpV06CuNBrv8OViijjuuONudw7rGlZrSMmQxAIcLmeoKUsUxRqD8RicCcBIqETC6hg63gAWcgNcrwss55NWkynAvMFYEnHwfgZtEnAhMBztu6DapoHydD8ZSWQ9F+YqfGOcJW66oRqFWlVhCiijCLGM0M8TiGEPRbGG1gpV0aBYL1HXVcgzEoIjTnthOmQBFEWJoqqCEUEcpYjiCNZPSmAsBr3Ug6sNILZWQdUaVtfQjZ9CGW8moADdlFgtplgul5jP51itVt4NLkWW95AkKYRwlLT2AJf7qZzWXnPW1JBRhF6WQbYE/rWnEJblygvxe25aR0GsPtzU3xqANbDGYjwaAYADjHWNuqwBqzdgQ3CkcYz44jGODw/QqAbrqkJTOy1ZUzWAjsBS6y20IwyHhwCcjTpN1JTy58IoMGMgmcFyNkOv10OaZUgSAaU0lrOps+nmHGmSYDAYYDqdIthXe2t3HrQ8GqapoZoGzCokEYcQFkYpqHqNau0ywXQdQ3vdEOcMed4L9yMBP8DANCVU7TOvtMZU+ymz0mgahbpuYOAAcBInyAYD9PIcTzxxGeuVy9/K+n2Mx2PnSgg3wVmu1lCqgbEaYAZW9cCy3FnRA4i4RCzd85DELvR12EuhjUFRCkTCgnODo/0RmL9XtdEo6gIPf/b/ucnr9HTrc7irrrrqqquubqe6LcEPUWj+9y9+/7O8J195VQI4e7Z3oquuunrO12KxwMiD2q666qqrrrq6Xeq2BD+XLl3Cpz71KbzwhS/EY489huFw+Gzv0jNeFPTaHX93/N3xd8f/TJa1FovFApcuXXpG37errrrqqquu/jLqtgQ/nHPccccdAJxG569i80PVHX93/N3xd8f/TFc38emqq6666up2rXPE7XbVVVddddVVV1111VVXXd2+dVtOfrrqqquuuurquVpKKzD99HlIjO2+/ki26btU5G3Ydyl7jtDaptk940nw3Y9N692P7TxGG71eb+dtS28utEutinLnbc+zwrxa774Pg0F/523rc9w7ldp9WwCorX76jXyVy93PW57kO29r7JfOxLu1yD10l7LncPVPs3TnbQ12P8dxnOy+E+d4lhkX53jZ3V9XYPeTNhgMdt62ruun3Ubx3e+D23bykyQJfvzHfzwEnP5Vq+74u+Pvjr87/r+qx99VV1111VVXf95itvMr7aqrrrrqqqu/cM3nc4xGI7z2B/4Loh1Wrs8z+TlPtGx+jokHhQDvUovFfOdtv1yTn35/94lAnu++7XkmP1Wxe9bVeVaYze4L1+ea/OhzTHMsO19LeLtNfvq93c/beSY/a7X7eVgXz/7k51xX+RwwwZ7jk2pd7z5J3mnyU63xv372TZjNZk+rhb1tJz9dddVVV1111VVXXXXVVVfnqQ78dNVVV1111VVXXXXVVVd/JaoDP1111VVXXXXVVVddddXVX4nqwE9XXXXVVVddddVVV1119Veibkvw8/M///O45557kKYp7r//fvyf//N/nu1d+rLUT/zET4AxtvX1NV/zNeHnZVnibW97Gw4ODtDv9/HGN74R165dexb3+C9WH/vYx/Dt3/7tuHTpEhhj+PVf//Wtn1tr8WM/9mO4ePEisizDq1/9anz2s5/d2ubs7AxvfvObMRwOMR6P8b3f+71YLpfP4FH8+evpjv+7vuu7nnQ/vPa1r93a5nY+/ve85z34xm/8RgwGAxwfH+P1r389Hnrooa1tdrnnH330UXzbt30b8jzH8fExfuiHfghK7S6sfLZql+N/xSte8aR74B//43+8tc3tevxdddVVV1119UzUbQd+fuVXfgXvfOc78eM//uP4v//3/+KlL30pXvOa1+D69evP9q59Weqv//W/jitXroSv3/u93ws/e8c73oHf/M3fxK/+6q/iox/9KC5fvow3vOENz+Le/sVqtVrhpS99KX7+53/+KX/+0z/90/i5n/s5vPe978XHP/5x9Ho9vOY1r0FZbhxk3vzmN+NP//RP8eEPfxi/9Vu/hY997GN461vf+kwdwl+onu74AeC1r33t1v3wX//rf936+e18/B/96Efxtre9DX/wB3+AD3/4w2iaBt/yLd+C1WrjrPR097zWGt/2bd+Guq7x+7//+3j/+9+P973vffixH/uxZ+OQzlW7HD8AvOUtb9m6B376p386/Ox2Pv6uuuqqq666eibqtrO6vv/++/GN3/iN+I//8T8CAIwxuOuuu/D93//9+JEf+ZFnee/+cusnfuIn8Ou//uv4xCc+8aSfzWYzHB0d4QMf+AD+wT/4BwCAz3zmM/jar/1aPPDAA/ibf/NvPsN7+5dbjDF88IMfxOtf/3oAbupz6dIl/LN/9s/wgz/4gwDcObhw4QLe97734U1vehM+/elP44UvfCH+8A//EN/wDd8AAPjQhz6Eb/3Wb8Xjjz+OS5cuPVuHc+669fgBN/mZTqdPmghRfSUdPwDcuHEDx8fH+OhHP4pv/uZv3ume/+3f/m38vb/393D58mVcuHABAPDe974XP/zDP4wbN24gPkf447Ndtx4/4CY/X/d1X4ef/dmffcrf+Uo6/tuxOqvrTXVW1646q+tNdVbXftvO6hpAZ3W9c9V1jQcffBCvfvWrw/c453j1q1+NBx544Fncsy9fffazn8WlS5dw33334c1vfjMeffRRAMCDDz6Ipmm2zsXXfM3X4O677/6KPBef//zncfXq1a3jHY1GuP/++8PxPvDAAxiPx6HxB4BXv/rV4Jzj4x//+DO+z1+O+shHPoLj42O84AUvwD/5J/8Ep6en4Wdfacc/m80AAPv7+wB2u+cfeOABvPjFLw6NPwC85jWvwXw+x5/+6Z8+g3v/F69bj5/ql37pl3B4eIgXvehFeNe73oX1eh1+9pV0/F111VVXXXX15Sj5bO/AeermzZvQWm/9ww4AFy5cwGc+85lnaa++fHX//ffjfe97H17wghfgypUrePe7342/83f+Dv7kT/4EV69eRRzHGI/HW79z4cIFXL169dnZ4S9j0TE91bWnn129ehXHx8dbP5dSYn9//yvinLz2ta/FG97wBtx777145JFH8KM/+qN43etehwceeABCiK+o4zfG4Ad+4AfwTd/0TXjRi14EADvd81evXn3Ke4R+drvUUx0/AHzHd3wHnve85+HSpUv45Cc/iR/+4R/GQw89hF/7tV8D8JVz/Ld73VzMIKunX6k051gtjmW087bFDqukVHmy+8ryaDDYeVuldt+H5TlWws8xHMG1G7vT4S/f3F0vG53jWlzYP9h52yTafTLbnGM1flXuPnFRze7XDTjffSnEeY7vHNOc/u7TnOIcEz51jomZYrtPUGO5e+tdr3efMi6K9dNvRPuQ737OYrb7NKc5h750l+k4FRNPf874DttQ3Vbg569ave51rwt/fslLXoL7778fz3ve8/Df/tt/Q5Zlz+KedfVs1Jve9Kbw5xe/+MV4yUteguc///n4yEc+gle96lXP4p795dfb3vY2/Mmf/MmWxu2vUn2p42/rt1784hfj4sWLeNWrXoVHHnkEz3/+85/p3eyqq6666qqr265uK9rb4eEhhBBPcne6du0aTk5OnqW9euZqPB7jq7/6q/Hwww/j5OQEdV1jOp1ubfOVei7omP6sa39ycvIk4wulFM7Ozr4iz8l9992Hw8NDPPzwwwC+co7/7W9/O37rt34L/+t//S/ceeed4fu73PMnJydPeY/Qz26H+lLH/1R1//33A8DWPXC7H39XXXXVVVddfTnrtgI/cRzjZS97GX7nd34nfM8Yg9/5nd/By1/+8mdxz56ZWi6XeOSRR3Dx4kW87GUvQxRFW+fioYcewqOPPvoVeS7uvfdenJycbB3vfD7Hxz/+8XC8L3/5yzGdTvHggw+GbX73d38XxpjQJH4l1eOPP47T01NcvHgRwO1//NZavP3tb8cHP/hB/O7v/i7uvfferZ/vcs+//OUvxx//8R9vgcAPf/jDGA6HeOELX/jMHMifs57u+J+qyAylfQ/crsffVVddddVVV89E3Xa0t3e+8534zu/8TnzDN3wD/sbf+Bv42Z/9WaxWK3z3d3/3s71rf+n1gz/4g/j2b/92PO95z8Ply5fx4///9u4/tqny7eP4Z+3WbrCtozAZc2xOpiDqMJkyGhGVIQMTArInQTQ6dYGIgwiLYjDgxB/BYJ6omDn/0KB/MFSMaCBBVJQZE4Yys+DPBRYSIDBQ8t2AQtfSnucPH5rvFNndUXbo+n4lTbaei7PrOvdp6dX2vk99vZxOp+bPny+Px6OamhrV1dXJ6/UqOztbS5Yskc/nS9iV3k6fPh19B1v6a5GDtrY2eb1eFRYWaunSpXrppZd03XXXqbi4WKtWrVJ+fn50RbQbbrhBM2bM0IIFC/T2228rFApp8eLFuv/++xNipbOL1e/1erV69WpVVVUpLy9PHR0dWr58uUpKSlRZWSkp8euvra1VU1OTPvvsM2VlZUXnqHg8HmVkZBid89OnT9f48eP10EMPae3aters7NTKlStVW1srdwxzG+zQV/0dHR1qamrSvffeq+HDh2vv3r1atmyZpkyZotLSUkmJXT8AAAMh4ZqfefPm6Y8//tBzzz2nzs5O3XLLLfr888//Mcl3MDh8+LDmz5+vEydOKDc3V5MnT1ZLS4tyc3MlSa+99pocDoeqqqrU09OjyspKvfXWWzZn3X979uzR3XffHf29rq5OklRdXa333ntPy5cvl9/v18KFC9XV1aXJkyfr888/V3p6evTfbNiwQYsXL1ZFRUX02Kxbt27Aa+mPi9Xf2NiovXv36v3331dXV5fy8/M1ffp0vfjii71e1CZy/Y2NjZL+Ws75v61fv16PPPKIpL7PeafTqa1bt2rRokXy+XwaOnSoqqur9cILLwxUGf3WV/0ul0tfffVV9A2f0aNHq6qqSitXrozGJnL9AAAMhIS7zg8AAFei89f5ubWmQamuvheluVyrvQ3JiOFaODGt9ma+QlRsq72Zr1I1dKh5bX7/aePYRFvtzf1fb/r1JZbjcDlXe7NkviKaw2k+KyOW1d6CV8Bqb46UGFZ7C5jnO5hXezsX6nssQj1ntP1//2fwXecHAAAAAPqL5gcAAABAUqD5AQAAAJAUaH4AAAAAJIWEW+0NAIArWVZ6hlINJvOePXPWeJ9pKebvVQbPmu83w2U+yd7hNJ/UnRLDBPA0mS+60H3GfPJ+sMc8NjfHfAJ4hsFiFudlp8ewiEGG+X4DgYBxbErYfOL+iByPcawkDU03P27+s+aT98/GsGBGLOt2pcVyvjvMJ/pHwuY5WJEY1hmLobZYFn7oPmt+fMOp5scs1Wm+AEZPDOewDA5DOIYFZPjkBwAAAEBSoPkBAAAAkBRofgAAAAAkBZofAAAAAEmB5gcAAABAUqD5AQAAAJAUaH4AAAAAJAWaHwAAAABJgeYHAAAAQFKg+QEAAACQFFLtTgAAgMFkSHqG0twZfcZlpLqN95k1NNM4Ns2VZh7rdhnHdnX9xzi2+3S3cWzQOmccm5Zq/rLF7RpiHOtJzzKO7Qn1GMc6Us1zcDpSjGNzss3zHeYxjz3xny7jWEnq9p81jk11mp/vwXOhGLIwP27hsPm5FokhNhA2DtW5UCSGWPPjEEMKClvmsU53DOdwqvlzj8MyfxwN8w7rMyYY8Jv/beNIAAAAAEhgND8AgEGvsbFRpaWlys7OVnZ2tnw+n7Zt2xbdHggEVFtbq+HDhyszM1NVVVU6duyYjRkDAC4Hmh8AwKBXUFCgV155Ra2trdqzZ4+mTp2q2bNn65dffpEkLVu2TFu2bNGmTZvU3NysI0eOaO7cuTZnDQCIN+b8AAAGvVmzZvX6/eWXX1ZjY6NaWlpUUFCgd999V01NTZo6daokaf369brhhhvU0tKiSZMm2ZEyAOAy4JMfAEBSCYfD+uCDD+T3++Xz+dTa2qpQKKRp06ZFY8aNG6fCwkLt2rXrX/fT09OjkydP9roBAK5sND8AgKTw008/KTMzU263W48//rg2b96s8ePHq7OzUy6XSzk5Ob3iR44cqc7Ozn/d35o1a+TxeKK30aNHX+YKAHAowosAAAr6SURBVACXiuYHAJAUxo4dq7a2Nu3evVuLFi1SdXW1fv31137vb8WKFeru7o7eDh06FMdsAQCXA3N+AABJweVyqaSkRJJUVlamH374QW+88YbmzZunYDCorq6uXp/+HDt2THl5ef+6P7fbLbfb/NolAAD78ckPACApRSIR9fT0qKysTGlpadqxY0d0W3t7uw4ePCifz2djhgCAeOOTHwDAoLdixQrNnDlThYWFOnXqlJqamrRz505t375dHo9HNTU1qqurk9frVXZ2tpYsWSKfz8dKbwAwyND8AAAGvePHj+vhhx/W0aNH5fF4VFpaqu3bt+uee+6RJL322mtyOByqqqpST0+PKisr9dZbb/Xrb50LnVOK41yfceFw2Hyfkb73d54zhv/aA4GAcWyaM804dszVxcaxJwLdxrE5Q4cYx6amWMaxPUHz2GzHUOPYcCRiHNt1+qxxbKbL/Is7oXDIODYYie0LQamp5uea02kem2L+0FBPyPwYZ2akG8dGwuaPuYA/aBx7LoZzIiMzyzjWMj+Fle52GcemxvC4D5qXpoyMTOPYsMHzXySG50iaHwDAoPfuu+9edHt6eroaGhrU0NAwQBkBAOzAnB8AAAAASYHmBwAAAEBSoPkBAAAAkBRofgAAAAAkBZofAAAAAEmB5gcAAABAUqD5AQAAAJAUaH4AAAAAJAUucgoAQBxY/3+J9XM9Z43iw2Hzy9iHXObvVabIfL9WDJeFj4TMr6AeTDXPNxTwm+/XGUO+KeaxwaB5rBwpxqHhiPkl70OBgHFsMGKeQyhsPm6hUAzHQVJKivk4h53mLzlDQfNzWOaHQsGUkHFsJJbj1mO+33PBGPbrMD9/Yngoy2mZ52s504xjQ+bpyhk2P3csg8fc+ecRk+e0FCuWZz4AAHBBhw8f1ujRo+1OAwCS1qFDh1RQUHDRGJofAADiIBKJ6MiRI8rKylJKyl/vVJ48eVKjR4/WoUOHlJ2dbXOG8UVtiYnaEtdgru9Sa7MsS6dOnVJ+fr4cjot/qsTX3gAAiAOHw/Gv7zhmZ2cPuhcr51FbYqK2xDWY67uU2jwej1EcCx4AAAAASAo0PwAAAACSAs0PAACXidvtVn19vdxut92pxB21JSZqS1yDub6BrI0FDwAAAAAkBT75AQAAAJAUaH4AAAAAJAWaHwAAAABJgeYHAAAAQFKg+QEA4DJpaGjQNddco/T0dJWXl+v777+3O6VL9vzzzyslJaXXbdy4cXan1S/ffvutZs2apfz8fKWkpOjTTz/ttd2yLD333HMaNWqUMjIyNG3aNO3bt8+eZGPUV22PPPLIP8ZxxowZ9iQbozVr1ui2225TVlaWrrrqKs2ZM0ft7e29YgKBgGprazV8+HBlZmaqqqpKx44dsyljcya13XXXXf8Yu8cff9ymjM01NjaqtLQ0eiFTn8+nbdu2RbcP1JjR/AAAcBl8+OGHqqurU319vX788UdNmDBBlZWVOn78uN2pXbIbb7xRR48ejd6+++47u1PqF7/frwkTJqihoeGC29euXat169bp7bff1u7duzV06FBVVlYqEAgMcKax66s2SZoxY0avcdy4ceMAZth/zc3Nqq2tVUtLi7788kuFQiFNnz5dfr8/GrNs2TJt2bJFmzZtUnNzs44cOaK5c+famLUZk9okacGCBb3Gbu3atTZlbK6goECvvPKKWltbtWfPHk2dOlWzZ8/WL7/8ImkAx8wCAABxN3HiRKu2tjb6ezgctvLz8601a9bYmNWlq6+vtyZMmGB3GnEnydq8eXP090gkYuXl5Vmvvvpq9L6uri7L7XZbGzdutCHD/vt7bZZlWdXV1dbs2bNtySfejh8/bkmympubLcv6a5zS0tKsTZs2RWN+++03S5K1a9cuu9Lsl7/XZlmWdeedd1pPPvmkfUnF0bBhw6x33nlnQMeMT34AAIizYDCo1tZWTZs2LXqfw+HQtGnTtGvXLhszi499+/YpPz9f1157rR588EEdPHjQ7pTi7sCBA+rs7Ow1hh6PR+Xl5YNiDCVp586duuqqqzR27FgtWrRIJ06csDulfunu7pYkeb1eSVJra6tCoVCvsRs3bpwKCwsTbuz+Xtt5GzZs0IgRI3TTTTdpxYoVOnPmjB3p9Vs4HNYHH3wgv98vn883oGOWGte9AQAA/fnnnwqHwxo5cmSv+0eOHKnff//dpqzio7y8XO+9957Gjh2ro0ePavXq1brjjjv0888/Kysry+704qazs1OSLjiG57clshkzZmju3LkqLi5WR0eHnn32Wc2cOVO7du2S0+m0Oz1jkUhES5cu1e23366bbrpJ0l9j53K5lJOT0ys20cbuQrVJ0gMPPKCioiLl5+dr7969euaZZ9Te3q5PPvnExmzN/PTTT/L5fAoEAsrMzNTmzZs1fvx4tbW1DdiY0fwAAABjM2fOjP5cWlqq8vJyFRUV6aOPPlJNTY2NmSEW999/f/Tnm2++WaWlpRozZox27typiooKGzOLTW1trX7++eeEnXd2Mf9W28KFC6M/33zzzRo1apQqKirU0dGhMWPGDHSaMRk7dqza2trU3d2tjz/+WNXV1Wpubh7QHPjaGwAAcTZixAg5nc5/rFR07Ngx5eXl2ZTV5ZGTk6Prr79e+/fvtzuVuDo/TskwhpJ07bXXasSIEQk1josXL9bWrVv1zTffqKCgIHp/Xl6egsGgurq6esUn0tj9W20XUl5eLkkJMXYul0slJSUqKyvTmjVrNGHCBL3xxhsDOmY0PwAAxJnL5VJZWZl27NgRvS8SiWjHjh3y+Xw2ZhZ/p0+fVkdHh0aNGmV3KnFVXFysvLy8XmN48uRJ7d69e9CNoSQdPnxYJ06cSIhxtCxLixcv1ubNm/X111+ruLi41/aysjKlpaX1Grv29nYdPHjwih+7vmq7kLa2NklKiLH7u0gkop6engEdM772BgDAZVBXV6fq6mrdeuutmjhxol5//XX5/X49+uijdqd2SZ566inNmjVLRUVFOnLkiOrr6+V0OjV//ny7U4vZ6dOne71bfuDAAbW1tcnr9aqwsFBLly7VSy+9pOuuu07FxcVatWqV8vPzNWfOHPuSNnSx2rxer1avXq2qqirl5eWpo6NDy5cvV0lJiSorK23M2kxtba2ampr02WefKSsrKzonxOPxKCMjQx6PRzU1Naqrq5PX61V2draWLFkin8+nSZMm2Zz9xfVVW0dHh5qamnTvvfdq+PDh2rt3r5YtW6YpU6aotLTU5uwvbsWKFZo5c6YKCwt16tQpNTU1aefOndq+ffvAjllc144DAABRb775plVYWGi5XC5r4sSJVktLi90pXbJ58+ZZo0aNslwul3X11Vdb8+bNs/bv3293Wv3yzTffWJL+cauurrYs66/lrletWmWNHDnScrvdVkVFhdXe3m5v0oYuVtuZM2es6dOnW7m5uVZaWppVVFRkLViwwOrs7LQ7bSMXqkuStX79+mjM2bNnrSeeeMIaNmyYNWTIEOu+++6zjh49al/Shvqq7eDBg9aUKVMsr9drud1uq6SkxHr66aet7u5uexM38Nhjj1lFRUWWy+WycnNzrYqKCuuLL76Ibh+oMUuxLMuKbzsFAAAAAFce5vwAAAAASAo0PwAAAACSAs0PAAAAgKRA8wMAAAAgKdD8AAAAAEgKND8AAAAAkgLNDwAAAICkQPMDAAAAICnQ/AAAAABICjQ/AAAAAJICzQ8AAACApEDzAwAAACAp/B/JbEJTCQYwFwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = Image.open('./ship.jpg')\n",
    "reshape_image = image.resize((32,32))\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image)\n",
    "plt.title('image')\n",
    "print(image.size)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(reshape_image)\n",
    "plt.title('reshape image')\n",
    "print(reshape_image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e322d2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "cat_tensor = transform(reshape_image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "eb98fd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "4714f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    net = net.to('cuda')\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    cat_tensor = cat_tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "808feb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'net': OrderedDict([('conv1.weight',\n",
       "               tensor([[[[ 1.9007e-02,  7.0236e-02,  7.6553e-02],\n",
       "                         [ 3.6165e-02,  9.3259e-02,  9.6969e-02],\n",
       "                         [-2.0013e-02,  1.0872e-02,  5.7526e-02]],\n",
       "               \n",
       "                        [[-2.6176e-02,  4.3282e-02,  5.6957e-02],\n",
       "                         [-2.3329e-02,  3.2779e-02,  6.1962e-02],\n",
       "                         [-5.4937e-02, -4.2050e-02,  9.0840e-03]],\n",
       "               \n",
       "                        [[-4.1336e-02,  1.8785e-02,  3.5406e-02],\n",
       "                         [-5.0364e-02, -1.3069e-02,  6.8028e-03],\n",
       "                         [-7.8665e-02, -8.8680e-02, -4.3480e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 6.1746e-02, -2.7466e-02, -1.1448e-01],\n",
       "                         [-3.0563e-02, -4.4555e-02,  6.4489e-02],\n",
       "                         [ 6.0118e-03, -5.7901e-02,  4.4292e-02]],\n",
       "               \n",
       "                        [[ 8.0762e-02,  2.2446e-02, -3.5991e-02],\n",
       "                         [-6.1249e-02, -6.8931e-02,  8.6970e-02],\n",
       "                         [-3.7146e-02, -1.1523e-01,  2.8131e-02]],\n",
       "               \n",
       "                        [[ 6.8880e-02,  3.5894e-02, -2.8244e-02],\n",
       "                         [-2.4070e-02, -1.4089e-02,  9.1884e-02],\n",
       "                         [-2.8364e-02, -7.3092e-02,  4.5346e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.0935e-03,  7.2321e-04, -7.3478e-04],\n",
       "                         [ 2.6425e-03,  5.3305e-03,  1.1040e-03],\n",
       "                         [ 5.3372e-05,  3.7510e-03,  2.2624e-03]],\n",
       "               \n",
       "                        [[ 2.8151e-03,  9.8630e-04,  2.0010e-03],\n",
       "                         [ 7.8858e-04,  1.6661e-03,  3.3772e-03],\n",
       "                         [ 1.2018e-03,  5.4584e-03,  4.5174e-03]],\n",
       "               \n",
       "                        [[-9.8260e-04,  5.6146e-03,  1.6715e-03],\n",
       "                         [ 2.9113e-03,  3.8610e-03,  1.3256e-03],\n",
       "                         [-1.1605e-03,  1.6404e-03, -1.7739e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-5.5277e-02,  6.1332e-02,  5.0265e-03],\n",
       "                         [ 9.6435e-02,  2.5184e-01,  1.7966e-01],\n",
       "                         [ 4.7841e-02,  2.2429e-01,  1.1533e-01]],\n",
       "               \n",
       "                        [[-2.5380e-02,  7.2066e-02,  1.6537e-02],\n",
       "                         [ 9.5351e-02,  2.1425e-01,  1.3266e-01],\n",
       "                         [ 2.7265e-02,  1.3124e-01,  4.8531e-02]],\n",
       "               \n",
       "                        [[-4.4578e-02,  1.0237e-02, -3.3339e-02],\n",
       "                         [ 3.8979e-04,  4.9319e-02,  1.6803e-02],\n",
       "                         [-7.1598e-02, -3.9167e-02, -7.7914e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.4576e-03, -5.5636e-03, -1.6652e-02],\n",
       "                         [ 3.4139e-02,  2.9471e-02,  2.0157e-02],\n",
       "                         [-1.8158e-03, -4.4402e-03, -1.9362e-02]],\n",
       "               \n",
       "                        [[ 4.4067e-02,  6.3040e-02,  2.2848e-02],\n",
       "                         [ 1.0260e-01,  1.0762e-01,  6.4571e-02],\n",
       "                         [ 4.4424e-02,  4.3347e-02,  1.7122e-02]],\n",
       "               \n",
       "                        [[ 2.4773e-02,  1.3081e-02, -2.5522e-02],\n",
       "                         [ 3.0211e-02,  4.1099e-03, -1.0456e-02],\n",
       "                         [-2.2870e-02, -4.4691e-02, -3.7024e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 6.3285e-02,  7.9099e-02,  1.7159e-02],\n",
       "                         [ 1.1396e-01, -1.7734e-02, -1.1205e-01],\n",
       "                         [ 4.8252e-02, -4.2283e-02, -7.1835e-02]],\n",
       "               \n",
       "                        [[ 5.7688e-02,  2.6439e-02, -3.9356e-02],\n",
       "                         [ 8.7005e-02, -5.5604e-02, -1.2615e-01],\n",
       "                         [ 4.1639e-02, -4.2516e-02, -4.5510e-02]],\n",
       "               \n",
       "                        [[ 3.3705e-02,  2.2446e-02, -6.9992e-02],\n",
       "                         [ 6.5969e-02, -4.3293e-02, -1.4877e-01],\n",
       "                         [ 2.8293e-02, -4.5900e-02, -9.8892e-02]]]], device='cuda:0')),\n",
       "              ('bn1.weight',\n",
       "               tensor([0.1976, 0.0505, 0.0055, 0.5232, 0.4387, 0.5654, 0.1499, 0.0039, 0.6549,\n",
       "                       0.2514, 0.0410, 0.3529, 0.4009, 0.0348, 0.1920, 0.2485, 0.2804, 0.0039,\n",
       "                       0.4103, 0.1053, 0.2659, 0.0040, 0.2469, 0.5034, 0.0059, 0.4642, 0.5179,\n",
       "                       0.0063, 0.5407, 0.6041, 0.4610, 0.6096, 0.2611, 0.3092, 0.0486, 0.5736,\n",
       "                       0.3541, 0.2342, 0.4672, 0.4721, 0.0045, 0.0048, 0.3220, 0.4685, 0.0065,\n",
       "                       0.2735, 0.5449, 0.3289, 0.1044, 0.1487, 0.5391, 0.0039, 0.7240, 0.3213,\n",
       "                       0.3220, 0.7244, 0.0565, 0.6576, 0.0010, 0.6185, 0.0179, 0.4328, 0.1758,\n",
       "                       0.0265], device='cuda:0')),\n",
       "              ('bn1.bias',\n",
       "               tensor([-0.1831,  0.2004, -0.0162,  1.0028,  0.3620,  0.4361, -0.0133, -0.0119,\n",
       "                       -0.4594,  0.1892, -0.0775,  0.3802, -0.1438, -0.0599, -0.0910,  0.2007,\n",
       "                        0.1836, -0.0108,  0.5474,  0.0165, -0.2416, -0.0143, -0.1502,  0.3956,\n",
       "                       -0.0182, -0.3213,  0.2584, -0.0236,  0.3313, -0.3151,  0.3578, -0.0936,\n",
       "                        0.2497, -0.1770,  0.0234,  0.2236, -0.2090, -0.2094, -0.0947,  0.2951,\n",
       "                       -0.0123, -0.0133, -0.0964, -0.2097, -0.0244,  0.2124,  0.1915,  0.4605,\n",
       "                        0.0341,  0.0970, -0.1535, -0.0156,  0.5278,  0.4293,  0.3583,  0.5519,\n",
       "                       -0.1514,  0.8724, -0.0068, -0.3867, -0.0551, -0.0665, -0.0432, -0.1079],\n",
       "                      device='cuda:0')),\n",
       "              ('bn1.running_mean',\n",
       "               tensor([ 0.1040, -0.0747,  0.0216, -0.0932,  0.1780, -0.0176,  0.2522, -0.0225,\n",
       "                       -0.5347,  0.4647, -0.0696, -0.1247, -0.3309, -0.0162,  0.1066, -0.0788,\n",
       "                        0.1466,  0.0185,  0.0271,  0.1211,  0.1624,  0.0069,  0.1364, -0.0729,\n",
       "                       -0.0336,  0.4383,  0.0151,  0.0178, -0.0666, -0.4192,  0.0372, -0.6510,\n",
       "                        0.0158, -0.2002,  0.1342,  0.1622,  0.2142,  0.2013, -0.3706, -0.0065,\n",
       "                        0.0402,  0.0269,  0.2858,  0.5055,  0.0204, -0.2914, -0.8579,  0.2330,\n",
       "                        0.1580,  0.2769, -0.3358,  0.0107,  0.0831, -0.0493,  0.1776,  0.0614,\n",
       "                        0.1918, -0.0561,  0.0076, -0.3637,  0.0515,  0.6231,  0.1985, -0.1024],\n",
       "                      device='cuda:0')),\n",
       "              ('bn1.running_var',\n",
       "               tensor([1.1888e-02, 4.3724e-03, 1.7680e-04, 4.2769e-02, 9.9226e-02, 3.1747e-01,\n",
       "                       2.7160e-02, 2.6607e-04, 1.2310e-01, 1.1621e-01, 1.9838e-03, 3.1148e-02,\n",
       "                       7.0532e-02, 4.8837e-04, 1.1393e-02, 5.3532e-02, 2.4645e-02, 1.3010e-04,\n",
       "                       3.6733e-02, 1.3561e-02, 1.7352e-02, 2.7021e-05, 1.9636e-02, 2.7290e-01,\n",
       "                       6.0104e-04, 8.7756e-02, 2.3008e-01, 1.2593e-04, 2.7750e-01, 7.1194e-02,\n",
       "                       5.0108e-02, 2.0951e-01, 4.6601e-02, 3.2978e-02, 1.7491e-02, 2.7460e-01,\n",
       "                       2.4619e-02, 2.0972e-02, 1.1649e-01, 3.2161e-01, 6.0176e-04, 2.7693e-04,\n",
       "                       4.3642e-02, 1.0901e-01, 1.9020e-04, 9.4279e-02, 2.9086e-01, 8.1507e-02,\n",
       "                       2.2812e-02, 4.1011e-02, 7.0070e-02, 5.8740e-05, 2.7147e-01, 8.4141e-02,\n",
       "                       6.7247e-02, 1.3532e-01, 1.4522e-02, 8.0132e-02, 6.4961e-05, 1.0387e-01,\n",
       "                       1.1107e-03, 1.5283e-01, 1.6150e-02, 2.1236e-02], device='cuda:0')),\n",
       "              ('bn1.num_batches_tracked', tensor(19550, device='cuda:0')),\n",
       "              ('layer1.0.conv1.weight',\n",
       "               tensor([[[[-1.3544e-02, -1.1473e-02, -1.0965e-02],\n",
       "                         [-8.3791e-03, -9.7506e-03, -1.0745e-02],\n",
       "                         [-9.7671e-03, -8.9909e-03, -1.2895e-02]],\n",
       "               \n",
       "                        [[-6.3044e-03, -4.8202e-03,  2.3802e-03],\n",
       "                         [-5.3463e-03, -4.0669e-04,  8.6596e-03],\n",
       "                         [ 1.9587e-03,  1.0426e-02,  1.6489e-02]],\n",
       "               \n",
       "                        [[-4.6092e-04, -6.2514e-04, -9.0282e-04],\n",
       "                         [-8.9276e-04, -4.3747e-04, -1.7888e-03],\n",
       "                         [ 2.8702e-04, -3.6100e-04, -1.3737e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.3215e-04, -1.3099e-03, -1.8464e-02],\n",
       "                         [ 3.2666e-03, -7.8385e-03, -2.7940e-02],\n",
       "                         [-1.1183e-02, -2.1700e-02, -3.5978e-02]],\n",
       "               \n",
       "                        [[-4.7493e-03, -3.3322e-03, -2.5348e-03],\n",
       "                         [-5.0209e-03, -2.9112e-03, -3.0384e-03],\n",
       "                         [-6.8923e-03, -6.9106e-03, -7.4238e-03]],\n",
       "               \n",
       "                        [[-5.6562e-03, -1.2055e-03,  5.9694e-03],\n",
       "                         [-6.4805e-03, -1.9967e-03,  5.1705e-03],\n",
       "                         [-3.9806e-03, -4.2637e-03, -2.7458e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-7.1786e-03, -8.0794e-03, -8.2884e-03],\n",
       "                         [ 1.4157e-03,  4.2071e-05, -4.8803e-03],\n",
       "                         [ 1.8763e-04,  4.4024e-05, -3.4782e-03]],\n",
       "               \n",
       "                        [[ 5.4074e-03,  1.0627e-02,  1.2079e-03],\n",
       "                         [ 2.8879e-03,  6.3805e-03, -4.0785e-03],\n",
       "                         [-7.5582e-03,  6.7599e-03,  1.2580e-02]],\n",
       "               \n",
       "                        [[-8.5102e-05, -8.5769e-04, -4.0654e-04],\n",
       "                         [-1.3080e-03, -9.4551e-04, -5.4669e-04],\n",
       "                         [-2.4217e-04, -3.7769e-04, -4.6998e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.1878e-02, -8.1689e-03, -1.3006e-02],\n",
       "                         [ 6.2355e-03,  8.5325e-03,  4.2030e-03],\n",
       "                         [-2.4501e-02, -2.9152e-02, -2.2715e-02]],\n",
       "               \n",
       "                        [[ 1.4767e-03,  1.8638e-03,  2.1510e-03],\n",
       "                         [ 6.4165e-03,  7.2385e-03,  8.9196e-03],\n",
       "                         [-1.0286e-02, -1.2909e-02, -1.4043e-02]],\n",
       "               \n",
       "                        [[ 8.3277e-03,  1.0591e-02,  9.3180e-03],\n",
       "                         [-4.9316e-03,  5.6412e-03,  9.5586e-03],\n",
       "                         [-1.5932e-02, -8.8284e-03, -7.7628e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.0721e-03,  1.0136e-02,  7.3945e-03],\n",
       "                         [-4.9693e-03, -2.6450e-03,  1.7048e-03],\n",
       "                         [-9.8999e-03, -1.2434e-02, -3.5528e-03]],\n",
       "               \n",
       "                        [[-5.1680e-03,  3.6367e-03, -9.2780e-03],\n",
       "                         [-2.0082e-02, -1.1113e-02, -8.7250e-03],\n",
       "                         [-9.9000e-03, -1.8782e-02, -1.5225e-02]],\n",
       "               \n",
       "                        [[-1.3017e-04,  1.4863e-04,  2.1424e-04],\n",
       "                         [ 1.0663e-04, -4.4243e-04, -8.2192e-04],\n",
       "                         [-4.7565e-04, -5.0281e-05,  3.9744e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.2052e-02,  3.3537e-02,  3.2463e-02],\n",
       "                         [ 2.4257e-02,  3.0712e-03,  1.0960e-02],\n",
       "                         [ 1.6856e-02, -5.0948e-03,  2.1454e-03]],\n",
       "               \n",
       "                        [[ 1.6019e-02,  1.5081e-02,  1.0547e-02],\n",
       "                         [ 9.3737e-03,  1.0741e-02,  4.8835e-03],\n",
       "                         [ 9.8608e-03,  1.0756e-02,  4.5672e-03]],\n",
       "               \n",
       "                        [[ 1.1028e-02,  1.8383e-02,  6.3104e-03],\n",
       "                         [ 9.1331e-03,  1.8000e-02,  3.2193e-03],\n",
       "                         [ 1.2713e-03,  1.9104e-02,  1.4473e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-1.6934e-02, -2.3915e-02, -2.1151e-02],\n",
       "                         [-1.3482e-02, -1.8111e-02, -1.5175e-02],\n",
       "                         [-1.1319e-02, -8.2055e-03, -1.3567e-02]],\n",
       "               \n",
       "                        [[ 1.0386e-03,  4.9794e-02, -7.3290e-03],\n",
       "                         [-1.8996e-03,  2.4114e-02, -8.3618e-03],\n",
       "                         [ 2.9021e-02,  1.6748e-02,  8.7569e-03]],\n",
       "               \n",
       "                        [[ 1.7436e-03,  7.1436e-04,  1.7519e-03],\n",
       "                         [ 1.7313e-03,  1.7249e-03,  1.8396e-03],\n",
       "                         [ 2.1811e-03,  1.0396e-03,  5.1630e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.8754e-02,  7.7418e-03, -7.7361e-03],\n",
       "                         [ 1.0723e-04,  2.6179e-03,  4.4013e-03],\n",
       "                         [ 1.0260e-02,  1.1875e-02,  1.9360e-02]],\n",
       "               \n",
       "                        [[-1.1196e-02, -7.3932e-03, -1.2233e-02],\n",
       "                         [-1.6870e-02, -3.4109e-03, -4.5534e-03],\n",
       "                         [-9.7342e-03, -3.1286e-03,  2.5141e-03]],\n",
       "               \n",
       "                        [[-6.6097e-03,  1.7612e-02, -3.4839e-02],\n",
       "                         [ 1.0226e-02,  2.4391e-02, -2.6291e-02],\n",
       "                         [ 1.3455e-02,  2.6524e-02, -7.0135e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.7620e-02, -2.7523e-03, -1.8463e-02],\n",
       "                         [-1.8579e-02, -4.1920e-03, -9.3822e-03],\n",
       "                         [-1.9712e-02, -1.1074e-02, -5.4163e-03]],\n",
       "               \n",
       "                        [[ 7.4433e-03,  2.2733e-02,  1.7404e-02],\n",
       "                         [-1.0458e-02,  2.8413e-03,  7.1028e-03],\n",
       "                         [-1.4303e-02, -8.8321e-03, -1.4987e-03]],\n",
       "               \n",
       "                        [[-8.0700e-04,  4.4379e-04, -2.5198e-04],\n",
       "                         [-5.8506e-05,  1.3875e-04, -8.1127e-04],\n",
       "                         [ 1.1522e-04,  1.1839e-05,  5.1289e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.0433e-03,  7.1147e-03,  4.9600e-03],\n",
       "                         [ 1.6916e-02,  1.3452e-02,  1.1542e-02],\n",
       "                         [ 5.6288e-04, -1.7110e-02, -1.4672e-02]],\n",
       "               \n",
       "                        [[-4.4573e-03,  1.2458e-03,  1.2978e-03],\n",
       "                         [-1.1539e-03,  1.2278e-03,  2.0343e-03],\n",
       "                         [ 5.4980e-03,  7.6046e-03,  7.8528e-03]],\n",
       "               \n",
       "                        [[ 2.0086e-02,  1.7759e-02,  7.0814e-03],\n",
       "                         [ 6.3375e-03, -7.3110e-04, -2.3657e-03],\n",
       "                         [-5.1081e-03, -1.6004e-02, -1.1055e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.1082e-03, -4.5743e-03, -1.5530e-03],\n",
       "                         [-1.5214e-03, -5.0497e-03, -4.0269e-03],\n",
       "                         [-1.7655e-03, -4.1618e-03, -6.4699e-03]],\n",
       "               \n",
       "                        [[-4.3757e-03, -3.6045e-03, -1.8247e-03],\n",
       "                         [-1.0903e-03, -3.4465e-04, -4.4646e-04],\n",
       "                         [-3.5699e-03,  5.1252e-04,  6.5671e-04]],\n",
       "               \n",
       "                        [[-1.2606e-03, -6.5068e-04, -4.4007e-04],\n",
       "                         [-1.0608e-03, -1.3409e-03, -1.2488e-03],\n",
       "                         [-8.5828e-04, -1.4280e-03, -1.7822e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 6.4835e-03, -5.9766e-03, -1.5945e-02],\n",
       "                         [ 1.2232e-02, -2.9329e-03, -1.1905e-02],\n",
       "                         [ 3.9294e-03, -5.6126e-03, -8.0394e-03]],\n",
       "               \n",
       "                        [[-1.2372e-02, -9.5842e-03, -4.7010e-03],\n",
       "                         [-1.2111e-02, -7.8337e-03, -2.6407e-03],\n",
       "                         [-1.0668e-02, -6.7878e-03, -1.5880e-03]],\n",
       "               \n",
       "                        [[-1.1094e-02, -1.2449e-02, -9.9629e-03],\n",
       "                         [-1.2747e-02, -1.3436e-02, -9.6818e-03],\n",
       "                         [-1.7646e-02, -1.6728e-02, -1.0408e-02]]]], device='cuda:0')),\n",
       "              ('layer1.0.bn1.weight',\n",
       "               tensor([0.2192, 0.6427, 0.3129, 0.4051, 0.2795, 0.3950, 0.2460, 0.1200, 0.1120,\n",
       "                       0.2826, 0.2414, 0.3555, 0.6199, 0.2266, 0.4507, 0.3709, 0.6855, 0.3606,\n",
       "                       0.3884, 0.1264, 0.4261, 0.4647, 0.1717, 0.2454, 0.4810, 0.2314, 0.2882,\n",
       "                       0.2371, 0.1268, 0.2249, 0.3544, 0.4054, 0.3381, 0.3530, 0.2039, 0.1310,\n",
       "                       0.1874, 0.3624, 0.1784, 0.1354, 0.4039, 0.5239, 0.2892, 0.1561, 0.2850,\n",
       "                       0.0788, 0.3355, 0.1052, 0.2660, 0.1778, 0.4140, 0.3188, 0.3301, 0.2176,\n",
       "                       0.2702, 0.3423, 0.5327, 0.3895, 0.3071, 0.3168, 0.1720, 0.8691, 0.3184,\n",
       "                       0.2321], device='cuda:0')),\n",
       "              ('layer1.0.bn1.bias',\n",
       "               tensor([ 0.0340, -0.7506,  0.1567, -0.1654, -0.1930, -0.3350,  0.0804,  0.0243,\n",
       "                       -0.0968,  0.0773, -0.1924, -0.2253,  0.4449, -0.0974, -0.2601, -0.2418,\n",
       "                        0.5553,  0.2789,  0.0400, -0.1966,  0.3909, -0.3110, -0.1345, -0.1469,\n",
       "                        0.6907,  0.0721, -0.1071,  0.0856, -0.1074, -0.0467,  0.0466,  0.1203,\n",
       "                       -0.0219,  0.2027, -0.1747, -0.0408, -0.0020,  0.0994, -0.0928, -0.1346,\n",
       "                        0.0759,  0.1300, -0.1084, -0.1074, -0.1123, -0.0775, -0.2917,  0.0393,\n",
       "                       -0.1845,  0.0805,  0.2641, -0.1194, -0.1512, -0.2272,  0.2067, -0.0269,\n",
       "                       -0.1956,  0.2888, -0.0581,  0.2081,  0.0126, -0.1995,  0.2395, -0.1473],\n",
       "                      device='cuda:0')),\n",
       "              ('layer1.0.bn1.running_mean',\n",
       "               tensor([-1.6986,  0.8937, -0.5254, -1.0427,  1.2022,  0.6291, -1.3925,  1.0378,\n",
       "                        0.6528, -1.1924,  0.4420,  0.5357, -0.7259,  0.0042, -1.1128, -0.4751,\n",
       "                       -0.1351, -1.0997, -0.7728,  1.0273, -0.8633, -2.5439,  0.2738,  0.1261,\n",
       "                        0.1292,  0.5413,  2.3079, -0.9505,  0.9134, -0.4978, -1.5083, -1.1700,\n",
       "                       -2.0619, -2.4761,  1.1320, -0.1932,  0.0294, -1.0680, -0.1034, -0.1164,\n",
       "                       -1.0610, -1.3521, -1.0641, -0.0686, -0.9736,  0.1277,  0.1144, -1.4516,\n",
       "                       -0.1541, -1.1470, -1.5038, -0.6200, -0.7012,  2.5031, -1.7818, -1.3411,\n",
       "                       -0.4101, -1.1138, -0.2755, -0.6228, -1.3124, -0.9673, -0.8783, -1.6653],\n",
       "                      device='cuda:0')),\n",
       "              ('layer1.0.bn1.running_var',\n",
       "               tensor([0.3138, 0.6265, 0.6583, 0.6481, 0.2182, 0.3186, 0.2349, 0.1428, 0.0508,\n",
       "                       0.6366, 0.1471, 0.2273, 0.9951, 0.2091, 0.6813, 0.6514, 1.5885, 0.9944,\n",
       "                       1.0461, 0.1508, 0.7599, 0.8255, 0.1898, 0.3595, 0.9062, 0.4416, 0.2685,\n",
       "                       0.5866, 0.0745, 0.3198, 0.4268, 0.9102, 1.0267, 0.7916, 0.1614, 0.0908,\n",
       "                       0.2141, 0.7914, 0.1092, 0.0432, 0.9231, 1.4161, 0.4694, 0.0453, 0.2384,\n",
       "                       0.0205, 0.1819, 0.2282, 0.2786, 0.2357, 0.4874, 0.4035, 0.3264, 0.3979,\n",
       "                       0.5331, 0.3209, 0.8411, 0.6922, 0.6314, 0.6133, 0.4501, 2.2987, 0.6643,\n",
       "                       0.2633], device='cuda:0')),\n",
       "              ('layer1.0.bn1.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer1.0.conv2.weight',\n",
       "               tensor([[[[ 1.9069e-02,  6.8985e-04,  1.7124e-03],\n",
       "                         [ 2.1016e-02,  4.8084e-03,  9.2486e-03],\n",
       "                         [ 3.4350e-02,  1.1867e-02,  1.0905e-02]],\n",
       "               \n",
       "                        [[-9.2064e-04, -6.9939e-04, -2.7984e-03],\n",
       "                         [ 4.5689e-03,  2.9681e-03, -2.3295e-03],\n",
       "                         [-1.9933e-02, -2.2793e-02, -2.6324e-02]],\n",
       "               \n",
       "                        [[-1.2987e-03, -5.6604e-03, -2.1488e-02],\n",
       "                         [ 3.1534e-03,  3.1630e-03, -1.9441e-02],\n",
       "                         [ 2.0497e-02,  1.5788e-02, -9.3261e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.7574e-02,  2.1294e-02, -5.9415e-02],\n",
       "                         [-2.9091e-02,  3.6305e-02, -3.1046e-02],\n",
       "                         [-1.7662e-03,  1.4997e-01,  1.9506e-02]],\n",
       "               \n",
       "                        [[ 1.8361e-02, -8.8901e-03, -2.6444e-02],\n",
       "                         [ 1.5576e-02,  1.4674e-02,  4.5013e-03],\n",
       "                         [-6.1844e-03,  4.4920e-02,  6.0880e-02]],\n",
       "               \n",
       "                        [[-3.7448e-03, -3.1392e-03, -9.8442e-03],\n",
       "                         [-2.2114e-03, -1.9758e-03, -7.5774e-03],\n",
       "                         [ 4.1647e-03, -2.7882e-04, -3.8160e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.5790e-02,  1.7847e-02, -2.1548e-02],\n",
       "                         [-2.3807e-02, -5.0789e-02, -9.6156e-03],\n",
       "                         [-1.9948e-02, -6.0907e-02, -3.0478e-02]],\n",
       "               \n",
       "                        [[-3.4119e-02,  1.1384e-02,  5.9118e-02],\n",
       "                         [ 7.0265e-02,  3.9015e-02,  1.7081e-02],\n",
       "                         [-4.9795e-02, -5.0088e-02, -3.5418e-02]],\n",
       "               \n",
       "                        [[-3.5965e-02, -1.7258e-02,  2.0804e-03],\n",
       "                         [ 4.6125e-02,  6.4451e-02, -6.4409e-02],\n",
       "                         [ 1.4216e-02,  2.7541e-02, -5.9792e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-6.3144e-02, -3.9137e-02, -2.4281e-02],\n",
       "                         [-1.4787e-01, -8.4686e-02, -6.8183e-02],\n",
       "                         [-5.1742e-02, -6.2280e-02, -1.4359e-01]],\n",
       "               \n",
       "                        [[-3.5721e-02, -5.2052e-03,  2.0673e-02],\n",
       "                         [ 2.3564e-02, -6.7103e-03, -4.2234e-03],\n",
       "                         [-9.1070e-03, -3.2459e-03,  7.6044e-03]],\n",
       "               \n",
       "                        [[-2.7013e-02,  7.5057e-03,  9.0816e-03],\n",
       "                         [-1.7569e-02, -7.5440e-03,  2.5910e-03],\n",
       "                         [-1.7245e-02, -2.9374e-02, -8.5068e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.4462e-02, -1.2841e-02,  1.4182e-02],\n",
       "                         [ 3.3129e-02,  1.4810e-02,  4.9493e-02],\n",
       "                         [ 6.0285e-03, -1.4211e-02,  1.1554e-02]],\n",
       "               \n",
       "                        [[ 3.9289e-02,  3.1166e-02,  3.2718e-02],\n",
       "                         [-2.5883e-02, -1.7178e-02, -8.1626e-03],\n",
       "                         [-8.5568e-03, -1.6940e-02, -3.2454e-02]],\n",
       "               \n",
       "                        [[-6.2626e-04, -1.4731e-02,  2.0413e-02],\n",
       "                         [-4.1686e-02, -4.1689e-02,  1.3810e-02],\n",
       "                         [-2.1880e-02, -2.8591e-02, -1.0020e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.0518e-01, -1.2726e-01, -1.1180e-01],\n",
       "                         [-1.1983e-01, -1.3989e-01, -1.5704e-01],\n",
       "                         [-9.5719e-02, -1.5060e-01, -4.7241e-02]],\n",
       "               \n",
       "                        [[ 5.7389e-02,  2.0569e-02,  1.5806e-02],\n",
       "                         [ 7.0011e-03,  3.0269e-02,  6.5969e-02],\n",
       "                         [-5.2854e-02, -3.9141e-02,  1.2841e-02]],\n",
       "               \n",
       "                        [[ 1.4185e-02, -9.0790e-03,  2.4928e-02],\n",
       "                         [ 1.0737e-02, -2.2959e-04,  3.9126e-02],\n",
       "                         [ 8.1509e-03,  9.7835e-03,  3.1634e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-3.8290e-03,  2.9525e-03, -1.1084e-02],\n",
       "                         [-5.7346e-03, -1.8571e-03, -8.7552e-03],\n",
       "                         [-2.9884e-03,  1.3642e-02,  7.9020e-03]],\n",
       "               \n",
       "                        [[-3.4664e-02, -3.8173e-02, -4.1683e-02],\n",
       "                         [-2.4966e-02, -2.6145e-02, -2.7757e-02],\n",
       "                         [-2.3705e-02, -2.6461e-02, -2.7079e-02]],\n",
       "               \n",
       "                        [[-3.9957e-02, -5.0433e-02, -3.4631e-02],\n",
       "                         [-4.8694e-02, -5.7964e-02, -4.9155e-02],\n",
       "                         [-2.8188e-02, -5.3385e-02, -2.9191e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.0883e-02, -1.6169e-02, -3.1085e-03],\n",
       "                         [ 1.4263e-02, -1.7016e-02, -1.6656e-02],\n",
       "                         [-1.9708e-03, -5.2262e-02, -3.9128e-02]],\n",
       "               \n",
       "                        [[-5.5050e-03,  2.4927e-03, -3.2838e-03],\n",
       "                         [-1.3338e-03,  9.6816e-03,  5.8168e-03],\n",
       "                         [-3.9784e-03,  4.0586e-02,  3.5939e-02]],\n",
       "               \n",
       "                        [[-1.0854e-02, -3.3102e-03, -8.2663e-03],\n",
       "                         [-8.7547e-03, -4.1244e-03, -1.1266e-04],\n",
       "                         [-1.2619e-02, -2.1109e-03,  9.2030e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.0409e-03, -1.5708e-02,  1.1108e-02],\n",
       "                         [-1.0766e-02, -2.9385e-03,  3.6468e-02],\n",
       "                         [ 6.6262e-03,  1.5610e-02,  2.9431e-02]],\n",
       "               \n",
       "                        [[-3.3462e-03, -3.3628e-03, -5.2846e-03],\n",
       "                         [-4.3037e-03, -5.5986e-03, -3.1925e-03],\n",
       "                         [-1.5919e-02, -1.5984e-02, -9.6689e-03]],\n",
       "               \n",
       "                        [[ 1.4012e-02,  5.9546e-03, -8.3187e-03],\n",
       "                         [-2.0084e-02, -3.7420e-02, -4.2414e-02],\n",
       "                         [-6.1001e-02, -4.6819e-02, -2.0225e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.0527e-01,  2.9596e-02, -4.6793e-02],\n",
       "                         [ 4.4546e-02, -8.2173e-03, -4.2059e-02],\n",
       "                         [-4.9474e-04, -7.5104e-02, -2.4877e-02]],\n",
       "               \n",
       "                        [[-5.6636e-02, -6.9029e-03,  2.7003e-02],\n",
       "                         [-7.7927e-02,  6.1731e-03,  6.6253e-02],\n",
       "                         [-3.0151e-02,  4.5045e-02,  2.9185e-02]],\n",
       "               \n",
       "                        [[ 6.9838e-03, -9.7477e-03,  5.3341e-03],\n",
       "                         [-9.5350e-03, -9.3179e-03,  1.3443e-02],\n",
       "                         [-1.8722e-02, -1.5589e-02,  2.7905e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.1928e-02,  3.9285e-02,  1.3534e-02],\n",
       "                         [ 5.4232e-02,  4.9432e-02, -2.2681e-02],\n",
       "                         [ 1.8586e-02, -7.4142e-03, -3.7798e-02]],\n",
       "               \n",
       "                        [[ 4.5479e-03,  8.1591e-04,  2.2759e-03],\n",
       "                         [-1.0320e-01, -8.1110e-02, -6.8908e-02],\n",
       "                         [ 2.2505e-02,  3.2131e-02,  2.8450e-02]],\n",
       "               \n",
       "                        [[-3.7539e-03, -2.6310e-02,  3.2190e-02],\n",
       "                         [-1.1691e-01,  1.4754e-02,  6.4618e-02],\n",
       "                         [-4.0547e-02,  3.4612e-03,  6.6499e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.4986e-02, -9.0468e-02,  2.8497e-02],\n",
       "                         [-3.9139e-02,  7.4785e-02, -9.6738e-03],\n",
       "                         [-6.2507e-02, -4.0455e-02, -1.0726e-01]],\n",
       "               \n",
       "                        [[-1.1685e-02, -6.2426e-03,  5.9854e-02],\n",
       "                         [ 5.6162e-02,  7.2911e-03,  2.4461e-02],\n",
       "                         [-2.8370e-02, -5.9957e-02, -4.7445e-02]],\n",
       "               \n",
       "                        [[-3.5160e-02,  4.7929e-02,  5.1959e-02],\n",
       "                         [-2.6560e-03,  7.9588e-02,  6.9003e-03],\n",
       "                         [ 2.6002e-02,  4.3582e-02, -1.5209e-02]]]], device='cuda:0')),\n",
       "              ('layer1.0.bn2.weight',\n",
       "               tensor([0.2730, 0.6006, 0.4744, 0.5238, 0.4625, 0.1756, 0.5195, 0.4931, 0.4394,\n",
       "                       0.6557, 0.3384, 0.3427, 0.2428, 0.2743, 0.1400, 0.4160, 0.4079, 0.5918,\n",
       "                       0.5557, 0.2747, 0.2959, 0.3804, 0.2879, 0.1700, 0.2415, 0.2360, 0.1376,\n",
       "                       0.2741, 0.6852, 0.3649, 0.4499, 0.2133, 0.7898, 0.0953, 0.3892, 0.4819,\n",
       "                       0.0590, 0.1952, 0.2505, 0.6218, 0.3570, 0.1806, 0.1002, 0.0552, 0.4652,\n",
       "                       0.2803, 0.0229, 0.4357, 0.3048, 0.4140, 0.2103, 0.3266, 0.2790, 0.3513,\n",
       "                       0.6242, 0.7304, 0.5866, 1.0111, 0.2456, 0.2424, 0.3858, 0.1225, 0.3838,\n",
       "                       0.6115], device='cuda:0')),\n",
       "              ('layer1.0.bn2.bias',\n",
       "               tensor([-0.1226,  0.1647,  0.1421, -0.3234, -0.4686,  0.0366,  0.2709, -0.0948,\n",
       "                       -0.3627, -0.2958, -0.0354, -0.1746, -0.1684, -0.1580, -0.0548, -0.5177,\n",
       "                       -0.2951,  0.0925, -0.5530,  0.0389,  0.0436, -0.0901, -0.0353, -0.2426,\n",
       "                        0.2502, -0.1324,  0.2122, -0.0389, -0.1523, -0.1613, -0.4007, -0.0318,\n",
       "                       -0.0030, -0.0085, -0.0102, -0.0647,  0.0074,  0.0303, -0.2672, -0.1647,\n",
       "                       -0.0906,  0.0740, -0.0488,  0.0502,  0.0576,  0.0638,  0.0699, -0.1114,\n",
       "                        0.0198, -0.2615, -0.0978,  0.1511, -0.1741, -0.2237,  0.1285,  0.1469,\n",
       "                       -0.0853, -0.1616,  0.0665,  0.1460, -0.1080, -0.0025,  0.0832,  0.3315],\n",
       "                      device='cuda:0')),\n",
       "              ('layer1.0.bn2.running_mean',\n",
       "               tensor([ 0.3619, -0.2755, -1.0458, -0.2549, -0.0287,  0.5415, -0.3715, -0.4579,\n",
       "                        0.6605, -0.3870, -0.3387, -0.4807,  0.1018, -0.3609, -0.2295, -0.2225,\n",
       "                       -0.3141, -0.2437, -0.0941, -0.1381, -0.1166, -0.0978, -0.7478,  0.1016,\n",
       "                       -0.3455,  0.3014, -0.2742, -0.2761, -0.6026, -0.2263,  0.5000,  0.0820,\n",
       "                       -0.5763, -0.0629, -0.3920,  0.1115, -0.2923, -0.4018,  0.6284, -0.3394,\n",
       "                        0.0251, -0.5045,  0.5569, -0.1208, -0.2418, -0.2447, -0.0435,  0.0760,\n",
       "                       -0.8172, -0.1543, -0.1374, -0.8758,  0.0242,  0.1508, -0.0957,  0.1482,\n",
       "                        0.1223, -1.3465, -0.2363, -0.3055,  0.0517, -0.2545, -0.4649, -0.6275],\n",
       "                      device='cuda:0')),\n",
       "              ('layer1.0.bn2.running_var',\n",
       "               tensor([0.1152, 0.5687, 0.4099, 0.4765, 0.4668, 0.2514, 0.6865, 0.2832, 0.3603,\n",
       "                       0.5218, 0.1983, 0.3641, 0.0980, 0.0937, 0.0679, 0.3003, 0.1958, 0.6735,\n",
       "                       0.5611, 0.1713, 0.1368, 0.3911, 0.2105, 0.2542, 0.3049, 0.1307, 0.3649,\n",
       "                       0.2123, 1.5412, 0.3228, 0.2559, 0.3045, 0.7076, 0.0709, 0.3786, 1.0511,\n",
       "                       0.0428, 0.1392, 0.1475, 1.0875, 0.1319, 0.1392, 0.0813, 0.0637, 0.4071,\n",
       "                       0.3208, 0.1159, 0.2796, 0.2597, 0.3038, 0.1820, 0.2260, 0.5032, 0.4717,\n",
       "                       0.9851, 1.2854, 0.3397, 1.2073, 0.2486, 0.1679, 0.1981, 0.1678, 0.2058,\n",
       "                       0.8333], device='cuda:0')),\n",
       "              ('layer1.0.bn2.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer1.1.conv1.weight',\n",
       "               tensor([[[[ 1.1134e-02, -3.9311e-02, -1.8223e-02],\n",
       "                         [-1.4003e-02, -4.0440e-02, -3.2995e-03],\n",
       "                         [ 7.5816e-03, -3.5254e-02, -2.8898e-03]],\n",
       "               \n",
       "                        [[ 2.5409e-02,  8.6290e-03, -7.4685e-02],\n",
       "                         [-1.3912e-01,  4.9180e-02, -2.3885e-02],\n",
       "                         [ 6.1066e-02, -1.6438e-01, -4.9764e-02]],\n",
       "               \n",
       "                        [[ 9.1760e-02,  4.6350e-02,  5.7086e-02],\n",
       "                         [ 1.0819e-01, -3.0211e-04,  2.1215e-02],\n",
       "                         [ 1.1081e-01,  7.1958e-02,  7.1229e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.9758e-02,  1.4937e-02,  5.7547e-02],\n",
       "                         [-2.6213e-02,  3.0735e-02,  6.0738e-02],\n",
       "                         [-2.0355e-03,  2.1922e-02,  2.2907e-02]],\n",
       "               \n",
       "                        [[-2.7940e-02, -1.3072e-02,  5.1320e-02],\n",
       "                         [-2.9579e-02,  1.3164e-02,  6.1555e-02],\n",
       "                         [-1.2329e-02,  1.6920e-02,  5.9757e-02]],\n",
       "               \n",
       "                        [[-1.0792e-01, -6.3972e-02, -1.6002e-01],\n",
       "                         [-4.1411e-02, -9.3300e-02, -2.1977e-01],\n",
       "                         [-9.9067e-02, -1.5306e-01,  3.3896e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.6145e-03,  4.1978e-04, -1.0921e-02],\n",
       "                         [ 2.1255e-02,  2.2299e-02, -3.7774e-03],\n",
       "                         [-1.5911e-03,  1.4402e-02, -5.1898e-03]],\n",
       "               \n",
       "                        [[-1.2078e-01, -9.3059e-02,  2.6086e-02],\n",
       "                         [ 7.7818e-02,  2.6429e-02, -6.8687e-02],\n",
       "                         [-7.0881e-02,  5.4085e-03, -1.5812e-03]],\n",
       "               \n",
       "                        [[ 3.5359e-02,  2.6523e-02,  3.7451e-02],\n",
       "                         [ 1.8862e-02,  1.3487e-02,  1.9576e-02],\n",
       "                         [ 2.6901e-02,  2.6017e-02,  4.1128e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.2091e-02,  1.8530e-02,  1.6271e-02],\n",
       "                         [ 7.7675e-03,  2.0309e-02,  1.6974e-02],\n",
       "                         [-6.6294e-03,  2.8781e-03, -4.6787e-03]],\n",
       "               \n",
       "                        [[ 2.7866e-02,  3.9343e-02,  4.9166e-02],\n",
       "                         [ 3.1005e-02,  3.4447e-02,  4.0760e-02],\n",
       "                         [ 2.6094e-02,  3.2334e-02,  2.9689e-02]],\n",
       "               \n",
       "                        [[ 8.7220e-02,  9.9026e-02,  1.9882e-02],\n",
       "                         [-6.3624e-02, -5.5483e-02,  4.5188e-03],\n",
       "                         [ 8.2729e-03,  1.8279e-02,  1.1644e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.2905e-02,  4.9819e-02,  3.6106e-02],\n",
       "                         [ 1.5690e-02,  1.9369e-02,  1.2668e-02],\n",
       "                         [-2.3350e-02, -2.6868e-02, -1.0902e-02]],\n",
       "               \n",
       "                        [[ 7.8568e-02, -2.9330e-02, -2.0766e-01],\n",
       "                         [-2.8065e-01, -6.2138e-02, -8.5929e-02],\n",
       "                         [ 7.9441e-02, -7.7784e-02, -1.5490e-01]],\n",
       "               \n",
       "                        [[ 1.5939e-02,  5.1890e-02,  3.7061e-03],\n",
       "                         [ 4.7714e-02,  2.3813e-02,  8.0245e-03],\n",
       "                         [ 5.0886e-02,  4.7698e-02,  2.0718e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 6.6143e-02,  6.4963e-02,  5.5864e-02],\n",
       "                         [ 6.5884e-03, -1.2060e-02, -7.5776e-03],\n",
       "                         [-1.7389e-02, -3.7389e-02, -2.8394e-02]],\n",
       "               \n",
       "                        [[ 6.0414e-02,  2.5574e-02,  3.5034e-02],\n",
       "                         [ 3.2163e-03, -1.7791e-02,  2.5440e-03],\n",
       "                         [ 2.1312e-02, -4.8337e-02, -5.8620e-02]],\n",
       "               \n",
       "                        [[-1.8879e-01, -1.0283e-01,  1.7723e-02],\n",
       "                         [-1.8241e-02,  6.1769e-02, -7.5427e-02],\n",
       "                         [-1.6397e-01, -7.1001e-02, -7.1616e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-6.2170e-03,  2.6949e-04, -1.0789e-02],\n",
       "                         [ 1.1475e-02, -3.2671e-03, -3.4209e-02],\n",
       "                         [ 1.1691e-02,  1.0531e-02, -1.7650e-02]],\n",
       "               \n",
       "                        [[-1.9581e-02, -2.5108e-02,  2.6631e-02],\n",
       "                         [-5.7530e-02, -1.2739e-01, -9.9233e-02],\n",
       "                         [-1.9016e-02,  6.5029e-02,  3.8323e-02]],\n",
       "               \n",
       "                        [[-2.1104e-02,  8.0902e-03,  3.5503e-02],\n",
       "                         [-2.5764e-04,  4.4248e-02,  7.1740e-02],\n",
       "                         [-1.9267e-02, -1.2858e-03,  2.6666e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.4125e-02,  2.2788e-02, -2.4968e-04],\n",
       "                         [ 4.3882e-02,  2.2183e-02, -1.0874e-02],\n",
       "                         [ 8.7135e-03, -5.4556e-03, -2.1949e-02]],\n",
       "               \n",
       "                        [[ 5.0417e-03,  2.2596e-02,  2.3661e-02],\n",
       "                         [ 2.7397e-02,  2.2382e-02,  1.1971e-02],\n",
       "                         [ 1.6770e-02,  2.3390e-03, -1.5745e-02]],\n",
       "               \n",
       "                        [[-2.6934e-02, -8.3937e-02, -6.1676e-02],\n",
       "                         [-3.3486e-02,  2.9573e-02,  9.1988e-02],\n",
       "                         [-8.0155e-02, -8.7874e-02, -2.8043e-04]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 8.1144e-07, -5.5783e-03, -1.3512e-02],\n",
       "                         [ 1.5167e-02, -1.2554e-03, -1.0947e-02],\n",
       "                         [ 7.4515e-03,  1.5527e-03, -2.9271e-03]],\n",
       "               \n",
       "                        [[-9.5460e-03, -1.5032e-02, -1.8105e-02],\n",
       "                         [ 8.1708e-02, -3.8478e-03, -1.4076e-02],\n",
       "                         [-3.4911e-02, -1.8612e-02,  4.8663e-02]],\n",
       "               \n",
       "                        [[-1.5192e-02,  5.7805e-03,  9.9540e-03],\n",
       "                         [-2.3513e-02,  4.9539e-03,  1.9592e-02],\n",
       "                         [-2.7411e-02, -9.8116e-03,  7.5669e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-6.7533e-03,  1.0062e-02,  5.1093e-03],\n",
       "                         [ 1.2744e-03,  1.1288e-02,  2.7781e-03],\n",
       "                         [ 2.0287e-03,  3.8831e-03, -1.1513e-02]],\n",
       "               \n",
       "                        [[-2.1547e-02,  2.0508e-02,  2.0892e-02],\n",
       "                         [-5.0226e-03,  2.5246e-02,  1.6495e-02],\n",
       "                         [ 1.0136e-02,  2.6823e-02,  1.5590e-02]],\n",
       "               \n",
       "                        [[-5.4106e-03, -5.3566e-02,  9.2731e-03],\n",
       "                         [-2.7469e-02, -1.2281e-02,  3.4505e-02],\n",
       "                         [ 6.1616e-03,  1.3420e-04, -5.3229e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.9637e-04,  7.2724e-03, -3.5655e-03],\n",
       "                         [-7.0587e-04, -3.3221e-03, -7.1702e-03],\n",
       "                         [-1.0425e-03, -3.3539e-03, -1.0364e-02]],\n",
       "               \n",
       "                        [[ 2.5758e-03,  5.6375e-03,  2.7401e-02],\n",
       "                         [ 2.4513e-02,  1.8181e-02,  2.7429e-02],\n",
       "                         [ 6.0588e-02, -2.6574e-02, -2.9387e-02]],\n",
       "               \n",
       "                        [[ 1.9054e-02,  6.2306e-03,  1.6836e-02],\n",
       "                         [ 7.0977e-03, -7.7311e-03,  8.7360e-03],\n",
       "                         [-1.0278e-02, -1.2450e-02,  1.1005e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.5326e-04,  1.9792e-03,  2.7191e-03],\n",
       "                         [-2.4737e-03, -1.9514e-03,  3.1174e-03],\n",
       "                         [-5.9275e-03, -4.2443e-03,  2.4680e-03]],\n",
       "               \n",
       "                        [[-1.9893e-02, -8.1919e-03,  1.5524e-03],\n",
       "                         [-1.8178e-02, -3.6694e-03,  1.3267e-02],\n",
       "                         [-8.8654e-03,  9.3741e-03,  2.1330e-02]],\n",
       "               \n",
       "                        [[-7.2727e-04,  4.2044e-02, -5.9019e-02],\n",
       "                         [ 3.0686e-05, -1.1024e-02, -4.3881e-02],\n",
       "                         [-4.4364e-02, -3.3814e-02, -4.2941e-02]]]], device='cuda:0')),\n",
       "              ('layer1.1.bn1.weight',\n",
       "               tensor([0.4780, 0.3244, 0.5345, 0.1215, 0.3262, 0.0743, 0.1620, 0.2096, 0.1030,\n",
       "                       0.1654, 0.1505, 0.5519, 0.2395, 0.4671, 0.2689, 0.3563, 0.1770, 0.2693,\n",
       "                       0.2531, 0.1639, 0.3725, 0.7157, 0.5796, 0.2009, 0.3723, 0.4626, 0.1223,\n",
       "                       0.3597, 0.3704, 0.3404, 0.2725, 0.2052, 0.3838, 0.3359, 0.1819, 0.3333,\n",
       "                       0.3759, 0.3658, 0.1343, 0.2887, 0.1988, 0.1969, 0.1663, 0.4618, 0.4026,\n",
       "                       0.3638, 0.3127, 0.1668, 0.1447, 0.5312, 0.2487, 0.1520, 0.4015, 0.3279,\n",
       "                       0.4472, 0.3376, 0.1991, 0.1819, 0.1891, 0.5557, 0.5920, 0.2677, 0.2414,\n",
       "                       0.1616], device='cuda:0')),\n",
       "              ('layer1.1.bn1.bias',\n",
       "               tensor([ 0.0361, -0.0815,  0.0905, -0.1767, -0.2645, -0.0564, -0.0767, -0.1365,\n",
       "                       -0.1280, -0.0697, -0.0962, -0.5059, -0.1102, -0.1572, -0.2275, -0.0266,\n",
       "                       -0.1155, -0.0686, -0.0637, -0.0244, -0.0222, -0.2524, -0.3323, -0.1622,\n",
       "                       -0.0486, -0.3485, -0.0360, -0.2362, -0.0239,  0.0634,  0.0484, -0.1205,\n",
       "                        0.0345, -0.2770,  0.0071, -0.3630, -0.4326, -0.0014, -0.1168, -0.1357,\n",
       "                       -0.1225, -0.0416, -0.0468, -0.4863, -0.3804, -0.0664, -0.0677, -0.0941,\n",
       "                       -0.1658, -0.1755,  0.0308, -0.0862, -0.3282, -0.2463, -0.1626, -0.1159,\n",
       "                       -0.0833, -0.0597, -0.1282,  0.0484, -0.1517, -0.0406, -0.1237, -0.1329],\n",
       "                      device='cuda:0')),\n",
       "              ('layer1.1.bn1.running_mean',\n",
       "               tensor([-2.0572, -0.5892, -2.2614,  0.7710, -1.3771, -0.0614, -0.2919, -0.1498,\n",
       "                        0.4805, -0.5496, -0.5261,  0.2782, -1.1842, -1.7342,  0.5252, -1.4542,\n",
       "                       -0.2457, -0.9017, -0.5838, -0.5756, -2.1592,  0.4859, -2.0291, -0.4904,\n",
       "                       -1.0806, -1.2123, -0.9891, -0.7867, -1.5225, -2.0685, -2.0187, -1.1952,\n",
       "                       -0.5464,  1.3326, -1.0736, -0.1653,  0.3989, -1.0250, -1.2178, -0.1283,\n",
       "                        1.0292, -0.9136, -0.8055,  0.4198, -0.7943, -2.2874,  0.1520, -1.6244,\n",
       "                        1.0877, -0.3749, -0.6725, -0.7011,  0.6226, -1.8208, -0.4779, -0.7308,\n",
       "                       -0.8811, -0.6606, -0.2864, -1.7009, -0.6484, -0.8536, -0.0234, -0.3243],\n",
       "                      device='cuda:0')),\n",
       "              ('layer1.1.bn1.running_var',\n",
       "               tensor([2.6993, 1.2884, 2.9069, 0.1579, 1.1680, 0.0553, 0.2020, 0.3933, 0.0634,\n",
       "                       0.2197, 0.4610, 0.6630, 0.6098, 3.5573, 0.6962, 1.6128, 0.3119, 0.7134,\n",
       "                       0.5758, 0.2290, 1.7992, 8.0221, 3.0077, 0.2513, 1.3644, 1.3085, 0.2295,\n",
       "                       0.8418, 1.6698, 1.5596, 1.1186, 0.2849, 1.6943, 0.9201, 0.8388, 0.5824,\n",
       "                       0.4130, 1.0928, 0.2265, 0.7094, 0.2014, 0.4070, 0.2337, 1.0211, 1.1134,\n",
       "                       1.6988, 1.3498, 0.2333, 0.2164, 3.8216, 1.1609, 0.3078, 0.4988, 1.4748,\n",
       "                       2.3594, 1.1232, 0.3630, 0.4576, 0.2700, 3.0503, 6.4583, 0.8362, 0.5604,\n",
       "                       0.3556], device='cuda:0')),\n",
       "              ('layer1.1.bn1.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer1.1.conv2.weight',\n",
       "               tensor([[[[ 1.1886e-02, -3.3993e-02, -7.4732e-02],\n",
       "                         [-4.1931e-04, -4.8190e-02, -3.6710e-02],\n",
       "                         [ 7.2154e-02,  1.7955e-02, -5.9993e-03]],\n",
       "               \n",
       "                        [[-4.8581e-03,  6.4314e-03,  3.8033e-02],\n",
       "                         [-2.0490e-02, -4.7536e-03,  2.8209e-02],\n",
       "                         [-2.4176e-02, -5.6404e-02, -2.4477e-02]],\n",
       "               \n",
       "                        [[-9.5971e-02, -5.4211e-03,  1.4704e-02],\n",
       "                         [-3.6527e-02, -2.3291e-02,  1.0345e-03],\n",
       "                         [ 2.3886e-02, -5.1167e-03,  2.1068e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.4278e-03,  2.1943e-02,  6.1356e-02],\n",
       "                         [ 6.1656e-03,  8.5176e-03,  5.1607e-02],\n",
       "                         [-9.3189e-03, -1.4638e-02,  7.2620e-04]],\n",
       "               \n",
       "                        [[-1.1866e-02,  4.7727e-03, -1.6809e-02],\n",
       "                         [ 3.3701e-03, -2.0994e-03, -5.5004e-03],\n",
       "                         [-4.4804e-03,  5.9269e-03,  4.5375e-04]],\n",
       "               \n",
       "                        [[ 1.4408e-03, -1.6680e-03, -4.9184e-03],\n",
       "                         [ 1.4795e-02,  1.3910e-02,  2.2906e-02],\n",
       "                         [ 1.6863e-02,  1.3534e-02,  1.7433e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.2289e-01, -2.2228e-01,  3.2306e-02],\n",
       "                         [ 1.6863e-01,  9.9112e-02, -7.9540e-02],\n",
       "                         [ 3.8244e-02,  2.5863e-02,  7.4928e-02]],\n",
       "               \n",
       "                        [[ 1.1511e-01,  6.9096e-03, -3.7290e-02],\n",
       "                         [-7.8335e-02,  4.1722e-02,  3.7263e-02],\n",
       "                         [-4.6125e-02, -3.9497e-02,  1.2982e-02]],\n",
       "               \n",
       "                        [[-6.0515e-02, -1.7980e-01,  7.9666e-02],\n",
       "                         [ 1.1811e-01,  2.1402e-02, -1.9954e-01],\n",
       "                         [-1.1213e-01,  1.7611e-01,  2.3668e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.0340e-02,  1.2920e-01,  2.1952e-02],\n",
       "                         [-5.5617e-02, -6.7331e-02,  6.4186e-02],\n",
       "                         [ 4.3893e-02,  5.0028e-02, -5.8292e-02]],\n",
       "               \n",
       "                        [[-2.8555e-02, -4.3929e-03,  9.8722e-03],\n",
       "                         [-1.7048e-02, -1.2507e-02, -1.0013e-02],\n",
       "                         [-1.1066e-03, -1.2310e-02, -2.5439e-02]],\n",
       "               \n",
       "                        [[ 7.1532e-04,  1.8082e-02, -1.0910e-02],\n",
       "                         [-2.5826e-02, -2.6851e-02, -2.0811e-02],\n",
       "                         [-4.3687e-02, -3.2632e-02, -2.6177e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-8.3443e-02, -2.1118e-02, -3.0258e-03],\n",
       "                         [-1.2147e-01, -2.1174e-02, -7.9238e-02],\n",
       "                         [-1.1114e-01,  1.3530e-03, -4.6193e-02]],\n",
       "               \n",
       "                        [[ 5.9655e-05,  7.3775e-03,  4.7025e-03],\n",
       "                         [-2.9197e-02, -3.6660e-02, -1.5506e-02],\n",
       "                         [ 5.3339e-03, -2.1004e-02, -4.5488e-02]],\n",
       "               \n",
       "                        [[ 5.5491e-02,  1.1988e-02,  9.2495e-02],\n",
       "                         [ 5.4840e-02,  6.6509e-03,  4.7236e-02],\n",
       "                         [-3.2539e-02, -2.8253e-02,  4.8783e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.2237e-03,  6.6429e-03, -1.1661e-02],\n",
       "                         [ 4.4530e-02,  3.4192e-02, -1.5950e-02],\n",
       "                         [ 9.7147e-03,  2.3621e-03, -2.4666e-02]],\n",
       "               \n",
       "                        [[ 9.0678e-03, -1.7128e-02, -1.1624e-02],\n",
       "                         [ 6.9589e-03, -3.0958e-02, -2.3727e-02],\n",
       "                         [ 2.6076e-02, -1.4408e-02, -2.5650e-02]],\n",
       "               \n",
       "                        [[-2.1151e-02, -2.9677e-02, -2.0478e-02],\n",
       "                         [-2.4566e-02, -3.5315e-02, -2.9349e-02],\n",
       "                         [-2.4724e-02, -1.4745e-02, -1.6636e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 1.2838e-02,  3.7511e-03,  9.3829e-04],\n",
       "                         [ 1.0033e-02,  2.0718e-02, -1.0227e-02],\n",
       "                         [ 1.4414e-02,  1.2469e-02,  2.5116e-03]],\n",
       "               \n",
       "                        [[-2.1404e-02, -2.0452e-02, -6.5635e-03],\n",
       "                         [-9.1968e-03,  7.2807e-03,  2.1040e-02],\n",
       "                         [-6.0458e-03,  1.3239e-02,  2.0682e-02]],\n",
       "               \n",
       "                        [[-4.4660e-02, -4.9880e-02, -5.2034e-02],\n",
       "                         [-3.1887e-02,  4.5309e-03, -1.9688e-02],\n",
       "                         [ 9.8260e-03,  3.9809e-02,  4.2028e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.1315e-03, -1.2607e-02, -2.8795e-03],\n",
       "                         [-1.6357e-02, -6.0755e-03,  1.5663e-02],\n",
       "                         [-3.3259e-03,  4.6340e-03,  1.7909e-02]],\n",
       "               \n",
       "                        [[-1.3012e-02, -1.1676e-02, -7.3002e-04],\n",
       "                         [-5.8324e-03, -2.5808e-03,  7.8569e-03],\n",
       "                         [ 2.9545e-04,  1.2009e-02,  1.0952e-02]],\n",
       "               \n",
       "                        [[-4.8743e-03, -4.6926e-03, -3.4482e-03],\n",
       "                         [-8.9376e-03, -7.9172e-03, -9.8446e-03],\n",
       "                         [-1.3139e-02, -8.9033e-03, -1.6078e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.2857e-02, -1.4282e-02, -2.7435e-02],\n",
       "                         [-6.4118e-02, -3.4082e-02, -2.9951e-02],\n",
       "                         [-4.9805e-02,  5.6325e-03,  7.5376e-02]],\n",
       "               \n",
       "                        [[-2.5698e-03, -1.6799e-04, -2.7266e-02],\n",
       "                         [-1.4955e-02, -4.3673e-02, -7.8335e-02],\n",
       "                         [-8.0120e-03, -1.1858e-02, -4.4453e-02]],\n",
       "               \n",
       "                        [[ 1.3777e-02,  1.3443e-03,  7.5255e-03],\n",
       "                         [ 3.9648e-02,  5.7244e-02, -4.9392e-02],\n",
       "                         [ 8.9890e-04, -6.2686e-03, -2.4671e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.3548e-02,  4.5490e-03,  4.4216e-02],\n",
       "                         [ 3.8238e-03, -1.1171e-02,  7.9794e-03],\n",
       "                         [-8.1641e-03, -6.7025e-03,  1.2070e-02]],\n",
       "               \n",
       "                        [[ 7.2383e-04,  1.4697e-03,  2.5709e-03],\n",
       "                         [-3.0371e-03, -9.3019e-03, -1.1293e-02],\n",
       "                         [ 1.9324e-04,  5.9109e-03, -2.4818e-02]],\n",
       "               \n",
       "                        [[ 3.8723e-02,  6.6950e-03, -2.1342e-02],\n",
       "                         [ 1.7292e-02, -3.6677e-03, -2.0553e-02],\n",
       "                         [ 2.3379e-03, -1.8802e-02, -3.0602e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.4991e-01, -3.2108e-02, -1.4593e-01],\n",
       "                         [-2.1040e-02, -1.3154e-01,  1.2715e-01],\n",
       "                         [-1.3558e-01,  1.5765e-01,  1.2155e-01]],\n",
       "               \n",
       "                        [[ 5.1886e-02,  3.8999e-02, -2.4437e-02],\n",
       "                         [-2.5774e-03, -5.5640e-02, -5.7485e-02],\n",
       "                         [-3.4533e-02, -4.5750e-02, -1.4983e-02]],\n",
       "               \n",
       "                        [[-3.4799e-02,  2.1042e-02,  7.8847e-02],\n",
       "                         [-1.0527e-02,  1.1472e-01,  2.7689e-02],\n",
       "                         [ 1.0839e-01,  1.1821e-01, -2.8053e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.0274e-02,  6.0473e-02,  5.9449e-02],\n",
       "                         [ 1.3951e-01,  4.7349e-02, -4.8940e-03],\n",
       "                         [ 7.5099e-02, -1.1790e-01, -6.4494e-02]],\n",
       "               \n",
       "                        [[-1.6573e-02,  1.9188e-02, -3.3339e-02],\n",
       "                         [ 2.8410e-02,  9.3382e-03, -5.6109e-02],\n",
       "                         [ 1.5989e-02, -5.9689e-02, -1.6102e-02]],\n",
       "               \n",
       "                        [[-1.8799e-02, -4.8213e-02,  2.7860e-02],\n",
       "                         [-1.5395e-02,  4.3338e-02,  7.2245e-02],\n",
       "                         [-4.8559e-03,  1.9764e-02, -1.1614e-02]]]], device='cuda:0')),\n",
       "              ('layer1.1.bn2.weight',\n",
       "               tensor([ 0.2709,  0.6643,  0.2816,  0.2895, -0.0277,  0.0282,  0.3302,  0.2060,\n",
       "                        0.3916,  0.1183,  0.3888,  0.0399,  0.0966,  0.6159,  0.0125,  0.2630,\n",
       "                        0.0945,  0.7877, -0.1809,  0.1768,  0.1266,  0.7249,  0.2525,  0.0742,\n",
       "                        0.2020,  0.1681,  0.0657,  0.5519,  0.5715,  0.0585,  0.0837, -0.0034,\n",
       "                        0.6668,  0.3153,  0.4203,  0.1887,  0.1351,  0.3310,  0.1653,  0.4637,\n",
       "                        0.2247,  0.2867,  0.0996,  0.0415,  0.7735,  0.0678,  0.0228, -0.0591,\n",
       "                        0.3197,  0.3939,  0.2044,  0.4098,  0.2389,  0.1953,  0.5449,  0.7557,\n",
       "                        0.2754,  0.3670,  0.4867,  0.1178,  0.2554,  0.1001,  0.2689,  0.7271],\n",
       "                      device='cuda:0')),\n",
       "              ('layer1.1.bn2.bias',\n",
       "               tensor([ 6.3526e-02, -7.8029e-01,  4.1196e-02, -6.2879e-01,  4.3124e-02,\n",
       "                        1.3454e-02,  7.4290e-02, -6.2932e-02, -1.2438e-01, -2.5643e-01,\n",
       "                       -1.3171e-02,  2.8218e-02,  2.3264e-03, -1.3346e-01, -3.0459e-02,\n",
       "                        1.1462e-01,  1.2587e-01, -3.4511e-01, -2.8507e-01,  2.8006e-02,\n",
       "                        6.5025e-03, -2.4100e-01, -1.0365e-01, -1.3247e-01,  5.7742e-02,\n",
       "                        6.2688e-03,  5.8594e-02, -1.6997e-01, -6.3769e-01,  5.1863e-02,\n",
       "                        3.5707e-02,  3.1831e-02, -7.4184e-01, -1.0317e-02, -1.1438e-01,\n",
       "                       -3.2837e-02, -3.8372e-02, -1.1138e-01, -3.6577e-02, -3.3477e-01,\n",
       "                       -1.2727e-01, -2.6645e-02,  3.6312e-02,  8.8852e-03, -2.7169e-01,\n",
       "                        1.0504e-02,  8.3467e-03,  7.1379e-02,  1.0512e-01, -3.1139e-01,\n",
       "                        6.1490e-02,  1.1441e-01, -2.9106e-01, -1.4927e-01, -6.8311e-01,\n",
       "                       -1.0441e+00,  1.2495e-02, -1.1516e+00, -1.1624e-02, -8.6783e-02,\n",
       "                       -1.4905e-01, -4.9724e-05,  1.7280e-02, -5.7090e-01], device='cuda:0')),\n",
       "              ('layer1.1.bn2.running_mean',\n",
       "               tensor([-0.0705, -0.0400, -0.6223,  0.0547, -0.0210,  0.0627, -0.3848, -0.3696,\n",
       "                        0.3432, -0.1612,  0.0234, -0.0323,  0.0411, -0.1037, -0.0435, -0.3792,\n",
       "                        0.0916, -0.0319,  0.1305,  0.0086, -0.0134, -0.1830, -0.1785,  0.0015,\n",
       "                       -0.0167,  0.2352, -0.0187, -0.1913, -0.3141,  0.1583,  0.0091, -0.0541,\n",
       "                       -0.0517, -0.2624, -0.2012, -0.3098, -0.1411, -0.3344,  0.3696, -0.0758,\n",
       "                        0.0309, -0.5059,  0.0530, -0.0025, -0.1063, -0.0576,  0.0183, -0.0080,\n",
       "                       -0.1618, -0.0037, -0.2082, -0.4616, -0.3902, -0.1145, -0.0724, -0.0591,\n",
       "                        0.0669,  0.0348, -0.4616, -0.2678, -0.0335,  0.0946, -0.1537, -0.1353],\n",
       "                      device='cuda:0')),\n",
       "              ('layer1.1.bn2.running_var',\n",
       "               tensor([0.0475, 0.2133, 0.1295, 0.0902, 0.0509, 0.0547, 0.2339, 0.0638, 0.0945,\n",
       "                       0.0791, 0.0883, 0.0292, 0.0131, 0.0938, 0.0075, 0.0817, 0.0334, 0.3767,\n",
       "                       0.0591, 0.0671, 0.0261, 0.2920, 0.0691, 0.0266, 0.0762, 0.0360, 0.0645,\n",
       "                       0.1536, 0.3071, 0.0327, 0.0206, 0.0493, 0.2936, 0.0655, 0.1326, 0.1780,\n",
       "                       0.0240, 0.0789, 0.0408, 0.3030, 0.0313, 0.0835, 0.0336, 0.0172, 0.2734,\n",
       "                       0.0488, 0.0236, 0.0530, 0.0922, 0.0880, 0.0935, 0.1390, 0.2336, 0.0802,\n",
       "                       0.2915, 0.6350, 0.1475, 0.1484, 0.2385, 0.0745, 0.0532, 0.0483, 0.0497,\n",
       "                       0.4343], device='cuda:0')),\n",
       "              ('layer1.1.bn2.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer2.0.conv1.weight',\n",
       "               tensor([[[[-0.0284, -0.0336, -0.0390],\n",
       "                         [-0.0208, -0.0113, -0.0252],\n",
       "                         [ 0.0241,  0.0228,  0.0167]],\n",
       "               \n",
       "                        [[-0.0276, -0.0282,  0.0135],\n",
       "                         [-0.0319, -0.0113, -0.0432],\n",
       "                         [ 0.0136,  0.0492, -0.0129]],\n",
       "               \n",
       "                        [[ 0.0416,  0.0460,  0.0531],\n",
       "                         [ 0.0073,  0.0199,  0.0234],\n",
       "                         [ 0.0006, -0.0033,  0.0182]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0083,  0.0160,  0.0305],\n",
       "                         [ 0.0234,  0.0546,  0.0644],\n",
       "                         [ 0.0359,  0.0627,  0.0720]],\n",
       "               \n",
       "                        [[ 0.0177,  0.0196,  0.0379],\n",
       "                         [-0.0046,  0.0035,  0.0253],\n",
       "                         [-0.0204, -0.0107, -0.0016]],\n",
       "               \n",
       "                        [[ 0.0085, -0.0037,  0.0430],\n",
       "                         [-0.0170,  0.0258,  0.0506],\n",
       "                         [ 0.0282,  0.0159,  0.0626]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0259,  0.0354,  0.0530],\n",
       "                         [ 0.0246,  0.0137,  0.0439],\n",
       "                         [ 0.0130,  0.0021, -0.0009]],\n",
       "               \n",
       "                        [[-0.0329, -0.0125, -0.0063],\n",
       "                         [-0.0279,  0.0118, -0.0780],\n",
       "                         [-0.0253, -0.0222, -0.0182]],\n",
       "               \n",
       "                        [[ 0.0440,  0.0324,  0.0233],\n",
       "                         [ 0.0253,  0.0146, -0.0125],\n",
       "                         [ 0.0118, -0.0021,  0.0078]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0358, -0.0395, -0.0434],\n",
       "                         [-0.0474, -0.0438, -0.0460],\n",
       "                         [-0.0418, -0.0342, -0.0274]],\n",
       "               \n",
       "                        [[-0.0405, -0.0345, -0.0251],\n",
       "                         [-0.0396, -0.0103, -0.0022],\n",
       "                         [-0.0137,  0.0393,  0.0539]],\n",
       "               \n",
       "                        [[ 0.0214,  0.0065, -0.0779],\n",
       "                         [ 0.0316, -0.0383, -0.1184],\n",
       "                         [ 0.0185,  0.0486, -0.0317]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0159,  0.0404,  0.0242],\n",
       "                         [-0.0065,  0.0013,  0.0185],\n",
       "                         [-0.0252, -0.0223, -0.0067]],\n",
       "               \n",
       "                        [[-0.0532, -0.0293, -0.0029],\n",
       "                         [-0.0675, -0.0436,  0.0083],\n",
       "                         [-0.0235, -0.0699, -0.0768]],\n",
       "               \n",
       "                        [[ 0.0070, -0.0161, -0.0520],\n",
       "                         [ 0.0508,  0.0124, -0.0165],\n",
       "                         [ 0.0495,  0.0186, -0.0112]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0052, -0.0194, -0.0330],\n",
       "                         [-0.0239, -0.0253, -0.0277],\n",
       "                         [-0.0338, -0.0360, -0.0314]],\n",
       "               \n",
       "                        [[ 0.0154, -0.0036, -0.0310],\n",
       "                         [ 0.0074,  0.0002, -0.0341],\n",
       "                         [ 0.0126,  0.0105, -0.0098]],\n",
       "               \n",
       "                        [[ 0.0320,  0.0059, -0.0482],\n",
       "                         [-0.0044, -0.0337, -0.0466],\n",
       "                         [-0.0796, -0.0357, -0.0284]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0103,  0.0107,  0.0077],\n",
       "                         [ 0.0140,  0.0229,  0.0148],\n",
       "                         [-0.0133, -0.0159, -0.0196]],\n",
       "               \n",
       "                        [[ 0.0137,  0.0378,  0.0397],\n",
       "                         [ 0.0755,  0.0506,  0.0955],\n",
       "                         [-0.0258, -0.0205,  0.0072]],\n",
       "               \n",
       "                        [[-0.0043, -0.0078, -0.0140],\n",
       "                         [ 0.0148,  0.0338,  0.0289],\n",
       "                         [ 0.0260,  0.0190,  0.0310]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0435,  0.0474,  0.0398],\n",
       "                         [ 0.0423,  0.0559,  0.0499],\n",
       "                         [ 0.0229,  0.0303,  0.0201]],\n",
       "               \n",
       "                        [[ 0.0017,  0.0190, -0.0040],\n",
       "                         [ 0.0403,  0.0614,  0.0501],\n",
       "                         [ 0.0246,  0.0452,  0.0331]],\n",
       "               \n",
       "                        [[ 0.0740,  0.0462,  0.0410],\n",
       "                         [-0.0015,  0.0585, -0.0295],\n",
       "                         [ 0.0185, -0.0641, -0.0238]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0329, -0.0328, -0.0070],\n",
       "                         [-0.0068,  0.0028,  0.0080],\n",
       "                         [ 0.0087,  0.0129, -0.0080]],\n",
       "               \n",
       "                        [[-0.0493, -0.0020,  0.0274],\n",
       "                         [ 0.0252, -0.0354,  0.0124],\n",
       "                         [ 0.0034,  0.0151, -0.0312]],\n",
       "               \n",
       "                        [[-0.0116, -0.0097, -0.0123],\n",
       "                         [-0.0121, -0.0105, -0.0181],\n",
       "                         [ 0.0014, -0.0130, -0.0181]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0242,  0.0253,  0.0143],\n",
       "                         [ 0.0602,  0.0570,  0.0390],\n",
       "                         [ 0.0598,  0.0588,  0.0386]],\n",
       "               \n",
       "                        [[ 0.0170,  0.0036, -0.0116],\n",
       "                         [ 0.0115,  0.0095,  0.0203],\n",
       "                         [-0.0032,  0.0137,  0.0040]],\n",
       "               \n",
       "                        [[ 0.0037, -0.0068,  0.0159],\n",
       "                         [ 0.0165,  0.0562,  0.0780],\n",
       "                         [-0.0245,  0.0616,  0.0539]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0027,  0.0017, -0.0062],\n",
       "                         [-0.0212, -0.0253, -0.0300],\n",
       "                         [-0.0052, -0.0173, -0.0266]],\n",
       "               \n",
       "                        [[-0.0111,  0.0166,  0.0523],\n",
       "                         [-0.0253,  0.0020, -0.0078],\n",
       "                         [ 0.0178, -0.0243,  0.0260]],\n",
       "               \n",
       "                        [[-0.0351,  0.0058,  0.0147],\n",
       "                         [-0.0305,  0.0140,  0.0240],\n",
       "                         [-0.0359,  0.0055,  0.0062]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0109, -0.0009, -0.0092],\n",
       "                         [ 0.0333,  0.0264,  0.0194],\n",
       "                         [ 0.0301,  0.0270,  0.0262]],\n",
       "               \n",
       "                        [[ 0.0354,  0.0337,  0.0226],\n",
       "                         [ 0.0372,  0.0584,  0.0432],\n",
       "                         [ 0.0146,  0.0253,  0.0323]],\n",
       "               \n",
       "                        [[ 0.0357, -0.0098, -0.0104],\n",
       "                         [ 0.0556,  0.0233,  0.0141],\n",
       "                         [ 0.0128, -0.0180,  0.0156]]]], device='cuda:0')),\n",
       "              ('layer2.0.bn1.weight',\n",
       "               tensor([0.2473, 0.3160, 0.2900, 0.3011, 0.3192, 0.3051, 0.2973, 0.4059, 0.2607,\n",
       "                       0.4187, 0.3949, 0.2260, 0.2789, 0.3885, 0.3528, 0.3749, 0.3966, 0.3059,\n",
       "                       0.3764, 0.5527, 0.3019, 0.3288, 0.2679, 0.4276, 0.3996, 0.4151, 0.3520,\n",
       "                       0.3636, 0.4160, 0.3393, 0.2543, 0.2334, 0.3073, 0.3491, 0.3072, 0.3780,\n",
       "                       0.3416, 0.2463, 0.3246, 0.3469, 0.2093, 0.4390, 0.4045, 0.2971, 0.5132,\n",
       "                       0.4104, 0.4225, 0.4237, 0.4376, 0.3491, 0.3592, 0.3059, 0.2182, 0.3950,\n",
       "                       0.2410, 0.2241, 0.3343, 0.3682, 0.2810, 0.2678, 0.4549, 0.4603, 0.3667,\n",
       "                       0.2924, 0.2265, 0.2338, 0.3132, 0.2926, 0.3061, 0.4045, 0.3148, 0.1762,\n",
       "                       0.4250, 0.4604, 0.3203, 0.4141, 0.1991, 0.2190, 0.3432, 0.3226, 0.2891,\n",
       "                       0.2456, 0.3719, 0.1980, 0.4388, 0.4992, 0.4535, 0.3086, 0.3296, 0.2953,\n",
       "                       0.2775, 0.4162, 0.3137, 0.4003, 0.2585, 0.3316, 0.4012, 0.3796, 0.3415,\n",
       "                       0.2163, 0.1555, 0.4200, 0.2619, 0.4449, 0.4504, 0.3819, 0.2974, 0.1773,\n",
       "                       0.3459, 0.3007, 0.4385, 0.3753, 0.1777, 0.3921, 0.5011, 0.4678, 0.4115,\n",
       "                       0.3945, 0.2857, 0.3762, 0.3590, 0.4037, 0.4326, 0.3688, 0.3760, 0.2526,\n",
       "                       0.2670, 0.2224], device='cuda:0')),\n",
       "              ('layer2.0.bn1.bias',\n",
       "               tensor([ 0.0260, -0.1086, -0.0708, -0.0592,  0.0794, -0.0459, -0.0262, -0.2267,\n",
       "                       -0.0547, -0.1241, -0.2439, -0.0548, -0.1551, -0.0380,  0.0299, -0.1211,\n",
       "                        0.0637, -0.0552, -0.1961, -0.0763,  0.0224,  0.0338, -0.0804, -0.0293,\n",
       "                       -0.0990,  0.1117,  0.0317, -0.0606,  0.0397, -0.0697, -0.1363, -0.1238,\n",
       "                       -0.0384, -0.1440, -0.1448, -0.1169, -0.1657, -0.0623, -0.1572, -0.0498,\n",
       "                       -0.1244, -0.1475, -0.0437, -0.0370,  0.0109,  0.1127, -0.1577, -0.1861,\n",
       "                       -0.0728,  0.0352, -0.0319, -0.0632,  0.1316, -0.2716, -0.0791, -0.0292,\n",
       "                        0.0268, -0.1836, -0.0034, -0.0333, -0.0684, -0.1203,  0.0515, -0.1315,\n",
       "                        0.0423, -0.0360,  0.0979, -0.0718,  0.0116, -0.0983, -0.1411, -0.0118,\n",
       "                       -0.1391, -0.1570, -0.0851, -0.0806, -0.0748, -0.0757, -0.1841, -0.0969,\n",
       "                       -0.0131, -0.0679, -0.0999,  0.0208, -0.1892, -0.1878, -0.0313, -0.0790,\n",
       "                       -0.0616, -0.0910, -0.0047, -0.0087, -0.1023, -0.0933, -0.0588, -0.0224,\n",
       "                       -0.0921, -0.1279,  0.2044, -0.1120, -0.0925,  0.0601,  0.0077,  0.0091,\n",
       "                       -0.1676, -0.1559, -0.1317, -0.0856, -0.0366,  0.1042, -0.0835, -0.2073,\n",
       "                       -0.0248,  0.0299, -0.1497, -0.1319, -0.2035, -0.1117, -0.0814, -0.0572,\n",
       "                       -0.1897,  0.0384, -0.1676, -0.2410, -0.1050, -0.0912, -0.1587, -0.0047],\n",
       "                      device='cuda:0')),\n",
       "              ('layer2.0.bn1.running_mean',\n",
       "               tensor([ 0.4718,  0.2754, -0.6470, -1.1232, -0.9425, -1.2191,  0.4904, -1.4306,\n",
       "                       -0.9624, -0.0442, -0.8393, -0.0519, -0.7445, -0.0677, -1.3363, -0.6164,\n",
       "                       -1.1733, -0.8397, -0.7829, -0.3686, -1.5964, -0.9150,  0.8310, -0.4946,\n",
       "                       -0.8173, -0.2834, -0.1598, -0.8187, -0.5652, -1.0345, -0.3325, -0.4784,\n",
       "                       -0.1724,  0.2268,  0.2795, -0.4493,  0.1368,  0.8912,  0.1887, -0.9309,\n",
       "                       -0.4027,  0.7875, -0.4611, -0.8845, -0.5044, -1.9232,  0.2440, -0.6239,\n",
       "                        0.1978, -0.9812, -0.1503,  0.1018, -1.2002, -0.2015, -0.2588, -0.5056,\n",
       "                       -0.4258,  1.3805, -0.7596, -1.2558, -1.3661, -0.4111, -1.4618, -0.5614,\n",
       "                       -0.5141, -0.1577, -0.6648, -0.7243, -1.1706, -0.2554, -0.1873, -0.6585,\n",
       "                       -0.7272, -0.6842,  0.3274, -0.3280, -0.9574,  0.7654,  0.5431, -1.2363,\n",
       "                       -0.3347,  0.2093, -0.7215, -1.4856, -0.6919, -0.6480,  0.3024, -0.1337,\n",
       "                       -0.2798, -0.6290, -0.8566,  0.7590,  0.4128,  0.1506,  0.1015, -1.3301,\n",
       "                       -0.6232,  0.1949, -1.3712, -0.8468,  0.9407, -0.6570, -0.3117,  0.0022,\n",
       "                       -1.6831, -0.8851, -0.5382, -0.2999, -0.3474, -0.8100, -0.5312,  0.2818,\n",
       "                        0.0637, -0.9640, -1.8686, -0.1070, -0.7017, -0.0623, -0.9487, -0.9010,\n",
       "                        0.8195, -0.2251, -0.7717,  0.6302,  0.0121,  0.5577,  1.0708, -0.2527],\n",
       "                      device='cuda:0')),\n",
       "              ('layer2.0.bn1.running_var',\n",
       "               tensor([0.7182, 0.9027, 0.5847, 0.6967, 1.2541, 0.9996, 0.8666, 1.1298, 0.5049,\n",
       "                       0.8101, 0.8436, 0.7136, 0.5933, 0.7876, 0.6654, 0.7139, 1.1380, 0.6796,\n",
       "                       2.1850, 1.8834, 0.8314, 0.9724, 0.7016, 1.2263, 1.1993, 1.0099, 1.1609,\n",
       "                       1.3121, 1.1602, 0.9791, 0.3738, 0.4353, 1.1630, 0.9245, 1.2671, 0.9373,\n",
       "                       0.6026, 0.4484, 0.6848, 1.0835, 0.2589, 1.5176, 1.4574, 0.9094, 1.8419,\n",
       "                       2.3892, 1.5188, 1.5901, 1.6701, 1.0315, 0.8915, 0.7337, 0.5447, 1.4992,\n",
       "                       0.2907, 0.4548, 0.7854, 1.1618, 1.2993, 0.6897, 1.9440, 1.6032, 1.8910,\n",
       "                       0.9704, 0.4009, 0.2968, 1.3169, 0.6236, 0.8335, 1.1241, 0.7448, 0.2691,\n",
       "                       1.1318, 0.9428, 1.2909, 1.0868, 0.3403, 0.5321, 1.4397, 0.8250, 0.7537,\n",
       "                       0.4619, 1.2249, 0.4522, 1.4192, 1.2749, 1.0960, 1.1081, 1.1355, 0.5497,\n",
       "                       0.6408, 1.2656, 1.5057, 1.1778, 0.5968, 1.6006, 1.0777, 0.7040, 1.3761,\n",
       "                       0.5485, 0.3043, 1.2343, 0.6838, 2.5443, 0.9925, 0.9069, 0.5589, 0.2922,\n",
       "                       0.8398, 0.4907, 1.2304, 1.0432, 0.2105, 1.6771, 2.6610, 1.3133, 0.9222,\n",
       "                       1.3619, 0.6981, 0.8818, 1.2856, 1.2977, 1.4400, 0.6179, 1.0117, 0.6194,\n",
       "                       0.9880, 0.4181], device='cuda:0')),\n",
       "              ('layer2.0.bn1.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer2.0.conv2.weight',\n",
       "               tensor([[[[ 0.0391, -0.0214, -0.1100],\n",
       "                         [ 0.0425, -0.0228, -0.1214],\n",
       "                         [ 0.0030, -0.0161, -0.0181]],\n",
       "               \n",
       "                        [[-0.0180, -0.0091,  0.0461],\n",
       "                         [-0.0166, -0.0131, -0.0488],\n",
       "                         [ 0.0149,  0.0320, -0.0485]],\n",
       "               \n",
       "                        [[-0.0358, -0.0110,  0.0265],\n",
       "                         [-0.1045, -0.0128,  0.0875],\n",
       "                         [-0.1166, -0.0241,  0.0239]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0139, -0.0043, -0.0132],\n",
       "                         [ 0.0582, -0.0063, -0.1018],\n",
       "                         [ 0.0500,  0.0116, -0.1010]],\n",
       "               \n",
       "                        [[ 0.0495, -0.0021, -0.0477],\n",
       "                         [ 0.1215,  0.0247, -0.0640],\n",
       "                         [ 0.0694,  0.0419, -0.0400]],\n",
       "               \n",
       "                        [[ 0.0218,  0.0095, -0.0383],\n",
       "                         [-0.0024, -0.0023, -0.0131],\n",
       "                         [-0.0423,  0.0221,  0.0200]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0379, -0.0334, -0.0099],\n",
       "                         [-0.0123, -0.0326, -0.0049],\n",
       "                         [-0.0085, -0.0136,  0.0015]],\n",
       "               \n",
       "                        [[ 0.0797,  0.0494,  0.0609],\n",
       "                         [ 0.0214,  0.0108,  0.0260],\n",
       "                         [ 0.0335, -0.0089, -0.0120]],\n",
       "               \n",
       "                        [[ 0.0119,  0.0685,  0.0322],\n",
       "                         [ 0.0390,  0.0579,  0.0586],\n",
       "                         [ 0.0124,  0.0445,  0.0519]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0189, -0.0319, -0.0102],\n",
       "                         [-0.0296, -0.0379, -0.0430],\n",
       "                         [-0.0079, -0.0344, -0.0288]],\n",
       "               \n",
       "                        [[-0.0011, -0.0124, -0.0242],\n",
       "                         [-0.0129, -0.0254, -0.0453],\n",
       "                         [-0.0152, -0.0421, -0.0405]],\n",
       "               \n",
       "                        [[-0.0052, -0.0243, -0.0219],\n",
       "                         [ 0.0138, -0.0236, -0.0031],\n",
       "                         [ 0.0094, -0.0093,  0.0056]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0084, -0.0296, -0.0149],\n",
       "                         [ 0.0046, -0.0197, -0.0406],\n",
       "                         [ 0.0233, -0.0097, -0.0084]],\n",
       "               \n",
       "                        [[ 0.0086,  0.0026,  0.0204],\n",
       "                         [ 0.0151,  0.0238,  0.0642],\n",
       "                         [ 0.0303,  0.0566,  0.0060]],\n",
       "               \n",
       "                        [[ 0.0236,  0.0356,  0.0262],\n",
       "                         [ 0.0034,  0.0200,  0.0256],\n",
       "                         [ 0.0155,  0.0259,  0.0028]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0009, -0.0005, -0.0226],\n",
       "                         [-0.0148, -0.0238, -0.0096],\n",
       "                         [-0.0195, -0.0053, -0.0066]],\n",
       "               \n",
       "                        [[-0.0363, -0.0176, -0.0603],\n",
       "                         [ 0.0033, -0.0027, -0.0153],\n",
       "                         [-0.0113,  0.0214,  0.0168]],\n",
       "               \n",
       "                        [[ 0.0013,  0.0108,  0.0243],\n",
       "                         [-0.0004, -0.0040, -0.0086],\n",
       "                         [-0.0011, -0.0361, -0.0323]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0304, -0.0380, -0.0296],\n",
       "                         [-0.0165,  0.0264, -0.0077],\n",
       "                         [ 0.0394,  0.0897,  0.0003]],\n",
       "               \n",
       "                        [[-0.0230,  0.0559, -0.0236],\n",
       "                         [-0.0429, -0.0341, -0.0805],\n",
       "                         [-0.0158, -0.0264, -0.0464]],\n",
       "               \n",
       "                        [[ 0.0246,  0.0833,  0.0270],\n",
       "                         [ 0.0020,  0.0119, -0.0358],\n",
       "                         [ 0.0174, -0.0166, -0.0199]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0138, -0.0145, -0.0305],\n",
       "                         [-0.0343, -0.0701, -0.0595],\n",
       "                         [-0.0412, -0.0652, -0.0549]],\n",
       "               \n",
       "                        [[ 0.0149, -0.0352, -0.0269],\n",
       "                         [-0.0274, -0.0379, -0.0385],\n",
       "                         [ 0.0214,  0.0406, -0.0061]],\n",
       "               \n",
       "                        [[-0.0225, -0.0320, -0.0591],\n",
       "                         [ 0.0306,  0.0091, -0.0308],\n",
       "                         [ 0.0166,  0.0238, -0.0008]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0297, -0.0399, -0.0131],\n",
       "                         [-0.0128, -0.0314, -0.0301],\n",
       "                         [ 0.0025, -0.0109, -0.0219]],\n",
       "               \n",
       "                        [[ 0.0365,  0.0458,  0.0385],\n",
       "                         [-0.0332,  0.0032,  0.0281],\n",
       "                         [-0.0403, -0.0391, -0.0533]],\n",
       "               \n",
       "                        [[ 0.0241,  0.0051, -0.0090],\n",
       "                         [ 0.0309,  0.0392,  0.0133],\n",
       "                         [ 0.0045,  0.0086,  0.0029]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0419, -0.0422, -0.0244],\n",
       "                         [-0.0316, -0.0409, -0.0165],\n",
       "                         [-0.0165, -0.0327, -0.0205]],\n",
       "               \n",
       "                        [[-0.0083, -0.0253, -0.0254],\n",
       "                         [-0.0020, -0.0119, -0.0404],\n",
       "                         [ 0.0463,  0.0149,  0.0007]],\n",
       "               \n",
       "                        [[-0.0091,  0.0029, -0.0066],\n",
       "                         [ 0.0204,  0.0335,  0.0203],\n",
       "                         [ 0.0169,  0.0414,  0.0328]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0161, -0.0028,  0.0202],\n",
       "                         [-0.0106, -0.0310, -0.0008],\n",
       "                         [ 0.0021, -0.0028, -0.0030]],\n",
       "               \n",
       "                        [[ 0.0017, -0.0260, -0.0281],\n",
       "                         [-0.0248, -0.0512, -0.0779],\n",
       "                         [-0.0179, -0.0582, -0.0421]],\n",
       "               \n",
       "                        [[ 0.0211,  0.0136, -0.0003],\n",
       "                         [ 0.0218, -0.0147, -0.0105],\n",
       "                         [-0.0191, -0.0198,  0.0166]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0174, -0.0119, -0.0088],\n",
       "                         [-0.0132, -0.0519, -0.0226],\n",
       "                         [-0.0356, -0.0693, -0.0350]],\n",
       "               \n",
       "                        [[ 0.0461,  0.0268,  0.0607],\n",
       "                         [ 0.0010, -0.0308,  0.0180],\n",
       "                         [ 0.0010, -0.0188, -0.0297]],\n",
       "               \n",
       "                        [[-0.0464, -0.0485, -0.0458],\n",
       "                         [-0.0235, -0.0273, -0.0110],\n",
       "                         [ 0.0238,  0.0027,  0.0038]]]], device='cuda:0')),\n",
       "              ('layer2.0.bn2.weight',\n",
       "               tensor([0.7286, 0.4502, 0.3405, 0.3607, 0.1570, 0.5333, 0.5033, 0.3763, 0.3999,\n",
       "                       0.4781, 0.4077, 0.3536, 0.2828, 0.3594, 0.4539, 0.6766, 0.7498, 0.6398,\n",
       "                       0.4251, 0.5285, 0.4955, 0.2871, 0.5096, 0.5055, 0.4698, 0.3663, 0.5754,\n",
       "                       0.5157, 0.3953, 0.4833, 0.4674, 0.5271, 0.6339, 0.2837, 0.3736, 0.3892,\n",
       "                       0.3895, 0.4178, 0.5066, 0.2146, 0.2685, 0.4498, 0.5231, 0.4152, 0.3341,\n",
       "                       0.4352, 0.5067, 0.2929, 0.5134, 0.4232, 0.3358, 0.3878, 0.4570, 0.2201,\n",
       "                       0.4414, 0.1524, 0.4162, 0.3282, 0.4290, 0.4393, 0.4617, 0.5689, 0.2263,\n",
       "                       0.2519, 0.3595, 0.1809, 0.4820, 0.3248, 0.2764, 0.5968, 0.5225, 0.6393,\n",
       "                       0.4897, 0.3753, 0.3952, 0.3659, 0.5053, 0.3082, 0.2198, 0.3333, 0.5295,\n",
       "                       0.6408, 0.3234, 0.2772, 0.1269, 0.1857, 0.3971, 0.4234, 0.3769, 0.4272,\n",
       "                       0.3768, 0.4565, 0.4177, 0.6289, 0.3773, 0.2353, 0.4197, 0.4537, 0.3245,\n",
       "                       0.4116, 0.5240, 0.4310, 0.2416, 0.3737, 0.2585, 0.2079, 0.3591, 0.5270,\n",
       "                       0.6029, 0.4846, 0.4263, 0.6364, 0.4274, 0.5291, 0.2907, 0.1059, 0.3675,\n",
       "                       0.4016, 0.2889, 0.3651, 0.2191, 0.3925, 0.3088, 0.3262, 0.4582, 0.4826,\n",
       "                       0.2285, 0.2666], device='cuda:0')),\n",
       "              ('layer2.0.bn2.bias',\n",
       "               tensor([-0.1845, -0.0208,  0.0716, -0.1156, -0.0984, -0.0328, -0.1430, -0.0213,\n",
       "                       -0.0849, -0.1763, -0.1455, -0.0273, -0.0423, -0.0297, -0.1436, -0.1578,\n",
       "                       -0.2201, -0.2058,  0.0421, -0.0653, -0.1350,  0.0555, -0.0607, -0.0918,\n",
       "                        0.0243, -0.0349, -0.1644, -0.0339, -0.0627, -0.0882, -0.1253, -0.1305,\n",
       "                       -0.1143, -0.0904,  0.0317, -0.0387, -0.0334, -0.0754, -0.0728, -0.0619,\n",
       "                       -0.0538, -0.1679, -0.0964, -0.0745, -0.1750, -0.1600, -0.2328, -0.0906,\n",
       "                        0.0822, -0.1553, -0.0883, -0.1656, -0.1272, -0.0291,  0.0268,  0.1247,\n",
       "                       -0.2504,  0.0049, -0.1407, -0.1272, -0.0938, -0.0935, -0.1643,  0.0353,\n",
       "                        0.0782,  0.0427, -0.1441, -0.2765, -0.0409, -0.1458, -0.2476, -0.1415,\n",
       "                        0.0867, -0.1236, -0.0342, -0.0410, -0.1111, -0.0908, -0.0744, -0.1218,\n",
       "                       -0.0669, -0.1384, -0.0630,  0.0562,  0.0425, -0.0674, -0.0755, -0.0786,\n",
       "                       -0.0621, -0.0083, -0.0604, -0.1303, -0.0494, -0.0993, -0.0668,  0.1466,\n",
       "                       -0.0536, -0.0421, -0.0564, -0.0756, -0.0377, -0.0291, -0.1540, -0.0606,\n",
       "                        0.0765, -0.0749, -0.0374, -0.1065, -0.1408, -0.0099,  0.0521, -0.1312,\n",
       "                       -0.0814, -0.1709, -0.0348, -0.0639, -0.0144, -0.1833, -0.0142, -0.0982,\n",
       "                        0.0119, -0.1212, -0.0726, -0.0912, -0.1583, -0.1763, -0.0244, -0.0141],\n",
       "                      device='cuda:0')),\n",
       "              ('layer2.0.bn2.running_mean',\n",
       "               tensor([-0.7638,  0.2101, -0.7433, -0.0682, -0.4483, -0.1785, -0.2673,  0.1298,\n",
       "                       -0.6873, -1.2026, -0.5977, -0.1844, -0.6322, -0.3155, -0.6972, -0.1425,\n",
       "                       -0.3797, -0.2525, -0.0977, -0.3338,  0.1053, -0.2868, -0.2718, -0.5841,\n",
       "                       -0.4246, -0.0320, -0.1144, -0.6020,  0.2792, -0.2195, -0.3273, -0.5784,\n",
       "                        0.0332,  0.1400, -0.9951, -0.8685, -0.2617, -0.4869, -0.2407, -0.6008,\n",
       "                        0.3375, -0.4479, -0.1274, -0.6052, -0.3178, -0.7990,  0.1845, -0.3004,\n",
       "                       -0.4118, -0.4157,  0.0204, -0.7896,  0.3626,  0.1676, -0.6868, -0.5332,\n",
       "                       -0.1548, -0.4056, -0.5625, -0.4131, -0.5773, -0.0200, -0.2057,  0.5957,\n",
       "                       -1.4314, -0.9866,  0.2065,  0.0633,  0.3427,  0.0477, -0.5463, -0.4567,\n",
       "                       -0.9320,  0.5394,  0.0797, -0.4544, -0.3290,  0.2139, -0.0799, -0.5628,\n",
       "                       -0.3389, -0.1389, -0.2207, -0.2651, -0.3189, -0.0886, -0.0398, -0.5658,\n",
       "                       -0.5238, -0.6663, -0.4834,  0.7289, -1.5350, -0.3134, -0.0621, -0.6860,\n",
       "                        0.1223, -0.3793, -0.8786, -0.7661, -0.5287, -0.7740, -0.1779, -1.0188,\n",
       "                       -0.6666, -0.3597, -0.5829,  0.0123, -0.7092, -0.7424, -0.7054, -0.2756,\n",
       "                       -0.6194, -0.5269, -0.3486, -0.2503, -1.2283, -0.1850, -0.4995, -0.9785,\n",
       "                       -1.1522, -0.2982, -0.1978, -0.6107,  0.0358, -0.9412, -0.3866, -0.7477],\n",
       "                      device='cuda:0')),\n",
       "              ('layer2.0.bn2.running_var',\n",
       "               tensor([0.9615, 0.3987, 0.2580, 0.1410, 0.2312, 0.3905, 0.4601, 0.2886, 0.1760,\n",
       "                       0.2686, 0.3633, 0.2856, 0.1587, 0.2524, 0.3037, 0.6600, 0.8714, 0.3593,\n",
       "                       0.3616, 0.6558, 0.3664, 0.1992, 0.4633, 0.3328, 0.4524, 0.2686, 0.3289,\n",
       "                       0.3312, 0.3091, 0.3620, 0.2820, 0.3537, 0.3785, 0.0988, 0.4888, 0.2897,\n",
       "                       0.2446, 0.2158, 0.2637, 0.2291, 0.2648, 0.3641, 0.4401, 0.2444, 0.1441,\n",
       "                       0.1811, 0.2339, 0.1882, 0.5074, 0.2814, 0.1941, 0.3125, 0.6478, 0.1189,\n",
       "                       0.7360, 0.1836, 0.4075, 0.2255, 0.3592, 0.3757, 0.3888, 0.3587, 0.1095,\n",
       "                       0.1670, 0.7790, 0.4029, 0.3542, 0.2232, 0.1536, 0.3413, 0.3184, 0.2852,\n",
       "                       1.0556, 0.2030, 0.1540, 0.3162, 0.3268, 0.1592, 0.1357, 0.1467, 0.4155,\n",
       "                       0.5706, 0.1872, 0.2669, 0.1185, 0.1414, 0.2127, 0.3733, 0.2135, 0.4615,\n",
       "                       0.2227, 0.3965, 0.4360, 0.5132, 0.2795, 0.3237, 0.3594, 0.3397, 0.2056,\n",
       "                       0.4976, 0.4648, 0.2546, 0.1878, 0.2158, 0.2179, 0.1499, 0.2425, 0.2983,\n",
       "                       0.4615, 0.3277, 0.5771, 0.4123, 0.4195, 0.3626, 0.2685, 0.1061, 0.3274,\n",
       "                       0.2856, 0.1611, 0.3247, 0.3233, 0.2269, 0.1705, 0.1775, 0.4546, 0.3055,\n",
       "                       0.1832, 0.3720], device='cuda:0')),\n",
       "              ('layer2.0.bn2.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer2.0.shortcut.0.weight',\n",
       "               tensor([[[[-0.0578]],\n",
       "               \n",
       "                        [[-0.0208]],\n",
       "               \n",
       "                        [[ 0.2411]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0244]],\n",
       "               \n",
       "                        [[ 0.1391]],\n",
       "               \n",
       "                        [[-0.0390]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0590]],\n",
       "               \n",
       "                        [[-0.0627]],\n",
       "               \n",
       "                        [[ 0.0239]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0903]],\n",
       "               \n",
       "                        [[-0.0831]],\n",
       "               \n",
       "                        [[-0.0967]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0401]],\n",
       "               \n",
       "                        [[-0.0523]],\n",
       "               \n",
       "                        [[ 0.0780]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0185]],\n",
       "               \n",
       "                        [[ 0.0151]],\n",
       "               \n",
       "                        [[-0.1508]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0399]],\n",
       "               \n",
       "                        [[ 0.0103]],\n",
       "               \n",
       "                        [[ 0.0014]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0874]],\n",
       "               \n",
       "                        [[-0.0102]],\n",
       "               \n",
       "                        [[ 0.0171]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0124]],\n",
       "               \n",
       "                        [[ 0.0012]],\n",
       "               \n",
       "                        [[-0.0087]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.1307]],\n",
       "               \n",
       "                        [[ 0.0777]],\n",
       "               \n",
       "                        [[ 0.0753]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0391]],\n",
       "               \n",
       "                        [[-0.0959]],\n",
       "               \n",
       "                        [[ 0.0796]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0810]],\n",
       "               \n",
       "                        [[-0.0041]],\n",
       "               \n",
       "                        [[ 0.0878]]]], device='cuda:0')),\n",
       "              ('layer2.0.shortcut.1.weight',\n",
       "               tensor([0.3138, 0.2605, 0.2625, 0.2173, 0.5339, 0.2905, 0.1090, 0.3423, 0.2813,\n",
       "                       0.2884, 0.3934, 0.2294, 0.3719, 0.3400, 0.1760, 0.1840, 0.3347, 0.1519,\n",
       "                       0.4017, 0.1410, 0.1979, 0.2760, 0.3461, 0.2635, 0.4409, 0.3475, 0.2510,\n",
       "                       0.1396, 0.3881, 0.2699, 0.2722, 0.3117, 0.1676, 0.1543, 0.1417, 0.3006,\n",
       "                       0.1852, 0.2309, 0.0755, 0.5656, 0.4208, 0.1697, 0.2705, 0.2995, 0.2868,\n",
       "                       0.2816, 0.2873, 0.2951, 0.2107, 0.1890, 0.2342, 0.2053, 0.3067, 0.1754,\n",
       "                       0.4932, 0.5287, 0.4157, 0.1291, 0.4729, 0.2534, 0.3948, 0.1863, 0.2608,\n",
       "                       0.4334, 0.2215, 0.5284, 0.0699, 0.6785, 0.3322, 0.1626, 0.2339, 0.2776,\n",
       "                       0.2393, 0.2096, 0.1713, 0.0253, 0.3535, 0.3371, 0.4436, 0.1970, 0.3207,\n",
       "                       0.3310, 0.2412, 0.2646, 0.4221, 0.5022, 0.2518, 0.3526, 0.2000, 0.1107,\n",
       "                       0.1799, 0.3917, 0.1847, 0.2560, 0.2843, 0.4307, 0.2199, 0.2876, 0.0650,\n",
       "                       0.3285, 0.1643, 0.1677, 0.8746, 0.2145, 0.2713, 0.5434, 0.2985, 0.2723,\n",
       "                       0.2032, 0.1602, 0.1393, 0.2447, 0.2724, 0.3152, 0.1943, 0.7103, 0.2675,\n",
       "                       0.2931, 0.4245, 0.3239, 0.4734, 0.2795, 0.3957, 0.2604, 0.2197, 0.1661,\n",
       "                       0.3257, 0.4126], device='cuda:0')),\n",
       "              ('layer2.0.shortcut.1.bias',\n",
       "               tensor([-0.1845, -0.0208,  0.0716, -0.1156, -0.0984, -0.0328, -0.1430, -0.0213,\n",
       "                       -0.0849, -0.1763, -0.1455, -0.0273, -0.0423, -0.0297, -0.1436, -0.1578,\n",
       "                       -0.2201, -0.2058,  0.0421, -0.0653, -0.1350,  0.0555, -0.0607, -0.0918,\n",
       "                        0.0243, -0.0349, -0.1644, -0.0339, -0.0627, -0.0882, -0.1253, -0.1305,\n",
       "                       -0.1143, -0.0904,  0.0317, -0.0387, -0.0334, -0.0754, -0.0728, -0.0619,\n",
       "                       -0.0538, -0.1679, -0.0964, -0.0745, -0.1750, -0.1600, -0.2328, -0.0906,\n",
       "                        0.0822, -0.1553, -0.0883, -0.1656, -0.1272, -0.0291,  0.0268,  0.1247,\n",
       "                       -0.2504,  0.0049, -0.1407, -0.1272, -0.0938, -0.0935, -0.1643,  0.0353,\n",
       "                        0.0782,  0.0427, -0.1441, -0.2765, -0.0409, -0.1458, -0.2476, -0.1415,\n",
       "                        0.0867, -0.1236, -0.0342, -0.0410, -0.1111, -0.0908, -0.0744, -0.1218,\n",
       "                       -0.0669, -0.1384, -0.0630,  0.0562,  0.0425, -0.0674, -0.0755, -0.0786,\n",
       "                       -0.0621, -0.0083, -0.0604, -0.1303, -0.0494, -0.0993, -0.0668,  0.1466,\n",
       "                       -0.0536, -0.0421, -0.0564, -0.0756, -0.0377, -0.0291, -0.1540, -0.0606,\n",
       "                        0.0765, -0.0749, -0.0374, -0.1065, -0.1408, -0.0099,  0.0521, -0.1312,\n",
       "                       -0.0814, -0.1709, -0.0348, -0.0639, -0.0144, -0.1833, -0.0142, -0.0982,\n",
       "                        0.0119, -0.1212, -0.0726, -0.0912, -0.1583, -0.1763, -0.0244, -0.0141],\n",
       "                      device='cuda:0')),\n",
       "              ('layer2.0.shortcut.1.running_mean',\n",
       "               tensor([ 1.7480e-01,  4.4523e-02, -2.3260e-01,  7.6615e-02,  4.6388e-01,\n",
       "                        1.9199e-01, -1.0176e-01, -3.3971e-01, -2.7611e-02, -2.5071e-01,\n",
       "                       -1.6309e-01, -6.1185e-01, -5.1231e-01, -1.5805e-02, -3.1384e-01,\n",
       "                       -2.0134e-01, -5.6361e-01,  9.9501e-05, -5.9926e-01, -1.7386e-01,\n",
       "                        1.9958e-01, -4.5278e-01, -1.4141e-01,  1.6834e-01, -2.9646e-01,\n",
       "                       -1.9446e-01,  3.7980e-01, -3.1746e-01, -2.6607e-01, -4.2164e-02,\n",
       "                       -3.5809e-02,  4.2709e-02,  1.5230e-01,  5.9357e-02, -1.6302e-01,\n",
       "                       -5.6530e-01, -9.4624e-03, -1.9626e-01, -2.3149e-01,  7.5738e-02,\n",
       "                       -2.9893e-01, -1.3746e-01, -2.4433e-01, -5.7721e-01,  7.6196e-02,\n",
       "                       -2.4909e-01, -8.8737e-02,  1.7715e-01, -3.5940e-01, -3.5322e-01,\n",
       "                        1.2332e-01,  1.8463e-01,  1.1451e-01, -1.5441e-01, -3.5056e-01,\n",
       "                       -6.7638e-01, -1.6105e-02,  1.8000e-01, -3.8728e-01, -2.1771e-01,\n",
       "                        3.1824e-02, -1.2355e-01,  2.5661e-01,  4.5491e-01, -3.1228e-01,\n",
       "                       -5.3461e-01,  7.6952e-02,  2.8165e-01,  2.1667e-01,  6.3678e-02,\n",
       "                        2.6684e-01,  1.3894e-01, -2.2633e-01, -1.6702e-02, -2.3451e-01,\n",
       "                       -8.0970e-02, -1.3968e-01,  5.5099e-03,  4.6908e-01, -1.4782e-01,\n",
       "                        2.1040e-01,  4.9773e-02, -8.5655e-02, -5.9089e-01, -5.0432e-01,\n",
       "                       -3.6305e-01, -3.7449e-01,  1.0714e-01, -1.0406e-01, -3.2138e-01,\n",
       "                       -2.5796e-01, -4.6953e-01, -2.6807e-01, -1.8036e-01, -3.5643e-01,\n",
       "                        9.9851e-02,  5.4002e-01,  2.0506e-01, -1.5897e-01, -3.1768e-01,\n",
       "                       -1.1065e-01, -1.5259e-01,  2.5174e-01, -3.9463e-01, -1.6404e-01,\n",
       "                        4.6430e-01,  3.5454e-02,  2.2592e-02, -6.6511e-02, -2.7699e-01,\n",
       "                       -3.4810e-01, -1.5995e-01, -4.4721e-01, -1.8618e-02, -4.6618e-01,\n",
       "                       -8.0661e-01, -5.5280e-01, -5.8277e-02, -4.0878e-01, -2.3242e-01,\n",
       "                       -6.1031e-01,  3.2966e-01,  1.6875e-01, -2.6618e-01, -1.5918e-01,\n",
       "                       -2.0518e-01, -2.6598e-01, -7.8942e-01], device='cuda:0')),\n",
       "              ('layer2.0.shortcut.1.running_var',\n",
       "               tensor([0.2032, 0.0996, 0.1456, 0.0506, 0.2197, 0.1726, 0.0911, 0.1529, 0.0769,\n",
       "                       0.0843, 0.1888, 0.0859, 0.1204, 0.1459, 0.0914, 0.0987, 0.1494, 0.0577,\n",
       "                       0.1875, 0.1124, 0.0878, 0.1422, 0.1608, 0.1274, 0.2700, 0.1856, 0.0937,\n",
       "                       0.0524, 0.2189, 0.1105, 0.1153, 0.1266, 0.0620, 0.0349, 0.1419, 0.1637,\n",
       "                       0.0777, 0.1045, 0.0452, 0.3588, 0.1914, 0.0914, 0.0987, 0.1144, 0.0817,\n",
       "                       0.1056, 0.0968, 0.0885, 0.1419, 0.0828, 0.0888, 0.1351, 0.1351, 0.0608,\n",
       "                       0.4775, 0.5188, 0.1557, 0.0388, 0.1644, 0.1358, 0.1665, 0.0611, 0.0732,\n",
       "                       0.2377, 0.2198, 0.3530, 0.0727, 0.2874, 0.1308, 0.0768, 0.1223, 0.0959,\n",
       "                       0.2365, 0.0431, 0.0530, 0.0161, 0.1821, 0.0599, 0.2150, 0.0635, 0.1592,\n",
       "                       0.1648, 0.1052, 0.1562, 0.1830, 0.1852, 0.1338, 0.1617, 0.0582, 0.0773,\n",
       "                       0.0546, 0.2282, 0.1221, 0.1481, 0.1221, 0.3929, 0.1339, 0.1523, 0.0481,\n",
       "                       0.2032, 0.0744, 0.0610, 0.3934, 0.0597, 0.1139, 0.2175, 0.1493, 0.1090,\n",
       "                       0.1202, 0.0796, 0.0875, 0.1468, 0.1368, 0.1187, 0.0776, 0.3399, 0.1147,\n",
       "                       0.0904, 0.1713, 0.1835, 0.2967, 0.1299, 0.1392, 0.0874, 0.1053, 0.0802,\n",
       "                       0.1391, 0.2636], device='cuda:0')),\n",
       "              ('layer2.0.shortcut.1.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer2.1.conv1.weight',\n",
       "               tensor([[[[ 0.0179, -0.0444,  0.0198],\n",
       "                         [ 0.0740,  0.0348, -0.0147],\n",
       "                         [ 0.0432,  0.0660,  0.0477]],\n",
       "               \n",
       "                        [[ 0.0092,  0.0658,  0.0179],\n",
       "                         [-0.0276, -0.0021, -0.0078],\n",
       "                         [-0.0157, -0.0165, -0.0319]],\n",
       "               \n",
       "                        [[ 0.0263,  0.0499, -0.0109],\n",
       "                         [-0.0242, -0.0211,  0.0029],\n",
       "                         [-0.0063,  0.0186,  0.0665]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0122, -0.0359, -0.0353],\n",
       "                         [ 0.0354,  0.0122,  0.0234],\n",
       "                         [ 0.0080,  0.0053, -0.0052]],\n",
       "               \n",
       "                        [[ 0.0237,  0.0706,  0.0568],\n",
       "                         [-0.0016,  0.0295,  0.0159],\n",
       "                         [-0.0351, -0.0171,  0.0118]],\n",
       "               \n",
       "                        [[-0.0724, -0.0166,  0.0419],\n",
       "                         [ 0.0151,  0.0067,  0.0358],\n",
       "                         [ 0.0589,  0.0156, -0.0134]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0340, -0.0326, -0.0110],\n",
       "                         [-0.0261,  0.0229,  0.0259],\n",
       "                         [-0.0199, -0.0072,  0.0194]],\n",
       "               \n",
       "                        [[-0.0130, -0.0264, -0.0142],\n",
       "                         [ 0.0545,  0.0245,  0.0174],\n",
       "                         [ 0.0793,  0.0716,  0.0787]],\n",
       "               \n",
       "                        [[ 0.0314,  0.0447,  0.0255],\n",
       "                         [ 0.0164,  0.0491,  0.0157],\n",
       "                         [-0.0325, -0.0010,  0.0095]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0317,  0.0298,  0.0206],\n",
       "                         [ 0.0207,  0.0210, -0.0126],\n",
       "                         [-0.0230, -0.0550, -0.0484]],\n",
       "               \n",
       "                        [[-0.0143, -0.0239, -0.0174],\n",
       "                         [ 0.0287,  0.0211,  0.0341],\n",
       "                         [ 0.0194,  0.0465,  0.0380]],\n",
       "               \n",
       "                        [[-0.0047, -0.0239, -0.0338],\n",
       "                         [-0.0398, -0.0469, -0.0492],\n",
       "                         [ 0.0656,  0.0941,  0.0573]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0333, -0.0524, -0.0442],\n",
       "                         [ 0.0058, -0.0703,  0.0041],\n",
       "                         [ 0.0903, -0.0212, -0.0758]],\n",
       "               \n",
       "                        [[-0.0640, -0.0865, -0.0608],\n",
       "                         [-0.0048, -0.0784, -0.0895],\n",
       "                         [ 0.0390,  0.0582,  0.0385]],\n",
       "               \n",
       "                        [[-0.0056, -0.0494, -0.0449],\n",
       "                         [ 0.0354,  0.0196, -0.0536],\n",
       "                         [-0.0184,  0.0605,  0.0185]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0258,  0.0390,  0.0754],\n",
       "                         [-0.0224, -0.0743, -0.0303],\n",
       "                         [ 0.0325, -0.0218, -0.0193]],\n",
       "               \n",
       "                        [[-0.0259, -0.0626, -0.0535],\n",
       "                         [ 0.0117, -0.0256, -0.1022],\n",
       "                         [ 0.0404,  0.0207,  0.0059]],\n",
       "               \n",
       "                        [[ 0.0741,  0.0531,  0.0532],\n",
       "                         [ 0.0313,  0.0722,  0.0554],\n",
       "                         [-0.0550, -0.0041,  0.0145]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0991,  0.0677,  0.0127],\n",
       "                         [ 0.0284,  0.0289, -0.0330],\n",
       "                         [-0.0113,  0.0236, -0.0312]],\n",
       "               \n",
       "                        [[-0.0061,  0.0309, -0.0152],\n",
       "                         [ 0.0081, -0.0003, -0.0107],\n",
       "                         [-0.0045, -0.0175, -0.0047]],\n",
       "               \n",
       "                        [[ 0.0536, -0.0883,  0.0047],\n",
       "                         [ 0.0421, -0.0491,  0.0339],\n",
       "                         [ 0.0158, -0.0484,  0.0744]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0206, -0.0501, -0.0536],\n",
       "                         [ 0.0711, -0.0312, -0.0576],\n",
       "                         [ 0.0893, -0.0115, -0.0613]],\n",
       "               \n",
       "                        [[-0.0422, -0.0081,  0.0076],\n",
       "                         [-0.0209, -0.0145,  0.0028],\n",
       "                         [-0.0115,  0.0041, -0.0084]],\n",
       "               \n",
       "                        [[ 0.0142, -0.0105, -0.0138],\n",
       "                         [ 0.0432,  0.0239, -0.0127],\n",
       "                         [ 0.0516,  0.0215, -0.0241]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0150, -0.0438, -0.0423],\n",
       "                         [-0.0280, -0.0631, -0.0381],\n",
       "                         [ 0.0156, -0.0566, -0.0475]],\n",
       "               \n",
       "                        [[ 0.0006,  0.0147,  0.0005],\n",
       "                         [ 0.0107,  0.0281,  0.0086],\n",
       "                         [-0.0159,  0.0016, -0.0153]],\n",
       "               \n",
       "                        [[-0.0111,  0.0171,  0.0163],\n",
       "                         [-0.0125, -0.0138, -0.0159],\n",
       "                         [-0.0194, -0.0271, -0.0204]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0328,  0.0222, -0.0211],\n",
       "                         [ 0.0259,  0.0222, -0.0008],\n",
       "                         [-0.0118, -0.0093, -0.0017]],\n",
       "               \n",
       "                        [[ 0.0029, -0.0122, -0.0060],\n",
       "                         [ 0.0103,  0.0027, -0.0134],\n",
       "                         [ 0.0192,  0.0249,  0.0213]],\n",
       "               \n",
       "                        [[-0.0211,  0.0109,  0.0061],\n",
       "                         [ 0.0219,  0.0029, -0.0114],\n",
       "                         [-0.0290, -0.0377, -0.0180]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0293, -0.0238, -0.0228],\n",
       "                         [ 0.0057, -0.0315, -0.0660],\n",
       "                         [-0.0078,  0.0247, -0.0089]],\n",
       "               \n",
       "                        [[-0.0387,  0.0040, -0.0060],\n",
       "                         [-0.0197,  0.0044,  0.0282],\n",
       "                         [ 0.0511,  0.0321,  0.0747]],\n",
       "               \n",
       "                        [[-0.0177,  0.0605,  0.0102],\n",
       "                         [-0.0634,  0.0493,  0.0667],\n",
       "                         [-0.0320, -0.0393,  0.0322]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0313, -0.0264, -0.0273],\n",
       "                         [ 0.0449, -0.0296, -0.0035],\n",
       "                         [ 0.0170, -0.0346, -0.0017]],\n",
       "               \n",
       "                        [[-0.0588,  0.0016,  0.0094],\n",
       "                         [-0.1004, -0.0290,  0.0025],\n",
       "                         [-0.0562, -0.0249, -0.0007]],\n",
       "               \n",
       "                        [[-0.0457, -0.0972, -0.0638],\n",
       "                         [ 0.0598, -0.0932, -0.1111],\n",
       "                         [ 0.1743,  0.1245,  0.0508]]]], device='cuda:0')),\n",
       "              ('layer2.1.bn1.weight',\n",
       "               tensor([0.3344, 0.3752, 0.4024, 0.3222, 0.4731, 0.2767, 0.3683, 0.3908, 0.1954,\n",
       "                       0.3809, 0.2509, 0.3027, 0.4292, 0.3702, 0.5501, 0.3067, 0.4218, 0.3264,\n",
       "                       0.2198, 0.2765, 0.2782, 0.2204, 0.2292, 0.1071, 0.5489, 0.1725, 0.2020,\n",
       "                       0.4334, 0.3090, 0.3119, 0.4608, 0.3837, 0.3223, 0.3475, 0.3284, 0.3661,\n",
       "                       0.2376, 0.3141, 0.3031, 0.4719, 0.3348, 0.4134, 0.3881, 0.4076, 0.4122,\n",
       "                       0.2551, 0.3847, 0.2979, 0.3639, 0.4575, 0.3581, 0.4190, 0.2885, 0.3082,\n",
       "                       0.3967, 0.3180, 0.3212, 0.2338, 0.4820, 0.3407, 0.4392, 0.2659, 0.3436,\n",
       "                       0.2234, 0.3618, 0.3135, 0.4445, 0.3061, 0.4219, 0.4056, 0.1972, 0.5524,\n",
       "                       0.3265, 0.3355, 0.2048, 0.4276, 0.2693, 0.3457, 0.4045, 0.4333, 0.4218,\n",
       "                       0.2938, 0.4990, 0.2848, 0.2863, 0.4174, 0.3375, 0.1885, 0.3728, 0.2903,\n",
       "                       0.4434, 0.2294, 0.3677, 0.3461, 0.3641, 0.3432, 0.3138, 0.3296, 0.2294,\n",
       "                       0.2946, 0.1913, 0.4995, 0.3776, 0.3142, 0.1796, 0.3949, 0.2966, 0.3625,\n",
       "                       0.2852, 0.2680, 0.3446, 0.3120, 0.4043, 0.3217, 0.3409, 0.3969, 0.1613,\n",
       "                       0.3720, 0.3651, 0.3440, 0.3714, 0.4860, 0.3595, 0.3008, 0.2976, 0.4213,\n",
       "                       0.2988, 0.3974], device='cuda:0')),\n",
       "              ('layer2.1.bn1.bias',\n",
       "               tensor([-0.2843, -0.2424, -0.3806, -0.1420, -0.3590, -0.2780, -0.2681, -0.2617,\n",
       "                       -0.1856, -0.2248, -0.2896, -0.2811, -0.3522, -0.4658, -0.4886, -0.2768,\n",
       "                       -0.2681, -0.2592, -0.2715, -0.1145, -0.1827, -0.1827, -0.2558, -0.0935,\n",
       "                       -0.3448, -0.1933, -0.2289, -0.2381, -0.3094, -0.1672, -0.2012, -0.2445,\n",
       "                       -0.3069, -0.2587, -0.3018, -0.3299, -0.2012, -0.2843, -0.2546, -0.2750,\n",
       "                       -0.2213, -0.3994, -0.2500, -0.2932, -0.1655, -0.1392, -0.2272, -0.2964,\n",
       "                       -0.2886, -0.3238, -0.2634, -0.3422, -0.2047, -0.2844, -0.2542, -0.1729,\n",
       "                       -0.1621, -0.3046, -0.2707, -0.1440, -0.2399, -0.1521, -0.3045, -0.2015,\n",
       "                       -0.3598, -0.1571, -0.2217, -0.2811, -0.2702, -0.2396, -0.1893, -0.4041,\n",
       "                       -0.2720, -0.1170, -0.1743, -0.3475, -0.1019, -0.3735, -0.2025, -0.3638,\n",
       "                       -0.2351, -0.4490, -0.4058, -0.2928, -0.2500, -0.2503, -0.2593, -0.1832,\n",
       "                       -0.1791, -0.1573, -0.4334, -0.3585, -0.2921, -0.2075, -0.2027, -0.2312,\n",
       "                       -0.2700, -0.2162, -0.0708, -0.1423, -0.1841, -0.3500, -0.3543, -0.1936,\n",
       "                       -0.1102, -0.3022, -0.1746, -0.3467, -0.1909, -0.3044, -0.3503, -0.3490,\n",
       "                       -0.2610, -0.1675, -0.3059, -0.3496, -0.2667, -0.2364, -0.3507, -0.3367,\n",
       "                       -0.2573, -0.2500, -0.2231, -0.2002, -0.2568, -0.3206, -0.2789, -0.3890],\n",
       "                      device='cuda:0')),\n",
       "              ('layer2.1.bn1.running_mean',\n",
       "               tensor([ 0.7712, -0.7295, -1.3995, -1.0927, -0.5948,  0.3206, -0.1372, -0.6750,\n",
       "                       -0.5812, -0.8046, -0.4041, -0.3254, -0.3917, -1.6384, -1.4248,  0.9125,\n",
       "                       -0.4397, -0.3503, -0.5645, -0.5433, -0.2425, -0.3633, -0.2052,  0.6062,\n",
       "                        0.1051, -0.3953,  0.5745, -0.1670, -0.9380, -1.4732, -0.3305, -1.0344,\n",
       "                       -0.4021, -0.8443, -0.0903,  0.1305,  0.7833, -0.6395, -0.3646, -1.9058,\n",
       "                       -1.8739, -0.5409, -0.5150, -0.0678, -1.7944,  0.5450,  0.2540, -1.3085,\n",
       "                       -0.1837, -1.7029, -0.5905, -0.2671, -0.0842,  1.5057, -1.7805, -0.7365,\n",
       "                        0.0501, -0.9598, -0.5412,  0.4724, -0.0995, -0.5103,  0.4145, -0.6911,\n",
       "                       -0.1557, -0.9704, -1.1466, -1.0259, -0.5660, -0.9426, -0.7804, -0.5012,\n",
       "                       -0.9005, -0.6084,  0.2282, -1.2355, -1.0912,  1.7501, -1.0613, -0.8415,\n",
       "                       -1.0949, -2.0717, -0.6621,  0.0129,  0.3814, -0.2018,  0.2545, -0.4170,\n",
       "                       -1.2538, -0.5630, -0.8730,  0.7359, -0.0770, -0.6981, -0.8990, -2.4055,\n",
       "                       -0.6184, -1.7546, -1.4014, -0.1413, -0.1960, -1.4714, -0.3777,  0.0236,\n",
       "                        0.5605, -1.5893, -0.7452,  0.0081, -0.0634, -0.7118, -0.9165, -0.2077,\n",
       "                       -0.3606, -0.5346, -0.8520, -0.4753,  0.1066, -0.4289, -0.6511, -1.1376,\n",
       "                       -1.1030,  0.0493, -0.6930, -0.1291, -1.5040, -0.3285, -1.0618, -1.1206],\n",
       "                      device='cuda:0')),\n",
       "              ('layer2.1.bn1.running_var',\n",
       "               tensor([1.0129, 0.8322, 1.3544, 0.7032, 1.2158, 0.7456, 0.3907, 0.7682, 0.3292,\n",
       "                       1.0601, 0.6414, 0.4246, 0.9162, 1.1195, 1.2391, 0.7209, 1.1024, 0.9326,\n",
       "                       0.5534, 0.6059, 0.2941, 0.4153, 0.3335, 0.1155, 1.3212, 0.3087, 0.2502,\n",
       "                       1.0458, 0.5627, 0.5227, 0.8707, 0.8686, 0.6206, 0.7877, 0.6548, 1.4007,\n",
       "                       0.4341, 0.5548, 0.6784, 0.9163, 0.6583, 1.3177, 1.3700, 0.7977, 1.2995,\n",
       "                       0.5018, 1.1254, 0.5453, 0.8044, 1.0532, 1.0356, 0.8452, 0.5154, 0.8788,\n",
       "                       0.8420, 0.7031, 0.6409, 0.6890, 1.1777, 0.9114, 0.7753, 0.3913, 1.0011,\n",
       "                       0.4439, 1.0515, 0.5044, 1.3821, 1.0033, 0.9780, 0.7623, 0.4304, 1.2959,\n",
       "                       0.6803, 1.2972, 0.4218, 1.1821, 0.5858, 1.4967, 1.0238, 1.5486, 0.7442,\n",
       "                       0.7308, 1.8226, 0.2993, 0.6936, 0.8792, 1.0078, 0.3043, 1.0703, 0.4711,\n",
       "                       1.0351, 0.7449, 0.9344, 0.8155, 0.8829, 0.7711, 0.6352, 0.6883, 1.1013,\n",
       "                       0.5102, 0.2360, 1.3701, 1.5436, 0.4642, 0.1923, 0.6065, 0.8577, 1.0505,\n",
       "                       0.5137, 0.5474, 0.7470, 0.3793, 1.0697, 0.7632, 0.7298, 1.0551, 0.3223,\n",
       "                       0.7949, 0.8177, 0.6247, 0.6857, 1.5151, 0.7656, 0.5547, 0.7378, 0.8828,\n",
       "                       0.4684, 1.2763], device='cuda:0')),\n",
       "              ('layer2.1.bn1.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer2.1.conv2.weight',\n",
       "               tensor([[[[ 2.7251e-02, -1.0422e-02, -2.7428e-02],\n",
       "                         [ 4.5278e-02,  4.2248e-02,  5.1892e-02],\n",
       "                         [ 3.2082e-03,  3.8707e-02,  1.8818e-02]],\n",
       "               \n",
       "                        [[-1.3633e-02,  3.5907e-04, -1.0726e-02],\n",
       "                         [ 1.1382e-02,  1.0014e-02,  1.8772e-02],\n",
       "                         [ 3.3935e-02,  2.1213e-02,  1.6997e-02]],\n",
       "               \n",
       "                        [[-4.5792e-02,  2.4497e-03, -1.2451e-02],\n",
       "                         [-4.4039e-02, -4.4140e-02, -7.2145e-02],\n",
       "                         [-5.0950e-02, -4.8379e-02, -6.8873e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.5853e-02, -1.6239e-02, -8.0093e-03],\n",
       "                         [-2.0759e-02,  1.4710e-02, -8.7014e-03],\n",
       "                         [-1.7844e-02, -6.4424e-03,  8.0788e-03]],\n",
       "               \n",
       "                        [[ 5.4043e-03, -1.1480e-02, -1.6441e-02],\n",
       "                         [ 1.2111e-02, -1.3527e-02, -1.9285e-02],\n",
       "                         [ 2.1028e-02, -1.8163e-03, -1.0897e-02]],\n",
       "               \n",
       "                        [[-2.6487e-02,  1.7504e-03,  2.3239e-03],\n",
       "                         [-1.1016e-02,  8.7183e-03,  1.8845e-02],\n",
       "                         [-5.0992e-02, -1.2577e-02,  2.2092e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.3495e-03, -1.4952e-02,  5.6610e-03],\n",
       "                         [-7.5949e-03, -2.1783e-02, -1.1276e-02],\n",
       "                         [ 1.1732e-02, -1.8010e-02,  1.4315e-03]],\n",
       "               \n",
       "                        [[ 1.7355e-02,  1.5396e-02, -4.8845e-03],\n",
       "                         [ 1.4144e-02,  3.0309e-02,  2.6623e-02],\n",
       "                         [ 1.6988e-03, -7.7026e-03,  2.5234e-05]],\n",
       "               \n",
       "                        [[ 3.2450e-02,  2.2579e-02,  3.3719e-02],\n",
       "                         [ 1.8209e-02, -2.2524e-04, -8.9670e-04],\n",
       "                         [-1.3758e-02, -1.7761e-02, -7.8894e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.5769e-02, -1.0451e-02,  4.5853e-02],\n",
       "                         [-1.0718e-02, -4.9900e-03,  6.7743e-02],\n",
       "                         [-2.0683e-02, -9.2461e-03,  6.3051e-02]],\n",
       "               \n",
       "                        [[-6.1757e-03, -1.2845e-02, -1.2901e-02],\n",
       "                         [ 9.3996e-03, -1.4704e-03, -1.4329e-02],\n",
       "                         [ 1.0012e-02,  4.3157e-03, -1.4191e-02]],\n",
       "               \n",
       "                        [[-1.4587e-02, -2.8726e-03,  1.0990e-02],\n",
       "                         [-3.0455e-03, -1.1618e-02, -1.1874e-03],\n",
       "                         [ 4.3655e-03, -9.5097e-03, -1.5013e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.7895e-02, -2.5809e-02, -1.4054e-02],\n",
       "                         [-1.2924e-02, -3.9339e-02, -3.4974e-02],\n",
       "                         [ 9.9223e-03, -1.5218e-02,  1.7995e-02]],\n",
       "               \n",
       "                        [[ 2.1666e-02, -8.7280e-04, -2.1684e-02],\n",
       "                         [ 8.0141e-02,  6.2649e-02, -1.1592e-02],\n",
       "                         [ 2.1487e-02, -3.4047e-03, -5.3432e-02]],\n",
       "               \n",
       "                        [[-1.2144e-02,  1.8343e-02,  3.4509e-02],\n",
       "                         [-1.7692e-02, -3.3908e-02, -1.6802e-02],\n",
       "                         [-3.8544e-02, -2.8350e-02,  2.7080e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.4739e-02,  4.4952e-02,  1.7957e-02],\n",
       "                         [ 4.7828e-02,  9.1381e-02,  7.6303e-02],\n",
       "                         [ 5.2488e-02,  8.1936e-02,  6.3797e-02]],\n",
       "               \n",
       "                        [[-1.3272e-02, -3.6898e-02, -4.5161e-02],\n",
       "                         [ 1.6869e-02,  1.7877e-03, -2.7808e-02],\n",
       "                         [ 6.1376e-02,  4.5477e-02,  2.0092e-03]],\n",
       "               \n",
       "                        [[-7.1222e-03, -3.6010e-03, -2.5197e-02],\n",
       "                         [-5.7037e-03, -1.1588e-02, -3.0060e-02],\n",
       "                         [-1.4831e-03, -2.7884e-02, -6.4260e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-6.1312e-03, -1.1308e-02, -1.7445e-02],\n",
       "                         [-1.3512e-02,  2.1039e-02,  1.7775e-02],\n",
       "                         [-3.7054e-03,  3.6557e-02,  2.7837e-02]],\n",
       "               \n",
       "                        [[-3.5000e-03, -1.4947e-02, -9.0247e-03],\n",
       "                         [-1.4507e-02, -2.6327e-02, -1.6037e-02],\n",
       "                         [-5.5960e-03, -1.3174e-02, -1.0996e-02]],\n",
       "               \n",
       "                        [[-6.5577e-02, -5.7374e-02, -2.1903e-02],\n",
       "                         [-2.4799e-02, -3.3383e-02, -3.9403e-03],\n",
       "                         [ 6.1412e-03, -1.6718e-02, -3.8895e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.0830e-03,  2.0805e-02,  2.4884e-03],\n",
       "                         [-6.4161e-03,  1.7466e-03,  3.0336e-02],\n",
       "                         [-3.0370e-02, -3.2167e-02,  1.3860e-02]],\n",
       "               \n",
       "                        [[-5.4046e-03, -3.0033e-03, -1.1787e-02],\n",
       "                         [-1.7190e-02,  1.0447e-03, -6.0773e-04],\n",
       "                         [-3.3523e-02, -1.6652e-02, -2.6322e-02]],\n",
       "               \n",
       "                        [[-2.6608e-03,  7.4021e-03, -2.5502e-03],\n",
       "                         [-3.7466e-02, -1.8409e-02,  5.6297e-03],\n",
       "                         [-3.6858e-02, -2.4097e-02, -1.7025e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.2916e-02, -1.5742e-02, -2.4101e-02],\n",
       "                         [-7.8611e-03, -3.6719e-02, -1.6741e-02],\n",
       "                         [ 2.9308e-03, -2.0187e-02, -1.2549e-02]],\n",
       "               \n",
       "                        [[ 2.9261e-02,  5.2158e-02,  2.5951e-02],\n",
       "                         [ 1.1499e-02,  2.2251e-02,  2.5300e-02],\n",
       "                         [-3.6364e-02, -2.9966e-02, -2.2018e-02]],\n",
       "               \n",
       "                        [[-4.6059e-02, -5.4902e-02, -6.1804e-02],\n",
       "                         [-1.6801e-02, -1.4636e-02, -2.7546e-02],\n",
       "                         [-5.2307e-02, -6.2820e-02, -4.1778e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.3103e-02, -1.3804e-02,  4.8501e-02],\n",
       "                         [-4.5293e-03, -2.5756e-02,  3.0282e-02],\n",
       "                         [-1.0556e-02, -4.0517e-02, -2.5384e-02]],\n",
       "               \n",
       "                        [[-2.1186e-02, -2.0457e-02, -1.1943e-02],\n",
       "                         [-1.2301e-02,  1.6149e-03,  7.8116e-04],\n",
       "                         [-2.5038e-02, -3.6411e-03, -5.5198e-03]],\n",
       "               \n",
       "                        [[-4.5176e-02, -3.9715e-02, -2.2833e-02],\n",
       "                         [-3.4315e-02, -5.3661e-02, -5.6531e-02],\n",
       "                         [-3.5907e-02, -5.4068e-02, -6.3426e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.7759e-02, -2.3960e-02, -1.3376e-02],\n",
       "                         [ 6.3580e-02,  7.1081e-04, -2.0929e-02],\n",
       "                         [ 4.8938e-02,  2.3705e-02, -6.6852e-03]],\n",
       "               \n",
       "                        [[-1.0065e-02, -4.7602e-02, -6.8867e-02],\n",
       "                         [-1.4946e-02, -2.9976e-02, -1.3791e-02],\n",
       "                         [-2.6867e-02, -1.7727e-02, -1.7320e-02]],\n",
       "               \n",
       "                        [[-6.5905e-02,  1.4884e-02,  8.8199e-03],\n",
       "                         [ 4.6271e-03, -6.9398e-03, -8.7058e-04],\n",
       "                         [ 5.6152e-03,  1.7536e-02, -1.4398e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.3574e-02, -3.8115e-02,  1.6561e-02],\n",
       "                         [-2.2491e-02, -2.1375e-04,  5.9837e-02],\n",
       "                         [-2.6376e-02, -3.4349e-02,  1.5437e-02]],\n",
       "               \n",
       "                        [[ 4.3185e-02,  3.1998e-02,  3.6487e-02],\n",
       "                         [ 2.4115e-02,  1.1058e-02,  3.1039e-02],\n",
       "                         [ 2.4183e-02, -2.2587e-03,  7.5892e-03]],\n",
       "               \n",
       "                        [[-1.8877e-02, -2.4076e-03,  2.3510e-02],\n",
       "                         [-1.8206e-02, -3.0864e-02, -5.0147e-02],\n",
       "                         [-3.3181e-02, -3.2693e-02, -5.5378e-03]]]], device='cuda:0')),\n",
       "              ('layer2.1.bn2.weight',\n",
       "               tensor([0.1907, 0.1674, 0.3142, 0.1828, 0.1010, 0.3278, 0.3013, 0.2592, 0.2309,\n",
       "                       0.2230, 0.2240, 0.0718, 0.1785, 0.2304, 0.3706, 0.1992, 0.1484, 0.4049,\n",
       "                       0.3163, 0.3443, 0.2386, 0.3530, 0.3066, 0.3170, 0.2685, 0.2585, 0.3706,\n",
       "                       0.3335, 0.2904, 0.2725, 0.2529, 0.3566, 0.2468, 0.1739, 0.2731, 0.2634,\n",
       "                       0.4368, 0.2769, 0.3060, 0.3051, 0.2781, 0.4057, 0.1545, 0.4480, 0.3880,\n",
       "                       0.3849, 0.2275, 0.4100, 0.0522, 0.3160, 0.2462, 0.3749, 0.0048, 0.4540,\n",
       "                       0.2567, 0.1205, 0.2506, 0.3399, 0.1969, 0.1727, 0.3965, 0.3748, 0.2752,\n",
       "                       0.1855, 0.1418, 0.0395, 0.2699, 0.3944, 0.2118, 0.4298, 0.3055, 0.4803,\n",
       "                       0.1075, 0.4450, 0.2753, 0.3246, 0.2423, 0.3184, 0.2499, 0.4528, 0.2190,\n",
       "                       0.2000, 0.1474, 0.5179, 0.2931, 0.2864, 0.2806, 0.3277, 0.2743, 0.2576,\n",
       "                       0.4155, 0.1459, 0.4499, 0.2295, 0.2376, 0.2021, 0.1796, 0.2354, 0.4310,\n",
       "                       0.2083, 0.2746, 0.2691, 0.3126, 0.3524, 0.2613, 0.1856, 0.2460, 0.2651,\n",
       "                       0.2304, 0.4100, 0.2977, 0.3265, 0.2458, 0.3250, 0.3412, 0.0606, 0.2782,\n",
       "                       0.2810, 0.1331, 0.2953, 0.0968, 0.3432, 0.4825, 0.1874, 0.4575, 0.1438,\n",
       "                       0.2546, 0.2535], device='cuda:0')),\n",
       "              ('layer2.1.bn2.bias',\n",
       "               tensor([-0.1404, -0.0368, -0.1596, -0.1108, -0.1481, -0.3580, -0.3169, -0.1692,\n",
       "                       -0.0499, -0.0740, -0.1253, -0.1236, -0.1238,  0.0627, -0.1400, -0.2945,\n",
       "                        0.0304, -0.3250, -0.1638, -0.1039, -0.0492, -0.2244, -0.2762, -0.1865,\n",
       "                       -0.1554, -0.0601, -0.2865, -0.1675, -0.1268,  0.0228, -0.1914, -0.2592,\n",
       "                       -0.2140, -0.1223, -0.2388, -0.2409, -0.0491, -0.1016, -0.1801, -0.2381,\n",
       "                       -0.1891, -0.1822,  0.0288, -0.2209,  0.0214, -0.2299, -0.1428, -0.1259,\n",
       "                       -0.1220, -0.2129, -0.1512, -0.3998,  0.0174, -0.2538, -0.1665, -0.1805,\n",
       "                        0.0293, -0.1448, -0.1429, -0.1085, -0.1698, -0.3606, -0.0601, -0.0389,\n",
       "                        0.0296, -0.0243, -0.1146, -0.2979,  0.0407, -0.4907, -0.1805, -0.2968,\n",
       "                        0.0072, -0.3188, -0.1102, -0.1004, -0.1716,  0.0075, -0.2479, -0.3060,\n",
       "                       -0.2532, -0.2668, -0.1197, -0.0719, -0.1798, -0.2312, -0.0422, -0.1412,\n",
       "                       -0.1166,  0.0098, -0.0539, -0.0826, -0.1401, -0.3519, -0.2542, -0.1260,\n",
       "                       -0.1769, -0.1485,  0.0048, -0.0450, -0.0949, -0.0865, -0.3479, -0.1903,\n",
       "                       -0.1428, -0.1355, -0.2082, -0.0492,  0.0596, -0.2654, -0.0774, -0.1338,\n",
       "                       -0.1941, -0.4039, -0.2895,  0.0129, -0.0286, -0.2028, -0.1002, -0.2379,\n",
       "                       -0.0574, -0.1941, -0.1106, -0.2689, -0.3165, -0.1556, -0.0958, -0.2024],\n",
       "                      device='cuda:0')),\n",
       "              ('layer2.1.bn2.running_mean',\n",
       "               tensor([-0.1614, -0.1307, -0.2203,  0.1543, -0.2158, -0.3413, -0.0562, -0.2137,\n",
       "                        0.0852,  0.0269, -0.3448, -0.1446, -0.0638, -0.0482, -0.3108, -0.2483,\n",
       "                       -0.1743, -0.0022,  0.2994, -0.2593, -0.2437, -0.3068, -0.0123, -0.1974,\n",
       "                       -0.0926, -0.3634, -0.2867,  0.2519,  0.1692, -0.4289, -0.0191, -0.1340,\n",
       "                       -0.1581, -0.0063, -0.2595, -0.1917, -0.2378,  0.0557, -0.1474, -0.3547,\n",
       "                       -0.3236, -0.0947, -0.3568, -0.1925, -0.5961, -0.1883, -0.2313, -0.0760,\n",
       "                       -0.1210, -0.3968, -0.0736, -0.3089, -0.1486,  0.2168, -0.1383, -0.2313,\n",
       "                        0.0952, -0.1915, -0.1464, -0.1931, -0.3739,  0.3124,  0.1706,  0.0927,\n",
       "                       -0.2633, -0.0962,  0.2215,  0.0021,  0.1731,  0.0087, -0.0149, -0.0061,\n",
       "                       -0.0794,  0.5901,  0.2526, -0.2822, -0.1195, -0.3648, -0.1250, -0.1505,\n",
       "                       -0.1187, -0.1311, -0.1409, -0.4932, -0.2845, -0.1731, -0.4234, -0.2662,\n",
       "                       -0.0982, -0.2478, -0.5120,  0.0673, -0.6182, -0.3047, -0.1782, -0.2517,\n",
       "                       -0.2179, -0.0069, -0.3521, -0.1407, -0.3387, -0.2849, -0.3884, -0.1609,\n",
       "                       -0.2137, -0.2547, -0.3051,  0.0751, -0.2746, -0.1126, -0.5910, -0.2857,\n",
       "                       -0.2016, -0.4684, -0.1813, -0.0628, -0.1414, -0.0961, -0.1682, -0.0163,\n",
       "                       -0.1137, -0.0735, -0.2945, -0.0687, -0.5360, -0.1449, -0.2218, -0.3642],\n",
       "                      device='cuda:0')),\n",
       "              ('layer2.1.bn2.running_var',\n",
       "               tensor([0.0531, 0.0331, 0.0860, 0.0392, 0.0591, 0.0971, 0.0844, 0.0568, 0.0531,\n",
       "                       0.0553, 0.0506, 0.0388, 0.0366, 0.0674, 0.0751, 0.0319, 0.0916, 0.1042,\n",
       "                       0.0973, 0.1365, 0.0845, 0.0881, 0.0666, 0.0959, 0.0641, 0.0465, 0.0865,\n",
       "                       0.0832, 0.0975, 0.1099, 0.0570, 0.0892, 0.0552, 0.0178, 0.0705, 0.0946,\n",
       "                       0.1223, 0.0523, 0.0763, 0.1102, 0.0702, 0.1052, 0.0520, 0.0797, 0.1185,\n",
       "                       0.0841, 0.0405, 0.1039, 0.0295, 0.0795, 0.0462, 0.0813, 0.0299, 0.0826,\n",
       "                       0.1119, 0.0566, 0.0818, 0.0785, 0.0566, 0.0808, 0.1246, 0.1082, 0.0871,\n",
       "                       0.0462, 0.0673, 0.0350, 0.0740, 0.0929, 0.0396, 0.0873, 0.0798, 0.0949,\n",
       "                       0.0457, 0.1262, 0.0633, 0.0722, 0.0550, 0.0983, 0.0643, 0.0662, 0.0528,\n",
       "                       0.0605, 0.0430, 0.2098, 0.0888, 0.0666, 0.0814, 0.0979, 0.0729, 0.0994,\n",
       "                       0.0929, 0.0487, 0.1714, 0.0645, 0.0562, 0.0872, 0.0544, 0.0452, 0.1141,\n",
       "                       0.0515, 0.0882, 0.0472, 0.1134, 0.0585, 0.0779, 0.0524, 0.0577, 0.0733,\n",
       "                       0.0877, 0.0784, 0.1341, 0.0987, 0.0657, 0.0976, 0.0819, 0.0233, 0.0855,\n",
       "                       0.0671, 0.0370, 0.0852, 0.0398, 0.0675, 0.1391, 0.0331, 0.1022, 0.0384,\n",
       "                       0.0363, 0.1006], device='cuda:0')),\n",
       "              ('layer2.1.bn2.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer3.0.conv1.weight',\n",
       "               tensor([[[[-4.0157e-02, -2.1133e-02,  2.7097e-02],\n",
       "                         [-1.8857e-02, -5.5085e-02, -2.4093e-02],\n",
       "                         [-3.0013e-02, -4.1570e-02, -2.4727e-02]],\n",
       "               \n",
       "                        [[-2.2537e-02, -2.0962e-02, -8.1721e-03],\n",
       "                         [-3.0717e-02, -1.0728e-02, -2.9057e-02],\n",
       "                         [-4.6545e-03, -1.8149e-02, -3.6309e-02]],\n",
       "               \n",
       "                        [[ 3.5351e-03,  5.8768e-03, -1.5021e-03],\n",
       "                         [-1.0889e-02,  2.5171e-03,  2.6682e-02],\n",
       "                         [-2.4054e-02,  1.6990e-02,  2.0393e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-9.9902e-03, -1.8439e-02,  2.5808e-02],\n",
       "                         [-3.5564e-02, -1.4273e-02, -1.3086e-02],\n",
       "                         [ 1.1827e-02, -1.3742e-02, -2.7089e-02]],\n",
       "               \n",
       "                        [[-2.0605e-02, -1.8837e-02, -9.0920e-03],\n",
       "                         [-3.2180e-02, -9.2808e-03, -2.6269e-03],\n",
       "                         [-1.5567e-02, -8.7101e-03, -1.2520e-02]],\n",
       "               \n",
       "                        [[-1.4697e-02, -3.9426e-02,  2.6637e-02],\n",
       "                         [-2.8926e-02, -1.4119e-02,  1.4749e-02],\n",
       "                         [ 2.8718e-02,  1.9057e-02, -2.3316e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.1456e-02, -4.2017e-02,  1.4941e-04],\n",
       "                         [-1.0205e-02, -3.7377e-02, -4.4928e-02],\n",
       "                         [ 3.4497e-02, -2.1085e-02, -4.0683e-02]],\n",
       "               \n",
       "                        [[-2.7869e-02, -1.3786e-02, -2.7282e-02],\n",
       "                         [-1.1302e-02, -1.0020e-02, -6.3718e-03],\n",
       "                         [ 1.8893e-02,  6.9619e-05,  9.2051e-03]],\n",
       "               \n",
       "                        [[ 2.6314e-02,  4.4484e-02,  4.5633e-02],\n",
       "                         [-3.7226e-03,  5.6414e-02,  5.7166e-02],\n",
       "                         [ 8.3446e-03,  3.8097e-02,  3.7984e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.3579e-03, -2.0263e-02,  6.8843e-03],\n",
       "                         [-5.2755e-03,  2.9977e-04, -2.8025e-02],\n",
       "                         [ 1.1095e-02, -1.4307e-02,  1.1631e-02]],\n",
       "               \n",
       "                        [[ 9.1933e-04,  8.2346e-03,  1.9109e-03],\n",
       "                         [-3.1804e-02, -2.6294e-02, -2.7306e-02],\n",
       "                         [-2.8777e-02, -4.0971e-02, -3.9295e-02]],\n",
       "               \n",
       "                        [[ 2.0803e-02,  7.6093e-03, -2.4245e-02],\n",
       "                         [ 7.7681e-03, -1.8556e-02, -3.5435e-02],\n",
       "                         [ 2.9261e-02,  1.3985e-02,  1.8885e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.0023e-04,  9.8625e-03,  5.4793e-02],\n",
       "                         [ 4.3885e-02,  2.1595e-02,  2.8554e-02],\n",
       "                         [ 3.3648e-02,  1.9625e-02,  1.2737e-02]],\n",
       "               \n",
       "                        [[-4.3673e-03, -8.6556e-03,  1.8212e-02],\n",
       "                         [ 7.0539e-03, -1.6487e-03,  1.1398e-02],\n",
       "                         [ 1.1920e-02, -2.1941e-03, -3.8530e-04]],\n",
       "               \n",
       "                        [[ 1.0656e-02, -4.3782e-03, -3.0865e-02],\n",
       "                         [ 2.0427e-02,  2.0198e-02, -3.0472e-02],\n",
       "                         [ 2.6739e-02,  6.6643e-02,  2.0294e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.9283e-02, -1.8165e-02, -3.1948e-02],\n",
       "                         [-1.6229e-02, -2.2246e-02, -3.3563e-02],\n",
       "                         [-2.3440e-02, -3.3414e-02, -2.1211e-02]],\n",
       "               \n",
       "                        [[ 3.1252e-03, -2.0264e-02,  9.9224e-03],\n",
       "                         [ 1.7299e-03, -2.5247e-03, -9.5703e-03],\n",
       "                         [ 1.6709e-02,  3.9792e-02,  3.2716e-02]],\n",
       "               \n",
       "                        [[ 9.2616e-03, -1.3666e-02, -2.7696e-02],\n",
       "                         [-4.8416e-03, -1.7262e-03, -3.7862e-02],\n",
       "                         [-1.2791e-02, -2.7187e-02, -3.4573e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-4.7660e-02,  2.5269e-02,  1.0792e-01],\n",
       "                         [-6.3434e-02,  3.9878e-02,  1.0419e-01],\n",
       "                         [-2.5715e-02,  1.1418e-02,  7.4494e-02]],\n",
       "               \n",
       "                        [[-6.8938e-02, -2.9075e-02, -1.9574e-02],\n",
       "                         [-4.6318e-02, -2.6186e-02, -1.6837e-02],\n",
       "                         [-5.3173e-02, -4.7132e-02, -6.1956e-02]],\n",
       "               \n",
       "                        [[ 8.6545e-02,  4.8905e-02,  4.2711e-02],\n",
       "                         [ 5.2042e-02,  5.4166e-02,  3.1445e-02],\n",
       "                         [ 5.5419e-02,  6.8470e-02,  2.5133e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.4497e-02, -6.5736e-02, -2.3473e-02],\n",
       "                         [-1.9700e-02, -1.4108e-02, -1.5108e-02],\n",
       "                         [-7.2974e-03, -2.1161e-02, -1.1032e-02]],\n",
       "               \n",
       "                        [[-1.5523e-02, -5.0127e-02,  3.2647e-03],\n",
       "                         [-3.0986e-02, -5.5600e-02, -1.5488e-02],\n",
       "                         [-1.3808e-02, -5.0081e-02, -1.0664e-02]],\n",
       "               \n",
       "                        [[ 1.3787e-02,  2.2390e-02, -2.5104e-02],\n",
       "                         [ 2.7411e-02,  1.9423e-02,  1.9877e-02],\n",
       "                         [ 1.3730e-02,  1.6741e-02, -4.6220e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1136e-02, -2.9942e-02, -5.8646e-02],\n",
       "                         [ 2.0618e-02, -3.0530e-02, -3.9851e-02],\n",
       "                         [-4.2046e-02, -8.4750e-02, -1.0079e-01]],\n",
       "               \n",
       "                        [[ 2.9561e-02,  1.5157e-02,  2.4980e-02],\n",
       "                         [-1.1318e-02,  3.5041e-03,  1.5185e-02],\n",
       "                         [-4.2322e-02, -3.8520e-02, -4.9473e-02]],\n",
       "               \n",
       "                        [[ 8.4203e-03, -3.3449e-02, -3.1278e-02],\n",
       "                         [-3.6061e-03,  1.0084e-02,  3.8452e-03],\n",
       "                         [-6.2461e-03,  1.2642e-02,  5.7938e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.4799e-02,  1.6686e-02,  3.8666e-02],\n",
       "                         [ 2.2401e-02,  4.2409e-02, -9.2800e-04],\n",
       "                         [ 1.7480e-02,  1.5902e-02, -4.0123e-03]],\n",
       "               \n",
       "                        [[-1.4677e-02, -4.4562e-02, -3.4052e-02],\n",
       "                         [-3.0334e-02, -4.5829e-02, -1.1237e-03],\n",
       "                         [ 3.1089e-02, -6.2811e-03,  3.7153e-02]],\n",
       "               \n",
       "                        [[-5.7104e-02, -6.2172e-02, -3.6366e-02],\n",
       "                         [ 1.3238e-03, -1.6142e-02, -6.2270e-03],\n",
       "                         [ 1.9096e-02,  8.3979e-03, -2.1820e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.3275e-02, -4.1019e-02, -9.9588e-03],\n",
       "                         [-7.7470e-02, -7.4066e-02, -1.3854e-02],\n",
       "                         [-5.2086e-02, -2.9166e-02, -3.7033e-02]],\n",
       "               \n",
       "                        [[ 2.6138e-02,  3.6094e-02,  2.6299e-02],\n",
       "                         [ 1.5020e-02,  1.7449e-02, -2.1175e-02],\n",
       "                         [-4.5737e-03,  1.0459e-02, -3.1692e-02]],\n",
       "               \n",
       "                        [[-1.7686e-02, -1.5885e-03, -2.2488e-02],\n",
       "                         [-7.8887e-03, -1.1920e-03, -2.3798e-02],\n",
       "                         [ 1.6037e-02,  5.3814e-03,  1.4139e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.9459e-02, -2.9403e-02, -7.5244e-03],\n",
       "                         [-1.6882e-02, -3.3219e-02,  2.0620e-02],\n",
       "                         [ 8.8203e-03,  2.2635e-02,  6.1749e-03]],\n",
       "               \n",
       "                        [[-1.0825e-02,  9.1161e-03, -7.7669e-03],\n",
       "                         [-1.1411e-02, -1.3657e-02, -8.2997e-03],\n",
       "                         [ 2.0540e-04,  1.0339e-02,  1.5263e-02]],\n",
       "               \n",
       "                        [[ 2.3070e-02,  4.2367e-02, -5.9946e-03],\n",
       "                         [ 1.0831e-02,  1.5215e-02,  1.0870e-02],\n",
       "                         [ 4.3589e-03, -2.3800e-03, -1.7466e-02]]]], device='cuda:0')),\n",
       "              ('layer3.0.bn1.weight',\n",
       "               tensor([0.2702, 0.3293, 0.3376, 0.2430, 0.3079, 0.2598, 0.3509, 0.2535, 0.3730,\n",
       "                       0.3917, 0.4247, 0.2972, 0.3354, 0.2944, 0.4513, 0.3159, 0.3923, 0.2473,\n",
       "                       0.2614, 0.3171, 0.1995, 0.2814, 0.3807, 0.3626, 0.2362, 0.1881, 0.3788,\n",
       "                       0.3296, 0.3049, 0.2642, 0.3320, 0.3037, 0.3533, 0.3644, 0.2870, 0.4534,\n",
       "                       0.4478, 0.3795, 0.4301, 0.4578, 0.1933, 0.3462, 0.3199, 0.3610, 0.2335,\n",
       "                       0.3343, 0.3050, 0.2843, 0.3439, 0.3615, 0.4520, 0.3800, 0.3710, 0.4396,\n",
       "                       0.3951, 0.3271, 0.3351, 0.3817, 0.2794, 0.3829, 0.3167, 0.3435, 0.3842,\n",
       "                       0.4164, 0.3217, 0.4019, 0.3207, 0.2900, 0.2744, 0.2987, 0.2445, 0.3604,\n",
       "                       0.3325, 0.3710, 0.3295, 0.3558, 0.3156, 0.3200, 0.3470, 0.4330, 0.3186,\n",
       "                       0.3330, 0.3386, 0.3364, 0.3877, 0.2779, 0.3504, 0.4309, 0.3644, 0.3606,\n",
       "                       0.3533, 0.5027, 0.3283, 0.3470, 0.3053, 0.2322, 0.2957, 0.3878, 0.3637,\n",
       "                       0.3716, 0.3332, 0.4085, 0.4161, 0.3372, 0.2955, 0.3874, 0.3718, 0.3163,\n",
       "                       0.3883, 0.3727, 0.4317, 0.3334, 0.3601, 0.3110, 0.4384, 0.2770, 0.4378,\n",
       "                       0.3984, 0.3588, 0.4216, 0.2890, 0.3356, 0.2341, 0.2103, 0.3681, 0.2918,\n",
       "                       0.3228, 0.3473, 0.3403, 0.3889, 0.5112, 0.2685, 0.3682, 0.3514, 0.2736,\n",
       "                       0.3290, 0.4050, 0.3548, 0.3495, 0.3437, 0.3888, 0.4489, 0.3782, 0.2979,\n",
       "                       0.3252, 0.2397, 0.3101, 0.2966, 0.2889, 0.3313, 0.2870, 0.2296, 0.3191,\n",
       "                       0.4305, 0.4213, 0.3223, 0.2277, 0.4769, 0.3017, 0.4108, 0.3852, 0.3039,\n",
       "                       0.3462, 0.3084, 0.4086, 0.3407, 0.4469, 0.2068, 0.3275, 0.3649, 0.3510,\n",
       "                       0.2347, 0.2566, 0.2808, 0.2614, 0.3584, 0.3421, 0.3953, 0.3531, 0.4047,\n",
       "                       0.1394, 0.3252, 0.3439, 0.4509, 0.3009, 0.4311, 0.5153, 0.2264, 0.3121,\n",
       "                       0.2703, 0.3177, 0.3196, 0.4065, 0.3743, 0.3296, 0.3880, 0.3462, 0.3167,\n",
       "                       0.2189, 0.4108, 0.3370, 0.4633, 0.4066, 0.3353, 0.2462, 0.3103, 0.3868,\n",
       "                       0.4091, 0.3185, 0.3775, 0.3341, 0.3432, 0.2594, 0.3217, 0.3485, 0.3050,\n",
       "                       0.2472, 0.2993, 0.4034, 0.2583, 0.2113, 0.3437, 0.3816, 0.4800, 0.4130,\n",
       "                       0.2844, 0.3091, 0.3977, 0.5067, 0.3904, 0.4094, 0.2848, 0.3540, 0.3305,\n",
       "                       0.3025, 0.3188, 0.2500, 0.2686, 0.3660, 0.3394, 0.2956, 0.3769, 0.4271,\n",
       "                       0.2913, 0.3839, 0.3964, 0.3301, 0.3425, 0.3201, 0.2658, 0.3733, 0.3768,\n",
       "                       0.1724, 0.3425, 0.2702, 0.2963], device='cuda:0')),\n",
       "              ('layer3.0.bn1.bias',\n",
       "               tensor([-0.2227, -0.1935, -0.1690, -0.1268, -0.1127, -0.1553, -0.3054, -0.1636,\n",
       "                       -0.1784, -0.2407, -0.3139, -0.2123, -0.2158, -0.2278, -0.2913, -0.2354,\n",
       "                       -0.1997, -0.1196, -0.1593, -0.1880, -0.1864, -0.1237, -0.2168, -0.2154,\n",
       "                       -0.2777, -0.1290, -0.2501, -0.2669, -0.1927, -0.0531, -0.2430, -0.1321,\n",
       "                       -0.2222, -0.1435, -0.1504, -0.2116, -0.4027, -0.2071, -0.1459, -0.1138,\n",
       "                       -0.1437, -0.2363, -0.0886, -0.2315, -0.1132, -0.3308, -0.0582, -0.1045,\n",
       "                       -0.1518, -0.1110, -0.1155, -0.2187, -0.2529, -0.2788, -0.2161, -0.2044,\n",
       "                       -0.2426, -0.1294, -0.2357, -0.1484, -0.1402, -0.0651, -0.1427, -0.2400,\n",
       "                       -0.1918, -0.2488, -0.2091, -0.2472, -0.2859, -0.1260, -0.2585, -0.1556,\n",
       "                       -0.2637, -0.1681, -0.1377, -0.1919, -0.1393, -0.1801, -0.2214, -0.3083,\n",
       "                       -0.1567, -0.1802, -0.1867, -0.1210, -0.2620, -0.1611, -0.1838, -0.2094,\n",
       "                       -0.2584, -0.1452, -0.1171, -0.2184, -0.2019, -0.2224, -0.1526, -0.1449,\n",
       "                       -0.2552, -0.1323, -0.2522, -0.2700, -0.1368, -0.2718, -0.0793, -0.1737,\n",
       "                       -0.1621, -0.0481, -0.2874, -0.0475, -0.2504, -0.1291, -0.2784, -0.2210,\n",
       "                       -0.2144, -0.2089, -0.2941, -0.1604, -0.3449, -0.1181, -0.1714, -0.2038,\n",
       "                       -0.1363, -0.2191, -0.1569, -0.1608, -0.1905, -0.1874, -0.1252, -0.2138,\n",
       "                       -0.0503, -0.1938, -0.3041, -0.1668, -0.1347,  0.0349, -0.1546, -0.2724,\n",
       "                       -0.1756, -0.1365, -0.3243, -0.2443, -0.2611, -0.2409, -0.1675, -0.1689,\n",
       "                       -0.0694, -0.1206, -0.2860, -0.0681, -0.1584, -0.2244, -0.1989, -0.2628,\n",
       "                       -0.3201, -0.1385, -0.2001, -0.2942, -0.0883, -0.3933, -0.0997, -0.1640,\n",
       "                       -0.2457, -0.3157, -0.1831, -0.1158, -0.2186, -0.3744, -0.3318, -0.2072,\n",
       "                       -0.2018, -0.1747, -0.2843, -0.1362, -0.1157, -0.1851, -0.0029, -0.1944,\n",
       "                       -0.2777, -0.3138, -0.0899, -0.1330, -0.0601, -0.1332, -0.2461, -0.1882,\n",
       "                       -0.1094, -0.2117, -0.2466, -0.2145, -0.1083, -0.1425, -0.2426, -0.2109,\n",
       "                       -0.2354, -0.1764, -0.0664, -0.1987, -0.1367, -0.1715, -0.1635, -0.2644,\n",
       "                       -0.2281, -0.2437, -0.2468, -0.2353, -0.1308, -0.2427, -0.2880, -0.1867,\n",
       "                       -0.2931, -0.1934, -0.2218, -0.1702, -0.0559, -0.0973, -0.0954, -0.2270,\n",
       "                       -0.2689, -0.1829, -0.1943, -0.2021, -0.1516, -0.2129, -0.3222, -0.1989,\n",
       "                       -0.2180, -0.0916, -0.1955, -0.1885, -0.1854, -0.1681, -0.0831, -0.2358,\n",
       "                       -0.1550, -0.1336, -0.1499, -0.1365, -0.2721, -0.1617, -0.1900, -0.1446,\n",
       "                       -0.2447, -0.1407, -0.0570, -0.1518, -0.2735, -0.2760, -0.1381, -0.2097,\n",
       "                       -0.2310, -0.1433, -0.1204, -0.0898, -0.1251, -0.2746, -0.3091, -0.0315],\n",
       "                      device='cuda:0')),\n",
       "              ('layer3.0.bn1.running_mean',\n",
       "               tensor([ 0.0776, -0.6656, -0.9000, -0.4472, -0.8976, -0.3352, -0.9638, -0.6092,\n",
       "                       -1.4183, -1.3243, -2.0433, -0.7794, -0.8277, -0.5292, -0.0673, -0.1410,\n",
       "                       -0.2063, -0.6576, -0.6752, -0.8356,  0.0597, -0.8259, -0.7351, -0.3946,\n",
       "                       -0.2799, -0.5367, -1.0603, -0.8176, -0.6972, -0.9420, -0.9143,  0.3084,\n",
       "                       -0.9612, -1.1290, -0.3703, -0.1400,  0.0158, -0.4062, -0.7653,  0.0325,\n",
       "                       -0.0327, -0.6899, -0.5438, -0.6913, -0.9920, -0.1565,  0.0504, -0.6109,\n",
       "                       -0.4669,  0.0791, -0.7576, -0.7952, -0.1911, -1.0732, -1.2105, -0.4369,\n",
       "                        0.3047, -1.0734, -0.4594, -1.3911, -0.7781, -0.5925, -1.2290, -0.6730,\n",
       "                       -0.1846,  0.8619, -0.3351, -0.2577, -0.4002,  0.1069,  0.7765, -1.7540,\n",
       "                       -0.4806, -0.8710, -0.9528, -0.3767, -0.3918, -1.3549, -0.7639,  0.7073,\n",
       "                        0.1541,  0.8561, -0.7862, -0.1896, -0.2680, -0.4568, -0.9887, -1.0788,\n",
       "                       -1.2063, -1.1355, -0.7915, -1.0912, -0.4783, -0.5614, -0.6054, -0.2503,\n",
       "                        0.2231, -1.0220, -0.6716, -0.6654, -0.2837,  0.3952, -0.9768, -0.6886,\n",
       "                       -0.6245, -0.4060, -0.4735, -0.2556, -1.0916, -0.7934,  0.1781, -0.0982,\n",
       "                       -0.5551, -1.3634, -0.6933, -0.2982, -0.6905, -1.2111, -1.5645, -1.0286,\n",
       "                       -0.4822, -0.7595, -0.2288, -0.2096, -0.9635, -0.3756, -0.9112, -0.3979,\n",
       "                       -1.1136, -0.4883, -2.1243,  0.3191, -0.4002, -1.3494,  0.0644, -1.1442,\n",
       "                       -0.2578, -0.5497,  0.3026, -0.1942, -0.1743, -0.8661, -0.3670, -1.0267,\n",
       "                       -0.8113, -0.5345,  0.3901, -0.9941, -0.1476, -1.1274, -0.3231, -0.1746,\n",
       "                       -0.8419, -0.6998, -0.4374, -0.0115, -1.1926,  0.6591, -0.7084,  0.0510,\n",
       "                       -0.5493, -0.3735,  0.2681, -0.1297, -0.5267, -0.4257, -0.3652, -1.1999,\n",
       "                       -0.6776, -0.4843, -0.8894, -0.3918, -0.6042, -1.3893, -0.8173, -0.9584,\n",
       "                       -0.9142, -0.6160, -0.6439, -1.0584, -0.4655, -1.1319, -0.9203, -0.3353,\n",
       "                       -0.6861, -0.7523, -0.4178,  0.1727,  0.0481, -0.5388, -0.7040, -0.0302,\n",
       "                       -0.7291, -1.7007, -0.8424, -1.0243, -0.6805, -0.6202, -0.7213, -0.3030,\n",
       "                       -0.8676, -0.7176, -0.9159, -1.3472, -1.0746, -0.8601, -0.6987, -0.6720,\n",
       "                        0.6398, -0.9133, -0.7147, -0.6453, -0.9466, -0.2756, -0.8485, -0.0771,\n",
       "                       -0.5967, -0.8395,  0.0129, -0.6144, -0.5167, -0.4438, -0.4260, -0.7823,\n",
       "                       -0.6666,  0.2604, -0.2942, -0.3739, -0.5197, -0.3836, -0.3816, -0.0837,\n",
       "                       -1.0778, -0.5055, -0.8053, -0.1433, -0.4134, -0.3403, -0.1678, -1.0138,\n",
       "                       -0.4739,  0.0334, -1.1679, -0.3400, -0.1018, -0.0382, -0.6854, -0.3705,\n",
       "                       -1.0024, -1.0974, -1.2062, -0.8895,  0.1036, -0.7401, -0.3812, -0.8941],\n",
       "                      device='cuda:0')),\n",
       "              ('layer3.0.bn1.running_var',\n",
       "               tensor([0.5336, 0.4767, 0.5745, 0.2952, 0.7951, 0.5336, 1.2374, 0.3536, 0.9920,\n",
       "                       0.9589, 1.0303, 0.4609, 0.7680, 0.6265, 1.2213, 0.5467, 1.0158, 0.3226,\n",
       "                       0.6863, 0.5259, 0.3412, 0.7807, 0.9274, 0.8854, 0.7603, 0.4728, 1.1786,\n",
       "                       0.7340, 0.7699, 0.9691, 1.0387, 0.6590, 0.8253, 0.7914, 0.5762, 0.9855,\n",
       "                       0.9375, 0.8844, 0.8886, 0.9823, 0.2652, 1.0536, 0.5302, 0.5804, 0.5983,\n",
       "                       0.7703, 0.6403, 0.7367, 1.0315, 1.1393, 1.0205, 0.9420, 0.7120, 1.1067,\n",
       "                       0.8306, 0.5485, 0.5779, 0.7682, 0.9862, 1.1882, 0.6121, 0.8160, 1.5694,\n",
       "                       0.7908, 0.6658, 1.3452, 0.6842, 0.6835, 0.7117, 0.6427, 0.4483, 0.9201,\n",
       "                       0.7224, 0.8243, 0.5968, 0.8026, 0.9234, 0.6775, 0.7290, 1.1371, 0.5987,\n",
       "                       0.6409, 0.9189, 0.7629, 1.1939, 0.5015, 0.6505, 1.0473, 0.7314, 0.8618,\n",
       "                       0.7345, 1.2769, 1.1010, 0.7658, 0.7578, 0.4996, 0.4591, 0.7689, 0.7797,\n",
       "                       0.8422, 0.4378, 0.7650, 0.8863, 0.6788, 0.6893, 0.9304, 0.6806, 0.8043,\n",
       "                       0.7252, 1.0290, 1.4324, 0.6064, 0.5280, 0.7219, 0.9128, 0.4530, 1.1680,\n",
       "                       0.9317, 1.1049, 0.9648, 0.5430, 0.7420, 0.1633, 0.2669, 0.8046, 0.6263,\n",
       "                       0.8930, 0.7529, 1.4364, 0.8653, 1.4752, 0.3873, 0.7207, 1.2943, 0.4972,\n",
       "                       0.8155, 0.9119, 0.7108, 0.6511, 0.8685, 0.6455, 1.6461, 0.8643, 0.7896,\n",
       "                       0.3937, 0.6218, 0.5569, 0.7691, 0.8892, 0.6495, 0.7238, 0.4062, 1.0287,\n",
       "                       0.9653, 1.0060, 0.8248, 0.4796, 1.1832, 0.5867, 1.0957, 0.6803, 0.8095,\n",
       "                       0.4692, 1.3142, 1.0614, 0.8440, 0.8463, 0.6127, 0.6686, 1.1684, 0.7844,\n",
       "                       0.2608, 0.5199, 0.8354, 0.7856, 0.6803, 0.6632, 0.9769, 0.8055, 0.9122,\n",
       "                       0.2985, 0.8471, 0.6252, 1.0474, 0.7401, 0.9145, 1.2751, 0.3253, 0.5384,\n",
       "                       0.5619, 0.9765, 0.6145, 1.1217, 1.0707, 0.5876, 1.2095, 0.6694, 0.7899,\n",
       "                       0.7432, 1.1507, 0.5392, 1.0197, 1.2213, 0.7168, 0.7308, 0.7608, 1.0696,\n",
       "                       0.6493, 0.6524, 0.8140, 0.5928, 0.5945, 0.8102, 1.0881, 0.8388, 0.7146,\n",
       "                       0.4660, 0.7830, 1.2111, 0.8885, 0.3563, 0.5725, 0.8803, 1.2987, 0.8913,\n",
       "                       0.4400, 0.9149, 0.9746, 0.9505, 0.6554, 1.0196, 0.4545, 0.9530, 0.8315,\n",
       "                       0.8923, 0.7078, 0.5441, 0.6820, 0.6543, 1.2994, 0.7152, 0.6172, 0.8139,\n",
       "                       0.7023, 0.8730, 0.7009, 0.4990, 0.5414, 1.0045, 0.8892, 0.8078, 0.9332,\n",
       "                       0.2594, 1.3168, 0.9660, 0.4642], device='cuda:0')),\n",
       "              ('layer3.0.bn1.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer3.0.conv2.weight',\n",
       "               tensor([[[[-2.1234e-03, -5.8185e-03,  4.1593e-03],\n",
       "                         [ 1.0715e-02, -4.3158e-03,  1.2585e-02],\n",
       "                         [ 9.1274e-03, -1.2382e-02, -1.3661e-03]],\n",
       "               \n",
       "                        [[ 1.5485e-04, -1.0325e-02, -4.4392e-02],\n",
       "                         [-1.8295e-02, -2.1681e-02,  1.5667e-03],\n",
       "                         [-4.0033e-02, -3.1465e-02, -1.4127e-02]],\n",
       "               \n",
       "                        [[ 4.8492e-02,  6.0407e-02, -1.0262e-02],\n",
       "                         [-1.9271e-02, -1.1507e-04, -2.5121e-02],\n",
       "                         [-2.8035e-02, -1.3412e-02, -1.1730e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.2514e-03, -8.9832e-03, -2.7626e-02],\n",
       "                         [-3.8094e-02, -2.6218e-02, -5.2825e-03],\n",
       "                         [ 7.7480e-03, -3.0604e-02,  3.6634e-02]],\n",
       "               \n",
       "                        [[ 1.6415e-02,  2.8504e-02, -2.6871e-02],\n",
       "                         [ 3.4913e-02,  7.6067e-03,  1.8116e-02],\n",
       "                         [-2.6289e-02, -5.5059e-02,  7.8492e-03]],\n",
       "               \n",
       "                        [[-3.0425e-02, -3.1166e-02, -3.1815e-02],\n",
       "                         [-9.7396e-03, -8.9143e-03, -1.0261e-02],\n",
       "                         [-1.5993e-02, -2.1114e-02,  2.7527e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.2748e-02, -2.9163e-02, -3.3887e-02],\n",
       "                         [-8.1924e-03, -3.4105e-02, -3.6179e-02],\n",
       "                         [-1.2856e-02, -1.5141e-02, -1.9835e-02]],\n",
       "               \n",
       "                        [[-1.1055e-02,  2.8408e-03,  1.0720e-02],\n",
       "                         [-3.8391e-02, -2.0529e-02, -2.8698e-02],\n",
       "                         [ 2.2894e-03, -1.0500e-02, -1.7281e-02]],\n",
       "               \n",
       "                        [[-9.8554e-03,  2.3311e-02,  2.5342e-02],\n",
       "                         [-3.3005e-02, -1.9911e-02,  1.9839e-02],\n",
       "                         [-7.3790e-03, -1.5294e-02,  1.7903e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.7331e-02, -4.9632e-03, -3.4373e-02],\n",
       "                         [ 2.7958e-02, -7.8549e-03, -3.4212e-02],\n",
       "                         [-6.1888e-02, -3.8285e-02,  6.0147e-04]],\n",
       "               \n",
       "                        [[-4.6108e-03,  5.5535e-02,  5.2035e-03],\n",
       "                         [-2.5976e-02,  1.4181e-02, -2.9903e-02],\n",
       "                         [-2.9203e-02,  2.2907e-02,  1.8232e-02]],\n",
       "               \n",
       "                        [[-1.1954e-02, -8.2414e-03, -5.5900e-03],\n",
       "                         [-7.3038e-03,  1.3422e-02, -3.4766e-02],\n",
       "                         [ 2.6858e-02,  6.7455e-02,  1.3046e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.5584e-04,  2.0118e-03, -2.2828e-03],\n",
       "                         [ 1.7184e-02,  7.7972e-03, -1.0493e-02],\n",
       "                         [ 1.6686e-02,  2.4142e-02, -2.1196e-02]],\n",
       "               \n",
       "                        [[ 2.2009e-02,  5.1214e-03, -1.3214e-02],\n",
       "                         [ 4.8747e-02,  3.9920e-02,  7.1755e-03],\n",
       "                         [ 1.4092e-02,  2.7460e-02,  2.8728e-03]],\n",
       "               \n",
       "                        [[ 3.7127e-02,  3.7896e-02,  3.2777e-02],\n",
       "                         [ 2.4879e-02,  8.6994e-03,  1.5124e-02],\n",
       "                         [ 1.8780e-02,  3.7803e-03, -5.8261e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.4219e-03,  4.3927e-02, -1.8380e-02],\n",
       "                         [-1.3497e-02,  1.7778e-02, -1.4030e-02],\n",
       "                         [-2.1762e-02,  8.7466e-03, -2.9568e-02]],\n",
       "               \n",
       "                        [[ 5.1470e-02, -1.7731e-03, -3.4969e-03],\n",
       "                         [ 6.2641e-03, -3.1000e-02, -4.9512e-02],\n",
       "                         [ 2.1647e-02,  5.3098e-03, -1.8809e-02]],\n",
       "               \n",
       "                        [[ 1.5934e-02, -7.6184e-03, -9.2262e-03],\n",
       "                         [-1.9182e-02, -1.3027e-02, -3.3894e-02],\n",
       "                         [-1.6292e-02, -2.1739e-02, -2.6508e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-5.1283e-03, -4.9413e-03, -2.4909e-03],\n",
       "                         [ 4.8539e-02,  1.8618e-02,  1.3473e-02],\n",
       "                         [ 2.7100e-02,  2.5746e-02,  3.1167e-03]],\n",
       "               \n",
       "                        [[-1.6865e-02,  1.5147e-02,  5.1374e-02],\n",
       "                         [-4.9459e-03,  8.1079e-03,  3.0291e-02],\n",
       "                         [ 1.9015e-02, -2.0355e-02, -2.6508e-02]],\n",
       "               \n",
       "                        [[ 1.0489e-02,  1.9014e-02, -1.6858e-02],\n",
       "                         [-4.9385e-03, -6.7988e-03,  3.0209e-03],\n",
       "                         [-1.4269e-02,  2.0216e-03,  2.1994e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.7808e-03, -1.6284e-02, -4.3502e-02],\n",
       "                         [-3.4550e-02,  5.1321e-03, -1.3611e-02],\n",
       "                         [-2.0017e-02, -1.8317e-02, -5.0312e-03]],\n",
       "               \n",
       "                        [[-5.4625e-02, -4.0992e-03, -4.6120e-04],\n",
       "                         [-6.5751e-02, -1.0864e-02, -3.1570e-02],\n",
       "                         [ 5.2218e-02,  7.7976e-03, -2.8945e-02]],\n",
       "               \n",
       "                        [[-4.2506e-03, -1.5562e-02, -1.2112e-02],\n",
       "                         [-6.2654e-03, -3.3839e-02, -2.5010e-02],\n",
       "                         [-1.1724e-02, -6.3808e-02, -3.3202e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.0125e-02, -1.3792e-02, -1.4571e-02],\n",
       "                         [-2.6343e-02,  3.6802e-02,  3.9374e-02],\n",
       "                         [-2.2605e-02,  4.6585e-02,  6.5312e-02]],\n",
       "               \n",
       "                        [[ 3.8056e-02,  5.9197e-02,  2.0801e-02],\n",
       "                         [-1.6746e-02, -3.7117e-03, -1.3740e-02],\n",
       "                         [ 1.7907e-02,  4.9200e-02,  5.8388e-02]],\n",
       "               \n",
       "                        [[-5.7520e-05,  5.1266e-02,  1.4912e-02],\n",
       "                         [-3.0803e-02, -1.5785e-02, -2.9737e-02],\n",
       "                         [ 5.7099e-05, -9.9671e-03, -3.7336e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.7529e-02,  2.2743e-02,  4.5359e-04],\n",
       "                         [ 5.1083e-02,  4.0248e-02,  3.6406e-02],\n",
       "                         [ 4.9139e-02, -1.8767e-03,  4.3260e-03]],\n",
       "               \n",
       "                        [[-8.5558e-03,  4.0740e-03,  8.6189e-03],\n",
       "                         [ 2.5784e-03,  5.1888e-02, -1.5169e-02],\n",
       "                         [-3.3271e-02, -2.3954e-02, -7.1472e-03]],\n",
       "               \n",
       "                        [[ 1.9301e-02,  2.4052e-02,  8.6335e-03],\n",
       "                         [ 4.7158e-02,  1.1429e-02,  1.3038e-02],\n",
       "                         [-2.9443e-02, -1.0594e-02,  1.8421e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-8.7499e-03, -2.6182e-02, -3.5962e-02],\n",
       "                         [ 5.4096e-04, -2.1335e-02, -4.2388e-02],\n",
       "                         [-3.0729e-03, -1.5743e-02, -1.7503e-02]],\n",
       "               \n",
       "                        [[-1.2412e-02,  1.1473e-02,  9.5854e-03],\n",
       "                         [ 5.1372e-02,  3.8786e-02,  1.3465e-02],\n",
       "                         [-8.1760e-03,  3.0555e-02, -9.7642e-03]],\n",
       "               \n",
       "                        [[-4.8235e-03,  1.3329e-02,  4.0579e-03],\n",
       "                         [-2.2952e-02, -4.0203e-02, -4.8567e-02],\n",
       "                         [ 2.6620e-02, -5.3430e-04, -5.9706e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 6.0000e-02,  2.9592e-02,  2.4535e-02],\n",
       "                         [ 7.4544e-02,  1.5012e-02,  3.9908e-03],\n",
       "                         [ 2.6508e-02,  2.1210e-02,  3.8372e-02]],\n",
       "               \n",
       "                        [[-1.8927e-02, -2.2875e-02, -1.1980e-02],\n",
       "                         [-2.2387e-02, -6.4758e-02, -2.2768e-02],\n",
       "                         [ 2.0987e-02, -7.9422e-03,  1.5227e-02]],\n",
       "               \n",
       "                        [[ 2.5260e-02,  5.6173e-02,  2.8466e-02],\n",
       "                         [ 1.3450e-02,  3.9547e-02,  1.7489e-02],\n",
       "                         [-1.5136e-02, -7.7090e-03, -4.0845e-02]]]], device='cuda:0')),\n",
       "              ('layer3.0.bn2.weight',\n",
       "               tensor([0.4764, 0.4454, 0.3101, 0.3486, 0.3328, 0.3517, 0.3614, 0.4217, 0.3595,\n",
       "                       0.3059, 0.5079, 0.3565, 0.5335, 0.3488, 0.3823, 0.4038, 0.4211, 0.3420,\n",
       "                       0.3415, 0.4445, 0.2708, 0.3765, 0.3141, 0.4937, 0.3106, 0.4313, 0.4990,\n",
       "                       0.3805, 0.3943, 0.5088, 0.4059, 0.4060, 0.3412, 0.4629, 0.3894, 0.3640,\n",
       "                       0.3236, 0.3189, 0.3975, 0.4794, 0.5080, 0.5468, 0.4134, 0.4623, 0.4291,\n",
       "                       0.3973, 0.4342, 0.4429, 0.4865, 0.4505, 0.4584, 0.3542, 0.4492, 0.3535,\n",
       "                       0.4342, 0.4096, 0.3893, 0.4842, 0.4560, 0.4810, 0.5126, 0.4271, 0.3684,\n",
       "                       0.3811, 0.3140, 0.3782, 0.2818, 0.3079, 0.4426, 0.3677, 0.3030, 0.3033,\n",
       "                       0.2903, 0.3425, 0.3287, 0.4194, 0.4460, 0.4128, 0.5173, 0.4337, 0.3295,\n",
       "                       0.4310, 0.4706, 0.4632, 0.3797, 0.2165, 0.4502, 0.4285, 0.3961, 0.3863,\n",
       "                       0.2589, 0.4579, 0.4721, 0.3709, 0.4893, 0.3731, 0.3573, 0.3368, 0.3464,\n",
       "                       0.4222, 0.5631, 0.4179, 0.3827, 0.3833, 0.3089, 0.5002, 0.3158, 0.4785,\n",
       "                       0.4716, 0.2183, 0.3652, 0.3799, 0.4068, 0.3618, 0.3454, 0.5358, 0.3760,\n",
       "                       0.3959, 0.3276, 0.2219, 0.3892, 0.4129, 0.2705, 0.3709, 0.4305, 0.3694,\n",
       "                       0.4639, 0.3617, 0.4134, 0.4460, 0.4085, 0.4548, 0.2815, 0.4220, 0.3140,\n",
       "                       0.5312, 0.3494, 0.3837, 0.3631, 0.3847, 0.3947, 0.3828, 0.5365, 0.2933,\n",
       "                       0.4300, 0.4194, 0.4320, 0.3484, 0.3080, 0.4405, 0.3406, 0.3613, 0.4933,\n",
       "                       0.4504, 0.4464, 0.3845, 0.4067, 0.4149, 0.4691, 0.4759, 0.5160, 0.4708,\n",
       "                       0.4460, 0.3577, 0.4572, 0.4319, 0.4417, 0.4354, 0.3626, 0.3846, 0.4525,\n",
       "                       0.4141, 0.4274, 0.3569, 0.4013, 0.4261, 0.3634, 0.3777, 0.3954, 0.3794,\n",
       "                       0.4595, 0.3882, 0.3870, 0.4051, 0.3919, 0.2103, 0.3503, 0.3615, 0.4447,\n",
       "                       0.4602, 0.4382, 0.3420, 0.4678, 0.2583, 0.5556, 0.4588, 0.3600, 0.3726,\n",
       "                       0.4184, 0.3303, 0.5077, 0.3871, 0.4547, 0.4163, 0.4024, 0.2261, 0.4949,\n",
       "                       0.4197, 0.4255, 0.3006, 0.3036, 0.4101, 0.3661, 0.3719, 0.3771, 0.3957,\n",
       "                       0.3796, 0.4826, 0.3985, 0.3551, 0.3546, 0.4967, 0.2973, 0.5573, 0.4091,\n",
       "                       0.4517, 0.3599, 0.4351, 0.4669, 0.4551, 0.3429, 0.4752, 0.4215, 0.3842,\n",
       "                       0.2987, 0.3541, 0.4853, 0.3712, 0.5000, 0.5086, 0.4203, 0.4649, 0.3217,\n",
       "                       0.3682, 0.4399, 0.2717, 0.4508, 0.3173, 0.4268, 0.3233, 0.4086, 0.3845,\n",
       "                       0.2864, 0.4942, 0.4517, 0.4505], device='cuda:0')),\n",
       "              ('layer3.0.bn2.bias',\n",
       "               tensor([-0.1446, -0.1329, -0.1624, -0.1563, -0.1624, -0.2004, -0.2749, -0.2458,\n",
       "                       -0.1302, -0.2300, -0.1955, -0.1134, -0.2556, -0.1284, -0.1665, -0.2255,\n",
       "                       -0.1313, -0.1023, -0.2120, -0.1979, -0.1131, -0.1157, -0.0814, -0.2023,\n",
       "                       -0.0904, -0.1736, -0.2565, -0.0998, -0.2470, -0.1202, -0.1588, -0.2243,\n",
       "                       -0.1873, -0.1645, -0.2208, -0.1334, -0.1094, -0.1524, -0.1409, -0.2547,\n",
       "                       -0.1835, -0.1829, -0.1210, -0.2170, -0.1513, -0.0362, -0.1483, -0.1988,\n",
       "                       -0.2080, -0.1344, -0.1569, -0.1322, -0.1765, -0.1633, -0.1462, -0.1836,\n",
       "                       -0.1406, -0.1437, -0.1723, -0.1815, -0.1561, -0.0529, -0.1574, -0.1899,\n",
       "                       -0.1207, -0.1642, -0.1740, -0.1478, -0.1409, -0.1920, -0.2103, -0.1268,\n",
       "                       -0.1233, -0.1430, -0.1823, -0.1911, -0.1795, -0.0913, -0.2252, -0.2364,\n",
       "                       -0.1358, -0.1041, -0.1448, -0.1538, -0.2529, -0.1168, -0.2596, -0.1484,\n",
       "                       -0.1100, -0.1732, -0.1263, -0.2455, -0.1765, -0.2452, -0.1579, -0.1546,\n",
       "                       -0.1313, -0.1404, -0.1248, -0.1743, -0.1717, -0.2293, -0.0858, -0.1584,\n",
       "                       -0.1564, -0.2282, -0.1206, -0.2853, -0.2942, -0.1165, -0.1982, -0.2683,\n",
       "                       -0.2587, -0.1475, -0.1697, -0.2546, -0.0739, -0.2317, -0.1571, -0.1466,\n",
       "                       -0.1601, -0.1303, -0.0334, -0.1127, -0.2452, -0.0611, -0.1320, -0.2273,\n",
       "                       -0.1152, -0.1314, -0.1618, -0.2376, -0.1437, -0.0632, -0.2072, -0.0762,\n",
       "                       -0.1648, -0.1640, -0.1716, -0.1408, -0.0489, -0.2186, -0.1476, -0.1636,\n",
       "                       -0.1129, -0.1904, -0.2086, -0.0733, -0.1007, -0.2525, -0.3038, -0.2026,\n",
       "                       -0.2562, -0.1346, -0.1767, -0.2226, -0.1485, -0.0608, -0.1760, -0.1844,\n",
       "                       -0.1908, -0.2014, -0.1149, -0.3402, -0.2474, -0.1609, -0.1622, -0.1101,\n",
       "                       -0.1367, -0.1303, -0.2089, -0.0693, -0.1869, -0.1676, -0.1711, -0.1849,\n",
       "                       -0.0247, -0.1445, -0.1966, -0.1108, -0.2178, -0.1009, -0.2214, -0.1308,\n",
       "                       -0.2087, -0.0975, -0.2202, -0.1325, -0.1359, -0.1649, -0.1395, -0.2303,\n",
       "                       -0.1133, -0.1243, -0.1769, -0.2816, -0.1039, -0.1930, -0.1571, -0.1789,\n",
       "                       -0.2248, -0.0888, -0.1603, -0.1167, -0.1677, -0.0864, -0.1617, -0.1040,\n",
       "                       -0.1904, -0.1116, -0.1279, -0.0746, -0.1111, -0.1325, -0.1292, -0.1644,\n",
       "                       -0.1717, -0.2217, -0.2196, -0.1823, -0.1540, -0.1916, -0.1764, -0.2709,\n",
       "                       -0.1957, -0.2154, -0.1336, -0.1430, -0.1763, -0.0840, -0.0930, -0.1579,\n",
       "                       -0.1458, -0.0965, -0.1684, -0.1359, -0.1531, -0.1375, -0.2091, -0.0958,\n",
       "                       -0.2215, -0.2715, -0.2541, -0.1942, -0.1960, -0.0659, -0.1664, -0.1133,\n",
       "                       -0.2244, -0.1400, -0.1559, -0.2044, -0.1599, -0.1419, -0.2456, -0.0696],\n",
       "                      device='cuda:0')),\n",
       "              ('layer3.0.bn2.running_mean',\n",
       "               tensor([-3.5336e-01, -3.1127e-02, -3.2885e-01, -5.6041e-02, -8.2883e-02,\n",
       "                       -4.1181e-01,  1.2375e-02,  3.2314e-02, -3.4232e-01, -2.1026e-01,\n",
       "                       -3.0777e-02, -7.3479e-03, -5.0298e-01, -5.1867e-01,  5.1411e-02,\n",
       "                       -4.1051e-01, -2.7454e-01, -6.4199e-01, -2.8212e-01, -6.3350e-01,\n",
       "                        2.4527e-02, -5.4513e-01, -2.4396e-01, -4.3314e-02, -4.8740e-01,\n",
       "                       -2.7897e-01, -8.7685e-02, -1.4365e-01, -3.1867e-01, -2.5492e-01,\n",
       "                       -6.0104e-01, -9.3279e-02, -1.9459e-01, -4.3582e-01, -3.3446e-01,\n",
       "                       -3.9391e-01, -1.3654e-02, -1.8564e-01, -2.5290e-01, -3.6763e-01,\n",
       "                       -3.6001e-02, -2.0931e-02, -3.5133e-01, -3.9218e-01, -8.4671e-02,\n",
       "                       -2.3177e-01, -5.9786e-01, -2.2346e-01, -3.0027e-01, -1.5835e-01,\n",
       "                       -3.3546e-01, -6.2878e-01, -3.9236e-01, -1.4354e-02, -3.1898e-01,\n",
       "                       -2.8916e-01, -1.0467e-01, -1.1905e-01, -3.0891e-01, -2.8619e-01,\n",
       "                       -3.9868e-01, -3.0269e-01, -2.2381e-01, -3.9519e-01, -1.7536e-01,\n",
       "                       -2.8904e-01, -3.0438e-01, -1.6824e-01, -1.2333e-01, -1.8040e-01,\n",
       "                       -1.7459e-01, -1.9111e-01, -1.2995e-01, -1.6115e-01, -1.3489e-01,\n",
       "                       -4.5523e-01, -4.3214e-01, -5.1509e-01, -3.3482e-01, -1.8102e-01,\n",
       "                       -2.4956e-01, -4.1362e-01,  4.8565e-02, -2.6666e-01, -3.0430e-01,\n",
       "                       -3.3045e-01, -6.2574e-02, -9.9152e-02, -2.3013e-01,  1.0238e-01,\n",
       "                       -2.1199e-01, -2.6232e-01, -1.1155e-01, -3.4553e-01, -5.2252e-01,\n",
       "                       -4.0159e-01, -3.6930e-01, -2.0894e-01, -2.9834e-01, -2.7271e-01,\n",
       "                       -2.0346e-01, -7.8767e-01, -5.9945e-01, -2.0284e-01,  7.8611e-02,\n",
       "                       -1.9993e-01, -5.1490e-01, -4.9828e-01,  3.1481e-01, -4.4680e-02,\n",
       "                       -1.8335e-01, -1.5709e-01, -1.2316e-01, -7.2974e-01, -5.4002e-02,\n",
       "                        2.5559e-02, -5.3670e-01, -6.1394e-01, -2.6937e-01, -4.5664e-01,\n",
       "                       -2.0130e-01,  6.2617e-02, -4.1031e-01,  4.6085e-04, -4.4030e-01,\n",
       "                       -3.3069e-01, -1.9336e-01, -1.3713e-02, -2.7315e-01, -5.9430e-01,\n",
       "                       -2.0009e-02,  2.8505e-02, -4.9114e-01, -3.4240e-01, -1.1515e-01,\n",
       "                       -3.1846e-01, -2.1986e-01, -1.8716e-01, -1.6630e-02, -2.6153e-01,\n",
       "                       -4.0746e-01, -2.7741e-01, -6.4136e-02, -2.2741e-01, -2.5693e-01,\n",
       "                       -1.0088e-01, -2.2400e-01, -4.1279e-01,  3.3246e-02, -3.0392e-01,\n",
       "                       -1.9814e-01, -5.9575e-01, -3.3889e-01, -1.7848e-01, -2.5631e-01,\n",
       "                       -2.0743e-01, -4.9270e-01, -1.4470e+00, -2.1515e-01, -3.6364e-01,\n",
       "                       -1.2326e-01,  9.5314e-02, -4.1128e-01, -6.1353e-02, -1.9132e-01,\n",
       "                       -2.4201e-01, -1.3543e-01, -1.4268e-01, -8.7190e-02, -3.3851e-01,\n",
       "                       -9.1785e-02, -9.3655e-02, -3.0401e-01, -2.4535e-01, -7.2906e-02,\n",
       "                       -6.1781e-01, -6.3137e-01, -1.5900e-01, -3.1595e-02, -1.5838e-01,\n",
       "                       -3.0878e-01, -1.1002e-01, -4.7036e-01,  3.8008e-04, -4.6140e-01,\n",
       "                       -1.7859e-01, -8.3567e-02, -1.1281e-01,  8.6002e-02, -4.0840e-01,\n",
       "                       -2.2818e-01, -7.0548e-02, -4.6664e-01, -2.1514e-01, -6.0302e-01,\n",
       "                       -2.5618e-02, -1.5104e-01, -1.7670e-01, -3.0187e-01, -3.6429e-01,\n",
       "                       -7.5352e-02, -6.5979e-01, -5.0686e-01, -3.1106e-01, -1.8459e-01,\n",
       "                       -1.9876e-01, -3.4647e-01,  7.0899e-02, -6.9792e-02, -2.3436e-01,\n",
       "                       -4.9079e-01, -2.6327e-01, -1.0075e-01, -9.9779e-01, -2.3390e-01,\n",
       "                       -3.2913e-01, -3.1424e-01,  8.7023e-02, -4.6008e-02, -1.4888e-01,\n",
       "                        7.6378e-02, -4.3169e-01, -3.2205e-02, -5.4007e-01, -1.2979e-01,\n",
       "                       -1.9828e-01, -3.4731e-01, -3.3983e-01, -5.3965e-01, -2.0067e-01,\n",
       "                       -1.8965e-01, -3.3742e-01,  2.2835e-02, -3.6080e-01, -5.1370e-01,\n",
       "                       -3.3080e-01, -2.3909e-01, -2.4739e-01, -2.6406e-01, -3.9857e-01,\n",
       "                       -5.8528e-02, -2.1644e-01, -1.9221e-01, -4.2760e-02, -5.0019e-01,\n",
       "                       -5.6424e-01,  2.4278e-02, -1.9851e-01, -3.1152e-02, -2.8140e-01,\n",
       "                       -2.6998e-01,  6.3280e-02, -3.0284e-01, -2.9731e-01, -2.0810e-01,\n",
       "                       -3.0186e-01], device='cuda:0')),\n",
       "              ('layer3.0.bn2.running_var',\n",
       "               tensor([0.2468, 0.2284, 0.1321, 0.1466, 0.2026, 0.1971, 0.1506, 0.2171, 0.1630,\n",
       "                       0.1506, 0.2427, 0.3323, 0.3443, 0.1439, 0.1667, 0.4791, 0.2871, 0.2356,\n",
       "                       0.1132, 0.3044, 0.1354, 0.1926, 0.1974, 0.2376, 0.4346, 0.2521, 0.2040,\n",
       "                       0.2051, 0.2065, 0.2704, 0.1975, 0.1888, 0.1634, 0.2867, 0.1989, 0.2193,\n",
       "                       0.1469, 0.1593, 0.1884, 0.2586, 0.2051, 0.2272, 0.2438, 0.2317, 0.2840,\n",
       "                       0.1565, 0.2368, 0.2072, 0.3175, 0.2314, 0.1762, 0.2400, 0.3536, 0.1202,\n",
       "                       0.2611, 0.1885, 0.1505, 0.2644, 0.2458, 0.2668, 0.3237, 0.2866, 0.2182,\n",
       "                       0.2362, 0.1598, 0.1806, 0.1331, 0.1473, 0.1936, 0.1825, 0.1432, 0.1021,\n",
       "                       0.1871, 0.1415, 0.1996, 0.2569, 0.1966, 0.2052, 0.2529, 0.1891, 0.1097,\n",
       "                       0.2607, 0.2319, 0.2167, 0.1815, 0.1651, 0.2259, 0.2363, 0.1671, 0.1948,\n",
       "                       0.1522, 0.2217, 0.2223, 0.2102, 0.2858, 0.2312, 0.1895, 0.1660, 0.2316,\n",
       "                       0.1817, 0.3126, 0.2052, 0.2336, 0.1613, 0.0831, 0.2021, 0.2138, 0.2793,\n",
       "                       0.3249, 0.1240, 0.1506, 0.2233, 0.2350, 0.2572, 0.1239, 0.2824, 0.2736,\n",
       "                       0.3408, 0.1722, 0.0980, 0.1837, 0.2591, 0.1065, 0.1884, 0.2081, 0.2995,\n",
       "                       0.2001, 0.2465, 0.3052, 0.2391, 0.1411, 0.2966, 0.1316, 0.3116, 0.1223,\n",
       "                       0.2914, 0.2180, 0.1998, 0.1175, 0.2188, 0.2561, 0.2887, 0.3970, 0.1078,\n",
       "                       0.2304, 0.1702, 0.1751, 0.2392, 0.1760, 0.2269, 0.1940, 0.2696, 0.2873,\n",
       "                       0.2441, 0.2310, 0.1909, 0.1967, 0.3217, 0.1920, 0.2667, 0.2583, 0.2452,\n",
       "                       0.1657, 0.1843, 0.2398, 0.2257, 0.3124, 0.1954, 0.2147, 0.2184, 0.1839,\n",
       "                       0.1964, 0.2142, 0.2678, 0.1992, 0.2832, 0.3098, 0.1875, 0.1736, 0.1354,\n",
       "                       0.2354, 0.2198, 0.2942, 0.2456, 0.2000, 0.1419, 0.1759, 0.1361, 0.2350,\n",
       "                       0.2156, 0.2518, 0.2615, 0.2560, 0.1050, 0.3339, 0.2148, 0.2049, 0.1871,\n",
       "                       0.2442, 0.1809, 0.2223, 0.2474, 0.3387, 0.2936, 0.1363, 0.0934, 0.3584,\n",
       "                       0.2298, 0.1842, 0.1280, 0.2094, 0.1652, 0.1130, 0.3484, 0.1680, 0.2161,\n",
       "                       0.1547, 0.2022, 0.1547, 0.1158, 0.2001, 0.1832, 0.1878, 0.2973, 0.1984,\n",
       "                       0.2340, 0.2102, 0.2640, 0.2479, 0.3942, 0.1603, 0.2035, 0.2615, 0.1802,\n",
       "                       0.1635, 0.2635, 0.2896, 0.1690, 0.3055, 0.3065, 0.2556, 0.1594, 0.1525,\n",
       "                       0.2521, 0.2030, 0.1908, 0.2694, 0.1360, 0.2265, 0.1034, 0.2121, 0.1953,\n",
       "                       0.1459, 0.2523, 0.2361, 0.2822], device='cuda:0')),\n",
       "              ('layer3.0.bn2.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer3.0.shortcut.0.weight',\n",
       "               tensor([[[[-0.0212]],\n",
       "               \n",
       "                        [[ 0.0055]],\n",
       "               \n",
       "                        [[ 0.0593]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0704]],\n",
       "               \n",
       "                        [[ 0.0110]],\n",
       "               \n",
       "                        [[-0.0562]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0436]],\n",
       "               \n",
       "                        [[ 0.1013]],\n",
       "               \n",
       "                        [[-0.0034]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0558]],\n",
       "               \n",
       "                        [[-0.0067]],\n",
       "               \n",
       "                        [[-0.0127]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0449]],\n",
       "               \n",
       "                        [[-0.0198]],\n",
       "               \n",
       "                        [[ 0.0447]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0051]],\n",
       "               \n",
       "                        [[-0.0015]],\n",
       "               \n",
       "                        [[-0.0166]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0472]],\n",
       "               \n",
       "                        [[ 0.0595]],\n",
       "               \n",
       "                        [[-0.0345]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0308]],\n",
       "               \n",
       "                        [[ 0.0165]],\n",
       "               \n",
       "                        [[ 0.0200]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0382]],\n",
       "               \n",
       "                        [[ 0.0193]],\n",
       "               \n",
       "                        [[ 0.0233]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0367]],\n",
       "               \n",
       "                        [[ 0.0205]],\n",
       "               \n",
       "                        [[-0.0303]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0915]],\n",
       "               \n",
       "                        [[ 0.0697]],\n",
       "               \n",
       "                        [[-0.0043]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0040]],\n",
       "               \n",
       "                        [[ 0.0086]],\n",
       "               \n",
       "                        [[-0.0186]]]], device='cuda:0')),\n",
       "              ('layer3.0.shortcut.1.weight',\n",
       "               tensor([0.1401, 0.1620, 0.2497, 0.0990, 0.1178, 0.2648, 0.2044, 0.2002, 0.2011,\n",
       "                       0.2774, 0.1361, 0.2434, 0.2420, 0.2554, 0.1188, 0.1631, 0.1633, 0.2273,\n",
       "                       0.3388, 0.1859, 0.2232, 0.1488, 0.1700, 0.1019, 0.2938, 0.1713, 0.1493,\n",
       "                       0.1295, 0.1712, 0.1586, 0.2239, 0.1530, 0.0958, 0.1930, 0.0881, 0.2970,\n",
       "                       0.1840, 0.1965, 0.2166, 0.1651, 0.1843, 0.1078, 0.0790, 0.1813, 0.2086,\n",
       "                       0.1657, 0.2119, 0.1144, 0.1001, 0.1688, 0.1205, 0.1390, 0.1516, 0.1306,\n",
       "                       0.1917, 0.1352, 0.1858, 0.1788, 0.1504, 0.1797, 0.1457, 0.1930, 0.1906,\n",
       "                       0.1333, 0.1723, 0.2383, 0.1854, 0.2100, 0.2054, 0.1937, 0.1459, 0.1858,\n",
       "                       0.1876, 0.1597, 0.2837, 0.1640, 0.1601, 0.2498, 0.1818, 0.0979, 0.2123,\n",
       "                       0.2074, 0.1446, 0.2142, 0.1422, 0.2950, 0.1389, 0.1689, 0.1206, 0.1507,\n",
       "                       0.1671, 0.2608, 0.0889, 0.0702, 0.1465, 0.2223, 0.1528, 0.2448, 0.3235,\n",
       "                       0.1791, 0.2218, 0.1738, 0.1903, 0.2034, 0.1791, 0.0881, 0.3463, 0.2047,\n",
       "                       0.0527, 0.1585, 0.1548, 0.1890, 0.0924, 0.1593, 0.2356, 0.1962, 0.1571,\n",
       "                       0.1680, 0.1304, 0.3277, 0.3442, 0.1961, 0.0792, 0.0709, 0.2415, 0.0780,\n",
       "                       0.1345, 0.1736, 0.1050, 0.1673, 0.1953, 0.2184, 0.1732, 0.0793, 0.2127,\n",
       "                       0.1924, 0.1404, 0.1476, 0.1612, 0.1058, 0.1099, 0.2391, 0.1676, 0.1483,\n",
       "                       0.1423, 0.1166, 0.1830, 0.1889, 0.1636, 0.2417, 0.2033, 0.2029, 0.1063,\n",
       "                       0.2328, 0.2087, 0.2330, 0.3958, 0.4096, 0.0938, 0.2746, 0.2063, 0.1882,\n",
       "                       0.1454, 0.1297, 0.1225, 0.2393, 0.1754, 0.1801, 0.2004, 0.2277, 0.1170,\n",
       "                       0.1646, 0.3167, 0.1894, 0.0520, 0.1976, 0.0233, 0.3249, 0.1271, 0.2428,\n",
       "                       0.0493, 0.1345, 0.1524, 0.2554, 0.1392, 0.2449, 0.1022, 0.0618, 0.0624,\n",
       "                       0.1795, 0.1879, 0.1775, 0.2462, 0.1831, 0.0718, 0.2306, 0.3411, 0.1721,\n",
       "                       0.0952, 0.4025, 0.1389, 0.2495, 0.2064, 0.1173, 0.1180, 0.2929, 0.3014,\n",
       "                       0.2350, 0.2540, 0.1455, 0.3779, 0.0815, 0.1205, 0.2837, 0.1338, 0.2028,\n",
       "                       0.2563, 0.1807, 0.2988, 0.1888, 0.1070, 0.0995, 0.2516, 0.0988, 0.1349,\n",
       "                       0.1768, 0.1637, 0.2595, 0.1311, 0.0980, 0.1178, 0.1039, 0.1286, 0.1661,\n",
       "                       0.3039, 0.2838, 0.1749, 0.1103, 0.2101, 0.1020, 0.1452, 0.1653, 0.1160,\n",
       "                       0.3342, 0.2434, 0.3066, 0.2072, 0.0863, 0.1127, 0.0811, 0.1734, 0.2133,\n",
       "                       0.2267, 0.0958, 0.1448, 0.1823], device='cuda:0')),\n",
       "              ('layer3.0.shortcut.1.bias',\n",
       "               tensor([-0.1446, -0.1329, -0.1624, -0.1563, -0.1624, -0.2004, -0.2749, -0.2458,\n",
       "                       -0.1302, -0.2300, -0.1955, -0.1134, -0.2556, -0.1284, -0.1665, -0.2255,\n",
       "                       -0.1313, -0.1023, -0.2120, -0.1979, -0.1131, -0.1157, -0.0814, -0.2023,\n",
       "                       -0.0904, -0.1736, -0.2565, -0.0998, -0.2470, -0.1202, -0.1588, -0.2243,\n",
       "                       -0.1873, -0.1645, -0.2208, -0.1334, -0.1094, -0.1524, -0.1409, -0.2547,\n",
       "                       -0.1835, -0.1829, -0.1210, -0.2170, -0.1513, -0.0362, -0.1483, -0.1988,\n",
       "                       -0.2080, -0.1344, -0.1569, -0.1322, -0.1765, -0.1633, -0.1462, -0.1836,\n",
       "                       -0.1406, -0.1437, -0.1723, -0.1815, -0.1561, -0.0529, -0.1574, -0.1899,\n",
       "                       -0.1207, -0.1642, -0.1740, -0.1478, -0.1409, -0.1920, -0.2103, -0.1268,\n",
       "                       -0.1233, -0.1430, -0.1823, -0.1911, -0.1795, -0.0913, -0.2252, -0.2364,\n",
       "                       -0.1358, -0.1041, -0.1448, -0.1538, -0.2529, -0.1168, -0.2596, -0.1484,\n",
       "                       -0.1100, -0.1732, -0.1263, -0.2455, -0.1765, -0.2452, -0.1579, -0.1546,\n",
       "                       -0.1313, -0.1404, -0.1248, -0.1743, -0.1717, -0.2293, -0.0858, -0.1584,\n",
       "                       -0.1564, -0.2282, -0.1206, -0.2853, -0.2942, -0.1165, -0.1982, -0.2683,\n",
       "                       -0.2587, -0.1475, -0.1697, -0.2546, -0.0739, -0.2317, -0.1571, -0.1466,\n",
       "                       -0.1601, -0.1303, -0.0334, -0.1127, -0.2452, -0.0611, -0.1320, -0.2273,\n",
       "                       -0.1152, -0.1314, -0.1618, -0.2376, -0.1437, -0.0632, -0.2072, -0.0762,\n",
       "                       -0.1648, -0.1640, -0.1716, -0.1408, -0.0489, -0.2186, -0.1476, -0.1636,\n",
       "                       -0.1129, -0.1904, -0.2086, -0.0733, -0.1007, -0.2525, -0.3038, -0.2026,\n",
       "                       -0.2562, -0.1346, -0.1767, -0.2226, -0.1485, -0.0608, -0.1760, -0.1844,\n",
       "                       -0.1908, -0.2014, -0.1149, -0.3402, -0.2474, -0.1609, -0.1622, -0.1101,\n",
       "                       -0.1367, -0.1303, -0.2089, -0.0693, -0.1869, -0.1676, -0.1711, -0.1849,\n",
       "                       -0.0247, -0.1445, -0.1966, -0.1108, -0.2178, -0.1009, -0.2214, -0.1308,\n",
       "                       -0.2087, -0.0975, -0.2202, -0.1325, -0.1359, -0.1649, -0.1395, -0.2303,\n",
       "                       -0.1133, -0.1243, -0.1769, -0.2816, -0.1039, -0.1930, -0.1571, -0.1789,\n",
       "                       -0.2248, -0.0888, -0.1603, -0.1167, -0.1677, -0.0864, -0.1617, -0.1040,\n",
       "                       -0.1904, -0.1116, -0.1279, -0.0746, -0.1111, -0.1325, -0.1292, -0.1644,\n",
       "                       -0.1717, -0.2217, -0.2196, -0.1823, -0.1540, -0.1916, -0.1764, -0.2709,\n",
       "                       -0.1957, -0.2154, -0.1336, -0.1430, -0.1763, -0.0840, -0.0930, -0.1579,\n",
       "                       -0.1458, -0.0965, -0.1684, -0.1359, -0.1531, -0.1375, -0.2091, -0.0958,\n",
       "                       -0.2215, -0.2715, -0.2541, -0.1942, -0.1960, -0.0659, -0.1664, -0.1133,\n",
       "                       -0.2244, -0.1400, -0.1559, -0.2044, -0.1599, -0.1419, -0.2456, -0.0696],\n",
       "                      device='cuda:0')),\n",
       "              ('layer3.0.shortcut.1.running_mean',\n",
       "               tensor([ 3.1947e-02, -8.4164e-03, -7.8311e-02, -2.7208e-01, -2.5972e-01,\n",
       "                       -9.8640e-03,  1.1742e-01, -3.0555e-01, -1.4743e-01, -4.7185e-02,\n",
       "                       -5.9862e-02, -2.1462e-01, -2.1880e-01, -2.7792e-01, -9.8420e-02,\n",
       "                       -1.3487e-01, -2.3917e-01, -2.9758e-01, -1.3219e-01, -2.7604e-01,\n",
       "                       -3.1412e-01, -2.9514e-01, -4.1728e-01, -8.5351e-02, -3.4270e-01,\n",
       "                       -7.2030e-02, -2.6946e-02, -2.7200e-01, -1.0558e-01, -6.5567e-03,\n",
       "                       -3.4378e-01,  1.6240e-01,  1.8277e-02, -1.8071e-01, -1.4357e-01,\n",
       "                       -1.5953e-01, -1.2021e-01, -1.7716e-03, -1.5497e-01, -2.1148e-01,\n",
       "                       -2.0426e-01, -4.8203e-02,  5.4082e-03, -2.0688e-01, -4.4413e-01,\n",
       "                       -9.9780e-03,  5.4609e-02, -1.8670e-01, -1.3608e-01,  2.9558e-03,\n",
       "                        4.7529e-02, -1.0043e-01,  2.1724e-02,  9.9477e-02,  8.8423e-02,\n",
       "                       -6.5665e-02, -3.3912e-02, -1.4629e-01, -1.1061e-01, -9.3023e-02,\n",
       "                       -1.0542e-01, -2.6023e-01,  5.2939e-02, -6.8502e-02, -2.3755e-01,\n",
       "                       -7.5859e-02, -1.3724e-01, -1.4469e-01,  2.8671e-03, -1.2613e-01,\n",
       "                       -2.0473e-01,  9.0146e-02, -1.4515e-01, -1.1787e-02, -3.6863e-01,\n",
       "                       -2.3415e-01, -1.8678e-01, -8.4626e-02, -8.5003e-02, -1.2941e-01,\n",
       "                       -2.9549e-01, -3.2676e-01,  2.3971e-02, -2.7181e-01, -5.1711e-02,\n",
       "                       -4.6081e-01,  2.7075e-02,  8.9637e-02, -2.3596e-01, -1.8690e-01,\n",
       "                       -1.7269e-01,  3.9525e-02, -1.8521e-02, -1.2535e-01, -2.1367e-01,\n",
       "                       -2.4004e-01,  1.8420e-02, -4.5129e-03, -1.8644e-01, -1.2771e-01,\n",
       "                        2.7543e-02,  4.9080e-02, -9.4641e-02, -4.7567e-02,  8.8588e-03,\n",
       "                       -5.3826e-02, -4.6675e-01, -8.5105e-02, -3.2361e-02, -1.7877e-01,\n",
       "                       -6.2590e-02, -2.0857e-01, -7.2260e-02, -1.2441e-01,  3.7632e-02,\n",
       "                       -2.3547e-01, -2.5005e-01, -2.8521e-01, -1.5947e-01, -2.8138e-01,\n",
       "                       -3.7671e-01, -1.2433e-01, -5.4710e-02,  6.9511e-02, -1.0082e-01,\n",
       "                       -9.2513e-02, -1.6104e-04,  1.0657e-02, -1.2634e-03, -2.9198e-01,\n",
       "                       -3.8515e-02, -1.4027e-01, -6.9054e-02, -1.2809e-01, -9.0340e-02,\n",
       "                       -1.6548e-01, -9.3607e-02, -1.1022e-01,  8.3314e-02,  9.7669e-02,\n",
       "                       -1.8156e-01, -3.0540e-01, -8.9360e-03,  1.2062e-02, -1.6095e-01,\n",
       "                       -8.2541e-02, -1.1991e-01, -3.7409e-01, -1.8707e-01, -1.6250e-01,\n",
       "                        1.0781e-01, -1.7585e-01, -2.0670e-01,  4.4858e-02,  3.8754e-02,\n",
       "                       -1.7235e-01, -1.2255e-02, -3.6362e-01, -1.7561e-01, -5.7062e-02,\n",
       "                       -3.7590e-02, -1.3509e-02, -3.1966e-01, -5.0129e-02, -1.0234e-01,\n",
       "                       -1.1302e-01, -1.6662e-01, -1.5505e-02,  1.4416e-02, -1.0137e-01,\n",
       "                       -1.7536e-02, -1.6606e-01, -3.5177e-02, -1.6628e-01,  9.9068e-02,\n",
       "                       -2.9326e-01, -3.1596e-01, -4.7151e-02, -2.0571e-01, -8.5792e-02,\n",
       "                       -1.9838e-03, -2.4851e-01,  5.5260e-02, -1.2770e-01, -9.4198e-02,\n",
       "                       -1.1721e-01,  4.1205e-02, -5.9005e-02,  1.3893e-02, -1.0797e-01,\n",
       "                       -3.3587e-01, -1.4302e-01, -1.6020e-01, -1.0880e-01, -2.4963e-01,\n",
       "                       -8.5320e-02, -4.5392e-01, -3.8185e-02, -2.3286e-01,  7.6420e-02,\n",
       "                       -3.3993e-01, -2.5179e-01, -1.0041e-01, -3.1280e-01, -1.5154e-02,\n",
       "                       -9.4920e-02, -2.6814e-01, -1.6249e-01,  1.0564e-01, -1.9391e-02,\n",
       "                       -2.5207e-01, -1.4255e-01, -1.1040e-01, -4.3385e-01, -4.6249e-02,\n",
       "                        5.5185e-02, -1.4285e-02, -3.1509e-01,  2.2657e-01,  6.4558e-03,\n",
       "                       -9.1760e-02, -5.1243e-02, -5.7090e-02, -1.9196e-01, -4.3148e-02,\n",
       "                       -2.7898e-01, -3.4488e-02, -4.5759e-01, -1.5921e-01, -4.6062e-02,\n",
       "                       -7.6638e-02,  4.7989e-03, -2.8774e-02, -4.7440e-02, -1.1424e-01,\n",
       "                       -3.7033e-01, -1.3607e-01, -2.1701e-01, -2.3873e-01, -1.9986e-01,\n",
       "                        2.3011e-02, -1.1856e-01, -7.0472e-02, -8.7605e-02, -9.3535e-02,\n",
       "                       -2.2570e-01, -3.7612e-02, -8.7414e-02, -1.4240e-01,  1.2480e-01,\n",
       "                       -2.7792e-01, -4.8993e-02, -2.7242e-03,  1.4317e-02,  1.5132e-01,\n",
       "                        7.4386e-02], device='cuda:0')),\n",
       "              ('layer3.0.shortcut.1.running_var',\n",
       "               tensor([0.0666, 0.0479, 0.0670, 0.0438, 0.0633, 0.1195, 0.0744, 0.0662, 0.0653,\n",
       "                       0.0895, 0.0359, 0.1104, 0.1218, 0.0997, 0.0372, 0.1259, 0.1105, 0.0620,\n",
       "                       0.1231, 0.0725, 0.0774, 0.0585, 0.0902, 0.0393, 0.2253, 0.0533, 0.0530,\n",
       "                       0.0848, 0.0469, 0.0734, 0.0889, 0.0509, 0.0572, 0.1364, 0.0742, 0.1110,\n",
       "                       0.0960, 0.1021, 0.0920, 0.0587, 0.0661, 0.0530, 0.0373, 0.0890, 0.1009,\n",
       "                       0.0676, 0.1212, 0.0452, 0.0585, 0.0802, 0.0629, 0.0626, 0.0840, 0.0502,\n",
       "                       0.0779, 0.0621, 0.0460, 0.0785, 0.0487, 0.0650, 0.0951, 0.0880, 0.0860,\n",
       "                       0.0618, 0.0611, 0.0817, 0.0800, 0.0473, 0.0553, 0.0825, 0.0479, 0.0367,\n",
       "                       0.1014, 0.0663, 0.1633, 0.0833, 0.0538, 0.0589, 0.0538, 0.0484, 0.0596,\n",
       "                       0.0835, 0.0625, 0.0741, 0.0826, 0.1390, 0.0546, 0.0611, 0.0519, 0.0647,\n",
       "                       0.0915, 0.0760, 0.0305, 0.0330, 0.0565, 0.0715, 0.0744, 0.1329, 0.1714,\n",
       "                       0.0700, 0.1100, 0.0662, 0.1000, 0.0777, 0.0521, 0.0525, 0.1284, 0.0579,\n",
       "                       0.0369, 0.0527, 0.0763, 0.1032, 0.0611, 0.0555, 0.0627, 0.0911, 0.0872,\n",
       "                       0.1241, 0.0698, 0.0995, 0.1164, 0.0642, 0.0226, 0.0480, 0.1705, 0.0578,\n",
       "                       0.0424, 0.0814, 0.0719, 0.0696, 0.0650, 0.0907, 0.0644, 0.0731, 0.0572,\n",
       "                       0.0678, 0.0900, 0.0408, 0.0617, 0.0470, 0.0832, 0.0884, 0.1145, 0.0324,\n",
       "                       0.0642, 0.0600, 0.0564, 0.0959, 0.0704, 0.0954, 0.0852, 0.0879, 0.0828,\n",
       "                       0.0718, 0.1135, 0.0916, 0.1617, 0.2312, 0.0352, 0.0942, 0.0839, 0.1192,\n",
       "                       0.0535, 0.0411, 0.0713, 0.0986, 0.0653, 0.0831, 0.0617, 0.0841, 0.0376,\n",
       "                       0.0557, 0.1098, 0.1185, 0.0225, 0.0741, 0.0684, 0.1411, 0.0613, 0.0813,\n",
       "                       0.0430, 0.0520, 0.0686, 0.1152, 0.0640, 0.1125, 0.0604, 0.0416, 0.0433,\n",
       "                       0.0876, 0.0675, 0.0830, 0.1128, 0.0526, 0.0360, 0.0776, 0.0759, 0.0934,\n",
       "                       0.0399, 0.1653, 0.0357, 0.0957, 0.1060, 0.0724, 0.0318, 0.0760, 0.1332,\n",
       "                       0.0841, 0.0546, 0.0369, 0.1387, 0.0317, 0.0406, 0.1848, 0.0574, 0.0842,\n",
       "                       0.0972, 0.0596, 0.0900, 0.0489, 0.0562, 0.0687, 0.0893, 0.0586, 0.0417,\n",
       "                       0.0653, 0.0879, 0.1100, 0.0594, 0.0846, 0.0395, 0.0331, 0.0739, 0.0491,\n",
       "                       0.1026, 0.1008, 0.1075, 0.0539, 0.0903, 0.0357, 0.0730, 0.0469, 0.0533,\n",
       "                       0.1396, 0.0972, 0.1395, 0.0746, 0.0256, 0.0727, 0.0295, 0.1019, 0.0733,\n",
       "                       0.0982, 0.0699, 0.0541, 0.0779], device='cuda:0')),\n",
       "              ('layer3.0.shortcut.1.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer3.1.conv1.weight',\n",
       "               tensor([[[[ 0.0116,  0.0074, -0.0063],\n",
       "                         [ 0.0268,  0.0140, -0.0122],\n",
       "                         [ 0.0119, -0.0286, -0.0206]],\n",
       "               \n",
       "                        [[-0.0264, -0.0238,  0.0273],\n",
       "                         [-0.0319,  0.0020,  0.0496],\n",
       "                         [-0.0352, -0.0026,  0.0362]],\n",
       "               \n",
       "                        [[-0.0041,  0.0211, -0.0110],\n",
       "                         [ 0.0046,  0.0158,  0.0294],\n",
       "                         [-0.0074, -0.0042, -0.0095]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0734, -0.0145,  0.0002],\n",
       "                         [ 0.0534, -0.0064, -0.0091],\n",
       "                         [ 0.0203, -0.0155, -0.0113]],\n",
       "               \n",
       "                        [[ 0.0017, -0.0140, -0.0331],\n",
       "                         [-0.0226, -0.0203, -0.0301],\n",
       "                         [-0.0221,  0.0283, -0.0021]],\n",
       "               \n",
       "                        [[-0.0159, -0.0146, -0.0077],\n",
       "                         [-0.0217,  0.0081,  0.0069],\n",
       "                         [-0.0338, -0.0075,  0.0138]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0007, -0.0094,  0.0002],\n",
       "                         [ 0.0494, -0.0095, -0.0094],\n",
       "                         [ 0.0392, -0.0096, -0.0148]],\n",
       "               \n",
       "                        [[-0.0265,  0.0081, -0.0296],\n",
       "                         [-0.0131,  0.0181, -0.0234],\n",
       "                         [ 0.0147,  0.0300, -0.0071]],\n",
       "               \n",
       "                        [[-0.0129, -0.0169, -0.0054],\n",
       "                         [ 0.0120,  0.0143,  0.0042],\n",
       "                         [ 0.0024,  0.0132, -0.0096]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0280,  0.0733,  0.0476],\n",
       "                         [-0.0090,  0.0672,  0.0425],\n",
       "                         [-0.0336,  0.0152,  0.0469]],\n",
       "               \n",
       "                        [[ 0.0328,  0.0096, -0.0246],\n",
       "                         [ 0.0335,  0.0042,  0.0187],\n",
       "                         [ 0.0259, -0.0047,  0.0224]],\n",
       "               \n",
       "                        [[-0.0019,  0.0047, -0.0040],\n",
       "                         [ 0.0093,  0.0048,  0.0033],\n",
       "                         [ 0.0135, -0.0013,  0.0148]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0256, -0.0149, -0.0057],\n",
       "                         [-0.0109, -0.0307, -0.0241],\n",
       "                         [-0.0184,  0.0012, -0.0073]],\n",
       "               \n",
       "                        [[-0.0270, -0.0381, -0.0252],\n",
       "                         [-0.0459, -0.0271,  0.0162],\n",
       "                         [-0.0156, -0.0089,  0.0447]],\n",
       "               \n",
       "                        [[ 0.0228, -0.0015,  0.0004],\n",
       "                         [ 0.0073,  0.0116,  0.0071],\n",
       "                         [-0.0205, -0.0025, -0.0160]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0188,  0.0258,  0.0018],\n",
       "                         [ 0.0399,  0.0054, -0.0042],\n",
       "                         [-0.0278, -0.0485, -0.0165]],\n",
       "               \n",
       "                        [[-0.0154, -0.0164, -0.0020],\n",
       "                         [-0.0221, -0.0358,  0.0297],\n",
       "                         [-0.0018, -0.0182,  0.0043]],\n",
       "               \n",
       "                        [[ 0.0166, -0.0240,  0.0105],\n",
       "                         [ 0.0072, -0.0114, -0.0359],\n",
       "                         [ 0.0052,  0.0078, -0.0088]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0172, -0.0259, -0.0091],\n",
       "                         [-0.0057, -0.0260, -0.0295],\n",
       "                         [-0.0315, -0.0310, -0.0324]],\n",
       "               \n",
       "                        [[-0.0247, -0.0034, -0.0224],\n",
       "                         [-0.0520,  0.0068, -0.0131],\n",
       "                         [-0.0397,  0.0311,  0.0445]],\n",
       "               \n",
       "                        [[ 0.0505,  0.0441,  0.0282],\n",
       "                         [ 0.0536,  0.0406,  0.0220],\n",
       "                         [ 0.0167,  0.0124, -0.0104]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0506, -0.0148,  0.0541],\n",
       "                         [-0.0481, -0.0487,  0.0239],\n",
       "                         [-0.0180, -0.0462, -0.0406]],\n",
       "               \n",
       "                        [[ 0.0033,  0.0242,  0.0295],\n",
       "                         [-0.0002,  0.0307,  0.0406],\n",
       "                         [ 0.0026,  0.0319,  0.0405]],\n",
       "               \n",
       "                        [[-0.0113, -0.0220, -0.0261],\n",
       "                         [ 0.0049, -0.0102, -0.0172],\n",
       "                         [-0.0136, -0.0059, -0.0012]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0094, -0.0182, -0.0027],\n",
       "                         [-0.0115, -0.0147,  0.0014],\n",
       "                         [-0.0321, -0.0097, -0.0183]],\n",
       "               \n",
       "                        [[-0.0148,  0.0474,  0.0276],\n",
       "                         [-0.0077,  0.0484,  0.0242],\n",
       "                         [-0.0025, -0.0053, -0.0134]],\n",
       "               \n",
       "                        [[-0.0043,  0.0087,  0.0189],\n",
       "                         [-0.0086,  0.0148,  0.0339],\n",
       "                         [-0.0141, -0.0149, -0.0154]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0013, -0.0131,  0.0238],\n",
       "                         [ 0.0024,  0.0065, -0.0150],\n",
       "                         [-0.0396, -0.0095, -0.0279]],\n",
       "               \n",
       "                        [[ 0.0262,  0.0088,  0.0066],\n",
       "                         [-0.0033,  0.0045, -0.0295],\n",
       "                         [ 0.0216,  0.0157, -0.0092]],\n",
       "               \n",
       "                        [[-0.0264, -0.0083, -0.0399],\n",
       "                         [-0.0193,  0.0139, -0.0208],\n",
       "                         [ 0.0061,  0.0120,  0.0078]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0122, -0.0076,  0.0367],\n",
       "                         [-0.0127, -0.0330, -0.0100],\n",
       "                         [ 0.0016, -0.0122, -0.0002]],\n",
       "               \n",
       "                        [[ 0.0108, -0.0521,  0.0076],\n",
       "                         [ 0.0211, -0.0543,  0.0208],\n",
       "                         [ 0.1113, -0.0269,  0.0284]],\n",
       "               \n",
       "                        [[-0.0016, -0.0004, -0.0043],\n",
       "                         [-0.0101, -0.0179, -0.0012],\n",
       "                         [ 0.0072, -0.0123, -0.0092]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0047, -0.0136, -0.0056],\n",
       "                         [ 0.0207, -0.0097, -0.0365],\n",
       "                         [-0.0236, -0.0068, -0.0601]],\n",
       "               \n",
       "                        [[-0.0380, -0.0243, -0.0167],\n",
       "                         [ 0.0048, -0.0150,  0.0128],\n",
       "                         [ 0.0018, -0.0248,  0.0126]],\n",
       "               \n",
       "                        [[ 0.0355,  0.0652, -0.0346],\n",
       "                         [-0.0246,  0.0094, -0.0417],\n",
       "                         [-0.0237, -0.0184, -0.0236]]]], device='cuda:0')),\n",
       "              ('layer3.1.bn1.weight',\n",
       "               tensor([0.3010, 0.2621, 0.2624, 0.4289, 0.3292, 0.3126, 0.2837, 0.2544, 0.4249,\n",
       "                       0.3710, 0.3137, 0.2568, 0.2133, 0.4002, 0.2807, 0.2373, 0.1510, 0.2998,\n",
       "                       0.3311, 0.3121, 0.3970, 0.2931, 0.2910, 0.2524, 0.3092, 0.3436, 0.4696,\n",
       "                       0.2865, 0.3259, 0.3143, 0.3640, 0.3399, 0.3503, 0.3694, 0.2483, 0.3195,\n",
       "                       0.2881, 0.2009, 0.2748, 0.3404, 0.2982, 0.3822, 0.2329, 0.3708, 0.3738,\n",
       "                       0.2707, 0.3601, 0.2457, 0.2821, 0.2476, 0.2718, 0.3506, 0.3209, 0.3440,\n",
       "                       0.3040, 0.3065, 0.1752, 0.3096, 0.3059, 0.2558, 0.2818, 0.4044, 0.2793,\n",
       "                       0.3292, 0.3503, 0.3306, 0.2558, 0.2814, 0.2574, 0.3747, 0.3523, 0.3038,\n",
       "                       0.3546, 0.3118, 0.3473, 0.2299, 0.3948, 0.4302, 0.3313, 0.3249, 0.3391,\n",
       "                       0.3866, 0.3047, 0.3268, 0.3356, 0.3495, 0.3768, 0.2993, 0.3547, 0.2862,\n",
       "                       0.2974, 0.2209, 0.3053, 0.3231, 0.3122, 0.3876, 0.2829, 0.3088, 0.2743,\n",
       "                       0.3167, 0.3421, 0.3646, 0.2017, 0.2757, 0.3759, 0.3025, 0.2854, 0.3042,\n",
       "                       0.3941, 0.3749, 0.3137, 0.3190, 0.2135, 0.2335, 0.3084, 0.3527, 0.3663,\n",
       "                       0.3007, 0.3969, 0.2500, 0.3752, 0.2467, 0.2396, 0.3422, 0.2328, 0.3006,\n",
       "                       0.2929, 0.4185, 0.2756, 0.3118, 0.2848, 0.2635, 0.2298, 0.3260, 0.3328,\n",
       "                       0.3295, 0.3606, 0.3160, 0.3740, 0.4237, 0.2273, 0.3069, 0.3699, 0.1309,\n",
       "                       0.2753, 0.3284, 0.3188, 0.3353, 0.3044, 0.3133, 0.3876, 0.2197, 0.3602,\n",
       "                       0.2395, 0.2114, 0.2584, 0.1778, 0.2557, 0.3846, 0.2772, 0.2817, 0.3572,\n",
       "                       0.4271, 0.2590, 0.3248, 0.2336, 0.3168, 0.2510, 0.4298, 0.3329, 0.2267,\n",
       "                       0.3098, 0.3799, 0.3427, 0.3236, 0.3157, 0.2608, 0.3107, 0.2545, 0.2579,\n",
       "                       0.3455, 0.3897, 0.3491, 0.3942, 0.3362, 0.4199, 0.2882, 0.3085, 0.1313,\n",
       "                       0.2737, 0.3466, 0.3008, 0.3620, 0.3754, 0.3016, 0.2033, 0.3191, 0.3614,\n",
       "                       0.1953, 0.2120, 0.3872, 0.3344, 0.3242, 0.2611, 0.3115, 0.3747, 0.2310,\n",
       "                       0.2514, 0.2541, 0.3016, 0.3135, 0.2936, 0.3912, 0.3636, 0.2927, 0.3537,\n",
       "                       0.4260, 0.3540, 0.3070, 0.3565, 0.4037, 0.2355, 0.3417, 0.3292, 0.3701,\n",
       "                       0.3968, 0.3406, 0.3088, 0.2646, 0.3835, 0.3095, 0.2511, 0.2595, 0.2148,\n",
       "                       0.2552, 0.3453, 0.2469, 0.3747, 0.2625, 0.2536, 0.3813, 0.2313, 0.3135,\n",
       "                       0.4125, 0.2099, 0.3938, 0.2906, 0.3297, 0.3023, 0.3779, 0.2750, 0.2675,\n",
       "                       0.2689, 0.2420, 0.2243, 0.3570], device='cuda:0')),\n",
       "              ('layer3.1.bn1.bias',\n",
       "               tensor([-0.3084, -0.2487, -0.3046, -0.3213, -0.3189, -0.2284, -0.1493, -0.1568,\n",
       "                       -0.3773, -0.2609, -0.2621, -0.1257, -0.3147, -0.3183, -0.2840, -0.2396,\n",
       "                       -0.2447, -0.2148, -0.2320, -0.2361, -0.3737, -0.3028, -0.2851, -0.2549,\n",
       "                       -0.2748, -0.3046, -0.3134, -0.2464, -0.1731, -0.2669, -0.5208, -0.4183,\n",
       "                       -0.1463, -0.3579, -0.2108, -0.1512, -0.3003, -0.2126, -0.3759, -0.2695,\n",
       "                       -0.2461, -0.1676, -0.3078, -0.2503, -0.2498, -0.2370, -0.3192, -0.2071,\n",
       "                       -0.2124, -0.2213, -0.2861, -0.2316, -0.2772, -0.3552, -0.2753, -0.3036,\n",
       "                       -0.2167, -0.2156, -0.1908, -0.3055, -0.2114, -0.2705, -0.2372, -0.2935,\n",
       "                       -0.1658, -0.2663, -0.2667, -0.2583, -0.1681, -0.1942, -0.2611, -0.2390,\n",
       "                       -0.2316, -0.2550, -0.2197, -0.2214, -0.3252, -0.2698, -0.2672, -0.3650,\n",
       "                       -0.2759, -0.3189, -0.2580, -0.2608, -0.2445, -0.3682, -0.4335, -0.3122,\n",
       "                       -0.2508, -0.1922, -0.2923, -0.1772, -0.2600, -0.2835, -0.3138, -0.2186,\n",
       "                       -0.1746, -0.3092, -0.3806, -0.2932, -0.3321, -0.2781, -0.3147, -0.2636,\n",
       "                       -0.2646, -0.3026, -0.1104, -0.3272, -0.3762, -0.2712, -0.3818, -0.2309,\n",
       "                       -0.2227, -0.2615, -0.2255, -0.3048, -0.3647, -0.3749, -0.2293, -0.3911,\n",
       "                       -0.2013, -0.2576, -0.2707, -0.3786, -0.2366, -0.2610, -0.2314, -0.2720,\n",
       "                       -0.2592, -0.4138, -0.4344, -0.2645, -0.2531, -0.2037, -0.2370, -0.3032,\n",
       "                       -0.3597, -0.1857, -0.4723, -0.3305, -0.2127, -0.1632, -0.3018, -0.1313,\n",
       "                       -0.1709, -0.3084, -0.2799, -0.3187, -0.2709, -0.3702, -0.4281, -0.1814,\n",
       "                       -0.3077, -0.2288, -0.2225, -0.3233, -0.1985, -0.2452, -0.2969, -0.2504,\n",
       "                       -0.1789, -0.3439, -0.5063, -0.2486, -0.1979, -0.2608, -0.2588, -0.1908,\n",
       "                       -0.3882, -0.4616, -0.2808, -0.1457, -0.3951, -0.3713, -0.2883, -0.2060,\n",
       "                       -0.2234, -0.1827, -0.2565, -0.1407, -0.3540, -0.2592, -0.2918, -0.3413,\n",
       "                       -0.2694, -0.3308, -0.2207, -0.3042, -0.1581, -0.1607, -0.1634, -0.2565,\n",
       "                       -0.1439, -0.4536, -0.1883, -0.3073, -0.1653, -0.3930, -0.1736, -0.1357,\n",
       "                       -0.3780, -0.2496, -0.3051, -0.3295, -0.2353, -0.3726, -0.2711, -0.2160,\n",
       "                       -0.2295, -0.2638, -0.2170, -0.2944, -0.2817, -0.2834, -0.1586, -0.2473,\n",
       "                       -0.3396, -0.1772, -0.3211, -0.2993, -0.3298, -0.1965, -0.3054, -0.2192,\n",
       "                       -0.3772, -0.3994, -0.3324, -0.2819, -0.2266, -0.3910, -0.2716, -0.1563,\n",
       "                       -0.2202, -0.2464, -0.1650, -0.2565, -0.3127, -0.3155, -0.2311, -0.1948,\n",
       "                       -0.3220, -0.3449, -0.1950, -0.3499, -0.1910, -0.3034, -0.2516, -0.3178,\n",
       "                       -0.3986, -0.3108, -0.2971, -0.1922, -0.2132, -0.2081, -0.2491, -0.3474],\n",
       "                      device='cuda:0')),\n",
       "              ('layer3.1.bn1.running_mean',\n",
       "               tensor([-0.1079, -0.1861, -0.0094, -0.4796, -0.4354,  0.0502, -0.6545, -0.3077,\n",
       "                       -0.2081, -0.5586, -0.2420, -0.3251, -0.2477, -0.1595, -0.8894, -0.3070,\n",
       "                       -0.1405, -0.5306, -1.0040, -0.7619, -0.2159, -0.6269, -0.3004, -0.3058,\n",
       "                       -0.4587,  1.1100, -0.5618, -0.1044, -0.2089,  0.0168,  0.0127,  0.0917,\n",
       "                       -0.6717, -0.8018, -0.8419, -0.4846, -0.4060, -0.1235,  0.2326, -0.5097,\n",
       "                       -0.0117, -1.2062, -0.3040, -0.8991, -0.6809, -0.1915, -0.6861, -0.3313,\n",
       "                       -0.4546, -0.3544, -0.3747, -0.9943, -0.3660, -0.2864, -0.4541, -0.1995,\n",
       "                        0.0272, -0.5307, -0.4322, -0.3810, -0.4348, -0.3212, -0.4788, -0.3211,\n",
       "                       -0.6294, -0.7759, -0.2324, -0.8243, -0.5067, -0.5257, -0.8177, -0.4005,\n",
       "                       -0.5374, -0.7910, -0.8671, -0.4395, -0.8831, -0.5576, -0.1024, -0.2937,\n",
       "                       -0.2889, -0.7173, -0.5510, -0.4066, -0.5501, -0.4795,  0.0132, -0.5411,\n",
       "                       -0.8225, -0.2080, -0.3785, -0.4218, -0.4207, -0.5100, -0.1139, -1.4228,\n",
       "                       -1.2060, -0.4452, -0.4693, -0.2604, -0.6444,  0.0522, -0.4491, -0.2496,\n",
       "                       -0.2613, -0.0857, -0.6861, -0.0890, -0.5682, -0.0887, -0.2685, -0.8873,\n",
       "                       -0.2650, -0.4347, -0.6755, -0.6747, -0.6955, -0.4359, -0.4534, -0.2223,\n",
       "                       -0.7248, -0.4611, -0.1682, -0.2612, -0.2284, -0.7007, -0.5911, -0.4762,\n",
       "                       -0.3169, -0.4290, -0.1251, -0.2109,  0.1167,  0.3689, -0.9138, -0.3903,\n",
       "                       -0.5708, -0.1439, -0.0556, -0.8995, -0.4937, -0.6732, -0.5972, -0.8002,\n",
       "                       -0.8288, -0.1008, -0.6965, -0.6407, -0.6135, -0.3072,  0.4375, -0.0692,\n",
       "                       -0.1972, -0.8025, -0.2622, -0.3423, -0.3878, -0.1794, -0.7971, -0.1868,\n",
       "                       -0.4828, -1.1402, -0.4412, -0.8874, -0.4681, -0.3259, -0.4984, -0.1748,\n",
       "                       -1.0373, -0.0192, -0.0221, -0.6733, -0.6614, -0.1613, -0.6585, -0.4125,\n",
       "                       -0.8076, -0.5805, -0.3555, -0.4308, -0.0256, -0.8212, -0.4625, -0.4451,\n",
       "                       -0.6451, -0.5244, -0.4535, -0.1348, -0.3247, -0.5092, -1.0972, -0.4699,\n",
       "                       -0.0664, -0.1301, -0.3566, -0.5681, -0.5433, -0.4379, -0.1820, -0.4470,\n",
       "                       -0.7784,  0.0215, -0.2033, -0.5473, -0.4407, -0.2661,  0.4640, -0.2106,\n",
       "                        0.2057, -0.5318, -0.5957, -0.6870, -0.7037, -0.2714, -0.9173, -0.4645,\n",
       "                       -0.6606, -0.6793, -0.0230, -0.6497, -0.5022, -0.2993, -0.2822, -0.7200,\n",
       "                       -0.4766, -0.2330, -0.3528, -0.3687, -0.4237, -0.7705, -0.1356, -0.4545,\n",
       "                       -0.5716, -0.2204, -0.6102, -0.6454, -0.4286, -0.8599, -0.7652, -0.4946,\n",
       "                       -0.1674, -0.1526, -0.4343, -0.4357, -0.7631, -0.4396, -0.7101, -0.1808,\n",
       "                       -0.4662, -0.4745,  0.2174, -0.3845, -0.8482, -0.7340,  0.1734, -0.3636],\n",
       "                      device='cuda:0')),\n",
       "              ('layer3.1.bn1.running_var',\n",
       "               tensor([0.2050, 0.2373, 0.2508, 0.4463, 0.3752, 0.2439, 0.3021, 0.1493, 0.3000,\n",
       "                       0.2648, 0.2417, 0.1486, 0.2251, 0.3436, 0.3667, 0.1654, 0.1468, 0.2378,\n",
       "                       0.5314, 0.3278, 0.3604, 0.3865, 0.2857, 0.2411, 0.4272, 0.4356, 0.4164,\n",
       "                       0.3166, 0.3205, 0.2158, 0.4228, 0.4047, 0.3281, 0.3516, 0.2945, 0.4126,\n",
       "                       0.2784, 0.1438, 0.2324, 0.2902, 0.3026, 0.7489, 0.1675, 0.3331, 0.3786,\n",
       "                       0.1894, 0.3671, 0.2573, 0.2268, 0.1981, 0.2677, 0.3872, 0.2751, 0.3598,\n",
       "                       0.2608, 0.2761, 0.2278, 0.2581, 0.1868, 0.3127, 0.2803, 0.4780, 0.2715,\n",
       "                       0.3917, 0.2265, 0.3502, 0.2121, 0.2451, 0.2676, 0.4536, 0.3866, 0.2774,\n",
       "                       0.3680, 0.2942, 0.3617, 0.1755, 0.4630, 0.4418, 0.2781, 0.3092, 0.2243,\n",
       "                       0.3158, 0.2989, 0.3165, 0.3117, 0.3058, 0.3873, 0.3643, 0.4297, 0.2270,\n",
       "                       0.2856, 0.2482, 0.2924, 0.3391, 0.3754, 0.5598, 0.4007, 0.3258, 0.3455,\n",
       "                       0.3069, 0.3951, 0.4086, 0.3135, 0.2352, 0.3159, 0.2507, 0.3031, 0.2719,\n",
       "                       0.3267, 0.3746, 0.4166, 0.3934, 0.1736, 0.1966, 0.2360, 0.3438, 0.3492,\n",
       "                       0.4122, 0.3662, 0.2082, 0.3901, 0.3329, 0.1567, 0.2855, 0.2047, 0.3668,\n",
       "                       0.2829, 0.3961, 0.2981, 0.4217, 0.2293, 0.1535, 0.1577, 0.2683, 0.3667,\n",
       "                       0.3450, 0.3632, 0.2152, 0.3193, 0.4295, 0.1771, 0.4123, 0.3922, 0.1621,\n",
       "                       0.2752, 0.2635, 0.3021, 0.3932, 0.2005, 0.2778, 0.3927, 0.1294, 0.4261,\n",
       "                       0.3091, 0.2076, 0.3072, 0.2038, 0.1661, 0.4362, 0.2533, 0.2031, 0.4033,\n",
       "                       0.3604, 0.3247, 0.3243, 0.1464, 0.2128, 0.2451, 0.5359, 0.3807, 0.1754,\n",
       "                       0.2836, 0.4229, 0.1715, 0.2292, 0.2530, 0.3100, 0.2982, 0.2071, 0.2811,\n",
       "                       0.3327, 0.3631, 0.4038, 0.3258, 0.3728, 0.4816, 0.4483, 0.3649, 0.0929,\n",
       "                       0.3069, 0.3908, 0.2571, 0.2535, 0.3062, 0.2766, 0.1642, 0.4098, 0.3766,\n",
       "                       0.0954, 0.1840, 0.3587, 0.2951, 0.2387, 0.2783, 0.1915, 0.3209, 0.2191,\n",
       "                       0.1255, 0.2517, 0.2562, 0.3705, 0.3077, 0.3434, 0.3464, 0.2645, 0.2454,\n",
       "                       0.5013, 0.4810, 0.3030, 0.2890, 0.3864, 0.2535, 0.2609, 0.4271, 0.3416,\n",
       "                       0.3827, 0.2295, 0.3743, 0.2634, 0.3742, 0.2972, 0.2210, 0.3091, 0.1993,\n",
       "                       0.1941, 0.4315, 0.2662, 0.3909, 0.3806, 0.2675, 0.3407, 0.2210, 0.3253,\n",
       "                       0.4590, 0.2536, 0.3991, 0.3131, 0.3023, 0.2472, 0.3414, 0.3251, 0.1688,\n",
       "                       0.4186, 0.3122, 0.1707, 0.4180], device='cuda:0')),\n",
       "              ('layer3.1.bn1.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer3.1.conv2.weight',\n",
       "               tensor([[[[ 0.0011, -0.0118, -0.0010],\n",
       "                         [ 0.0159,  0.0102,  0.0095],\n",
       "                         [ 0.0033, -0.0069, -0.0019]],\n",
       "               \n",
       "                        [[ 0.0089,  0.0011,  0.0397],\n",
       "                         [-0.0350, -0.0220,  0.0241],\n",
       "                         [-0.0181, -0.0309, -0.0088]],\n",
       "               \n",
       "                        [[-0.0213, -0.0019, -0.0057],\n",
       "                         [ 0.0107, -0.0046, -0.0100],\n",
       "                         [-0.0042, -0.0074, -0.0067]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0083,  0.0091,  0.0079],\n",
       "                         [ 0.0109, -0.0006, -0.0096],\n",
       "                         [-0.0235, -0.0309, -0.0293]],\n",
       "               \n",
       "                        [[ 0.0107,  0.0216,  0.0241],\n",
       "                         [ 0.0023,  0.0134,  0.0204],\n",
       "                         [-0.0179, -0.0275,  0.0101]],\n",
       "               \n",
       "                        [[-0.0178, -0.0045, -0.0177],\n",
       "                         [ 0.0224,  0.0175, -0.0015],\n",
       "                         [ 0.0213,  0.0293, -0.0306]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0073,  0.0159,  0.0101],\n",
       "                         [ 0.0044, -0.0094, -0.0216],\n",
       "                         [-0.0209, -0.0147, -0.0018]],\n",
       "               \n",
       "                        [[-0.0259,  0.0167,  0.0088],\n",
       "                         [-0.0029,  0.0041,  0.0070],\n",
       "                         [ 0.0108, -0.0078,  0.0123]],\n",
       "               \n",
       "                        [[-0.0180, -0.0003, -0.0027],\n",
       "                         [-0.0103, -0.0043, -0.0120],\n",
       "                         [ 0.0018,  0.0025, -0.0094]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0120, -0.0136, -0.0103],\n",
       "                         [-0.0130, -0.0003,  0.0109],\n",
       "                         [ 0.0140,  0.0015,  0.0156]],\n",
       "               \n",
       "                        [[-0.0030,  0.0076,  0.0057],\n",
       "                         [ 0.0132,  0.0295,  0.0028],\n",
       "                         [ 0.0084, -0.0289, -0.0292]],\n",
       "               \n",
       "                        [[-0.0650, -0.0222, -0.0192],\n",
       "                         [-0.0336, -0.0013, -0.0196],\n",
       "                         [ 0.0214,  0.0122, -0.0021]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0208,  0.0043, -0.0211],\n",
       "                         [-0.0265, -0.0226, -0.0434],\n",
       "                         [ 0.0308, -0.0125, -0.0117]],\n",
       "               \n",
       "                        [[ 0.0020,  0.0132,  0.0294],\n",
       "                         [-0.0076, -0.0037, -0.0118],\n",
       "                         [ 0.0177,  0.0181, -0.0259]],\n",
       "               \n",
       "                        [[ 0.0025,  0.0283,  0.0061],\n",
       "                         [ 0.0390,  0.0242, -0.0008],\n",
       "                         [ 0.0582,  0.0099, -0.0182]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0148,  0.0222, -0.0146],\n",
       "                         [-0.0039,  0.0057, -0.0215],\n",
       "                         [ 0.0066,  0.0131, -0.0097]],\n",
       "               \n",
       "                        [[ 0.0343,  0.0225,  0.0044],\n",
       "                         [ 0.0033, -0.0071, -0.0078],\n",
       "                         [-0.0272, -0.0468, -0.0521]],\n",
       "               \n",
       "                        [[-0.0203, -0.0036, -0.0094],\n",
       "                         [-0.0159, -0.0055, -0.0111],\n",
       "                         [ 0.0043, -0.0172,  0.0022]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0195, -0.0148, -0.0159],\n",
       "                         [ 0.0619, -0.0174, -0.0125],\n",
       "                         [ 0.0434,  0.0050, -0.0128]],\n",
       "               \n",
       "                        [[ 0.0121, -0.0109,  0.0043],\n",
       "                         [-0.0019,  0.0180, -0.0071],\n",
       "                         [ 0.0607,  0.0514,  0.0159]],\n",
       "               \n",
       "                        [[ 0.0311,  0.0216,  0.0304],\n",
       "                         [ 0.0072, -0.0170, -0.0084],\n",
       "                         [-0.0199, -0.0270, -0.0293]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0216, -0.0109, -0.0268],\n",
       "                         [ 0.0151, -0.0006, -0.0171],\n",
       "                         [ 0.0156,  0.0176,  0.0067]],\n",
       "               \n",
       "                        [[ 0.0206,  0.0128, -0.0046],\n",
       "                         [ 0.0019, -0.0014, -0.0162],\n",
       "                         [ 0.0164,  0.0172,  0.0035]],\n",
       "               \n",
       "                        [[-0.0398, -0.0352,  0.0042],\n",
       "                         [-0.0401, -0.0321,  0.0038],\n",
       "                         [-0.0528, -0.0187,  0.0353]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0078, -0.0377, -0.0230],\n",
       "                         [-0.0248, -0.0233, -0.0276],\n",
       "                         [-0.0220,  0.0010, -0.0119]],\n",
       "               \n",
       "                        [[-0.0084,  0.0063,  0.0375],\n",
       "                         [ 0.0022,  0.0038,  0.0145],\n",
       "                         [-0.0019, -0.0021,  0.0244]],\n",
       "               \n",
       "                        [[ 0.0041, -0.0036, -0.0032],\n",
       "                         [-0.0073, -0.0030, -0.0108],\n",
       "                         [-0.0079, -0.0157, -0.0005]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0465,  0.0210, -0.0075],\n",
       "                         [-0.0357,  0.0102,  0.0006],\n",
       "                         [-0.0122,  0.0123,  0.0122]],\n",
       "               \n",
       "                        [[-0.0206, -0.0150, -0.0228],\n",
       "                         [-0.0095, -0.0134, -0.0183],\n",
       "                         [-0.0115,  0.0054,  0.0046]],\n",
       "               \n",
       "                        [[ 0.0238, -0.0026,  0.0151],\n",
       "                         [ 0.0068, -0.0306, -0.0058],\n",
       "                         [ 0.0279, -0.0457, -0.0284]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0066, -0.0044, -0.0081],\n",
       "                         [ 0.0032, -0.0096, -0.0178],\n",
       "                         [ 0.0141,  0.0039, -0.0036]],\n",
       "               \n",
       "                        [[ 0.0061, -0.0019,  0.0276],\n",
       "                         [ 0.0162,  0.0266,  0.0248],\n",
       "                         [-0.0276,  0.0005,  0.0100]],\n",
       "               \n",
       "                        [[ 0.0166,  0.0059, -0.0029],\n",
       "                         [ 0.0265,  0.0090,  0.0019],\n",
       "                         [ 0.0118,  0.0088, -0.0029]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0056, -0.0158, -0.0106],\n",
       "                         [-0.0165,  0.0003, -0.0013],\n",
       "                         [ 0.0006, -0.0023, -0.0078]],\n",
       "               \n",
       "                        [[ 0.0055,  0.0031,  0.0093],\n",
       "                         [ 0.0343,  0.0436,  0.0253],\n",
       "                         [ 0.0294,  0.0182,  0.0182]],\n",
       "               \n",
       "                        [[-0.0268, -0.0166,  0.0077],\n",
       "                         [-0.0215, -0.0110,  0.0538],\n",
       "                         [ 0.0017, -0.0200,  0.0389]]]], device='cuda:0')),\n",
       "              ('layer3.1.bn2.weight',\n",
       "               tensor([ 0.2404,  0.2431,  0.3285,  0.2594,  0.2417,  0.2473,  0.0976,  0.1722,\n",
       "                        0.2180,  0.2984,  0.3025,  0.2545,  0.1678,  0.3555,  0.2728,  0.3095,\n",
       "                        0.0921,  0.3426,  0.1202,  0.1419,  0.1735,  0.2330,  0.3860,  0.2689,\n",
       "                       -0.0733,  0.2506,  0.2499,  0.1166,  0.2174,  0.0870,  0.2681,  0.2450,\n",
       "                        0.3372,  0.3161,  0.1865,  0.2704,  0.2171,  0.2316,  0.1658,  0.3018,\n",
       "                        0.3559,  0.1488,  0.0993,  0.2082,  0.1098,  0.2757,  0.4224,  0.1654,\n",
       "                        0.2295,  0.1657,  0.1843,  0.3056,  0.2566,  0.2079,  0.2635,  0.3804,\n",
       "                        0.1844,  0.2421,  0.3078,  0.2183,  0.2186,  0.2458,  0.1379,  0.3249,\n",
       "                        0.1798,  0.1127,  0.2711,  0.3051,  0.2707,  0.1801,  0.3218,  0.1911,\n",
       "                        0.2883,  0.1479,  0.1636,  0.2275,  0.2066,  0.2406,  0.3010,  0.3176,\n",
       "                        0.2132,  0.1058,  0.4037,  0.3000,  0.3045,  0.1685,  0.3214,  0.1494,\n",
       "                        0.2443,  0.1697,  0.1991,  0.2482,  0.3114,  0.2182,  0.1575,  0.2684,\n",
       "                        0.2714,  0.1598,  0.2528,  0.2060,  0.2799,  0.1108,  0.1640,  0.3445,\n",
       "                        0.1831,  0.3233,  0.2544,  0.3441,  0.2794,  0.3706,  0.1909,  0.1559,\n",
       "                        0.2173,  0.2688,  0.2844,  0.4097,  0.2328,  0.1904,  0.2234,  0.0507,\n",
       "                        0.2556,  0.2391,  0.3036,  0.1650,  0.3222,  0.2579,  0.3397,  0.3043,\n",
       "                        0.1113,  0.2490,  0.2963,  0.2175,  0.2987,  0.2496,  0.2589,  0.2885,\n",
       "                        0.2123,  0.3164,  0.2590,  0.2492,  0.2882,  0.2691,  0.3027,  0.1412,\n",
       "                        0.2786,  0.1417,  0.1981,  0.2670,  0.2224,  0.1289,  0.1901,  0.2313,\n",
       "                        0.1443,  0.3015,  0.2943,  0.1825,  0.2650,  0.2126,  0.4598,  0.3720,\n",
       "                        0.1990,  0.2924,  0.3055,  0.2640,  0.1951,  0.2163,  0.1822,  0.3562,\n",
       "                        0.0852,  0.1441,  0.3821,  0.2710,  0.2834,  0.2153,  0.1237,  0.2573,\n",
       "                        0.2834,  0.1305,  0.2201,  0.1767,  0.3179,  0.0980,  0.2313,  0.1419,\n",
       "                        0.3131,  0.0599,  0.2536,  0.3089,  0.1860,  0.2579,  0.1459,  0.2873,\n",
       "                        0.2246,  0.2280,  0.2895,  0.2826,  0.1748,  0.1538,  0.2087,  0.0892,\n",
       "                        0.2382,  0.3362,  0.1989,  0.2064,  0.1457,  0.2173,  0.3149,  0.1670,\n",
       "                        0.3965,  0.2463,  0.2120,  0.2551,  0.1838,  0.0210,  0.2665,  0.2137,\n",
       "                        0.1464,  0.4254,  0.1524,  0.1589,  0.0293,  0.1588,  0.3628,  0.2657,\n",
       "                        0.2054,  0.3178,  0.3019,  0.2666,  0.1338,  0.1838,  0.2722,  0.2447,\n",
       "                        0.1984,  0.3241,  0.2532,  0.2886,  0.3563,  0.2493,  0.3687,  0.2933,\n",
       "                        0.1907,  0.1529,  0.3104,  0.2800,  0.2308,  0.2534,  0.1607,  0.1024,\n",
       "                        0.3266,  0.2969,  0.2549,  0.1490,  0.0916,  0.2982,  0.2919,  0.1183],\n",
       "                      device='cuda:0')),\n",
       "              ('layer3.1.bn2.bias',\n",
       "               tensor([-0.2904, -0.1196, -0.1844, -0.1156, -0.1882, -0.0942, -0.1020, -0.0406,\n",
       "                       -0.1159, -0.1614, -0.2411, -0.1105, -0.2153, -0.2707, -0.1988, -0.1072,\n",
       "                       -0.1130, -0.2498, -0.0405, -0.0444, -0.1632, -0.2103, -0.2085, -0.2573,\n",
       "                        0.0016, -0.1656, -0.2622, -0.1312, -0.1771, -0.0042, -0.1659, -0.0593,\n",
       "                       -0.1517, -0.3206, -0.1842, -0.1558, -0.1817, -0.2203, -0.1250, -0.3021,\n",
       "                       -0.2132, -0.1262, -0.0739, -0.2934, -0.1538, -0.0986, -0.3379, -0.1095,\n",
       "                       -0.1438, -0.1047, -0.1753, -0.1497, -0.1620, -0.1560, -0.1240, -0.2243,\n",
       "                       -0.0394, -0.3096, -0.1984, -0.1895, -0.0637, -0.0791, -0.1093, -0.2665,\n",
       "                       -0.1046, -0.1796, -0.1628, -0.1241, -0.1195, -0.2090, -0.1915, -0.2211,\n",
       "                       -0.0724, -0.1280, -0.1754, -0.1765, -0.1294, -0.1604, -0.1620, -0.1310,\n",
       "                       -0.1030, -0.1577, -0.3672, -0.1840, -0.2851, -0.0815, -0.2328, -0.0961,\n",
       "                       -0.2141, -0.1586, -0.1133, -0.2035, -0.2647, -0.2025, -0.2518, -0.1614,\n",
       "                       -0.2332, -0.0874, -0.1900, -0.2387, -0.3304, -0.0656, -0.0774, -0.2198,\n",
       "                       -0.2567, -0.2409, -0.2811, -0.0759, -0.1848, -0.1587, -0.1256, -0.1701,\n",
       "                       -0.1402, -0.0870, -0.2203, -0.4663, -0.1818, -0.2136, -0.1967, -0.0303,\n",
       "                       -0.1913, -0.2509, -0.0407, -0.0019, -0.2580, -0.0435, -0.2102, -0.2933,\n",
       "                       -0.1084, -0.1945, -0.2755, -0.0636, -0.1736, -0.2510, -0.1792, -0.1765,\n",
       "                       -0.1807, -0.0877, -0.2599, -0.1401, -0.1959, -0.1315, -0.3769, -0.1363,\n",
       "                       -0.1915, -0.2216, -0.1441, -0.1482, -0.1924, -0.0962, -0.0602, -0.2790,\n",
       "                       -0.2665, -0.2630, -0.3007, -0.1722, -0.1878,  0.0400, -0.3755, -0.2260,\n",
       "                       -0.1609, -0.1327, -0.0925, -0.2662, -0.1871, -0.1939, -0.0673, -0.1961,\n",
       "                       -0.1069, -0.1713, -0.2773, -0.2061, -0.2339, -0.2021, -0.0695, -0.2268,\n",
       "                       -0.0270, -0.0546, -0.2693, -0.1567, -0.2422, -0.0662, -0.1157, -0.1623,\n",
       "                       -0.2130, -0.0292, -0.1066, -0.2278, -0.2377, -0.0964, -0.1233, -0.1952,\n",
       "                       -0.0934, -0.1733, -0.0855, -0.1426, -0.0512, -0.1036, -0.1017, -0.1233,\n",
       "                       -0.1396, -0.2490, -0.1229, -0.2113, -0.1580, -0.1092, -0.1895, -0.1713,\n",
       "                       -0.2260, -0.0696, -0.1989, -0.0988, -0.1438, -0.0187, -0.1324, -0.1837,\n",
       "                       -0.1328, -0.4227, -0.1947, -0.1104, -0.0391, -0.0950, -0.3119, -0.2855,\n",
       "                       -0.1880, -0.2914, -0.2938, -0.2258, -0.1564, -0.1667, -0.1510, -0.1075,\n",
       "                       -0.1926, -0.1922, -0.1400, -0.2457, -0.2373, -0.3321, -0.3247, -0.2789,\n",
       "                        0.0148, -0.1941, -0.2523, -0.0994, -0.1722, -0.2144, -0.1163, -0.0555,\n",
       "                       -0.2855, -0.1053, -0.1995, -0.1127, -0.1121, -0.2899, -0.2443, -0.0342],\n",
       "                      device='cuda:0')),\n",
       "              ('layer3.1.bn2.running_mean',\n",
       "               tensor([-0.1304, -0.2303, -0.2137,  0.1468, -0.1563, -0.2020, -0.0221, -0.2416,\n",
       "                       -0.2196, -0.1006, -0.1855,  0.1909, -0.2124, -0.1820, -0.2165, -0.4847,\n",
       "                       -0.1207, -0.2871, -0.1843, -0.2554, -0.1597, -0.0593, -0.2491, -0.2853,\n",
       "                       -0.1441, -0.3176, -0.1973, -0.2366, -0.2262, -0.0359, -0.2532, -0.0938,\n",
       "                       -0.2334, -0.2548, -0.2184, -0.1522, -0.0947,  0.0556, -0.0186, -0.2649,\n",
       "                       -0.1044, -0.2077, -0.0157, -0.3020, -0.0603, -0.1434, -0.3664,  0.0238,\n",
       "                       -0.2429,  0.1142, -0.1642,  0.0285, -0.1973, -0.2344, -0.1192, -0.1146,\n",
       "                       -0.1257, -0.1313, -0.1761, -0.2588, -0.1209, -0.2184, -0.1703, -0.3222,\n",
       "                        0.2190, -0.1175, -0.1548, -0.1202, -0.1266, -0.0218, -0.4518, -0.0552,\n",
       "                       -0.2366, -0.0591, -0.2206, -0.1519, -0.0801, -0.0931, -0.2034, -0.0466,\n",
       "                        0.0023,  0.3916, -0.0552, -0.1632, -0.1405, -0.0371,  0.0699, -0.1915,\n",
       "                       -0.1058, -0.1303, -0.2636, -0.2611, -0.0714, -0.2147, -0.0115,  0.0344,\n",
       "                       -0.2600,  0.1922, -0.2590,  0.1989, -0.2006, -0.1006, -0.1692, -0.2549,\n",
       "                        0.1464, -0.1998, -0.2157, -0.4121, -0.2409, -0.3286, -0.1575, -0.1270,\n",
       "                       -0.1971, -0.2922, -0.1250, -0.2219, -0.2598, -0.0789, -0.1079, -0.0504,\n",
       "                       -0.1113, -0.2583, -0.0881, -0.1735, -0.1731, -0.1101, -0.0821, -0.2952,\n",
       "                       -0.0937, -0.1331,  0.0056, -0.4433,  0.0056, -0.1401, -0.0696, -0.0729,\n",
       "                       -0.1930, -0.5033, -0.1279, -0.1989, -0.2493, -0.2523, -0.3253,  0.0664,\n",
       "                       -0.0012,  0.0950, -0.2090, -0.1719, -0.1932, -0.1554, -0.0489, -0.0370,\n",
       "                       -0.2056, -0.2018, -0.0481, -0.0347, -0.2137,  0.3685, -0.3106, -0.1944,\n",
       "                       -0.1254, -0.3329, -0.4351, -0.0879, -0.1824, -0.2481, -0.1666, -0.2979,\n",
       "                       -0.1719, -0.1939, -0.0259, -0.1333, -0.2307, -0.2067, -0.0564, -0.1128,\n",
       "                       -0.1152, -0.0993,  0.1441, -0.0293, -0.0324, -0.1077, -0.2666, -0.1868,\n",
       "                       -0.1519, -0.0423, -0.2474, -0.2985, -0.1988, -0.0474, -0.1790, -0.2070,\n",
       "                        0.1515, -0.0815, -0.1570, -0.1147, -0.2590,  0.0041, -0.3613, -0.1597,\n",
       "                       -0.1497, -0.2875,  0.0262, -0.2595, -0.1233, -0.2146,  0.0453, -0.2206,\n",
       "                       -0.3042, -0.0475, -0.1234, -0.1432, -0.1306, -0.0782, -0.2529, -0.1662,\n",
       "                       -0.2900, -0.0798, -0.1345, -0.2219, -0.1453,  0.0622, -0.2341, -0.1594,\n",
       "                       -0.2171, -0.0538, -0.2191, -0.0893, -0.1696, -0.2324, -0.0030,  0.1897,\n",
       "                        0.1750, -0.1907, -0.3310,  0.1484, -0.3083, -0.1289, -0.2075, -0.1866,\n",
       "                       -0.0551, -0.0788, -0.0520, -0.2847, -0.2423, -0.3328, -0.1966, -0.1018,\n",
       "                       -0.2029, -0.2923, -0.2079, -0.1186, -0.1299, -0.2175, -0.3539,  0.1132],\n",
       "                      device='cuda:0')),\n",
       "              ('layer3.1.bn2.running_var',\n",
       "               tensor([0.0322, 0.0430, 0.0459, 0.0348, 0.0335, 0.0352, 0.0089, 0.0454, 0.0473,\n",
       "                       0.0458, 0.0340, 0.0450, 0.0286, 0.0436, 0.0497, 0.1053, 0.0317, 0.0561,\n",
       "                       0.0376, 0.0386, 0.0146, 0.0334, 0.0557, 0.0552, 0.0226, 0.0546, 0.0443,\n",
       "                       0.0260, 0.0359, 0.0141, 0.0439, 0.0255, 0.0521, 0.0461, 0.0460, 0.0528,\n",
       "                       0.0352, 0.0506, 0.0229, 0.0732, 0.0800, 0.0225, 0.0170, 0.0433, 0.0273,\n",
       "                       0.0329, 0.0857, 0.0140, 0.0393, 0.0264, 0.0267, 0.0473, 0.0651, 0.0276,\n",
       "                       0.0459, 0.0663, 0.0166, 0.0407, 0.0539, 0.0438, 0.0436, 0.0385, 0.0257,\n",
       "                       0.0660, 0.0427, 0.0210, 0.0306, 0.0586, 0.0410, 0.0346, 0.0816, 0.0181,\n",
       "                       0.0532, 0.0215, 0.0228, 0.0366, 0.0332, 0.0443, 0.0552, 0.0611, 0.0374,\n",
       "                       0.0565, 0.0624, 0.0487, 0.0565, 0.0235, 0.0619, 0.0267, 0.0404, 0.0204,\n",
       "                       0.0366, 0.0386, 0.0435, 0.0338, 0.0191, 0.0502, 0.0484, 0.0258, 0.0475,\n",
       "                       0.0357, 0.0719, 0.0166, 0.0356, 0.0583, 0.0322, 0.0623, 0.0337, 0.0876,\n",
       "                       0.0425, 0.0677, 0.0334, 0.0293, 0.0384, 0.0613, 0.0459, 0.0789, 0.0435,\n",
       "                       0.0303, 0.0288, 0.0064, 0.0343, 0.0419, 0.0499, 0.0283, 0.0586, 0.0589,\n",
       "                       0.0558, 0.0857, 0.0234, 0.0369, 0.0387, 0.0707, 0.0342, 0.0484, 0.0480,\n",
       "                       0.0334, 0.0293, 0.0712, 0.0504, 0.0402, 0.0518, 0.0500, 0.0690, 0.0171,\n",
       "                       0.0431, 0.0237, 0.0381, 0.0417, 0.0321, 0.0205, 0.0296, 0.0390, 0.0341,\n",
       "                       0.0628, 0.0625, 0.0326, 0.0388, 0.0697, 0.0769, 0.0695, 0.0454, 0.0751,\n",
       "                       0.0663, 0.0414, 0.0490, 0.0308, 0.0336, 0.0554, 0.0332, 0.0342, 0.0570,\n",
       "                       0.0477, 0.0446, 0.0431, 0.0284, 0.0461, 0.0982, 0.0297, 0.0407, 0.0281,\n",
       "                       0.0544, 0.0249, 0.0555, 0.0261, 0.0500, 0.0172, 0.0510, 0.0549, 0.0389,\n",
       "                       0.0294, 0.0322, 0.0536, 0.0376, 0.0338, 0.0610, 0.0357, 0.0334, 0.0190,\n",
       "                       0.0479, 0.0293, 0.0480, 0.0582, 0.0250, 0.0423, 0.0237, 0.0413, 0.0488,\n",
       "                       0.0205, 0.0842, 0.0365, 0.0346, 0.0338, 0.0261, 0.0128, 0.0493, 0.0261,\n",
       "                       0.0278, 0.0848, 0.0195, 0.0209, 0.0109, 0.0319, 0.0656, 0.0527, 0.0399,\n",
       "                       0.0617, 0.0525, 0.0417, 0.0270, 0.0423, 0.0514, 0.0544, 0.0386, 0.0658,\n",
       "                       0.0471, 0.0515, 0.0742, 0.0443, 0.0597, 0.0684, 0.0639, 0.0293, 0.0336,\n",
       "                       0.0675, 0.0503, 0.0483, 0.0262, 0.0194, 0.0482, 0.0511, 0.0610, 0.0200,\n",
       "                       0.0172, 0.0441, 0.0444, 0.0299], device='cuda:0')),\n",
       "              ('layer3.1.bn2.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer4.0.conv1.weight',\n",
       "               tensor([[[[-5.5354e-03, -2.6108e-03, -1.2555e-02],\n",
       "                         [ 7.2680e-03, -7.3095e-04,  2.9739e-02],\n",
       "                         [ 1.5818e-02, -8.8150e-03,  1.0096e-02]],\n",
       "               \n",
       "                        [[-1.3166e-02, -1.8981e-02, -3.4210e-02],\n",
       "                         [ 2.6940e-02,  1.5430e-02,  2.4247e-03],\n",
       "                         [-4.0529e-03,  9.7698e-04,  2.0435e-03]],\n",
       "               \n",
       "                        [[-9.4003e-03, -1.4340e-02,  1.1506e-02],\n",
       "                         [-1.5560e-02, -5.3754e-03, -1.0926e-02],\n",
       "                         [-3.8395e-03, -6.5931e-03, -3.3202e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.4350e-02, -1.5938e-02,  4.3836e-03],\n",
       "                         [ 6.8980e-03, -2.1725e-02,  9.7676e-03],\n",
       "                         [ 1.0246e-02, -2.6097e-02, -1.4853e-02]],\n",
       "               \n",
       "                        [[-4.7425e-03, -7.0705e-03, -8.2211e-03],\n",
       "                         [-2.1918e-02,  5.4982e-03, -1.5220e-02],\n",
       "                         [-9.7165e-03, -1.1922e-02, -1.2301e-02]],\n",
       "               \n",
       "                        [[-2.8887e-02, -1.9174e-02, -1.2841e-02],\n",
       "                         [-1.5339e-02, -3.5974e-03, -5.1969e-03],\n",
       "                         [ 9.7838e-03, -2.3807e-02, -1.1868e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.0355e-02,  4.4546e-03, -1.3851e-02],\n",
       "                         [ 1.4050e-04,  1.3115e-02,  2.1058e-02],\n",
       "                         [ 2.3133e-02,  7.7650e-03,  4.9658e-02]],\n",
       "               \n",
       "                        [[ 6.3125e-03, -2.3348e-02, -8.0748e-03],\n",
       "                         [-8.4258e-05, -7.4857e-03,  8.3053e-03],\n",
       "                         [-4.6735e-03, -6.5231e-03, -2.3274e-03]],\n",
       "               \n",
       "                        [[-6.5643e-03, -2.3957e-02,  6.5861e-03],\n",
       "                         [-1.8701e-02, -2.9029e-02, -2.7359e-02],\n",
       "                         [ 2.9496e-02,  1.4656e-02,  1.3266e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 9.6425e-03,  1.4159e-02,  1.4403e-02],\n",
       "                         [ 7.3425e-03,  4.3940e-03, -4.5327e-03],\n",
       "                         [ 8.9590e-03,  1.5334e-02, -1.0967e-02]],\n",
       "               \n",
       "                        [[ 7.1079e-03,  2.0511e-02, -7.7070e-03],\n",
       "                         [-3.2072e-03,  4.7095e-03, -1.0559e-02],\n",
       "                         [-1.9226e-02, -1.3781e-02, -2.3227e-02]],\n",
       "               \n",
       "                        [[ 1.3744e-02,  2.3356e-02,  2.8738e-02],\n",
       "                         [-8.9915e-03,  1.1285e-02,  2.8376e-02],\n",
       "                         [-4.8242e-03,  1.2449e-02,  1.8702e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.9537e-03, -2.8387e-03,  1.1951e-02],\n",
       "                         [-7.8913e-03,  1.6577e-03,  1.1632e-02],\n",
       "                         [ 2.4379e-03, -4.5090e-03, -8.3151e-03]],\n",
       "               \n",
       "                        [[ 7.0876e-03,  6.4510e-04, -3.8417e-03],\n",
       "                         [-2.6191e-03, -1.1824e-02, -1.3387e-02],\n",
       "                         [-4.2968e-03, -1.2475e-02,  5.1202e-03]],\n",
       "               \n",
       "                        [[-7.4884e-03, -1.4032e-02,  1.6124e-03],\n",
       "                         [-3.3212e-03, -1.1091e-02, -1.8481e-03],\n",
       "                         [ 6.0633e-03,  7.3241e-04,  8.2445e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.2891e-02,  7.2384e-03, -6.4721e-03],\n",
       "                         [-1.5259e-02,  8.9337e-03,  7.4370e-03],\n",
       "                         [ 4.0862e-04, -5.9723e-03,  3.2128e-03]],\n",
       "               \n",
       "                        [[ 7.1456e-03, -3.6532e-03,  1.4113e-02],\n",
       "                         [-4.9872e-03,  9.0002e-03,  2.2895e-03],\n",
       "                         [-8.5897e-04, -8.0949e-04, -1.2855e-02]],\n",
       "               \n",
       "                        [[-1.5064e-02, -1.6003e-02,  1.3830e-03],\n",
       "                         [ 4.3638e-03, -8.1466e-03, -1.9440e-04],\n",
       "                         [ 4.9073e-03,  6.9053e-03,  2.0947e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 1.8923e-02,  1.0730e-02,  7.6794e-03],\n",
       "                         [ 8.9368e-03,  1.4575e-02,  2.2135e-02],\n",
       "                         [ 1.3978e-02,  2.9955e-02,  3.3965e-02]],\n",
       "               \n",
       "                        [[-1.1424e-03,  1.4216e-02,  1.7978e-02],\n",
       "                         [ 1.4105e-03,  6.1685e-03,  1.6386e-02],\n",
       "                         [ 1.8781e-03,  4.0828e-03,  7.1397e-04]],\n",
       "               \n",
       "                        [[-6.1253e-03, -8.8707e-03, -5.9282e-03],\n",
       "                         [ 2.2211e-02,  7.8872e-03,  8.8505e-03],\n",
       "                         [ 2.5278e-02,  2.6348e-02,  6.0362e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-7.8921e-03, -4.4426e-03, -9.7676e-03],\n",
       "                         [ 4.8068e-04, -1.1713e-02, -1.1005e-02],\n",
       "                         [ 1.0966e-02, -1.1121e-03, -9.9830e-03]],\n",
       "               \n",
       "                        [[-9.3550e-03,  1.9044e-03,  9.2395e-04],\n",
       "                         [-1.9802e-02, -6.3800e-03, -1.4687e-02],\n",
       "                         [-6.3822e-03, -1.9696e-02,  7.1271e-03]],\n",
       "               \n",
       "                        [[-1.7112e-02, -2.1608e-02, -7.0826e-03],\n",
       "                         [-3.0197e-02, -1.6666e-02, -4.5439e-03],\n",
       "                         [-1.5134e-02, -1.7757e-02, -6.3111e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.3327e-02,  1.8296e-04, -4.1062e-03],\n",
       "                         [-1.1663e-02, -1.0419e-02, -1.5171e-02],\n",
       "                         [ 4.0268e-03,  4.5139e-03, -1.2699e-02]],\n",
       "               \n",
       "                        [[-2.1950e-02,  6.5318e-03, -6.5543e-03],\n",
       "                         [ 4.8423e-02,  4.0479e-02, -3.2126e-02],\n",
       "                         [ 4.2639e-02,  1.9844e-02, -3.4800e-02]],\n",
       "               \n",
       "                        [[-2.5894e-02,  1.3616e-02,  1.3476e-02],\n",
       "                         [ 1.2863e-02,  1.8565e-02,  1.0683e-02],\n",
       "                         [ 1.4049e-02,  2.1388e-02,  1.5181e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.6868e-02, -9.1853e-03, -1.9264e-02],\n",
       "                         [-1.8044e-02, -2.0817e-02, -2.3438e-02],\n",
       "                         [ 7.0008e-03, -3.3240e-02, -3.2798e-02]],\n",
       "               \n",
       "                        [[-9.2574e-03,  1.8971e-04,  9.1681e-03],\n",
       "                         [-2.7717e-02,  2.0426e-03,  2.0207e-02],\n",
       "                         [ 2.0144e-04, -1.7562e-02,  2.5916e-02]],\n",
       "               \n",
       "                        [[ 1.2417e-02, -1.3337e-02, -3.4545e-03],\n",
       "                         [-3.9850e-03, -5.7786e-03, -1.8288e-02],\n",
       "                         [-9.6319e-04, -7.1805e-03,  5.4274e-05]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.6268e-03,  1.7449e-03,  8.5532e-03],\n",
       "                         [ 7.8514e-03,  9.8129e-03,  1.7355e-02],\n",
       "                         [-3.4711e-03,  7.0539e-03,  1.8050e-03]],\n",
       "               \n",
       "                        [[ 1.8308e-03, -1.5632e-02, -1.6623e-02],\n",
       "                         [ 7.4920e-03,  8.6718e-03,  1.3285e-02],\n",
       "                         [-1.7673e-02,  7.5530e-04,  1.7740e-03]],\n",
       "               \n",
       "                        [[ 7.8416e-03,  1.5437e-02,  3.1712e-04],\n",
       "                         [ 9.4175e-03, -2.7670e-03, -7.9413e-03],\n",
       "                         [-3.3178e-03, -6.2387e-03, -6.3358e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.4532e-03, -7.9169e-03, -6.3851e-03],\n",
       "                         [ 3.5907e-03, -1.3561e-02, -9.4481e-03],\n",
       "                         [-1.1491e-02, -6.0202e-03,  1.9051e-03]],\n",
       "               \n",
       "                        [[-6.3509e-03,  2.4419e-03, -6.5660e-03],\n",
       "                         [-1.3479e-02, -3.3775e-03, -1.3831e-02],\n",
       "                         [-1.1719e-02,  4.7822e-03, -1.9766e-03]],\n",
       "               \n",
       "                        [[ 6.5384e-03,  1.8981e-02,  1.6411e-02],\n",
       "                         [ 5.0384e-03, -3.7081e-03, -2.7725e-03],\n",
       "                         [-9.5976e-03, -1.7712e-02, -8.9764e-03]]]], device='cuda:0')),\n",
       "              ('layer4.0.bn1.weight',\n",
       "               tensor([0.1693, 0.2311, 0.1533, 0.3129, 0.1182, 0.1944, 0.2026, 0.2009, 0.1348,\n",
       "                       0.2277, 0.3034, 0.1317, 0.2135, 0.2066, 0.2022, 0.2291, 0.2163, 0.1843,\n",
       "                       0.1702, 0.2543, 0.1719, 0.2415, 0.2094, 0.1754, 0.1538, 0.2029, 0.1547,\n",
       "                       0.1880, 0.1439, 0.2349, 0.1000, 0.1877, 0.1985, 0.0947, 0.2429, 0.1856,\n",
       "                       0.2285, 0.2146, 0.2310, 0.1915, 0.1801, 0.2457, 0.2368, 0.2743, 0.1567,\n",
       "                       0.2152, 0.2469, 0.1524, 0.2159, 0.1617, 0.2077, 0.3153, 0.1467, 0.3001,\n",
       "                       0.1894, 0.2834, 0.2791, 0.2278, 0.1404, 0.1981, 0.2200, 0.2285, 0.1192,\n",
       "                       0.2473, 0.2320, 0.1774, 0.1692, 0.2256, 0.1496, 0.3052, 0.1904, 0.2085,\n",
       "                       0.1838, 0.1866, 0.2007, 0.2374, 0.2877, 0.1756, 0.2072, 0.2317, 0.2389,\n",
       "                       0.2531, 0.2726, 0.3008, 0.1645, 0.2225, 0.1476, 0.1814, 0.2096, 0.2514,\n",
       "                       0.1813, 0.1957, 0.1882, 0.2956, 0.1582, 0.1932, 0.1524, 0.2144, 0.1709,\n",
       "                       0.2370, 0.2820, 0.2460, 0.2804, 0.2586, 0.2727, 0.1559, 0.3878, 0.2765,\n",
       "                       0.1410, 0.1632, 0.2526, 0.2611, 0.1939, 0.1711, 0.2432, 0.1714, 0.2279,\n",
       "                       0.2721, 0.2303, 0.1629, 0.1921, 0.2077, 0.1957, 0.1920, 0.1295, 0.2231,\n",
       "                       0.2117, 0.2557, 0.1761, 0.2209, 0.1591, 0.0888, 0.2104, 0.2401, 0.2301,\n",
       "                       0.1251, 0.2445, 0.1797, 0.2009, 0.1649, 0.1682, 0.1774, 0.2636, 0.1951,\n",
       "                       0.1893, 0.2237, 0.2139, 0.2434, 0.3306, 0.2100, 0.1912, 0.2296, 0.1437,\n",
       "                       0.2961, 0.2082, 0.2578, 0.2266, 0.1632, 0.2439, 0.2164, 0.1537, 0.1916,\n",
       "                       0.1932, 0.2147, 0.1684, 0.2436, 0.1263, 0.3536, 0.1474, 0.2677, 0.1587,\n",
       "                       0.1761, 0.2540, 0.2182, 0.2408, 0.2046, 0.1461, 0.2120, 0.2760, 0.2660,\n",
       "                       0.1646, 0.1165, 0.1155, 0.2331, 0.2473, 0.1932, 0.1385, 0.2316, 0.1303,\n",
       "                       0.2178, 0.1995, 0.1987, 0.1813, 0.2605, 0.1975, 0.1215, 0.2465, 0.2174,\n",
       "                       0.2892, 0.1599, 0.1376, 0.1445, 0.1897, 0.1973, 0.2265, 0.1380, 0.2206,\n",
       "                       0.2465, 0.1414, 0.2217, 0.1548, 0.1128, 0.2199, 0.2069, 0.1848, 0.2658,\n",
       "                       0.1282, 0.1753, 0.2018, 0.2791, 0.3434, 0.1690, 0.1909, 0.2324, 0.2476,\n",
       "                       0.1603, 0.1456, 0.2145, 0.1885, 0.2335, 0.2019, 0.2300, 0.2690, 0.2209,\n",
       "                       0.1300, 0.2052, 0.2330, 0.2004, 0.2640, 0.2834, 0.2466, 0.2620, 0.1494,\n",
       "                       0.1753, 0.2886, 0.1986, 0.1989, 0.2244, 0.1604, 0.2039, 0.2043, 0.1901,\n",
       "                       0.1594, 0.2600, 0.1406, 0.3191, 0.1098, 0.2751, 0.1870, 0.2827, 0.2842,\n",
       "                       0.2107, 0.2302, 0.2047, 0.1764, 0.2570, 0.2731, 0.1648, 0.2682, 0.2508,\n",
       "                       0.2210, 0.1425, 0.2595, 0.1961, 0.1477, 0.1732, 0.2477, 0.1431, 0.2282,\n",
       "                       0.2671, 0.2571, 0.2123, 0.1339, 0.1521, 0.2591, 0.2238, 0.1747, 0.2426,\n",
       "                       0.2599, 0.3447, 0.1901, 0.1077, 0.1345, 0.2897, 0.2299, 0.3356, 0.2183,\n",
       "                       0.2262, 0.2374, 0.0881, 0.2418, 0.2005, 0.2514, 0.1558, 0.1912, 0.2163,\n",
       "                       0.2110, 0.2964, 0.1358, 0.1992, 0.2168, 0.1884, 0.2422, 0.1661, 0.2401,\n",
       "                       0.1948, 0.2015, 0.2249, 0.2346, 0.2188, 0.2115, 0.1700, 0.1689, 0.1804,\n",
       "                       0.2630, 0.2286, 0.1387, 0.2095, 0.1414, 0.1866, 0.2292, 0.1958, 0.1160,\n",
       "                       0.2108, 0.2140, 0.2343, 0.2007, 0.2262, 0.1813, 0.1810, 0.2215, 0.2031,\n",
       "                       0.1877, 0.2678, 0.2180, 0.1455, 0.1776, 0.1590, 0.2903, 0.2893, 0.1961,\n",
       "                       0.1447, 0.1714, 0.2226, 0.3044, 0.2205, 0.2652, 0.2215, 0.2134, 0.1691,\n",
       "                       0.2446, 0.1393, 0.2466, 0.2750, 0.2221, 0.2277, 0.2203, 0.2213, 0.2584,\n",
       "                       0.1781, 0.1021, 0.1792, 0.2006, 0.1810, 0.1862, 0.1317, 0.2344, 0.2183,\n",
       "                       0.2443, 0.1713, 0.2040, 0.1852, 0.2086, 0.1990, 0.1924, 0.1939, 0.2231,\n",
       "                       0.2065, 0.1971, 0.2279, 0.1926, 0.2280, 0.2378, 0.2491, 0.2777, 0.2776,\n",
       "                       0.2590, 0.2211, 0.1774, 0.3092, 0.2267, 0.2117, 0.2260, 0.0975, 0.2349,\n",
       "                       0.1747, 0.2814, 0.1815, 0.2152, 0.1089, 0.1793, 0.2157, 0.1984, 0.2540,\n",
       "                       0.1911, 0.1620, 0.1573, 0.2770, 0.2603, 0.1626, 0.2250, 0.2084, 0.1832,\n",
       "                       0.1234, 0.1196, 0.1363, 0.2517, 0.1633, 0.2334, 0.2592, 0.2270, 0.1781,\n",
       "                       0.1816, 0.1045, 0.1961, 0.1038, 0.2052, 0.2336, 0.2283, 0.2304, 0.2266,\n",
       "                       0.1827, 0.2503, 0.1027, 0.2911, 0.2312, 0.2587, 0.1806, 0.2182, 0.1400,\n",
       "                       0.2986, 0.1808, 0.1971, 0.2635, 0.2268, 0.1688, 0.1715, 0.1481, 0.1725,\n",
       "                       0.2352, 0.2000, 0.1726, 0.2015, 0.2075, 0.1354, 0.3278, 0.2989, 0.1567,\n",
       "                       0.2010, 0.2840, 0.1945, 0.2191, 0.1601, 0.2455, 0.1774, 0.2157, 0.2003,\n",
       "                       0.2805, 0.1689, 0.2160, 0.2207, 0.2229, 0.1770, 0.1529, 0.1835, 0.0919,\n",
       "                       0.3125, 0.2458, 0.2330, 0.2247, 0.2001, 0.1892, 0.1668, 0.2244, 0.2514,\n",
       "                       0.2191, 0.1807, 0.2655, 0.1754, 0.2248, 0.2405, 0.1867, 0.1259, 0.2605,\n",
       "                       0.2373, 0.1890, 0.1745, 0.2522, 0.1582, 0.1624, 0.2672, 0.1420],\n",
       "                      device='cuda:0')),\n",
       "              ('layer4.0.bn1.bias',\n",
       "               tensor([-0.1166, -0.1225, -0.0361, -0.1398, -0.0711, -0.1665, -0.0562, -0.1684,\n",
       "                       -0.1387, -0.1316, -0.0849,  0.0013, -0.1287, -0.1274, -0.1140, -0.0316,\n",
       "                       -0.1320, -0.1414, -0.1171, -0.1314, -0.0686, -0.1516, -0.0940, -0.1794,\n",
       "                       -0.0913, -0.1279, -0.0367, -0.0510, -0.0550, -0.1077, -0.0818, -0.1441,\n",
       "                       -0.0847, -0.0713, -0.1390, -0.0760, -0.1748, -0.1438, -0.0692, -0.1921,\n",
       "                       -0.1031, -0.1295, -0.1124, -0.1148, -0.0599, -0.1480, -0.1959, -0.0839,\n",
       "                       -0.1270, -0.1013, -0.0952, -0.0973, -0.0504, -0.1011, -0.1220, -0.0928,\n",
       "                       -0.1635, -0.1686, -0.1363, -0.1117, -0.1735, -0.1653, -0.0855, -0.1435,\n",
       "                       -0.1680, -0.1067, -0.0945, -0.1199, -0.0620, -0.2158, -0.0628, -0.1320,\n",
       "                       -0.1393, -0.1300, -0.1395, -0.1013, -0.0642, -0.1439, -0.1081, -0.1400,\n",
       "                       -0.1283, -0.1413,  0.0093, -0.0889, -0.1240, -0.1537, -0.1253, -0.1282,\n",
       "                       -0.1346, -0.0982, -0.1634, -0.0493, -0.1391, -0.1364, -0.0908, -0.1325,\n",
       "                       -0.0977, -0.0510, -0.1423, -0.1299, -0.1053, -0.1029, -0.0880, -0.1153,\n",
       "                       -0.1784, -0.0783, -0.1981, -0.1208, -0.1098, -0.0794, -0.0829, -0.2310,\n",
       "                       -0.1235, -0.0798, -0.1533, -0.1184, -0.1861, -0.1184, -0.1364, -0.1053,\n",
       "                       -0.1387, -0.1207, -0.2057, -0.1064, -0.0552, -0.1491, -0.1443, -0.1108,\n",
       "                       -0.0747, -0.1700, -0.0875, -0.0927, -0.1438, -0.0775, -0.1057, -0.0953,\n",
       "                       -0.1188, -0.1522, -0.1108, -0.1368, -0.1586, -0.0680, -0.1375, -0.1030,\n",
       "                       -0.1169, -0.1503, -0.0869, -0.1311, -0.1252, -0.0963, -0.1320, -0.2145,\n",
       "                       -0.0770, -0.1880, -0.0825, -0.1351, -0.0159, -0.0763, -0.1010, -0.1389,\n",
       "                       -0.0898, -0.1573, -0.0860, -0.0751, -0.0692, -0.0596, -0.0815, -0.2222,\n",
       "                       -0.0575, -0.1372, -0.0748, -0.0456, -0.1926, -0.0421, -0.1196, -0.0825,\n",
       "                       -0.0893, -0.1420, -0.1053, -0.1245, -0.0895, -0.1209, -0.1450, -0.1112,\n",
       "                       -0.0735, -0.1507, -0.1306, -0.2115, -0.0759, -0.1678, -0.1294, -0.0873,\n",
       "                       -0.1006, -0.0840, -0.1085, -0.1108, -0.1658, -0.1396, -0.1522, -0.1017,\n",
       "                       -0.0415, -0.0601, -0.0744, -0.0729, -0.0556, -0.0723, -0.1051, -0.1480,\n",
       "                       -0.1071, -0.0994, -0.0449, -0.0604, -0.0971, -0.0883, -0.1266, -0.1455,\n",
       "                       -0.1251, -0.1205, -0.1245, -0.1811, -0.2318, -0.1101, -0.1447, -0.0907,\n",
       "                       -0.1456, -0.0913, -0.0647, -0.0844, -0.0968, -0.1599, -0.1201, -0.1713,\n",
       "                       -0.0796, -0.1341, -0.1265, -0.0895, -0.1333, -0.1347, -0.1779, -0.1603,\n",
       "                       -0.1079, -0.1047, -0.1132, -0.1359, -0.1550, -0.0798, -0.0866, -0.0681,\n",
       "                       -0.1723, -0.0794, -0.1077, -0.1009, -0.0998, -0.0868, -0.0588, -0.2028,\n",
       "                       -0.1204, -0.1479, -0.0141, -0.1304, -0.0517, -0.1091, -0.1303, -0.0664,\n",
       "                       -0.0455, -0.1135, -0.2201, -0.1234, -0.1187, -0.1069, -0.1927, -0.0653,\n",
       "                       -0.1477, -0.0935, -0.1100, -0.1387, -0.0753, -0.1009, -0.0822, -0.1060,\n",
       "                       -0.0940, -0.0686, -0.0566, -0.1264, -0.1265, -0.1031, -0.0862, -0.0448,\n",
       "                       -0.1695, -0.2645, -0.1234, -0.0932, -0.0776, -0.0485, -0.0661, -0.1643,\n",
       "                       -0.1654, -0.1648, -0.1933, -0.0615, -0.0796, -0.0503, -0.1040, -0.0769,\n",
       "                       -0.1912, -0.0775, -0.0586, -0.0872, -0.0188, -0.1047, -0.1037, -0.1139,\n",
       "                       -0.1624, -0.0692, -0.0748, -0.0858, -0.0520, -0.1258, -0.0813, -0.0798,\n",
       "                       -0.0494, -0.1131, -0.1214, -0.1493, -0.0813, -0.0767, -0.0984, -0.0937,\n",
       "                       -0.0578, -0.1140, -0.1050, -0.0843, -0.0632, -0.1195, -0.0621, -0.1795,\n",
       "                       -0.0641, -0.0964, -0.0665, -0.1154, -0.1454, -0.2198, -0.0755, -0.0857,\n",
       "                       -0.1341, -0.1205, -0.1807, -0.0187, -0.1589, -0.2084, -0.0503, -0.1072,\n",
       "                       -0.1440, -0.1308, -0.1410, -0.0709, -0.1274, -0.1186, -0.0786, -0.0545,\n",
       "                       -0.1091, -0.1012, -0.1299, -0.0213, -0.1026, -0.1409, -0.0740, -0.1394,\n",
       "                       -0.1246, -0.1515, -0.1105, -0.0952, -0.0359, -0.0235, -0.1080, -0.0816,\n",
       "                       -0.1839, -0.2385, -0.1208, -0.1497, -0.2086, -0.1037, -0.1121, -0.1183,\n",
       "                       -0.0809, -0.0971, -0.1101, -0.1018, -0.1302, -0.1124, -0.1299, -0.1111,\n",
       "                       -0.1322, -0.1657, -0.2056, -0.1050, -0.0692, -0.1506, -0.1192, -0.1441,\n",
       "                       -0.0597, -0.0731, -0.1522, -0.0473, -0.1328, -0.1385, -0.1896, -0.2540,\n",
       "                       -0.1476, -0.1069, -0.0900, -0.1226, -0.1264, -0.1123, -0.1915, -0.1233,\n",
       "                       -0.1004, -0.1271, -0.1316, -0.0926, -0.1476, -0.0563, -0.1025, -0.0906,\n",
       "                       -0.1852, -0.1460, -0.1347, -0.0925, -0.1631, -0.0884, -0.1301, -0.0820,\n",
       "                       -0.1349, -0.0546, -0.0289, -0.1242, -0.0090, -0.0529, -0.0471, -0.0405,\n",
       "                       -0.2135, -0.1169, -0.1040, -0.0547, -0.0745, -0.1476, -0.1415, -0.0876,\n",
       "                       -0.0981, -0.0868, -0.1311, -0.0864, -0.0866, -0.0564, -0.1016, -0.1150,\n",
       "                       -0.0379, -0.0970, -0.0862, -0.1643, -0.0693, -0.1609, -0.1270, -0.1403,\n",
       "                       -0.1351, -0.1404, -0.0989, -0.0951, -0.0450, -0.0596, -0.1748, -0.0836,\n",
       "                       -0.1515, -0.0320, -0.1325, -0.0797, -0.1440, -0.1652, -0.1399, -0.0427,\n",
       "                       -0.1171, -0.1063, -0.1336, -0.0780, -0.1366, -0.1022, -0.2065, -0.0889,\n",
       "                       -0.1600, -0.0555, -0.2302, -0.1099, -0.1309, -0.1409, -0.1330, -0.0841,\n",
       "                       -0.0584, -0.1366, -0.0597, -0.1124, -0.0959, -0.0840, -0.0670, -0.0892,\n",
       "                       -0.0116, -0.1135, -0.1334, -0.1885, -0.1310, -0.1122, -0.1408, -0.0892],\n",
       "                      device='cuda:0')),\n",
       "              ('layer4.0.bn1.running_mean',\n",
       "               tensor([ 6.7418e-02, -5.5052e-02, -1.8896e-01,  2.5808e-03,  5.9186e-02,\n",
       "                       -4.8506e-01, -4.8241e-01, -2.9799e-01, -2.2725e-01, -3.6155e-01,\n",
       "                       -5.4605e-02, -2.7696e-01, -2.8401e-01, -2.6190e-02,  1.4662e-01,\n",
       "                       -5.4401e-01,  6.5706e-02, -5.1937e-02, -2.5344e-01, -4.0476e-01,\n",
       "                       -2.0256e-01, -5.2778e-01, -3.7256e-01, -5.0874e-02,  1.4614e-01,\n",
       "                       -1.2428e-01, -1.7579e-01, -5.6889e-01, -3.1262e-01,  1.3021e-02,\n",
       "                       -3.3434e-01,  7.1102e-02, -1.7760e-01,  1.8729e-01, -4.2787e-01,\n",
       "                       -3.8337e-01, -7.5943e-02,  8.6261e-02, -4.7710e-01, -8.0790e-02,\n",
       "                       -2.3865e-01, -2.9739e-01, -1.1870e-01, -5.8807e-01, -1.8411e-01,\n",
       "                       -1.4417e-01, -5.8324e-01, -3.8121e-01, -3.5528e-01, -1.5167e-01,\n",
       "                       -1.6463e-01, -3.5831e-01, -4.9137e-01, -5.1218e-01, -1.9359e-01,\n",
       "                       -5.6852e-01, -4.4599e-01, -3.0794e-01, -2.4954e-01, -3.0441e-01,\n",
       "                       -1.2009e-01, -8.0197e-02,  1.7681e-01, -3.0815e-01, -3.2086e-01,\n",
       "                        9.1636e-02, -1.8228e-01, -1.8867e-01,  7.6764e-02, -1.6688e-01,\n",
       "                       -2.8391e-01, -1.5431e-01, -5.4549e-01, -2.4359e-01, -3.4909e-01,\n",
       "                       -4.3738e-01, -5.5009e-01, -4.1069e-01, -6.3391e-01,  1.0581e-01,\n",
       "                       -3.6512e-01, -2.5664e-01, -4.8576e-01, -6.4587e-01, -1.8127e-01,\n",
       "                       -4.6284e-01,  1.2055e-02, -4.5963e-02, -3.8028e-01, -2.9070e-01,\n",
       "                       -4.2900e-01, -2.9657e-01, -1.5954e-01, -2.6180e-01, -2.5932e-01,\n",
       "                       -3.3314e-01,  2.7302e-02, -3.3474e-01, -1.0336e-02, -2.0435e-01,\n",
       "                       -4.9257e-01, -5.4955e-01, -3.6817e-01, -2.0447e-01, -8.1049e-02,\n",
       "                       -1.1109e-01, -4.1921e-01, -1.9170e-01, -1.6440e-01,  1.6717e-01,\n",
       "                       -2.0068e-01, -1.4414e-01, -3.2046e-02,  1.9528e-01, -3.8426e-01,\n",
       "                        2.2878e-02, -1.7210e-01, -9.5209e-02, -4.3826e-01, -4.1652e-01,\n",
       "                       -1.7797e-01, -1.9474e-01, -4.8698e-01, -3.6416e-01,  1.1449e-02,\n",
       "                       -3.4579e-01, -3.8342e-01, -1.0359e-01, -5.9027e-02, -1.0930e-01,\n",
       "                       -9.1073e-02,  1.5563e-02, -1.4361e-01, -3.0487e-01, -3.9339e-01,\n",
       "                       -2.0140e-01, -2.0892e-01, -3.3767e-01, -3.6575e-01, -3.2577e-01,\n",
       "                       -1.2422e-01, -3.2522e-01, -1.1619e-01, -2.6627e-01,  6.2468e-02,\n",
       "                       -2.3796e-01, -3.0087e-01, -1.8138e-01, -2.4615e-01, -3.9665e-01,\n",
       "                        3.6627e-02, -2.6848e-01, -2.8486e-01, -4.7638e-01, -5.0197e-01,\n",
       "                       -5.1078e-01, -3.5272e-02, -3.2918e-02,  1.0825e-02, -3.5725e-01,\n",
       "                       -1.6570e-01, -3.5741e-01,  7.5103e-02, -2.4619e-01, -1.5493e-01,\n",
       "                       -3.1880e-01, -1.0970e-01, -3.5904e-01, -2.1779e-01, -9.2578e-02,\n",
       "                       -3.8992e-01, -5.9602e-01, -2.9357e-01, -4.3293e-01, -4.3184e-01,\n",
       "                       -5.9198e-01,  9.7690e-02, -5.8798e-01, -6.0504e-02, -4.5523e-01,\n",
       "                        4.0531e-02, -3.8886e-02, -1.3016e-01, -3.9482e-01, -1.9814e-01,\n",
       "                       -2.0026e-01,  7.0620e-02, -2.7990e-01, -1.1312e-01, -3.2159e-01,\n",
       "                       -2.7867e-01, -4.3315e-01, -1.0803e-01, -6.2278e-01, -1.0293e-01,\n",
       "                       -1.5084e-02, -2.0740e-01, -7.6414e-02, -8.6162e-02, -9.2760e-02,\n",
       "                       -3.8443e-01, -1.6304e-01, -2.2731e-01, -1.7825e-01, -4.6597e-02,\n",
       "                       -1.4225e-01, -3.1970e-01, -1.0087e-01, -1.2536e-02, -3.4736e-01,\n",
       "                       -5.3363e-01,  1.8281e-01, -4.8938e-01, -4.0179e-01, -5.5647e-02,\n",
       "                       -1.2777e-02,  1.3681e-01, -7.6548e-02, -3.1299e-01, -1.1654e-01,\n",
       "                       -3.6071e-01, -2.0363e-01, -3.3012e-01, -3.7442e-01, -3.1955e-01,\n",
       "                       -2.5566e-01, -2.3411e-01, -4.0572e-01, -3.1895e-01, -4.3514e-01,\n",
       "                       -2.5065e-01,  1.4070e-01, -6.4075e-01, -3.6031e-01, -2.2668e-01,\n",
       "                       -3.8887e-01, -2.5495e-01, -7.5488e-02, -1.8585e-01, -1.0933e-01,\n",
       "                       -6.8111e-01, -4.7692e-01,  1.0841e-01, -3.2142e-01, -1.5875e-01,\n",
       "                       -3.9525e-01, -4.2555e-01, -4.2632e-01, -2.4668e-01, -4.4266e-01,\n",
       "                       -3.6867e-01, -2.2630e-01, -4.0439e-01, -4.7811e-01, -1.3747e-01,\n",
       "                       -4.0793e-01,  7.6504e-02, -1.3421e-01, -2.1795e-01, -5.4838e-01,\n",
       "                       -3.8414e-01, -2.8255e-01, -1.7057e-01, -5.5571e-01, -3.5811e-01,\n",
       "                       -4.5549e-02, -1.0387e-01, -5.2065e-02, -4.1087e-01, -1.7714e-01,\n",
       "                       -1.3980e-01, -3.0798e-01, -6.8613e-02, -2.4021e-01, -2.3798e-01,\n",
       "                       -2.6997e-01, -1.7864e-01, -1.0329e-01, -4.8496e-01, -4.3834e-02,\n",
       "                       -3.3206e-01, -3.8551e-01,  2.3159e-01, -1.6426e-01, -3.9054e-01,\n",
       "                       -3.9830e-01, -1.2910e-01, -5.8799e-01, -4.0626e-01, -2.3076e-01,\n",
       "                       -2.6937e-01,  9.4208e-02, -1.1150e-01, -6.1985e-02,  3.6625e-03,\n",
       "                       -2.5340e-01, -4.4820e-01, -3.7052e-02, -1.5031e-02, -1.3146e-01,\n",
       "                       -2.8164e-01, -2.0886e-01, -3.3246e-01, -3.8285e-01, -8.6192e-02,\n",
       "                        1.5203e-04, -4.8174e-01, -6.4812e-01, -3.8951e-01, -4.6679e-01,\n",
       "                       -1.6311e-01,  2.5377e-01, -3.3735e-01, -1.2281e-01, -5.4890e-01,\n",
       "                       -2.6584e-01, -3.9436e-01, -3.3351e-01, -2.7536e-01, -2.7269e-01,\n",
       "                       -4.4365e-01, -2.1493e-01, -6.1967e-02, -2.5723e-01, -4.3853e-01,\n",
       "                       -2.0989e-01, -2.9608e-01, -1.6173e-01, -1.1686e-01, -1.0970e-01,\n",
       "                       -1.7084e-01, -1.9002e-01, -4.1344e-01, -2.4444e-01, -3.0813e-01,\n",
       "                       -3.7564e-01, -3.3670e-01, -2.4195e-01, -2.3223e-01, -2.6395e-02,\n",
       "                       -2.5970e-01,  6.7788e-02, -3.6805e-01, -4.6736e-01, -4.4792e-01,\n",
       "                       -8.9629e-02, -1.8937e-01, -3.0570e-01, -1.0420e-01, -3.4299e-01,\n",
       "                       -2.8127e-01, -1.9423e-01, -2.1677e-01, -2.1396e-01, -2.8279e-01,\n",
       "                       -5.4689e-01, -2.9821e-01, -3.5525e-01, -2.4302e-01, -3.1001e-01,\n",
       "                       -1.5296e-01, -2.1436e-01, -9.2233e-02, -4.4127e-01, -1.4804e-01,\n",
       "                       -7.3122e-02, -9.0437e-02, -4.4366e-01, -1.4723e-01, -2.4162e-01,\n",
       "                        3.4287e-02, -2.2696e-01, -3.2233e-01, -4.4923e-01, -3.2269e-01,\n",
       "                       -2.0991e-02,  1.2492e-01, -4.0444e-01, -3.6817e-01, -1.6179e-02,\n",
       "                       -2.5787e-01, -8.3439e-02, -1.3241e-01, -4.0432e-01, -3.8541e-01,\n",
       "                       -5.4093e-01, -2.6786e-01, -3.7303e-01, -4.0715e-01, -2.1925e-01,\n",
       "                       -2.5098e-01, -2.0846e-02, -1.4865e-01, -1.9742e-01, -5.0382e-01,\n",
       "                       -2.1803e-01, -6.8833e-02, -2.3209e-01, -4.2481e-01, -1.4672e-01,\n",
       "                        9.6605e-02, -5.7481e-02, -1.9603e-01,  1.5498e-02, -3.3337e-01,\n",
       "                        2.0156e-02, -2.4415e-01, -5.0385e-01, -8.6299e-02,  8.4028e-02,\n",
       "                       -7.3481e-02, -5.1877e-01, -1.7792e-01, -1.8650e-01, -2.9655e-01,\n",
       "                       -4.3216e-01, -1.7893e-01, -6.1279e-01, -5.0103e-01, -8.9092e-02,\n",
       "                       -2.3935e-01, -3.2218e-01,  5.5683e-03,  7.9526e-02, -1.9422e-01,\n",
       "                        5.9177e-02, -3.7993e-01, -1.8456e-01, -3.0680e-01, -3.9839e-01,\n",
       "                       -3.3387e-01, -3.3022e-01, -2.6098e-01,  1.6983e-02, -4.8928e-01,\n",
       "                        1.7722e-01, -1.8513e-01, -6.6227e-01, -6.1233e-01,  6.0940e-02,\n",
       "                       -3.6642e-01, -3.7158e-01, -2.0915e-01,  4.8095e-02,  1.4661e-01,\n",
       "                       -1.1229e-01, -1.6378e-01, -4.9367e-01, -2.4664e-01, -1.8562e-01,\n",
       "                       -4.4257e-01, -3.0429e-01, -3.3985e-01, -3.8763e-01, -1.6824e-01,\n",
       "                       -1.1061e-01, -1.7722e-01, -2.7439e-01, -2.6982e-01, -3.5880e-01,\n",
       "                       -3.4507e-01, -8.6749e-02, -4.2241e-01, -1.9224e-01, -2.8003e-01,\n",
       "                       -5.8095e-01, -3.8022e-01,  2.8381e-02, -3.6558e-01, -2.0270e-01,\n",
       "                       -1.7233e-01, -1.4266e-01, -2.6406e-01, -2.5242e-01, -1.8247e-01,\n",
       "                       -2.0274e-01, -1.7754e-01, -2.7029e-01, -5.4623e-02, -4.9191e-01,\n",
       "                       -7.8874e-02, -1.0455e-01, -2.5183e-01, -3.9896e-01, -4.5931e-01,\n",
       "                       -5.0991e-02, -4.7542e-01, -6.9379e-01, -2.2916e-01, -2.3721e-01,\n",
       "                       -3.2670e-01, -2.3736e-01,  2.5555e-02, -4.1395e-01, -3.3550e-01,\n",
       "                       -1.6788e-01, -2.7099e-01, -8.8919e-02, -4.7272e-01, -3.1952e-01,\n",
       "                       -3.6995e-01, -3.4187e-01,  5.0361e-02, -4.0878e-01, -3.8917e-01,\n",
       "                       -4.8244e-01, -2.3066e-01, -3.1927e-01, -2.2392e-01, -1.8675e-01,\n",
       "                       -2.0840e-01, -1.6909e-01], device='cuda:0')),\n",
       "              ('layer4.0.bn1.running_var',\n",
       "               tensor([0.0891, 0.1787, 0.0786, 0.2948, 0.0324, 0.1664, 0.1484, 0.1077, 0.0605,\n",
       "                       0.2973, 0.3033, 0.1042, 0.1543, 0.0837, 0.1135, 0.2303, 0.1621, 0.1713,\n",
       "                       0.0741, 0.1972, 0.1375, 0.2131, 0.1877, 0.1800, 0.0995, 0.1255, 0.0593,\n",
       "                       0.1384, 0.1071, 0.2558, 0.1361, 0.1311, 0.1473, 0.0301, 0.2167, 0.1231,\n",
       "                       0.1777, 0.0895, 0.1748, 0.1427, 0.2114, 0.2961, 0.2553, 0.1662, 0.0984,\n",
       "                       0.1256, 0.2437, 0.1169, 0.1136, 0.0668, 0.1280, 0.3155, 0.1428, 0.2685,\n",
       "                       0.1550, 0.1997, 0.2797, 0.1707, 0.0959, 0.1691, 0.2235, 0.1669, 0.0385,\n",
       "                       0.2230, 0.1702, 0.0715, 0.1324, 0.1160, 0.0579, 0.2459, 0.1486, 0.1231,\n",
       "                       0.2376, 0.1815, 0.1584, 0.2502, 0.1668, 0.1192, 0.3045, 0.1902, 0.1733,\n",
       "                       0.2058, 0.2988, 0.3026, 0.1934, 0.1764, 0.1734, 0.1125, 0.2532, 0.1648,\n",
       "                       0.1701, 0.0942, 0.1412, 0.2682, 0.0902, 0.0850, 0.2434, 0.1468, 0.2746,\n",
       "                       0.1863, 0.2659, 0.2341, 0.2592, 0.1602, 0.2795, 0.0930, 0.3307, 0.1875,\n",
       "                       0.0964, 0.0620, 0.1196, 0.3137, 0.1204, 0.1025, 0.2129, 0.0705, 0.1795,\n",
       "                       0.1901, 0.1911, 0.1740, 0.2473, 0.1537, 0.2316, 0.1292, 0.0365, 0.2308,\n",
       "                       0.2220, 0.1377, 0.0942, 0.1822, 0.0627, 0.0719, 0.1872, 0.1502, 0.1555,\n",
       "                       0.0726, 0.1638, 0.1623, 0.0967, 0.1785, 0.1352, 0.1657, 0.2160, 0.0884,\n",
       "                       0.1046, 0.2138, 0.2012, 0.1488, 0.1983, 0.2089, 0.2082, 0.2123, 0.0822,\n",
       "                       0.2377, 0.1531, 0.2035, 0.2142, 0.1313, 0.2405, 0.2011, 0.1257, 0.2374,\n",
       "                       0.0576, 0.1537, 0.0864, 0.1791, 0.0519, 0.2724, 0.0878, 0.1674, 0.0905,\n",
       "                       0.1523, 0.1519, 0.1573, 0.2428, 0.1621, 0.0582, 0.1946, 0.2693, 0.2145,\n",
       "                       0.1076, 0.0724, 0.1032, 0.1757, 0.1767, 0.1505, 0.0593, 0.1820, 0.0696,\n",
       "                       0.1833, 0.1413, 0.3374, 0.0683, 0.2350, 0.1320, 0.0664, 0.2436, 0.1384,\n",
       "                       0.2133, 0.0673, 0.0900, 0.0662, 0.1237, 0.1071, 0.1550, 0.0628, 0.2470,\n",
       "                       0.2100, 0.0881, 0.2049, 0.1120, 0.0425, 0.1983, 0.1926, 0.1297, 0.1479,\n",
       "                       0.0894, 0.1402, 0.1125, 0.1813, 0.3478, 0.1153, 0.2244, 0.1968, 0.1956,\n",
       "                       0.0667, 0.0922, 0.1907, 0.1640, 0.1355, 0.1947, 0.1585, 0.2434, 0.1201,\n",
       "                       0.1337, 0.1584, 0.1761, 0.1969, 0.1732, 0.1545, 0.2419, 0.2441, 0.0676,\n",
       "                       0.1443, 0.2560, 0.1026, 0.1834, 0.2260, 0.1038, 0.1908, 0.1416, 0.1244,\n",
       "                       0.2170, 0.2400, 0.1164, 0.2459, 0.0743, 0.2153, 0.1786, 0.2777, 0.2981,\n",
       "                       0.1252, 0.1560, 0.1491, 0.1747, 0.1920, 0.1990, 0.0849, 0.1730, 0.1749,\n",
       "                       0.1440, 0.1545, 0.2004, 0.1393, 0.1009, 0.1159, 0.1679, 0.1211, 0.1405,\n",
       "                       0.1611, 0.2422, 0.1185, 0.0793, 0.1705, 0.2617, 0.2289, 0.1284, 0.1709,\n",
       "                       0.2116, 0.2098, 0.1633, 0.0519, 0.0884, 0.3225, 0.1868, 0.3928, 0.2916,\n",
       "                       0.1359, 0.2066, 0.0399, 0.1795, 0.1780, 0.1560, 0.1081, 0.1131, 0.0693,\n",
       "                       0.2173, 0.2943, 0.0815, 0.1360, 0.1832, 0.0804, 0.2350, 0.0627, 0.3083,\n",
       "                       0.1610, 0.2107, 0.1725, 0.1843, 0.2564, 0.2024, 0.1635, 0.1429, 0.0939,\n",
       "                       0.2230, 0.1356, 0.1050, 0.1703, 0.0584, 0.1113, 0.1563, 0.1176, 0.1372,\n",
       "                       0.1503, 0.2658, 0.1629, 0.1533, 0.1404, 0.1899, 0.1154, 0.1394, 0.1780,\n",
       "                       0.1601, 0.2806, 0.1905, 0.0886, 0.2196, 0.1462, 0.2640, 0.2311, 0.0978,\n",
       "                       0.0912, 0.1175, 0.1916, 0.3708, 0.2176, 0.2758, 0.1474, 0.1173, 0.2463,\n",
       "                       0.2416, 0.0510, 0.0985, 0.1982, 0.2303, 0.1939, 0.2430, 0.2498, 0.2193,\n",
       "                       0.1330, 0.0374, 0.1476, 0.1529, 0.1753, 0.1458, 0.0971, 0.1609, 0.2597,\n",
       "                       0.3383, 0.0846, 0.1881, 0.1143, 0.1428, 0.1784, 0.1313, 0.1591, 0.1523,\n",
       "                       0.1355, 0.1359, 0.1873, 0.1900, 0.1592, 0.2281, 0.1446, 0.2971, 0.1524,\n",
       "                       0.1354, 0.1898, 0.1305, 0.2396, 0.1699, 0.1141, 0.2600, 0.0225, 0.1360,\n",
       "                       0.1626, 0.2274, 0.2311, 0.1107, 0.0379, 0.1723, 0.1635, 0.0878, 0.1532,\n",
       "                       0.2018, 0.1495, 0.0677, 0.2830, 0.2055, 0.0766, 0.2167, 0.2657, 0.0814,\n",
       "                       0.0598, 0.1218, 0.1161, 0.2107, 0.1226, 0.2897, 0.2601, 0.2332, 0.1466,\n",
       "                       0.1397, 0.0341, 0.1972, 0.0434, 0.1805, 0.2692, 0.1411, 0.2737, 0.2600,\n",
       "                       0.1407, 0.2237, 0.0357, 0.3207, 0.2056, 0.2435, 0.2600, 0.1817, 0.1184,\n",
       "                       0.2358, 0.1112, 0.1394, 0.2080, 0.2021, 0.1333, 0.2538, 0.0948, 0.1087,\n",
       "                       0.2467, 0.0929, 0.1039, 0.1807, 0.2186, 0.1316, 0.2980, 0.2755, 0.0941,\n",
       "                       0.1344, 0.1698, 0.1046, 0.1584, 0.1364, 0.1636, 0.1243, 0.1365, 0.1998,\n",
       "                       0.2812, 0.2349, 0.1105, 0.1021, 0.1545, 0.1363, 0.1294, 0.2982, 0.0579,\n",
       "                       0.3011, 0.3106, 0.1838, 0.1513, 0.2652, 0.0940, 0.0897, 0.1639, 0.2623,\n",
       "                       0.1527, 0.2075, 0.2676, 0.1537, 0.1929, 0.2759, 0.1274, 0.0429, 0.1704,\n",
       "                       0.1761, 0.1286, 0.1566, 0.2725, 0.1170, 0.0839, 0.2093, 0.1019],\n",
       "                      device='cuda:0')),\n",
       "              ('layer4.0.bn1.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer4.0.conv2.weight',\n",
       "               tensor([[[[ 2.6192e-03, -3.1673e-03,  1.6263e-03],\n",
       "                         [-3.3143e-03, -5.5848e-03, -5.9431e-03],\n",
       "                         [-9.2521e-04, -2.0621e-03,  2.1682e-03]],\n",
       "               \n",
       "                        [[ 5.9096e-03, -2.9197e-03,  2.0775e-03],\n",
       "                         [ 1.3730e-03,  3.5082e-03, -9.0557e-03],\n",
       "                         [ 5.4528e-03, -4.0488e-03,  4.4396e-03]],\n",
       "               \n",
       "                        [[-1.2963e-03,  1.6197e-02, -4.7692e-03],\n",
       "                         [-5.0985e-03,  6.6292e-03, -8.6242e-03],\n",
       "                         [-1.0283e-03, -9.8779e-04, -4.6668e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-6.1351e-04, -8.4138e-03, -5.0643e-03],\n",
       "                         [ 1.1150e-03, -6.4274e-03, -4.1098e-03],\n",
       "                         [ 8.6044e-04,  6.5824e-03, -1.4193e-02]],\n",
       "               \n",
       "                        [[ 1.5343e-02,  1.0961e-02,  6.3740e-03],\n",
       "                         [ 1.1182e-02,  1.6605e-02, -1.0134e-02],\n",
       "                         [-7.8969e-03,  6.3779e-03, -2.2781e-02]],\n",
       "               \n",
       "                        [[-2.0056e-02,  6.4007e-03, -9.1025e-04],\n",
       "                         [-1.8720e-02,  1.8949e-02, -4.3761e-03],\n",
       "                         [-6.4984e-04,  2.8319e-02, -6.5018e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.4317e-02,  9.6354e-03, -4.3643e-03],\n",
       "                         [-1.3048e-02, -1.3010e-03, -4.7314e-05],\n",
       "                         [ 6.3131e-03, -3.8401e-03,  6.0118e-03]],\n",
       "               \n",
       "                        [[ 2.0434e-02,  9.4777e-03,  1.2166e-03],\n",
       "                         [-2.5642e-03, -1.7724e-02,  5.1573e-03],\n",
       "                         [-1.1595e-02,  1.9483e-03, -1.0561e-02]],\n",
       "               \n",
       "                        [[ 1.2990e-02,  9.4382e-03,  1.7573e-02],\n",
       "                         [-1.0543e-02, -6.2065e-03, -1.5755e-03],\n",
       "                         [-3.2566e-03, -3.0264e-03,  5.8638e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.5641e-02, -1.0366e-03, -1.8713e-03],\n",
       "                         [ 3.5730e-03,  1.4888e-02,  4.9714e-03],\n",
       "                         [ 8.2676e-03,  2.1024e-02,  9.7858e-03]],\n",
       "               \n",
       "                        [[ 7.4937e-03,  1.4127e-02, -2.6840e-02],\n",
       "                         [ 1.6217e-02,  2.4961e-02,  5.4528e-03],\n",
       "                         [ 1.6302e-02,  1.2805e-02, -9.9887e-04]],\n",
       "               \n",
       "                        [[ 3.8246e-03, -6.3624e-03,  2.7845e-03],\n",
       "                         [-9.1355e-03, -9.7235e-03,  8.0120e-03],\n",
       "                         [-9.6046e-03,  6.2261e-03,  1.0782e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.3189e-02,  2.4591e-02,  1.4068e-02],\n",
       "                         [ 1.3045e-03,  1.7487e-02,  1.8291e-03],\n",
       "                         [ 1.0194e-02,  8.5158e-03,  2.0888e-03]],\n",
       "               \n",
       "                        [[ 7.7512e-03,  6.5111e-03, -7.4148e-03],\n",
       "                         [-9.7109e-03,  9.8466e-03, -5.6909e-03],\n",
       "                         [ 4.8978e-03,  1.7934e-02,  1.2756e-02]],\n",
       "               \n",
       "                        [[ 1.4152e-02,  1.6385e-02,  8.5919e-03],\n",
       "                         [ 2.2534e-03,  7.8553e-03, -6.5590e-03],\n",
       "                         [ 9.4554e-03,  1.0096e-02, -1.3038e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.1326e-02,  8.7246e-03, -1.4411e-03],\n",
       "                         [ 1.1483e-02, -3.8631e-03,  4.4424e-04],\n",
       "                         [ 1.8395e-03, -4.9388e-03,  1.6589e-03]],\n",
       "               \n",
       "                        [[ 2.4644e-03,  1.9573e-02,  3.6773e-02],\n",
       "                         [ 1.0551e-02,  7.7017e-03,  3.1616e-03],\n",
       "                         [-1.2147e-03,  2.6387e-03, -1.3580e-02]],\n",
       "               \n",
       "                        [[-3.6965e-03, -1.4543e-03, -8.2141e-03],\n",
       "                         [ 1.1446e-03, -2.6130e-03, -2.4834e-03],\n",
       "                         [ 7.0426e-03,  4.7973e-03, -2.7357e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-5.2096e-03, -1.4235e-02, -3.0978e-03],\n",
       "                         [-6.4352e-03, -8.9054e-03, -2.0263e-02],\n",
       "                         [-1.7724e-03, -9.1505e-04,  3.1884e-03]],\n",
       "               \n",
       "                        [[ 1.4758e-02,  1.1696e-02,  1.4687e-02],\n",
       "                         [ 7.2919e-03,  9.3798e-03,  2.4919e-03],\n",
       "                         [-1.4456e-02, -1.3555e-02, -1.6471e-02]],\n",
       "               \n",
       "                        [[-1.3848e-02, -2.3785e-02, -1.5988e-02],\n",
       "                         [ 1.2902e-02, -1.2046e-02, -1.1430e-02],\n",
       "                         [ 2.1023e-02,  1.5213e-02,  6.7307e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.4031e-03,  1.6177e-03,  8.2938e-04],\n",
       "                         [ 4.7612e-03, -6.3263e-03, -3.6352e-03],\n",
       "                         [-7.6884e-03, -9.8445e-03, -5.0030e-03]],\n",
       "               \n",
       "                        [[-2.6027e-03, -1.1083e-02,  1.8872e-02],\n",
       "                         [-2.7685e-03, -8.1254e-03, -7.1099e-03],\n",
       "                         [-2.2215e-03, -3.2981e-03, -2.9740e-04]],\n",
       "               \n",
       "                        [[ 7.9807e-03, -9.1403e-03, -6.2308e-03],\n",
       "                         [-1.1672e-02, -2.9576e-03,  2.2946e-03],\n",
       "                         [ 9.9802e-03,  1.1269e-02,  9.3631e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 6.1236e-03,  6.6844e-03, -7.3622e-05],\n",
       "                         [ 1.9599e-03,  1.0363e-02,  7.0099e-03],\n",
       "                         [ 1.3254e-02,  1.6833e-02,  4.6395e-03]],\n",
       "               \n",
       "                        [[ 8.1401e-03,  2.0528e-03,  2.5656e-03],\n",
       "                         [ 5.7469e-03, -1.5484e-02,  5.2817e-03],\n",
       "                         [-3.4968e-03, -2.5879e-02, -1.2298e-02]],\n",
       "               \n",
       "                        [[-4.5079e-03, -1.8974e-03,  7.5036e-03],\n",
       "                         [ 9.3061e-04,  4.4463e-03, -1.2010e-03],\n",
       "                         [ 8.0332e-03,  1.8592e-02,  1.1188e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.0390e-03, -1.7591e-03, -9.1509e-04],\n",
       "                         [-1.0431e-02,  3.4922e-03, -4.4334e-03],\n",
       "                         [-1.4479e-02, -1.0137e-03, -2.3076e-03]],\n",
       "               \n",
       "                        [[ 9.5247e-03, -2.2772e-03, -5.0169e-03],\n",
       "                         [ 2.1142e-02, -2.0816e-02, -2.2887e-02],\n",
       "                         [ 6.0090e-03, -1.1528e-02,  2.0277e-03]],\n",
       "               \n",
       "                        [[-8.1807e-03, -1.0521e-02, -1.2175e-02],\n",
       "                         [ 2.5164e-03, -1.5419e-03, -8.4507e-03],\n",
       "                         [ 7.4156e-03,  6.6955e-03,  9.8061e-04]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.8647e-04,  1.2028e-02,  7.6635e-03],\n",
       "                         [ 6.4765e-03,  4.2967e-03, -1.4837e-05],\n",
       "                         [-1.5970e-02,  2.5985e-03, -1.4090e-02]],\n",
       "               \n",
       "                        [[-1.6291e-02, -1.3993e-02,  1.5706e-02],\n",
       "                         [ 7.7546e-03,  1.1916e-02,  8.7791e-03],\n",
       "                         [ 3.1183e-02,  8.2994e-03,  2.9022e-03]],\n",
       "               \n",
       "                        [[ 1.4523e-02,  4.1042e-03,  2.9967e-03],\n",
       "                         [ 3.2179e-03, -1.0816e-03,  6.2405e-03],\n",
       "                         [-1.7833e-03, -8.1530e-03, -1.4603e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.1873e-02, -1.6842e-02, -6.4121e-03],\n",
       "                         [-3.9041e-03,  2.6088e-04,  2.3086e-03],\n",
       "                         [-1.9602e-02, -2.3690e-02, -2.8532e-02]],\n",
       "               \n",
       "                        [[ 8.0918e-03, -5.6796e-03, -1.7240e-02],\n",
       "                         [-1.8339e-02, -6.7259e-03, -3.5193e-02],\n",
       "                         [-1.6224e-02, -8.0210e-03, -2.8834e-02]],\n",
       "               \n",
       "                        [[ 1.2860e-03, -1.3931e-02, -2.7094e-02],\n",
       "                         [-7.4923e-03,  5.4086e-03, -1.0151e-02],\n",
       "                         [-3.1787e-03,  1.6735e-02, -1.0635e-02]]]], device='cuda:0')),\n",
       "              ('layer4.0.bn2.weight',\n",
       "               tensor([0.2517, 0.2962, 0.2502, 0.1605, 0.1684, 0.2802, 0.3352, 0.1979, 0.2772,\n",
       "                       0.3000, 0.1705, 0.4206, 0.1958, 0.3220, 0.0853, 0.1605, 0.3187, 0.2542,\n",
       "                       0.2067, 0.2798, 0.1405, 0.3039, 0.1993, 0.1268, 0.2989, 0.3275, 0.2079,\n",
       "                       0.1219, 0.1364, 0.1765, 0.1950, 0.2357, 0.2456, 0.2044, 0.2360, 0.2955,\n",
       "                       0.2870, 0.1225, 0.2369, 0.2201, 0.1738, 0.2528, 0.1405, 0.1458, 0.1782,\n",
       "                       0.2293, 0.2335, 0.2386, 0.3040, 0.2746, 0.2015, 0.2449, 0.2141, 0.4762,\n",
       "                       0.2082, 0.1812, 0.2644, 0.2732, 0.2347, 0.1689, 0.1722, 0.2443, 0.1128,\n",
       "                       0.2901, 0.1393, 0.2098, 0.1694, 0.3005, 0.2291, 0.2264, 0.2008, 0.2697,\n",
       "                       0.1269, 0.0821, 0.2369, 0.2725, 0.3181, 0.2280, 0.2058, 0.2838, 0.1217,\n",
       "                       0.3582, 0.3833, 0.1322, 0.3385, 0.2248, 0.2179, 0.1007, 0.1794, 0.2671,\n",
       "                       0.2855, 0.1644, 0.2885, 0.1597, 0.2885, 0.3818, 0.2001, 0.1656, 0.1947,\n",
       "                       0.2578, 0.2528, 0.2362, 0.1815, 0.2401, 0.2364, 0.2907, 0.3474, 0.2288,\n",
       "                       0.1019, 0.3315, 0.2342, 0.1893, 0.2722, 0.3125, 0.1999, 0.2564, 0.2290,\n",
       "                       0.2166, 0.4089, 0.1342, 0.2553, 0.1282, 0.2901, 0.2654, 0.2260, 0.2115,\n",
       "                       0.3354, 0.1299, 0.2628, 0.2658, 0.1625, 0.2673, 0.2880, 0.0609, 0.1450,\n",
       "                       0.2328, 0.1672, 0.2538, 0.0878, 0.1874, 0.1862, 0.2734, 0.2125, 0.2571,\n",
       "                       0.2437, 0.3138, 0.2498, 0.1717, 0.2109, 0.3317, 0.3034, 0.2151, 0.2185,\n",
       "                       0.2745, 0.2124, 0.2439, 0.1362, 0.1908, 0.3369, 0.1162, 0.1700, 0.1914,\n",
       "                       0.3139, 0.2063, 0.2015, 0.2676, 0.2079, 0.1858, 0.2236, 0.2326, 0.2035,\n",
       "                       0.2074, 0.1544, 0.1975, 0.2003, 0.2271, 0.0961, 0.3462, 0.3080, 0.2355,\n",
       "                       0.3071, 0.2829, 0.2384, 0.1702, 0.3178, 0.2132, 0.1912, 0.3147, 0.1378,\n",
       "                       0.2227, 0.2958, 0.1515, 0.1861, 0.3407, 0.2235, 0.1562, 0.1726, 0.2526,\n",
       "                       0.3372, 0.2195, 0.1726, 0.2145, 0.1962, 0.1276, 0.2679, 0.2815, 0.2579,\n",
       "                       0.2512, 0.3224, 0.2047, 0.2789, 0.1446, 0.3402, 0.2032, 0.3178, 0.1799,\n",
       "                       0.2502, 0.1626, 0.1981, 0.0988, 0.1760, 0.1244, 0.2798, 0.2250, 0.2763,\n",
       "                       0.1653, 0.2762, 0.1716, 0.2635, 0.1702, 0.1217, 0.3048, 0.2585, 0.2679,\n",
       "                       0.3119, 0.3193, 0.2428, 0.1224, 0.2845, 0.2359, 0.2840, 0.1866, 0.1958,\n",
       "                       0.1585, 0.1426, 0.2159, 0.2023, 0.1240, 0.0898, 0.3048, 0.1915, 0.3472,\n",
       "                       0.1059, 0.3147, 0.1945, 0.1102, 0.3025, 0.1730, 0.2354, 0.1578, 0.1712,\n",
       "                       0.2333, 0.2746, 0.2102, 0.1655, 0.2257, 0.1815, 0.2595, 0.2874, 0.3236,\n",
       "                       0.1703, 0.2231, 0.2268, 0.2505, 0.2608, 0.2204, 0.2444, 0.3011, 0.2502,\n",
       "                       0.1844, 0.2321, 0.3422, 0.1618, 0.2307, 0.3861, 0.2852, 0.1088, 0.1652,\n",
       "                       0.3039, 0.2459, 0.1514, 0.1694, 0.2909, 0.1862, 0.3806, 0.3600, 0.1929,\n",
       "                       0.2805, 0.1451, 0.2550, 0.1537, 0.3445, 0.1644, 0.4029, 0.2184, 0.2437,\n",
       "                       0.2651, 0.2340, 0.1549, 0.1099, 0.2089, 0.2751, 0.2843, 0.2402, 0.3380,\n",
       "                       0.1707, 0.2576, 0.2668, 0.1163, 0.3181, 0.3124, 0.1373, 0.2035, 0.2778,\n",
       "                       0.1444, 0.1499, 0.2398, 0.2672, 0.1746, 0.2686, 0.3892, 0.1977, 0.2133,\n",
       "                       0.2361, 0.2674, 0.2237, 0.2690, 0.3439, 0.2381, 0.0865, 0.2381, 0.1580,\n",
       "                       0.1659, 0.3185, 0.3526, 0.1577, 0.3009, 0.2164, 0.1100, 0.2638, 0.2412,\n",
       "                       0.1860, 0.2737, 0.2030, 0.1653, 0.2865, 0.1939, 0.1849, 0.3798, 0.2108,\n",
       "                       0.1496, 0.1786, 0.2384, 0.1847, 0.3241, 0.1877, 0.2718, 0.2091, 0.2111,\n",
       "                       0.1707, 0.2183, 0.1338, 0.2433, 0.2096, 0.3483, 0.1976, 0.1776, 0.2466,\n",
       "                       0.2502, 0.3734, 0.3801, 0.1471, 0.2810, 0.2001, 0.2242, 0.3243, 0.2052,\n",
       "                       0.3611, 0.2676, 0.1897, 0.2284, 0.2069, 0.1497, 0.2650, 0.3749, 0.4284,\n",
       "                       0.1669, 0.2893, 0.2747, 0.2250, 0.2676, 0.1927, 0.2884, 0.2754, 0.2414,\n",
       "                       0.2528, 0.1580, 0.2131, 0.1227, 0.3385, 0.1229, 0.3050, 0.1685, 0.2096,\n",
       "                       0.3237, 0.1775, 0.2391, 0.1617, 0.2522, 0.3690, 0.1687, 0.1351, 0.1280,\n",
       "                       0.2610, 0.2576, 0.3217, 0.2678, 0.2684, 0.2349, 0.2648, 0.1393, 0.1549,\n",
       "                       0.2378, 0.1803, 0.0902, 0.2853, 0.1858, 0.2096, 0.2732, 0.2013, 0.1659,\n",
       "                       0.2319, 0.2874, 0.2739, 0.1794, 0.1446, 0.2016, 0.1839, 0.2676, 0.1748,\n",
       "                       0.2565, 0.2857, 0.3241, 0.1857, 0.3101, 0.3693, 0.1408, 0.2854, 0.3770,\n",
       "                       0.2164, 0.2786, 0.4140, 0.1697, 0.2044, 0.1766, 0.2715, 0.2689, 0.2421,\n",
       "                       0.2632, 0.2885, 0.2570, 0.2307, 0.1633, 0.2340, 0.2075, 0.1026, 0.2429,\n",
       "                       0.1902, 0.2507, 0.2156, 0.2070, 0.2067, 0.2753, 0.3661, 0.2205, 0.1420,\n",
       "                       0.1439, 0.2918, 0.1471, 0.1875, 0.3015, 0.2598, 0.3550, 0.1580, 0.0823,\n",
       "                       0.2180, 0.1822, 0.1240, 0.2312, 0.1951, 0.2732, 0.1800, 0.1134, 0.2150,\n",
       "                       0.2278, 0.2794, 0.2912, 0.2188, 0.3008, 0.2608, 0.1775, 0.3867],\n",
       "                      device='cuda:0')),\n",
       "              ('layer4.0.bn2.bias',\n",
       "               tensor([-0.1193, -0.1386, -0.1510, -0.0555, -0.0741, -0.1472, -0.0763, -0.0701,\n",
       "                       -0.1091, -0.1594, -0.0928, -0.2545, -0.0894, -0.2281, -0.1080, -0.1222,\n",
       "                       -0.2161, -0.1457, -0.1034, -0.1405, -0.0597, -0.1875, -0.0819, -0.0330,\n",
       "                       -0.0911, -0.1015, -0.1109, -0.0800, -0.0891, -0.0657, -0.1317, -0.1261,\n",
       "                       -0.1326, -0.0778, -0.0912, -0.1096, -0.1250, -0.0454, -0.1695, -0.1933,\n",
       "                       -0.1033, -0.0896, -0.0768, -0.0969, -0.0645, -0.0987, -0.0757, -0.1462,\n",
       "                       -0.1293, -0.0976, -0.0934, -0.1272, -0.1286, -0.2711, -0.1217, -0.0767,\n",
       "                       -0.1479, -0.2169, -0.0935, -0.0575, -0.1461, -0.0884, -0.0818, -0.1219,\n",
       "                       -0.0507, -0.0790, -0.1207, -0.2251, -0.0753, -0.1568, -0.1182, -0.1979,\n",
       "                       -0.1507, -0.0417, -0.1442, -0.2117, -0.1961, -0.1170, -0.1072, -0.1559,\n",
       "                       -0.0664,  0.0620, -0.1892, -0.0699, -0.1152, -0.0857, -0.0814, -0.0736,\n",
       "                       -0.0943, -0.1266, -0.2347, -0.0674, -0.2066, -0.1030, -0.0695, -0.2379,\n",
       "                       -0.0516, -0.0486, -0.1060, -0.1650, -0.0894, -0.1054, -0.0481, -0.1194,\n",
       "                       -0.1814, -0.1525, -0.1735, -0.1317, -0.0673, -0.2707, -0.1946, -0.1155,\n",
       "                       -0.1424, -0.1049, -0.0739, -0.1465, -0.0266, -0.1283, -0.1065, -0.0724,\n",
       "                       -0.0809, -0.0426, -0.1617, -0.1708, -0.0257, -0.1494, -0.2588, -0.0441,\n",
       "                       -0.0899, -0.1813, -0.1495, -0.1908, -0.1317, -0.1017, -0.0876, -0.1648,\n",
       "                       -0.1116, -0.1243, -0.0008, -0.0971, -0.0578, -0.1388, -0.0891, -0.0916,\n",
       "                       -0.0995, -0.1622, -0.1956, -0.0925, -0.0805, -0.2749, -0.1507, -0.0921,\n",
       "                       -0.1124, -0.1294, -0.1090, -0.1433, -0.0085, -0.1194, -0.2182, -0.0543,\n",
       "                       -0.0584, -0.1359, -0.1685, -0.0822, -0.0905, -0.0980, -0.0689, -0.1088,\n",
       "                       -0.1416, -0.1887, -0.1030, -0.0783, -0.0693, -0.0702, -0.0573, -0.1052,\n",
       "                       -0.1213, -0.2233, -0.2100, -0.0874, -0.1118, -0.1882, -0.1267, -0.0798,\n",
       "                       -0.2148, -0.1364, -0.0621, -0.1883, -0.0945, -0.1133, -0.1676, -0.0687,\n",
       "                       -0.1115, -0.1821, -0.1331, -0.0845, -0.0556, -0.1431, -0.1239, -0.1188,\n",
       "                       -0.0476, -0.1006, -0.1072, -0.0708, -0.1366, -0.1568, -0.0297, -0.1021,\n",
       "                       -0.1474, -0.0737, -0.1218, -0.0605, -0.1056, -0.0575, -0.1748, -0.1060,\n",
       "                       -0.1314, -0.0889, -0.0986, -0.0371, -0.0841, -0.1369, -0.1006, -0.1030,\n",
       "                       -0.1210, -0.1366, -0.1872, -0.1118, -0.0955, -0.0416, -0.0591, -0.1391,\n",
       "                       -0.1283, -0.1162, -0.1444, -0.1997, -0.1225, -0.0365, -0.1479, -0.1133,\n",
       "                       -0.1215, -0.1192, -0.1083, -0.0645, -0.0610, -0.0715, -0.1019, -0.0660,\n",
       "                       -0.1305, -0.1436, -0.0821, -0.1493, -0.0306, -0.1278, -0.1178, -0.0442,\n",
       "                       -0.1734, -0.0920, -0.1636, -0.0911, -0.0739, -0.1064, -0.1320, -0.0999,\n",
       "                        0.0255, -0.0211, -0.1197, -0.1527, -0.1015, -0.1892, -0.0680, -0.1052,\n",
       "                       -0.0652, -0.2138, -0.1798, -0.0984, -0.1323, -0.0503, -0.1024, -0.1003,\n",
       "                       -0.0910, -0.1529, -0.0458, -0.1259, -0.2591, -0.0927, -0.0599, -0.1059,\n",
       "                       -0.2074, -0.0717, -0.0587, -0.0950, -0.1623, -0.0672, -0.1888, -0.1441,\n",
       "                       -0.0781, -0.1344, -0.0811, -0.1489, -0.0490, -0.1351, -0.0654, -0.1824,\n",
       "                       -0.1323, -0.0995, -0.1102, -0.0817, -0.1074, -0.0605, -0.0637, -0.0597,\n",
       "                       -0.2130, -0.1139, -0.1335, -0.0904, -0.0626, -0.1634, -0.0921, -0.1319,\n",
       "                       -0.1108, -0.0821, -0.0633, -0.1816, -0.1171, -0.0807, -0.0601, -0.0896,\n",
       "                       -0.1243, -0.0275, -0.2045, -0.0960, -0.0783, -0.0813, -0.1549, -0.0933,\n",
       "                       -0.1667, -0.1820, -0.1053, -0.0833, -0.1406, -0.0473, -0.0759, -0.1461,\n",
       "                       -0.1647, -0.0587, -0.1063, -0.0990, -0.0384, -0.1247, -0.1556, -0.0533,\n",
       "                       -0.1427, -0.1525, -0.0730, -0.1690, -0.1770, -0.0401, -0.1326, -0.1616,\n",
       "                       -0.1031, -0.1039, -0.0669, -0.1008, -0.0874, -0.0601, -0.1486, -0.0935,\n",
       "                       -0.0772, -0.0568, -0.0969, -0.0750, -0.0884, -0.1142, -0.1716, -0.0813,\n",
       "                       -0.0778, -0.0718, -0.0757, -0.2322, -0.1278, -0.1056, -0.1193, -0.0851,\n",
       "                       -0.0764, -0.1200, -0.0674, -0.2164, -0.1309, -0.1287, -0.0639, -0.1257,\n",
       "                       -0.1387, -0.1422, -0.2725, -0.1638, -0.1092, -0.1866, -0.1019, -0.1065,\n",
       "                       -0.0694, -0.0816, -0.1720, -0.1092, -0.1297, -0.1337, -0.0836, -0.1317,\n",
       "                       -0.0370, -0.1556, -0.0855, -0.1184, -0.0896, -0.0774, -0.1680, -0.0760,\n",
       "                       -0.1107, -0.1102, -0.1307, -0.1554, -0.1032, -0.0605, -0.0123, -0.1398,\n",
       "                       -0.1043, -0.1452, -0.1282, -0.1106, -0.1078, -0.1414, -0.0434, -0.1508,\n",
       "                       -0.1138, -0.0699, -0.0622, -0.1393, -0.0923, -0.1147, -0.1734, -0.0910,\n",
       "                       -0.0658, -0.0129, -0.2171, -0.0562, -0.1980, -0.0546, -0.1139, -0.0926,\n",
       "                       -0.1965, -0.0825, -0.1000, -0.1512, -0.1566, -0.0508, -0.1696, -0.1762,\n",
       "                       -0.0687, -0.1123, -0.0566, -0.1127, -0.0820, -0.1935, -0.0676, -0.0989,\n",
       "                       -0.0438, -0.1397, -0.1630, -0.1364, -0.1327, -0.0664, -0.1216, -0.0822,\n",
       "                       -0.0780, -0.1004, -0.0730, -0.0508, -0.1696, -0.0914, -0.1059, -0.1319,\n",
       "                       -0.0870, -0.1069, -0.1277, -0.2067, -0.0857, -0.0755, -0.0820, -0.1976,\n",
       "                       -0.1032, -0.1043, -0.2170, -0.1842, -0.3115, -0.0795, -0.0624, -0.1113,\n",
       "                       -0.0798, -0.0585, -0.0667, -0.1029, -0.1301, -0.0552, -0.1436, -0.1362,\n",
       "                       -0.0741, -0.1430, -0.1103, -0.1025, -0.1605, -0.1190, -0.0844, -0.0686],\n",
       "                      device='cuda:0')),\n",
       "              ('layer4.0.bn2.running_mean',\n",
       "               tensor([-2.2219e-01, -8.7739e-02,  1.2715e-02, -1.0260e-01,  3.2740e-03,\n",
       "                        7.0572e-03, -2.1114e-01, -1.1181e-01, -4.1309e-02, -2.3016e-01,\n",
       "                       -2.0637e-01,  1.6576e-02,  3.3026e-02, -2.7442e-02, -6.7538e-02,\n",
       "                       -1.0958e-01, -8.4994e-04, -8.2162e-02, -2.5197e-01, -3.0113e-01,\n",
       "                       -1.7568e-01, -2.1723e-02, -1.3418e-03, -5.4531e-02, -1.5359e-01,\n",
       "                       -1.9790e-01,  5.1775e-02,  2.7692e-02, -1.9926e-02, -2.1964e-01,\n",
       "                       -4.0737e-03,  2.7330e-02, -2.1785e-04, -1.1564e-01,  6.6944e-02,\n",
       "                       -2.2320e-03, -1.2272e-01, -5.6623e-02, -7.6254e-02, -7.5332e-02,\n",
       "                       -1.1286e-01, -1.4432e-01, -8.1821e-02, -5.0033e-02, -2.2955e-01,\n",
       "                       -9.8272e-02,  5.3655e-03,  7.4388e-02,  1.0706e-01, -2.3402e-02,\n",
       "                       -8.3990e-02, -2.9364e-02,  6.7140e-02, -5.7492e-04,  4.6587e-03,\n",
       "                       -2.3056e-01, -2.2638e-01,  3.9230e-02, -2.2581e-01, -1.1413e-01,\n",
       "                        7.5761e-02, -2.8132e-03, -1.4443e-01, -8.0733e-02, -9.1551e-02,\n",
       "                       -7.0939e-02,  3.6158e-02, -7.3303e-02, -9.5014e-02, -8.8143e-02,\n",
       "                       -6.8822e-02,  3.3034e-02, -8.5648e-02, -7.6263e-02, -3.3897e-02,\n",
       "                        4.1291e-02,  1.3723e-01,  3.6978e-02, -1.2428e-01, -8.1769e-02,\n",
       "                        5.1746e-02, -1.9775e-01,  2.5415e-02, -6.3676e-02, -8.0173e-03,\n",
       "                       -5.7013e-02, -9.8579e-02, -1.7806e-02, -1.9003e-01,  1.0820e-01,\n",
       "                        3.9940e-02, -1.7342e-01, -1.5576e-01,  6.4870e-02, -4.5519e-02,\n",
       "                        4.1384e-01, -2.6919e-01, -3.0322e-01, -3.1616e-02, -4.3431e-03,\n",
       "                       -2.2253e-01, -5.5120e-02, -2.0949e-03,  5.5902e-03,  2.8351e-02,\n",
       "                       -6.6810e-02, -1.0720e-01, -7.3246e-02, -4.0657e-02, -4.1326e-02,\n",
       "                       -1.4196e-01,  6.4812e-02,  2.2321e-02, -2.3671e-01, -3.4859e-02,\n",
       "                        2.5551e-02, -1.7985e-01, -1.6136e-01, -3.7551e-01, -8.4607e-02,\n",
       "                       -1.6075e-01,  1.2936e-02, -8.6512e-02, -7.2200e-02, -2.2490e-01,\n",
       "                        4.1303e-02, -8.7345e-02, -1.3988e-01, -1.9904e-01, -2.8606e-02,\n",
       "                        5.8555e-03,  3.2498e-02,  9.0520e-02, -6.2594e-02,  1.1704e-01,\n",
       "                       -1.7918e-01, -1.3394e-01,  2.4734e-02, -1.5211e-01, -3.5599e-02,\n",
       "                       -4.9634e-02,  2.4485e-02, -2.2156e-01, -1.0381e-01,  1.9719e-02,\n",
       "                        2.2411e-02,  6.6574e-02, -1.5120e-01, -2.0674e-01, -3.8934e-02,\n",
       "                       -1.4253e-01,  1.4224e-01, -2.1522e-01, -1.3983e-01, -6.2256e-02,\n",
       "                       -3.3287e-02, -2.1288e-01, -2.5784e-02, -2.0357e-03, -8.7632e-02,\n",
       "                       -1.2049e-01, -1.8946e-01,  2.5412e-02, -9.1921e-02, -7.7901e-02,\n",
       "                        5.1369e-03, -3.7475e-02, -6.3678e-02, -4.8309e-02, -1.4617e-02,\n",
       "                       -1.4185e-01, -7.8067e-02, -1.1073e-01,  7.6105e-03, -1.7849e-01,\n",
       "                       -1.4963e-02, -1.1590e-01, -4.0493e-02,  9.9907e-02,  4.4790e-02,\n",
       "                       -1.7107e-01, -2.8525e-02, -8.9189e-02, -1.3591e-02,  4.9561e-02,\n",
       "                       -2.9886e-02, -1.0837e-01,  2.6137e-02, -7.1606e-03, -2.0413e-03,\n",
       "                       -1.9732e-01,  5.2551e-02, -6.2630e-02, -8.6700e-02, -1.8219e-01,\n",
       "                       -1.2824e-01, -1.8336e-01, -4.5177e-02, -1.1639e-01, -1.0405e-01,\n",
       "                       -1.0171e-01,  3.2689e-02, -4.1385e-02, -2.1401e-01, -3.1310e-02,\n",
       "                       -4.7735e-02, -9.1139e-02, -3.0403e-02,  2.1807e-03, -1.3256e-01,\n",
       "                       -4.5860e-02, -1.8284e-02, -2.0035e-01, -1.2928e-01, -1.0407e-01,\n",
       "                        1.4581e-02, -8.2909e-02, -1.3027e-01, -2.3803e-01, -1.5708e-01,\n",
       "                       -1.0745e-01,  3.8669e-03, -1.9906e-02, -8.0670e-02, -9.0329e-02,\n",
       "                       -2.0169e-01,  7.4119e-03, -6.3784e-02, -6.9272e-02, -9.8125e-02,\n",
       "                       -8.1356e-02,  1.0315e-01, -3.8531e-02, -1.1912e-01, -3.1463e-02,\n",
       "                       -4.3853e-03, -8.4882e-03, -1.6178e-01,  3.9553e-02, -3.1186e-02,\n",
       "                       -2.8059e-01,  1.0556e-02, -2.7362e-02, -1.6125e-02, -3.0705e-02,\n",
       "                       -1.3126e-01, -1.2033e-01, -2.8935e-02,  1.5564e-02, -2.6017e-02,\n",
       "                       -3.5630e-01,  3.2263e-02, -1.4531e-01, -5.9245e-02, -1.9728e-01,\n",
       "                       -6.1600e-02,  3.6009e-02,  1.1256e-01,  1.1266e-01, -1.6962e-01,\n",
       "                       -1.0994e-01, -4.3359e-01, -5.3808e-02, -1.6498e-01, -3.7994e-01,\n",
       "                       -5.2027e-02, -4.0047e-02, -1.8162e-01, -3.4059e-01,  1.5414e-01,\n",
       "                       -1.6947e-01, -2.5846e-02, -2.0203e-01, -4.7433e-02, -1.3110e-01,\n",
       "                       -7.1256e-03, -8.8586e-02, -1.9380e-01, -1.7084e-01, -3.9371e-02,\n",
       "                       -2.1501e-01,  2.5143e-02, -8.0920e-02,  1.1357e-02, -4.9614e-02,\n",
       "                       -9.9430e-02, -9.7082e-02, -1.6839e-01,  9.7031e-02, -9.2452e-02,\n",
       "                       -4.3966e-02, -6.8129e-02, -1.2226e-01, -2.0369e-01,  2.3950e-02,\n",
       "                       -1.2331e-01, -3.0412e-01, -4.3382e-02,  6.5316e-02, -2.3738e-03,\n",
       "                       -1.2832e-01, -8.8704e-02, -1.6844e-01, -7.9974e-02, -3.6931e-03,\n",
       "                       -1.5680e-01, -4.1319e-02, -1.7357e-01, -9.2884e-02, -2.8206e-01,\n",
       "                       -1.4130e-01, -1.5803e-01, -1.6260e-01,  4.9217e-02,  1.7840e-02,\n",
       "                        3.6728e-02, -1.1570e-01, -2.4463e-01, -2.6351e-02, -1.5089e-01,\n",
       "                       -7.8516e-02, -7.0385e-02, -1.4267e-01, -8.6067e-02, -2.7606e-01,\n",
       "                       -1.2698e-02, -1.0127e-01, -8.3848e-02,  1.5557e-02, -1.7936e-01,\n",
       "                       -3.7456e-02, -8.5249e-02, -1.8589e-01, -1.6222e-02, -4.9422e-02,\n",
       "                       -3.2984e-02,  2.3827e-02, -8.5811e-02, -3.7854e-02, -3.0240e-02,\n",
       "                       -1.8949e-01, -2.7364e-01, -2.5189e-01,  2.1228e-01,  5.3809e-02,\n",
       "                        1.5187e-02, -2.3565e-01, -2.1691e-01, -1.0578e-01, -2.0314e-01,\n",
       "                       -3.5862e-02, -1.8468e-01, -3.6207e-02, -4.2944e-02,  4.3364e-02,\n",
       "                       -2.5216e-02, -1.8795e-01, -1.2008e-01, -2.6673e-01,  1.1310e-01,\n",
       "                        2.6239e-02, -7.9266e-02, -6.5818e-02,  5.5331e-02, -1.5992e-01,\n",
       "                       -2.3468e-01, -5.7502e-02, -2.1696e-01, -5.3849e-02, -3.1879e-01,\n",
       "                       -1.3672e-01, -9.2122e-02, -3.4110e-03, -1.8398e-01, -2.8819e-02,\n",
       "                       -7.3619e-03,  2.8121e-02, -1.6242e-01, -2.5772e-01,  2.1552e-02,\n",
       "                        1.1708e-02,  3.4884e-02, -2.9204e-02,  8.7692e-02,  6.6036e-03,\n",
       "                       -1.9554e-01, -4.9428e-02,  8.6723e-02,  2.9077e-02,  2.9960e-02,\n",
       "                       -5.1505e-02,  9.8476e-03, -8.5901e-02, -1.3800e-01,  1.8130e-01,\n",
       "                        4.5056e-04, -6.7278e-02,  2.6857e-02, -2.8492e-01,  1.7128e-01,\n",
       "                       -2.1431e-01,  4.8559e-02, -1.0512e-01, -2.3458e-01,  6.8808e-02,\n",
       "                        1.8568e-02, -1.0427e-01, -2.0684e-02, -9.9915e-02,  8.3356e-02,\n",
       "                       -9.0750e-03, -1.2373e-01, -1.2721e-01, -1.2387e-01, -3.8841e-02,\n",
       "                       -1.2088e-01, -1.3603e-01,  1.0054e-01, -1.8570e-01,  4.7323e-02,\n",
       "                        9.8101e-02, -1.7177e-02, -5.6773e-02, -1.3324e-01,  4.6171e-02,\n",
       "                        7.5211e-02, -4.1875e-02, -9.6841e-03,  8.2388e-02, -1.4044e-01,\n",
       "                       -6.6652e-02, -2.9495e-02, -9.8227e-02, -4.9839e-02, -1.6115e-01,\n",
       "                       -1.1758e-01, -9.6973e-02, -1.0108e-01, -4.9704e-02, -1.9565e-01,\n",
       "                        5.6306e-02, -3.0974e-01,  1.9741e-02, -2.7481e-01,  3.4158e-03,\n",
       "                       -2.2363e-02,  6.7699e-02,  8.9229e-02,  7.3819e-02,  1.6830e-02,\n",
       "                       -1.6956e-02,  2.4770e-02, -9.9455e-02, -2.5943e-01,  1.1402e-01,\n",
       "                        1.0160e-01, -1.0523e-01,  6.2393e-02, -1.9681e-01, -3.2538e-02,\n",
       "                       -1.6885e-01,  9.1927e-02, -2.3214e-01, -1.0435e-01, -2.4239e-01,\n",
       "                       -3.8279e-02,  1.7653e-02,  6.4023e-03, -3.8305e-02, -1.0458e-01,\n",
       "                        3.5993e-02, -1.1107e-01, -1.6070e-01,  1.4873e-01, -2.1996e-01,\n",
       "                       -3.6705e-02,  1.2122e-01, -4.4696e-02, -2.0136e-01, -2.3213e-02,\n",
       "                       -1.2550e-01,  1.8988e-02, -5.9794e-02,  5.3413e-02, -1.1495e-01,\n",
       "                       -9.8383e-02, -1.4910e-01,  1.4850e-02, -2.0422e-02, -1.6809e-02,\n",
       "                        7.3940e-02, -8.5370e-02,  1.8374e-01, -3.8965e-02, -9.5030e-02,\n",
       "                       -2.0869e-01, -1.5979e-01, -2.4004e-01, -1.0083e-01, -2.2265e-01,\n",
       "                       -2.0316e-01, -1.3062e-01, -1.1300e-01, -7.3201e-02, -5.5008e-02,\n",
       "                        1.0793e-01, -1.9053e-01, -1.5182e-01,  1.9891e-02, -1.1017e-01,\n",
       "                       -4.3441e-02, -2.7674e-01], device='cuda:0')),\n",
       "              ('layer4.0.bn2.running_var',\n",
       "               tensor([0.0439, 0.0546, 0.0592, 0.0360, 0.0150, 0.0466, 0.0775, 0.0409, 0.0335,\n",
       "                       0.0616, 0.0359, 0.1102, 0.0447, 0.0797, 0.0209, 0.0269, 0.0551, 0.0563,\n",
       "                       0.0411, 0.0533, 0.0532, 0.0606, 0.0266, 0.0152, 0.0493, 0.0581, 0.0423,\n",
       "                       0.0096, 0.0159, 0.0501, 0.0264, 0.0499, 0.0454, 0.0421, 0.0427, 0.0460,\n",
       "                       0.0521, 0.0103, 0.0400, 0.0393, 0.0346, 0.0503, 0.0301, 0.0161, 0.0396,\n",
       "                       0.0303, 0.0257, 0.0363, 0.0629, 0.0428, 0.0342, 0.0341, 0.0427, 0.1281,\n",
       "                       0.0343, 0.0308, 0.0581, 0.0519, 0.0421, 0.0175, 0.0520, 0.0413, 0.0180,\n",
       "                       0.0539, 0.0217, 0.0248, 0.0238, 0.0616, 0.0280, 0.0656, 0.0384, 0.0442,\n",
       "                       0.0328, 0.0234, 0.0460, 0.0697, 0.0687, 0.0441, 0.0377, 0.0443, 0.0159,\n",
       "                       0.1068, 0.0564, 0.0211, 0.0578, 0.0191, 0.0218, 0.0111, 0.0291, 0.0432,\n",
       "                       0.0506, 0.0228, 0.1209, 0.0415, 0.0719, 0.1845, 0.0362, 0.0276, 0.0208,\n",
       "                       0.0415, 0.0456, 0.0348, 0.0171, 0.0265, 0.0339, 0.0778, 0.0784, 0.0238,\n",
       "                       0.0089, 0.0614, 0.0433, 0.0283, 0.0478, 0.0698, 0.0248, 0.0465, 0.0400,\n",
       "                       0.0275, 0.1120, 0.0223, 0.0300, 0.0120, 0.0431, 0.0530, 0.0425, 0.0457,\n",
       "                       0.0937, 0.0276, 0.0464, 0.0532, 0.0277, 0.0377, 0.0647, 0.0130, 0.0229,\n",
       "                       0.0442, 0.0164, 0.0433, 0.0254, 0.0276, 0.0403, 0.0649, 0.0413, 0.0436,\n",
       "                       0.0337, 0.0383, 0.0552, 0.0222, 0.0257, 0.0627, 0.0563, 0.0503, 0.0420,\n",
       "                       0.0598, 0.0402, 0.0467, 0.0320, 0.0398, 0.0443, 0.0110, 0.0184, 0.0320,\n",
       "                       0.0845, 0.0433, 0.0501, 0.0320, 0.0506, 0.0294, 0.0409, 0.0388, 0.0269,\n",
       "                       0.0379, 0.0304, 0.0184, 0.0410, 0.0279, 0.0094, 0.0643, 0.0725, 0.0380,\n",
       "                       0.0828, 0.0610, 0.0300, 0.0285, 0.0703, 0.0358, 0.0315, 0.0788, 0.0279,\n",
       "                       0.0342, 0.0581, 0.0197, 0.0235, 0.0575, 0.0640, 0.0219, 0.0254, 0.0377,\n",
       "                       0.0798, 0.0399, 0.0255, 0.0335, 0.0218, 0.0312, 0.0515, 0.0570, 0.0482,\n",
       "                       0.0479, 0.0775, 0.0377, 0.0528, 0.0204, 0.0616, 0.0474, 0.0655, 0.0262,\n",
       "                       0.0389, 0.0264, 0.0437, 0.0116, 0.0291, 0.0334, 0.0559, 0.0695, 0.0491,\n",
       "                       0.0437, 0.0497, 0.0241, 0.0273, 0.0160, 0.0186, 0.0679, 0.0355, 0.0241,\n",
       "                       0.0500, 0.0752, 0.0639, 0.0232, 0.0485, 0.0471, 0.0438, 0.0211, 0.0347,\n",
       "                       0.0292, 0.0106, 0.0270, 0.0256, 0.0266, 0.0163, 0.0533, 0.0412, 0.0497,\n",
       "                       0.0131, 0.0686, 0.0414, 0.0085, 0.0740, 0.0191, 0.0467, 0.0274, 0.0318,\n",
       "                       0.0816, 0.0370, 0.0380, 0.0552, 0.0302, 0.0279, 0.0774, 0.0514, 0.0630,\n",
       "                       0.0169, 0.0286, 0.0532, 0.0592, 0.0379, 0.0351, 0.0624, 0.0760, 0.0463,\n",
       "                       0.0206, 0.0336, 0.0583, 0.0099, 0.0274, 0.0945, 0.0617, 0.0104, 0.0279,\n",
       "                       0.0780, 0.0514, 0.0223, 0.0213, 0.0668, 0.0301, 0.0708, 0.1152, 0.0479,\n",
       "                       0.0464, 0.0213, 0.0667, 0.0274, 0.0705, 0.0194, 0.0985, 0.0392, 0.0683,\n",
       "                       0.0479, 0.0439, 0.0339, 0.0398, 0.0254, 0.0367, 0.0589, 0.0485, 0.0497,\n",
       "                       0.0553, 0.0431, 0.0494, 0.0228, 0.0560, 0.0693, 0.0132, 0.0278, 0.0585,\n",
       "                       0.0360, 0.0274, 0.0374, 0.0302, 0.0301, 0.0391, 0.0922, 0.0378, 0.0501,\n",
       "                       0.0449, 0.0504, 0.0285, 0.0416, 0.0793, 0.0501, 0.0140, 0.0706, 0.0398,\n",
       "                       0.0417, 0.0896, 0.0651, 0.0314, 0.0661, 0.0444, 0.0154, 0.0580, 0.0554,\n",
       "                       0.0246, 0.0372, 0.0461, 0.0110, 0.0520, 0.0374, 0.0234, 0.0742, 0.0253,\n",
       "                       0.0171, 0.0420, 0.0249, 0.0298, 0.0696, 0.0240, 0.0429, 0.0329, 0.0217,\n",
       "                       0.0433, 0.0443, 0.0197, 0.0391, 0.0439, 0.0503, 0.0184, 0.0127, 0.0317,\n",
       "                       0.0475, 0.0828, 0.0975, 0.0133, 0.0398, 0.0358, 0.0338, 0.0679, 0.0287,\n",
       "                       0.0795, 0.0493, 0.0330, 0.0374, 0.0418, 0.0169, 0.0478, 0.0697, 0.0794,\n",
       "                       0.0183, 0.0501, 0.0640, 0.0423, 0.0464, 0.0211, 0.0475, 0.0737, 0.0408,\n",
       "                       0.0356, 0.0209, 0.0372, 0.0164, 0.0784, 0.0150, 0.0497, 0.0297, 0.0353,\n",
       "                       0.0412, 0.0191, 0.0343, 0.0230, 0.0582, 0.0956, 0.0301, 0.0121, 0.0088,\n",
       "                       0.0378, 0.0480, 0.0728, 0.0370, 0.0392, 0.0417, 0.0407, 0.0103, 0.0211,\n",
       "                       0.0450, 0.0176, 0.0198, 0.0377, 0.0200, 0.0253, 0.0264, 0.0295, 0.0158,\n",
       "                       0.0652, 0.0469, 0.0532, 0.0356, 0.0383, 0.0268, 0.0295, 0.0432, 0.0162,\n",
       "                       0.0312, 0.0623, 0.0551, 0.0419, 0.0706, 0.0872, 0.0145, 0.0762, 0.0796,\n",
       "                       0.0476, 0.0522, 0.1207, 0.0340, 0.0380, 0.0325, 0.0372, 0.0576, 0.0348,\n",
       "                       0.0620, 0.0446, 0.0369, 0.0288, 0.0233, 0.0743, 0.0305, 0.0076, 0.0485,\n",
       "                       0.0282, 0.0360, 0.0431, 0.0233, 0.0220, 0.0684, 0.0771, 0.0253, 0.0172,\n",
       "                       0.0199, 0.0464, 0.0169, 0.0198, 0.0597, 0.0362, 0.0896, 0.0285, 0.0133,\n",
       "                       0.0340, 0.0263, 0.0557, 0.0300, 0.0378, 0.0704, 0.0209, 0.0231, 0.0639,\n",
       "                       0.0443, 0.0430, 0.0535, 0.0379, 0.0634, 0.0574, 0.0260, 0.0833],\n",
       "                      device='cuda:0')),\n",
       "              ('layer4.0.bn2.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer4.0.shortcut.0.weight',\n",
       "               tensor([[[[-0.0127]],\n",
       "               \n",
       "                        [[-0.0113]],\n",
       "               \n",
       "                        [[ 0.0540]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0419]],\n",
       "               \n",
       "                        [[ 0.0278]],\n",
       "               \n",
       "                        [[-0.0439]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0150]],\n",
       "               \n",
       "                        [[ 0.0266]],\n",
       "               \n",
       "                        [[-0.0052]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0196]],\n",
       "               \n",
       "                        [[-0.0357]],\n",
       "               \n",
       "                        [[ 0.0441]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0161]],\n",
       "               \n",
       "                        [[-0.0363]],\n",
       "               \n",
       "                        [[-0.0054]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0136]],\n",
       "               \n",
       "                        [[-0.0110]],\n",
       "               \n",
       "                        [[-0.0245]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0017]],\n",
       "               \n",
       "                        [[-0.0308]],\n",
       "               \n",
       "                        [[ 0.0215]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0651]],\n",
       "               \n",
       "                        [[-0.0318]],\n",
       "               \n",
       "                        [[ 0.0212]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0447]],\n",
       "               \n",
       "                        [[-0.0440]],\n",
       "               \n",
       "                        [[ 0.0317]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0126]],\n",
       "               \n",
       "                        [[-0.0154]],\n",
       "               \n",
       "                        [[-0.0167]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0154]],\n",
       "               \n",
       "                        [[-0.0087]],\n",
       "               \n",
       "                        [[-0.0242]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0135]],\n",
       "               \n",
       "                        [[ 0.0115]],\n",
       "               \n",
       "                        [[-0.0110]]]], device='cuda:0')),\n",
       "              ('layer4.0.shortcut.1.weight',\n",
       "               tensor([ 0.1526,  0.0868,  0.1305,  0.1662,  0.0554,  0.1197,  0.0943,  0.1384,\n",
       "                        0.1364,  0.1419,  0.2055,  0.1074,  0.1675,  0.2161,  0.2333,  0.1110,\n",
       "                        0.0913,  0.1197,  0.1494,  0.2120,  0.1579,  0.1214,  0.0711,  0.1180,\n",
       "                        0.1478,  0.1001,  0.1557,  0.0522,  0.0996,  0.1772,  0.1265,  0.1484,\n",
       "                        0.1417,  0.1994,  0.1055,  0.1085,  0.1657,  0.1047,  0.1142,  0.1255,\n",
       "                        0.1500,  0.0903,  0.1550,  0.0772,  0.2046,  0.1017,  0.1925,  0.0286,\n",
       "                        0.0447,  0.1646,  0.1129,  0.1508,  0.0791,  0.0894,  0.1058,  0.0682,\n",
       "                        0.1629,  0.1462,  0.1716,  0.1422,  0.1480,  0.0924,  0.1445,  0.0587,\n",
       "                        0.1137,  0.0590,  0.0698,  0.1863,  0.0824,  0.1577,  0.1575,  0.2040,\n",
       "                        0.1996,  0.1399,  0.0913,  0.1232,  0.1665,  0.2207,  0.1075,  0.1689,\n",
       "                        0.1344,  0.1030,  0.0834,  0.1290,  0.1007,  0.1345,  0.1059,  0.1170,\n",
       "                        0.1383,  0.1245,  0.1452,  0.0733,  0.2210,  0.1653,  0.0969,  0.1945,\n",
       "                        0.1405,  0.2041,  0.1519,  0.1169,  0.1258,  0.0989,  0.0818,  0.0846,\n",
       "                        0.0665,  0.2026,  0.1509,  0.2119,  0.0514,  0.0643,  0.0442,  0.1112,\n",
       "                        0.1034,  0.1424,  0.0816,  0.0787,  0.1682,  0.1257,  0.0406,  0.1767,\n",
       "                        0.1910,  0.0641,  0.0959,  0.0713,  0.1808,  0.1179,  0.1342,  0.1625,\n",
       "                        0.1168,  0.1223,  0.1179,  0.0359,  0.1112,  0.1168,  0.0759,  0.1488,\n",
       "                        0.1307,  0.1003,  0.1684,  0.0491,  0.1812,  0.1400,  0.1521,  0.0984,\n",
       "                        0.0784,  0.0817,  0.2136,  0.1428,  0.1320,  0.0914,  0.1795,  0.0915,\n",
       "                        0.1228,  0.1260,  0.1679,  0.1824,  0.1804,  0.1263,  0.1146,  0.0997,\n",
       "                        0.1132,  0.1678,  0.1950,  0.0988,  0.1404,  0.1589,  0.1402,  0.1154,\n",
       "                        0.1249,  0.0149,  0.1239,  0.1388,  0.0977,  0.0672,  0.1002,  0.0749,\n",
       "                        0.1734,  0.0692,  0.0928,  0.0280,  0.1584,  0.0523,  0.1399,  0.1853,\n",
       "                        0.1756,  0.0640,  0.1230,  0.0602,  0.1165,  0.1016,  0.1919,  0.0859,\n",
       "                        0.0978,  0.0948,  0.1962,  0.1572,  0.1474,  0.0645,  0.1866,  0.2002,\n",
       "                        0.1081,  0.0605,  0.1258,  0.2089,  0.1313,  0.1453,  0.1186,  0.1431,\n",
       "                        0.0900,  0.1442,  0.1295,  0.1061,  0.0405,  0.1854,  0.1028,  0.1554,\n",
       "                        0.0989,  0.1702,  0.1738,  0.0682,  0.2066,  0.1754,  0.1416,  0.1876,\n",
       "                        0.0961,  0.1662,  0.1068,  0.1162,  0.1901,  0.1005,  0.1187,  0.0951,\n",
       "                        0.1356,  0.1237,  0.1050,  0.1001,  0.1340,  0.1507,  0.0833,  0.1292,\n",
       "                        0.0900,  0.0629,  0.1252,  0.1274,  0.0893,  0.1289,  0.1549,  0.1431,\n",
       "                        0.1981,  0.0720,  0.1454,  0.1155,  0.1573,  0.1027,  0.1622,  0.0550,\n",
       "                       -0.0202,  0.1348,  0.1371,  0.1454,  0.1688,  0.2004,  0.1721,  0.2226,\n",
       "                        0.1999,  0.1017,  0.1724,  0.1019,  0.2850,  0.0754,  0.1138,  0.1578,\n",
       "                        0.1078,  0.2132,  0.1215,  0.0602,  0.0977,  0.1925,  0.1003,  0.0829,\n",
       "                        0.1869,  0.1754,  0.0861,  0.2225,  0.2163,  0.0633,  0.1342,  0.0921,\n",
       "                        0.0827,  0.2054,  0.1320,  0.1250,  0.1807,  0.1077,  0.0702,  0.1959,\n",
       "                        0.1917,  0.1484,  0.0701,  0.1916,  0.1787,  0.1486,  0.1510,  0.1281,\n",
       "                        0.0468,  0.1408,  0.0923,  0.0974,  0.1800,  0.1953,  0.0965,  0.0924,\n",
       "                        0.1919,  0.1980,  0.1855,  0.1753,  0.1471,  0.1993,  0.1726,  0.1404,\n",
       "                        0.0763,  0.0648,  0.2201,  0.0860,  0.2517,  0.1179,  0.0926,  0.1367,\n",
       "                        0.1530,  0.1504,  0.2162,  0.1019,  0.1133,  0.0790,  0.1016,  0.1320,\n",
       "                        0.1080,  0.1241,  0.0886,  0.1502,  0.1740,  0.1848,  0.2350,  0.0401,\n",
       "                        0.1574,  0.2234,  0.1264,  0.1495,  0.1043,  0.1461,  0.1883,  0.1371,\n",
       "                        0.1345,  0.1437,  0.0809,  0.0958,  0.2396,  0.0573,  0.0747,  0.0849,\n",
       "                        0.0874,  0.1620,  0.1488,  0.0600,  0.1435,  0.1301,  0.1354,  0.1445,\n",
       "                        0.1359,  0.1841,  0.1064,  0.1134,  0.1638,  0.1494,  0.0821,  0.1280,\n",
       "                        0.0561,  0.1513,  0.1471,  0.0889,  0.1596,  0.0973,  0.1441,  0.1256,\n",
       "                        0.0796,  0.1535,  0.1279,  0.1442,  0.0765,  0.0862,  0.1124,  0.0910,\n",
       "                        0.1343,  0.1615,  0.1550,  0.1385,  0.0749,  0.2526,  0.1451,  0.1780,\n",
       "                        0.1852,  0.0574,  0.0847,  0.1422,  0.0969,  0.2096,  0.1411,  0.1251,\n",
       "                        0.1154,  0.2279,  0.1362,  0.0575,  0.1154,  0.0964,  0.1200,  0.1096,\n",
       "                        0.1358,  0.0647,  0.0970,  0.1219,  0.0895,  0.0214,  0.0682,  0.1675,\n",
       "                        0.1008,  0.1253,  0.0360,  0.1446,  0.0956,  0.0910,  0.0857,  0.1265,\n",
       "                        0.1025,  0.1205,  0.2171,  0.1576,  0.1557,  0.1322,  0.0842,  0.2085,\n",
       "                        0.0837,  0.1509,  0.0958,  0.1688,  0.1524,  0.1781,  0.0819,  0.1163,\n",
       "                        0.0591,  0.0982,  0.1363,  0.1523,  0.1218,  0.0999,  0.1352,  0.1371,\n",
       "                        0.1125,  0.1539,  0.1494,  0.1674,  0.1584,  0.0345,  0.1828,  0.1007,\n",
       "                        0.1025,  0.1467,  0.2109,  0.1972,  0.1862,  0.1268,  0.0774,  0.0994,\n",
       "                        0.1621,  0.2328,  0.1767,  0.0709,  0.0617,  0.1096,  0.1692,  0.1092,\n",
       "                        0.1727,  0.0601,  0.2040,  0.1230,  0.0821,  0.0850,  0.0977,  0.0881,\n",
       "                        0.1040,  0.1498,  0.1369,  0.0595,  0.1299,  0.0695,  0.0966,  0.1753,\n",
       "                        0.0542,  0.2180,  0.1039,  0.1728,  0.1136,  0.0974,  0.2296,  0.1700,\n",
       "                        0.0941,  0.0664,  0.1400,  0.1532,  0.1544,  0.1124,  0.1433,  0.1023],\n",
       "                      device='cuda:0')),\n",
       "              ('layer4.0.shortcut.1.bias',\n",
       "               tensor([-0.1193, -0.1386, -0.1510, -0.0555, -0.0741, -0.1472, -0.0763, -0.0701,\n",
       "                       -0.1091, -0.1594, -0.0928, -0.2545, -0.0894, -0.2281, -0.1080, -0.1222,\n",
       "                       -0.2161, -0.1457, -0.1034, -0.1405, -0.0597, -0.1875, -0.0819, -0.0330,\n",
       "                       -0.0911, -0.1015, -0.1109, -0.0800, -0.0891, -0.0657, -0.1317, -0.1261,\n",
       "                       -0.1326, -0.0778, -0.0912, -0.1096, -0.1250, -0.0454, -0.1695, -0.1933,\n",
       "                       -0.1033, -0.0896, -0.0768, -0.0969, -0.0645, -0.0987, -0.0757, -0.1462,\n",
       "                       -0.1293, -0.0976, -0.0934, -0.1272, -0.1286, -0.2711, -0.1217, -0.0767,\n",
       "                       -0.1479, -0.2169, -0.0935, -0.0575, -0.1461, -0.0884, -0.0818, -0.1219,\n",
       "                       -0.0507, -0.0790, -0.1207, -0.2251, -0.0753, -0.1568, -0.1182, -0.1979,\n",
       "                       -0.1507, -0.0417, -0.1442, -0.2117, -0.1961, -0.1170, -0.1072, -0.1559,\n",
       "                       -0.0664,  0.0620, -0.1892, -0.0699, -0.1152, -0.0857, -0.0814, -0.0736,\n",
       "                       -0.0943, -0.1266, -0.2347, -0.0674, -0.2066, -0.1030, -0.0695, -0.2379,\n",
       "                       -0.0516, -0.0486, -0.1060, -0.1650, -0.0894, -0.1054, -0.0481, -0.1194,\n",
       "                       -0.1814, -0.1525, -0.1735, -0.1317, -0.0673, -0.2707, -0.1946, -0.1155,\n",
       "                       -0.1424, -0.1049, -0.0739, -0.1465, -0.0266, -0.1283, -0.1065, -0.0724,\n",
       "                       -0.0809, -0.0426, -0.1617, -0.1708, -0.0257, -0.1494, -0.2588, -0.0441,\n",
       "                       -0.0899, -0.1813, -0.1495, -0.1908, -0.1317, -0.1017, -0.0876, -0.1648,\n",
       "                       -0.1116, -0.1243, -0.0008, -0.0971, -0.0578, -0.1388, -0.0891, -0.0916,\n",
       "                       -0.0995, -0.1622, -0.1956, -0.0925, -0.0805, -0.2749, -0.1507, -0.0921,\n",
       "                       -0.1124, -0.1294, -0.1090, -0.1433, -0.0085, -0.1194, -0.2182, -0.0543,\n",
       "                       -0.0584, -0.1359, -0.1685, -0.0822, -0.0905, -0.0980, -0.0689, -0.1088,\n",
       "                       -0.1416, -0.1887, -0.1030, -0.0783, -0.0693, -0.0702, -0.0573, -0.1052,\n",
       "                       -0.1213, -0.2233, -0.2100, -0.0874, -0.1118, -0.1882, -0.1267, -0.0798,\n",
       "                       -0.2148, -0.1364, -0.0621, -0.1883, -0.0945, -0.1133, -0.1676, -0.0687,\n",
       "                       -0.1115, -0.1821, -0.1331, -0.0845, -0.0556, -0.1431, -0.1239, -0.1188,\n",
       "                       -0.0476, -0.1006, -0.1072, -0.0708, -0.1366, -0.1568, -0.0297, -0.1021,\n",
       "                       -0.1474, -0.0737, -0.1218, -0.0605, -0.1056, -0.0575, -0.1748, -0.1060,\n",
       "                       -0.1314, -0.0889, -0.0986, -0.0371, -0.0841, -0.1369, -0.1006, -0.1030,\n",
       "                       -0.1210, -0.1366, -0.1872, -0.1118, -0.0955, -0.0416, -0.0591, -0.1391,\n",
       "                       -0.1283, -0.1162, -0.1444, -0.1997, -0.1225, -0.0365, -0.1479, -0.1133,\n",
       "                       -0.1215, -0.1192, -0.1083, -0.0645, -0.0610, -0.0715, -0.1019, -0.0660,\n",
       "                       -0.1305, -0.1436, -0.0821, -0.1493, -0.0306, -0.1278, -0.1178, -0.0442,\n",
       "                       -0.1734, -0.0920, -0.1636, -0.0911, -0.0739, -0.1064, -0.1320, -0.0999,\n",
       "                        0.0255, -0.0211, -0.1197, -0.1527, -0.1015, -0.1892, -0.0680, -0.1052,\n",
       "                       -0.0652, -0.2138, -0.1798, -0.0984, -0.1323, -0.0503, -0.1024, -0.1003,\n",
       "                       -0.0910, -0.1529, -0.0458, -0.1259, -0.2591, -0.0927, -0.0599, -0.1059,\n",
       "                       -0.2074, -0.0717, -0.0587, -0.0950, -0.1623, -0.0672, -0.1888, -0.1441,\n",
       "                       -0.0781, -0.1344, -0.0811, -0.1489, -0.0490, -0.1351, -0.0654, -0.1824,\n",
       "                       -0.1323, -0.0995, -0.1102, -0.0817, -0.1074, -0.0605, -0.0637, -0.0597,\n",
       "                       -0.2130, -0.1139, -0.1335, -0.0904, -0.0626, -0.1634, -0.0921, -0.1319,\n",
       "                       -0.1108, -0.0821, -0.0633, -0.1816, -0.1171, -0.0807, -0.0601, -0.0896,\n",
       "                       -0.1243, -0.0275, -0.2045, -0.0960, -0.0783, -0.0813, -0.1549, -0.0933,\n",
       "                       -0.1667, -0.1820, -0.1053, -0.0833, -0.1406, -0.0473, -0.0759, -0.1461,\n",
       "                       -0.1647, -0.0587, -0.1063, -0.0990, -0.0384, -0.1247, -0.1556, -0.0533,\n",
       "                       -0.1427, -0.1525, -0.0730, -0.1690, -0.1770, -0.0401, -0.1326, -0.1616,\n",
       "                       -0.1031, -0.1039, -0.0669, -0.1008, -0.0874, -0.0601, -0.1486, -0.0935,\n",
       "                       -0.0772, -0.0568, -0.0969, -0.0750, -0.0884, -0.1142, -0.1716, -0.0813,\n",
       "                       -0.0778, -0.0718, -0.0757, -0.2322, -0.1278, -0.1056, -0.1193, -0.0851,\n",
       "                       -0.0764, -0.1200, -0.0674, -0.2164, -0.1309, -0.1287, -0.0639, -0.1257,\n",
       "                       -0.1387, -0.1422, -0.2725, -0.1638, -0.1092, -0.1866, -0.1019, -0.1065,\n",
       "                       -0.0694, -0.0816, -0.1720, -0.1092, -0.1297, -0.1337, -0.0836, -0.1317,\n",
       "                       -0.0370, -0.1556, -0.0855, -0.1184, -0.0896, -0.0774, -0.1680, -0.0760,\n",
       "                       -0.1107, -0.1102, -0.1307, -0.1554, -0.1032, -0.0605, -0.0123, -0.1398,\n",
       "                       -0.1043, -0.1452, -0.1282, -0.1106, -0.1078, -0.1414, -0.0434, -0.1508,\n",
       "                       -0.1138, -0.0699, -0.0622, -0.1393, -0.0923, -0.1147, -0.1734, -0.0910,\n",
       "                       -0.0658, -0.0129, -0.2171, -0.0562, -0.1980, -0.0546, -0.1139, -0.0926,\n",
       "                       -0.1965, -0.0825, -0.1000, -0.1512, -0.1566, -0.0508, -0.1696, -0.1762,\n",
       "                       -0.0687, -0.1123, -0.0566, -0.1127, -0.0820, -0.1935, -0.0676, -0.0989,\n",
       "                       -0.0438, -0.1397, -0.1630, -0.1364, -0.1327, -0.0664, -0.1216, -0.0822,\n",
       "                       -0.0780, -0.1004, -0.0730, -0.0508, -0.1696, -0.0914, -0.1059, -0.1319,\n",
       "                       -0.0870, -0.1069, -0.1277, -0.2067, -0.0857, -0.0755, -0.0820, -0.1976,\n",
       "                       -0.1032, -0.1043, -0.2170, -0.1842, -0.3115, -0.0795, -0.0624, -0.1113,\n",
       "                       -0.0798, -0.0585, -0.0667, -0.1029, -0.1301, -0.0552, -0.1436, -0.1362,\n",
       "                       -0.0741, -0.1430, -0.1103, -0.1025, -0.1605, -0.1190, -0.0844, -0.0686],\n",
       "                      device='cuda:0')),\n",
       "              ('layer4.0.shortcut.1.running_mean',\n",
       "               tensor([-7.0854e-03,  1.6594e-02, -1.3497e-01, -1.4950e-01, -1.8028e-02,\n",
       "                       -7.0014e-02,  2.4442e-02, -9.0920e-02, -2.0293e-01, -9.9122e-02,\n",
       "                       -1.0394e-01, -6.2587e-02, -4.5695e-02, -2.9977e-02, -1.3245e-01,\n",
       "                       -1.0133e-01,  4.2735e-02, -3.4720e-02, -6.1884e-02, -1.2187e-01,\n",
       "                       -1.1429e-01, -5.7603e-02,  8.9916e-03, -5.2254e-02, -8.7386e-02,\n",
       "                       -1.0361e-01, -7.1606e-02,  6.4923e-02,  1.7606e-02, -6.6883e-02,\n",
       "                       -3.9698e-03, -1.3352e-01, -1.2690e-01, -1.6020e-01, -4.7311e-02,\n",
       "                        5.1251e-02, -5.9168e-02,  2.8287e-03,  4.4655e-02, -1.2782e-01,\n",
       "                       -8.3594e-02, -9.9697e-02, -1.7683e-01, -5.9719e-02, -9.3733e-02,\n",
       "                        1.4352e-03, -2.6896e-02, -8.1559e-03, -2.3130e-02, -5.4277e-02,\n",
       "                       -1.1090e-01, -3.2204e-02, -9.6552e-02, -9.9909e-02, -6.0781e-02,\n",
       "                       -9.4508e-02, -9.6842e-02, -8.8373e-02, -7.8291e-02,  1.0097e-02,\n",
       "                        9.9585e-03, -7.0975e-02, -1.2020e-01, -4.4574e-03, -1.5262e-01,\n",
       "                        3.6609e-02, -5.7101e-02, -2.1463e-02, -1.3184e-02, -7.3276e-02,\n",
       "                       -1.3621e-01, -1.2549e-01, -3.6647e-02, -1.5080e-01, -1.3629e-01,\n",
       "                       -7.6691e-02, -4.8916e-02,  1.6392e-01, -1.1903e-02,  7.8033e-02,\n",
       "                        6.3836e-03, -4.4368e-02, -4.6024e-02, -1.5512e-01, -1.0264e-01,\n",
       "                       -4.1624e-02, -6.4688e-02,  1.2240e-02, -1.5866e-01,  1.5861e-02,\n",
       "                        1.1922e-01, -3.4925e-02, -5.2129e-02,  3.1593e-02, -8.8707e-02,\n",
       "                       -8.2145e-03, -1.5623e-01, -1.8305e-01, -4.0127e-02, -7.7615e-02,\n",
       "                       -1.2130e-01, -1.0247e-01, -3.3393e-02, -7.6434e-02,  3.1100e-02,\n",
       "                       -8.7745e-02, -1.9133e-02,  2.6569e-02, -3.2899e-02, -1.0139e-01,\n",
       "                       -6.3364e-02, -6.9226e-02, -1.2044e-01, -1.0785e-01, -1.3029e-02,\n",
       "                       -5.6174e-02, -7.1743e-02,  7.9345e-02, -8.6811e-02, -6.1512e-02,\n",
       "                        7.5840e-03, -1.7266e-02, -3.8776e-02,  4.0182e-04, -1.3854e-01,\n",
       "                       -2.1086e-02, -1.3689e-01, -6.3547e-02, -3.6792e-02, -6.8372e-02,\n",
       "                        2.2631e-02,  5.4242e-03, -1.5445e-02, -3.3944e-02,  2.2849e-02,\n",
       "                        1.9178e-02, -1.1097e-03, -4.2708e-02, -6.7036e-02, -7.9510e-02,\n",
       "                        1.8475e-02, -1.2247e-01, -6.2415e-02, -1.0474e-01, -1.5897e-02,\n",
       "                       -3.0683e-02, -1.3905e-01, -3.1245e-02, -6.8482e-02,  1.3888e-02,\n",
       "                       -9.1056e-02, -3.0439e-02, -1.1172e-01, -3.9365e-02, -8.8275e-02,\n",
       "                       -1.3479e-01, -1.6930e-01, -5.0154e-02, -4.6830e-02, -3.6674e-02,\n",
       "                       -1.2664e-01, -8.8637e-02, -1.6937e-01, -8.9748e-02, -5.8233e-02,\n",
       "                       -9.6199e-02, -9.8602e-02, -5.7999e-03, -1.2886e-01,  1.9506e-02,\n",
       "                        2.2499e-02, -4.4034e-02, -1.1331e-01, -5.9397e-02,  2.2175e-02,\n",
       "                       -5.0526e-02,  4.9923e-02, -9.0395e-03, -8.9505e-02, -5.4522e-02,\n",
       "                       -7.3248e-03, -8.5779e-02,  8.8291e-02,  2.1073e-03, -3.4080e-02,\n",
       "                       -9.0279e-03, -2.8619e-02, -7.8222e-02, -9.3912e-02, -6.3103e-02,\n",
       "                        5.3309e-02,  1.8000e-02, -2.4127e-02,  3.4970e-03, -7.2813e-02,\n",
       "                       -4.4557e-02, -1.3912e-01, -9.1267e-02, -1.6252e-01, -5.2745e-02,\n",
       "                       -3.0778e-02, -1.1700e-01, -6.2693e-02, -1.6606e-01, -2.4645e-02,\n",
       "                        1.3783e-03, -7.4108e-02, -1.4684e-01, -7.4318e-02, -1.1458e-01,\n",
       "                       -4.3217e-02, -6.0133e-02, -2.3687e-02, -4.5196e-02, -7.4322e-02,\n",
       "                       -1.4827e-02, -3.4561e-02, -1.3342e-01, -2.1114e-02, -1.1004e-02,\n",
       "                       -7.4003e-03,  3.1431e-02,  4.4503e-02, -1.2632e-01, -8.5942e-02,\n",
       "                       -5.5856e-02,  2.2857e-02, -6.9497e-02, -8.2795e-02, -4.0014e-02,\n",
       "                       -8.9523e-02, -1.0799e-01, -9.4438e-02,  5.8948e-02, -3.1211e-02,\n",
       "                        2.9625e-03, -6.3229e-02, -1.0892e-01, -4.3623e-02, -9.5941e-02,\n",
       "                       -1.9248e-02, -3.8967e-02,  2.2484e-02, -1.6400e-01, -1.2497e-02,\n",
       "                       -6.2044e-02,  8.9595e-02, -1.3096e-01,  3.1476e-02, -8.5180e-03,\n",
       "                       -6.5246e-02,  3.1617e-02, -5.7036e-02, -1.2483e-02, -1.0635e-01,\n",
       "                        1.1727e-02, -1.6619e-02,  1.3885e-01, -4.2261e-02, -7.2784e-02,\n",
       "                       -1.2282e-01, -2.5167e-02, -8.2171e-02,  5.0857e-03, -2.0830e-01,\n",
       "                       -1.0075e-01,  6.1139e-02, -6.3397e-02,  6.9388e-02, -7.3850e-02,\n",
       "                       -4.1592e-02, -6.8884e-02, -5.6260e-02, -5.8951e-02, -4.9974e-02,\n",
       "                       -1.0789e-02, -2.6876e-02, -2.5226e-01,  5.0693e-02, -1.0338e-02,\n",
       "                        2.1870e-02,  2.4469e-03, -4.1797e-02, -4.3275e-07, -5.2694e-02,\n",
       "                       -4.6219e-02, -9.2843e-02, -5.2535e-02,  3.4816e-02, -1.4911e-01,\n",
       "                       -4.8212e-02, -1.1625e-01, -1.8132e-01, -3.6435e-02, -9.4850e-02,\n",
       "                       -1.2590e-01, -6.3108e-02, -2.5849e-02, -1.0392e-01,  3.7548e-02,\n",
       "                       -1.1098e-01, -1.5521e-01,  4.5323e-02, -9.1625e-02, -6.8368e-02,\n",
       "                       -5.6522e-02, -1.4768e-02, -1.1061e-01, -2.9676e-02, -2.0085e-01,\n",
       "                       -9.8895e-02, -1.0090e-01, -2.5404e-02, -1.1463e-01, -1.6823e-02,\n",
       "                       -1.3308e-01, -1.4337e-01, -1.3483e-01, -1.6705e-01, -4.3225e-02,\n",
       "                       -7.7132e-02,  9.4126e-03,  9.9201e-03, -4.2043e-02, -1.7667e-01,\n",
       "                       -7.2179e-02, -7.7304e-02, -5.3474e-02, -7.4636e-02, -1.4596e-01,\n",
       "                        3.0211e-02,  1.7703e-02, -3.0919e-02, -3.0888e-02, -1.1109e-01,\n",
       "                       -6.0212e-02, -5.0563e-02, -1.3136e-01,  1.0968e-02, -5.7754e-02,\n",
       "                       -2.8842e-01, -1.8264e-01, -1.3522e-01, -8.3078e-02,  9.8112e-03,\n",
       "                       -7.6991e-03,  1.0177e-01, -2.2514e-03, -7.9433e-02,  8.3964e-02,\n",
       "                       -1.1531e-01, -5.9319e-02, -1.5719e-01, -9.1914e-02, -1.2792e-02,\n",
       "                       -9.9612e-02, -5.0999e-02, -5.2433e-02,  6.6010e-03,  1.4820e-02,\n",
       "                       -8.7896e-02, -7.9253e-02, -2.4866e-02, -7.1876e-02, -1.5489e-02,\n",
       "                       -1.0198e-01,  6.2725e-03,  1.9361e-02, -4.3459e-02, -5.2343e-02,\n",
       "                       -1.3626e-01,  4.0831e-02, -8.0358e-02, -9.0868e-02,  3.1518e-02,\n",
       "                       -1.1703e-01, -6.8074e-02,  5.1739e-02, -6.0150e-02, -6.5722e-02,\n",
       "                       -8.9450e-02,  4.3528e-02,  1.4661e-02, -1.0405e-01, -8.5081e-02,\n",
       "                       -1.4121e-01, -1.4795e-01, -9.4840e-02,  1.8123e-02, -6.2310e-02,\n",
       "                       -6.3603e-02, -1.8616e-02, -4.7935e-02, -3.6892e-02, -9.7002e-03,\n",
       "                       -7.5488e-02, -4.4687e-02, -6.9263e-02, -1.4930e-01, -1.1594e-01,\n",
       "                       -7.2873e-02, -9.2597e-03, -1.0628e-02, -9.7400e-02,  1.7737e-02,\n",
       "                       -5.0923e-02, -5.3320e-02, -1.2438e-01, -1.0656e-01, -1.4755e-01,\n",
       "                       -6.3455e-02, -1.2153e-01, -1.2308e-01, -7.1859e-02, -7.0235e-02,\n",
       "                       -8.4018e-02, -2.8538e-02, -1.3581e-02,  2.2127e-02, -2.4243e-03,\n",
       "                       -1.3590e-01,  2.5107e-02,  1.1616e-02, -2.0886e-02, -1.3939e-01,\n",
       "                       -9.9584e-02, -2.0203e-02, -3.9525e-03, -9.8188e-02,  1.3978e-02,\n",
       "                       -7.5834e-03, -8.9674e-03, -5.6975e-03,  6.3443e-02, -1.9479e-01,\n",
       "                       -4.6748e-02, -9.4790e-02, -1.9678e-02, -5.8521e-02, -1.3239e-01,\n",
       "                       -7.6594e-02, -1.8849e-01, -1.0535e-01, -1.5623e-01, -3.3639e-02,\n",
       "                       -1.4093e-01,  1.6834e-03, -5.5097e-02, -1.8800e-03, -7.9280e-02,\n",
       "                       -3.6218e-02, -6.4889e-02, -1.6441e-01, -7.4496e-02,  5.5295e-02,\n",
       "                       -1.9568e-01, -1.4298e-02, -7.9789e-02, -4.3019e-02,  2.2383e-02,\n",
       "                       -8.8881e-02,  1.8326e-02,  2.9277e-02, -9.5625e-02, -5.7606e-02,\n",
       "                       -1.2036e-02, -1.0646e-01, -6.2808e-02, -2.0700e-02, -6.8069e-02,\n",
       "                        1.0155e-02, -9.2035e-02, -5.1098e-02, -5.4714e-02,  9.4266e-03,\n",
       "                        5.9719e-02, -1.0940e-01, -4.3806e-02, -9.6702e-03, -5.4770e-02,\n",
       "                        4.9649e-04,  1.9655e-02, -1.3906e-01, -3.8901e-02,  2.4055e-02,\n",
       "                        4.3728e-02, -8.6175e-02, -1.1067e-02, -7.5298e-02, -1.2684e-01,\n",
       "                       -2.4992e-02, -6.8175e-02, -2.2250e-02, -1.4798e-01, -7.0873e-02,\n",
       "                       -1.0740e-01,  1.8157e-02, -2.0543e-01,  1.4649e-02, -1.0215e-01,\n",
       "                       -4.8446e-02, -4.4887e-03, -4.9430e-02, -6.1138e-02, -9.1262e-02,\n",
       "                       -9.9552e-02, -1.3861e-01, -1.6521e-02, -4.7510e-02, -6.2076e-02,\n",
       "                       -1.1598e-01, -8.4715e-02], device='cuda:0')),\n",
       "              ('layer4.0.shortcut.1.running_var',\n",
       "               tensor([0.0204, 0.0202, 0.0140, 0.0212, 0.0033, 0.0150, 0.0185, 0.0182, 0.0184,\n",
       "                       0.0190, 0.0325, 0.0123, 0.0276, 0.0296, 0.0343, 0.0207, 0.0172, 0.0186,\n",
       "                       0.0243, 0.0200, 0.0347, 0.0173, 0.0087, 0.0134, 0.0164, 0.0164, 0.0305,\n",
       "                       0.0034, 0.0140, 0.0258, 0.0157, 0.0190, 0.0290, 0.0231, 0.0126, 0.0149,\n",
       "                       0.0249, 0.0054, 0.0140, 0.0178, 0.0154, 0.0171, 0.0174, 0.0068, 0.0498,\n",
       "                       0.0165, 0.0141, 0.0059, 0.0065, 0.0150, 0.0137, 0.0149, 0.0100, 0.0239,\n",
       "                       0.0095, 0.0077, 0.0177, 0.0217, 0.0190, 0.0100, 0.0336, 0.0082, 0.0144,\n",
       "                       0.0124, 0.0126, 0.0062, 0.0066, 0.0352, 0.0063, 0.0178, 0.0227, 0.0228,\n",
       "                       0.0264, 0.0287, 0.0136, 0.0241, 0.0244, 0.0245, 0.0201, 0.0294, 0.0118,\n",
       "                       0.0261, 0.0059, 0.0120, 0.0133, 0.0087, 0.0084, 0.0086, 0.0181, 0.0099,\n",
       "                       0.0186, 0.0113, 0.0713, 0.0360, 0.0199, 0.0239, 0.0203, 0.0346, 0.0123,\n",
       "                       0.0140, 0.0143, 0.0160, 0.0107, 0.0080, 0.0092, 0.0266, 0.0270, 0.0201,\n",
       "                       0.0029, 0.0258, 0.0120, 0.0101, 0.0129, 0.0236, 0.0113, 0.0138, 0.0156,\n",
       "                       0.0198, 0.0079, 0.0181, 0.0180, 0.0045, 0.0167, 0.0169, 0.0227, 0.0209,\n",
       "                       0.0441, 0.0239, 0.0192, 0.0129, 0.0103, 0.0058, 0.0205, 0.0137, 0.0073,\n",
       "                       0.0235, 0.0145, 0.0126, 0.0354, 0.0069, 0.0286, 0.0247, 0.0207, 0.0102,\n",
       "                       0.0068, 0.0081, 0.0482, 0.0122, 0.0150, 0.0131, 0.0253, 0.0119, 0.0227,\n",
       "                       0.0203, 0.0204, 0.0286, 0.0317, 0.0145, 0.0187, 0.0044, 0.0083, 0.0197,\n",
       "                       0.0459, 0.0142, 0.0249, 0.0133, 0.0235, 0.0132, 0.0173, 0.0103, 0.0126,\n",
       "                       0.0228, 0.0130, 0.0043, 0.0138, 0.0082, 0.0128, 0.0045, 0.0166, 0.0082,\n",
       "                       0.0191, 0.0117, 0.0148, 0.0328, 0.0136, 0.0098, 0.0107, 0.0143, 0.0137,\n",
       "                       0.0134, 0.0251, 0.0080, 0.0098, 0.0169, 0.0317, 0.0191, 0.0166, 0.0105,\n",
       "                       0.0292, 0.0223, 0.0118, 0.0127, 0.0104, 0.0322, 0.0173, 0.0229, 0.0154,\n",
       "                       0.0237, 0.0168, 0.0193, 0.0142, 0.0063, 0.0114, 0.0246, 0.0110, 0.0133,\n",
       "                       0.0119, 0.0173, 0.0332, 0.0044, 0.0297, 0.0274, 0.0190, 0.0397, 0.0144,\n",
       "                       0.0325, 0.0181, 0.0116, 0.0132, 0.0058, 0.0166, 0.0109, 0.0166, 0.0109,\n",
       "                       0.0106, 0.0253, 0.0208, 0.0182, 0.0116, 0.0158, 0.0112, 0.0039, 0.0122,\n",
       "                       0.0175, 0.0049, 0.0128, 0.0184, 0.0206, 0.0264, 0.0159, 0.0171, 0.0125,\n",
       "                       0.0132, 0.0221, 0.0230, 0.0024, 0.0036, 0.0079, 0.0252, 0.0150, 0.0260,\n",
       "                       0.0532, 0.0185, 0.0315, 0.0294, 0.0167, 0.0212, 0.0316, 0.0382, 0.0129,\n",
       "                       0.0095, 0.0118, 0.0136, 0.0288, 0.0129, 0.0091, 0.0142, 0.0359, 0.0122,\n",
       "                       0.0062, 0.0207, 0.0231, 0.0045, 0.0348, 0.0346, 0.0132, 0.0073, 0.0188,\n",
       "                       0.0157, 0.0289, 0.0130, 0.0133, 0.0298, 0.0133, 0.0102, 0.0280, 0.0298,\n",
       "                       0.0135, 0.0075, 0.0229, 0.0261, 0.0293, 0.0155, 0.0350, 0.0059, 0.0192,\n",
       "                       0.0122, 0.0173, 0.0238, 0.0307, 0.0101, 0.0118, 0.0451, 0.0194, 0.0165,\n",
       "                       0.0363, 0.0189, 0.0263, 0.0169, 0.0231, 0.0233, 0.0070, 0.0212, 0.0197,\n",
       "                       0.0373, 0.0120, 0.0105, 0.0132, 0.0201, 0.0214, 0.0334, 0.0144, 0.0144,\n",
       "                       0.0114, 0.0154, 0.0100, 0.0131, 0.0237, 0.0180, 0.0114, 0.0396, 0.0416,\n",
       "                       0.0243, 0.0127, 0.0189, 0.0348, 0.0219, 0.0202, 0.0109, 0.0252, 0.0211,\n",
       "                       0.0179, 0.0136, 0.0221, 0.0034, 0.0173, 0.0265, 0.0086, 0.0119, 0.0082,\n",
       "                       0.0059, 0.0210, 0.0144, 0.0090, 0.0253, 0.0150, 0.0197, 0.0198, 0.0109,\n",
       "                       0.0254, 0.0208, 0.0107, 0.0190, 0.0232, 0.0089, 0.0133, 0.0028, 0.0130,\n",
       "                       0.0290, 0.0112, 0.0286, 0.0045, 0.0152, 0.0155, 0.0114, 0.0257, 0.0119,\n",
       "                       0.0312, 0.0152, 0.0106, 0.0090, 0.0231, 0.0107, 0.0257, 0.0169, 0.0179,\n",
       "                       0.0067, 0.0324, 0.0304, 0.0184, 0.0204, 0.0065, 0.0141, 0.0321, 0.0160,\n",
       "                       0.0251, 0.0160, 0.0213, 0.0131, 0.0342, 0.0155, 0.0106, 0.0162, 0.0118,\n",
       "                       0.0139, 0.0084, 0.0182, 0.0064, 0.0132, 0.0238, 0.0113, 0.0029, 0.0051,\n",
       "                       0.0184, 0.0138, 0.0223, 0.0050, 0.0215, 0.0135, 0.0179, 0.0046, 0.0107,\n",
       "                       0.0153, 0.0097, 0.0247, 0.0156, 0.0128, 0.0113, 0.0065, 0.0287, 0.0080,\n",
       "                       0.0252, 0.0133, 0.0298, 0.0232, 0.0240, 0.0059, 0.0083, 0.0127, 0.0070,\n",
       "                       0.0122, 0.0180, 0.0237, 0.0162, 0.0184, 0.0236, 0.0089, 0.0290, 0.0198,\n",
       "                       0.0322, 0.0180, 0.0119, 0.0381, 0.0138, 0.0157, 0.0120, 0.0242, 0.0188,\n",
       "                       0.0259, 0.0092, 0.0086, 0.0091, 0.0149, 0.0372, 0.0189, 0.0058, 0.0081,\n",
       "                       0.0114, 0.0189, 0.0154, 0.0134, 0.0068, 0.0426, 0.0215, 0.0043, 0.0066,\n",
       "                       0.0145, 0.0128, 0.0101, 0.0120, 0.0212, 0.0070, 0.0285, 0.0074, 0.0089,\n",
       "                       0.0226, 0.0062, 0.0445, 0.0092, 0.0248, 0.0145, 0.0112, 0.0257, 0.0333,\n",
       "                       0.0133, 0.0092, 0.0207, 0.0174, 0.0351, 0.0192, 0.0159, 0.0247],\n",
       "                      device='cuda:0')),\n",
       "              ('layer4.0.shortcut.1.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer4.1.conv1.weight',\n",
       "               tensor([[[[ 1.1447e-03, -5.9516e-03,  2.4291e-05],\n",
       "                         [ 6.2323e-03, -2.7400e-03, -1.7611e-03],\n",
       "                         [ 1.2027e-02,  7.8936e-03,  6.4338e-03]],\n",
       "               \n",
       "                        [[-5.1159e-03, -9.1002e-03, -3.6099e-03],\n",
       "                         [-3.8031e-03, -6.8094e-04, -3.4810e-03],\n",
       "                         [ 6.1288e-03,  2.9642e-03, -3.6729e-06]],\n",
       "               \n",
       "                        [[ 2.9648e-03, -9.5130e-04, -2.3833e-03],\n",
       "                         [-4.0489e-03, -4.6985e-03, -4.4670e-03],\n",
       "                         [ 2.5214e-03, -2.5998e-05,  3.9950e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.8221e-03,  1.4319e-03, -1.6089e-03],\n",
       "                         [-2.8150e-03, -5.0233e-03, -6.8427e-03],\n",
       "                         [-5.2522e-03, -1.2655e-02, -1.6034e-02]],\n",
       "               \n",
       "                        [[-3.6108e-04,  2.5701e-03,  3.5130e-03],\n",
       "                         [-2.5782e-03, -1.7348e-03, -2.8626e-03],\n",
       "                         [-4.4558e-03, -8.4820e-03, -9.1382e-03]],\n",
       "               \n",
       "                        [[ 2.7158e-04, -1.3518e-03, -3.6830e-03],\n",
       "                         [-7.2252e-03, -2.6206e-03, -2.4934e-03],\n",
       "                         [ 5.0752e-04,  9.2118e-06, -5.1163e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.9958e-03,  2.7509e-03,  1.8676e-03],\n",
       "                         [ 8.1133e-03, -6.4037e-03, -2.1636e-03],\n",
       "                         [-4.7984e-04, -1.1126e-02, -5.9925e-04]],\n",
       "               \n",
       "                        [[-3.7205e-04, -5.6307e-03, -1.8467e-03],\n",
       "                         [-2.1872e-03,  2.1463e-03, -3.7204e-03],\n",
       "                         [ 4.6584e-03,  1.1162e-02,  9.9188e-03]],\n",
       "               \n",
       "                        [[ 1.3602e-02,  8.3247e-03,  9.4388e-03],\n",
       "                         [ 6.1684e-03,  2.0571e-03,  2.3845e-03],\n",
       "                         [ 1.2696e-03,  4.2854e-03,  4.6355e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.0829e-03,  2.0713e-04, -1.1245e-03],\n",
       "                         [-6.5376e-03, -1.1931e-02, -1.4855e-02],\n",
       "                         [-4.0587e-03, -6.7006e-05, -2.0469e-03]],\n",
       "               \n",
       "                        [[-2.8351e-03,  4.3982e-03, -4.0269e-03],\n",
       "                         [-1.2552e-02, -4.5839e-03, -4.6978e-03],\n",
       "                         [-4.8389e-03, -8.0624e-03, -5.8781e-03]],\n",
       "               \n",
       "                        [[-3.4947e-03, -1.1022e-03, -2.5510e-03],\n",
       "                         [ 1.5913e-02,  3.3441e-02,  2.0606e-02],\n",
       "                         [-1.3950e-02, -7.5198e-03, -1.2761e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-9.9132e-04, -7.5670e-03, -2.2490e-03],\n",
       "                         [-3.1115e-03, -7.7425e-03, -5.7314e-03],\n",
       "                         [-9.2588e-03, -4.1573e-03, -8.3879e-03]],\n",
       "               \n",
       "                        [[ 6.4715e-03,  6.4905e-03, -2.9022e-04],\n",
       "                         [ 8.0419e-03,  2.5301e-03, -2.2590e-03],\n",
       "                         [ 5.9897e-03,  1.1143e-02,  6.4069e-03]],\n",
       "               \n",
       "                        [[ 6.8428e-03,  1.5523e-02,  1.2650e-03],\n",
       "                         [ 3.4597e-03,  6.3222e-03, -2.1894e-03],\n",
       "                         [-8.4602e-03, -7.0883e-03, -5.0960e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.2086e-02,  9.4621e-03,  1.9562e-03],\n",
       "                         [ 7.3369e-03,  6.8209e-03,  8.3567e-03],\n",
       "                         [-1.7404e-03, -1.7113e-03, -7.0781e-03]],\n",
       "               \n",
       "                        [[-2.9312e-03, -5.3499e-03, -3.9075e-03],\n",
       "                         [-4.1994e-03, -4.5817e-03, -4.9324e-03],\n",
       "                         [ 1.4320e-03,  4.7184e-03,  4.2397e-03]],\n",
       "               \n",
       "                        [[ 9.4480e-04,  3.0899e-03,  1.0120e-03],\n",
       "                         [ 4.0787e-03,  6.5111e-03,  1.8498e-03],\n",
       "                         [-1.2477e-02, -1.5234e-02, -1.0645e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 5.0535e-04, -1.1792e-03, -1.7107e-03],\n",
       "                         [-8.6583e-03, -9.1442e-03, -7.7483e-03],\n",
       "                         [-3.5308e-03, -5.6751e-04, -4.8487e-03]],\n",
       "               \n",
       "                        [[-1.7226e-03,  2.1256e-03, -4.2786e-03],\n",
       "                         [ 1.4889e-03,  2.7039e-03,  4.3527e-03],\n",
       "                         [-2.3803e-04,  1.1678e-03,  5.2707e-03]],\n",
       "               \n",
       "                        [[ 1.4923e-03,  8.2884e-03,  2.7528e-03],\n",
       "                         [ 4.4392e-03,  1.6412e-02,  1.0743e-02],\n",
       "                         [-3.2596e-03,  7.5111e-04,  7.2416e-05]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.7058e-03,  8.1067e-03,  8.4454e-03],\n",
       "                         [-6.2808e-04, -8.3233e-03, -9.3222e-03],\n",
       "                         [-3.2893e-03, -1.1083e-02, -1.0397e-02]],\n",
       "               \n",
       "                        [[ 3.5270e-03,  8.8529e-04,  1.6312e-03],\n",
       "                         [ 3.9493e-03,  4.1975e-03, -9.8523e-04],\n",
       "                         [ 2.4684e-03, -5.3256e-04, -2.2624e-03]],\n",
       "               \n",
       "                        [[ 9.1523e-04,  3.5644e-03,  4.0248e-03],\n",
       "                         [ 4.0074e-03,  3.5138e-03,  1.2999e-03],\n",
       "                         [ 1.3519e-03, -2.1006e-03,  3.4724e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1246e-04,  7.1052e-03,  3.3388e-03],\n",
       "                         [-1.7770e-03,  8.8746e-03,  3.8255e-03],\n",
       "                         [ 3.8820e-03,  8.3060e-03,  7.3014e-04]],\n",
       "               \n",
       "                        [[-6.6662e-03, -3.4556e-03, -5.0290e-03],\n",
       "                         [-7.4087e-03, -1.2814e-02, -1.3266e-02],\n",
       "                         [ 2.1656e-03,  3.4929e-05,  1.6284e-03]],\n",
       "               \n",
       "                        [[ 2.3867e-06, -7.5035e-03, -1.1944e-02],\n",
       "                         [-9.3178e-03, -8.2735e-03, -1.4818e-02],\n",
       "                         [-1.2439e-02,  4.2110e-04,  3.7256e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.1337e-03,  4.5409e-03,  9.5382e-04],\n",
       "                         [ 6.5021e-03,  5.7327e-03,  5.1813e-03],\n",
       "                         [-1.2919e-02, -5.3265e-03, -8.2573e-03]],\n",
       "               \n",
       "                        [[-9.8998e-04, -3.3217e-03, -1.6907e-03],\n",
       "                         [ 9.4623e-03,  5.8988e-03,  4.8156e-03],\n",
       "                         [-9.3391e-04,  8.9995e-04,  6.1277e-03]],\n",
       "               \n",
       "                        [[ 8.2910e-03,  9.8174e-03,  2.1567e-03],\n",
       "                         [ 1.8835e-03,  1.3034e-02,  8.6396e-03],\n",
       "                         [ 1.6934e-02,  3.1236e-02,  6.9022e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.1705e-03, -5.6031e-03, -1.1710e-02],\n",
       "                         [ 3.8671e-03, -4.7649e-04, -7.5649e-04],\n",
       "                         [ 9.7608e-03,  6.4260e-03, -3.4146e-03]],\n",
       "               \n",
       "                        [[-5.4238e-03, -6.7308e-03, -7.3726e-03],\n",
       "                         [ 9.1727e-03, -3.8460e-03, -1.0792e-02],\n",
       "                         [-4.5225e-03, -1.0951e-02, -1.3809e-02]],\n",
       "               \n",
       "                        [[-4.7589e-03, -4.4005e-03, -5.6511e-03],\n",
       "                         [ 1.7038e-02,  1.2987e-02,  8.9380e-03],\n",
       "                         [ 1.6189e-02,  1.7432e-02,  9.3077e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.8765e-03, -1.0192e-02, -7.3768e-03],\n",
       "                         [ 6.0181e-03, -6.7817e-03, -7.0153e-03],\n",
       "                         [ 1.3939e-02,  1.3083e-02,  9.2245e-03]],\n",
       "               \n",
       "                        [[ 1.6213e-03, -2.3282e-03, -7.6894e-03],\n",
       "                         [ 4.0316e-03,  8.2101e-04, -4.7113e-04],\n",
       "                         [-4.4977e-03, -5.4941e-03, -4.6003e-03]],\n",
       "               \n",
       "                        [[ 1.8313e-02,  1.5052e-02,  8.6506e-03],\n",
       "                         [ 6.6515e-03,  6.6187e-03,  4.1743e-03],\n",
       "                         [ 4.8069e-03,  2.5717e-02,  2.1956e-02]]]], device='cuda:0')),\n",
       "              ('layer4.1.bn1.weight',\n",
       "               tensor([0.1356, 0.1513, 0.1393, 0.1306, 0.2118, 0.3745, 0.2835, 0.1152, 0.1332,\n",
       "                       0.2420, 0.2083, 0.2391, 0.1345, 0.1633, 0.2266, 0.2174, 0.1679, 0.2624,\n",
       "                       0.1078, 0.1233, 0.1803, 0.1234, 0.2091, 0.2320, 0.2026, 0.2168, 0.1029,\n",
       "                       0.1455, 0.2691, 0.1045, 0.1791, 0.1343, 0.2668, 0.1384, 0.1899, 0.2303,\n",
       "                       0.1115, 0.2286, 0.1419, 0.1424, 0.1128, 0.3514, 0.1605, 0.1279, 0.1598,\n",
       "                       0.1367, 0.1653, 0.1761, 0.1295, 0.1720, 0.1455, 0.2150, 0.2150, 0.0871,\n",
       "                       0.1365, 0.1208, 0.1687, 0.1210, 0.2245, 0.1394, 0.1420, 0.1636, 0.3499,\n",
       "                       0.1244, 0.1783, 0.1240, 0.2020, 0.1805, 0.1368, 0.2177, 0.1719, 0.1205,\n",
       "                       0.2253, 0.1782, 0.1620, 0.1974, 0.1411, 0.1782, 0.1218, 0.2196, 0.1323,\n",
       "                       0.3406, 0.1119, 0.1921, 0.1576, 0.1336, 0.1082, 0.1821, 0.1518, 0.1322,\n",
       "                       0.1080, 0.1426, 0.1400, 0.1903, 0.0960, 0.1811, 0.1888, 0.1820, 0.1651,\n",
       "                       0.1147, 0.2882, 0.1771, 0.1488, 0.1640, 0.2022, 0.1336, 0.1276, 0.2206,\n",
       "                       0.1657, 0.1831, 0.2626, 0.1774, 0.1761, 0.2725, 0.2009, 0.1262, 0.1180,\n",
       "                       0.2324, 0.1458, 0.0980, 0.2128, 0.2801, 0.1963, 0.1744, 0.1746, 0.1498,\n",
       "                       0.2357, 0.1530, 0.1660, 0.1783, 0.1911, 0.1854, 0.2401, 0.1236, 0.1063,\n",
       "                       0.1009, 0.2173, 0.2423, 0.2469, 0.1171, 0.1981, 0.1454, 0.2817, 0.1469,\n",
       "                       0.1547, 0.1073, 0.1791, 0.1846, 0.1321, 0.2617, 0.1636, 0.2266, 0.1858,\n",
       "                       0.1287, 0.1691, 0.1501, 0.1900, 0.3189, 0.1342, 0.1944, 0.1118, 0.1384,\n",
       "                       0.1608, 0.1487, 0.1471, 0.1569, 0.1768, 0.2081, 0.1820, 0.1683, 0.1251,\n",
       "                       0.2173, 0.1954, 0.2456, 0.1192, 0.1045, 0.1019, 0.1764, 0.1213, 0.2086,\n",
       "                       0.2303, 0.2538, 0.0863, 0.1630, 0.2146, 0.0903, 0.2822, 0.1695, 0.1317,\n",
       "                       0.1963, 0.1181, 0.1456, 0.2281, 0.1383, 0.3066, 0.1419, 0.1468, 0.1863,\n",
       "                       0.0995, 0.2125, 0.2177, 0.0814, 0.1553, 0.1044, 0.0941, 0.2004, 0.1968,\n",
       "                       0.1793, 0.1156, 0.1728, 0.1405, 0.2036, 0.2204, 0.2036, 0.2109, 0.1210,\n",
       "                       0.1619, 0.1041, 0.1525, 0.2194, 0.1901, 0.2029, 0.1582, 0.2443, 0.1285,\n",
       "                       0.1207, 0.1048, 0.2594, 0.1424, 0.2688, 0.1228, 0.2320, 0.2298, 0.2469,\n",
       "                       0.2042, 0.1992, 0.2320, 0.2112, 0.1640, 0.1603, 0.0790, 0.2210, 0.0976,\n",
       "                       0.1405, 0.1076, 0.1706, 0.0986, 0.1047, 0.2269, 0.1630, 0.2018, 0.2115,\n",
       "                       0.1186, 0.1389, 0.1480, 0.1370, 0.1336, 0.1267, 0.2102, 0.2757, 0.2211,\n",
       "                       0.1203, 0.1259, 0.2251, 0.1999, 0.1567, 0.2275, 0.1743, 0.2041, 0.1336,\n",
       "                       0.1935, 0.1870, 0.3128, 0.1856, 0.1054, 0.1424, 0.1991, 0.1166, 0.1347,\n",
       "                       0.1628, 0.1594, 0.1207, 0.1511, 0.2746, 0.1156, 0.1506, 0.1359, 0.1628,\n",
       "                       0.1502, 0.2842, 0.2532, 0.1299, 0.3925, 0.1092, 0.1630, 0.0956, 0.1663,\n",
       "                       0.1186, 0.1602, 0.1593, 0.2480, 0.2615, 0.2192, 0.1224, 0.3112, 0.1452,\n",
       "                       0.1607, 0.2545, 0.1642, 0.2060, 0.1345, 0.1360, 0.1792, 0.1382, 0.1505,\n",
       "                       0.1484, 0.2313, 0.1502, 0.0861, 0.1350, 0.2502, 0.1498, 0.1374, 0.1723,\n",
       "                       0.1743, 0.1758, 0.1447, 0.1353, 0.1187, 0.1084, 0.1806, 0.1178, 0.1200,\n",
       "                       0.2235, 0.1310, 0.0702, 0.0831, 0.1347, 0.1006, 0.1837, 0.1453, 0.1603,\n",
       "                       0.1077, 0.1726, 0.2017, 0.1864, 0.2464, 0.1442, 0.2692, 0.1893, 0.1926,\n",
       "                       0.1889, 0.1573, 0.3120, 0.1200, 0.1614, 0.1504, 0.1386, 0.1148, 0.1406,\n",
       "                       0.1989, 0.2089, 0.2086, 0.1314, 0.1513, 0.2672, 0.1665, 0.1945, 0.2742,\n",
       "                       0.1410, 0.1254, 0.1278, 0.1718, 0.1931, 0.1698, 0.1735, 0.1285, 0.2262,\n",
       "                       0.1410, 0.1264, 0.1198, 0.2532, 0.1569, 0.2815, 0.1277, 0.2338, 0.1097,\n",
       "                       0.1709, 0.2104, 0.1771, 0.1393, 0.1194, 0.0683, 0.1151, 0.2990, 0.1458,\n",
       "                       0.1467, 0.1859, 0.2905, 0.1185, 0.2062, 0.1284, 0.1266, 0.2472, 0.1071,\n",
       "                       0.1501, 0.2281, 0.1165, 0.1438, 0.1208, 0.1124, 0.1202, 0.1567, 0.1591,\n",
       "                       0.1353, 0.1526, 0.2030, 0.1206, 0.1668, 0.2085, 0.1338, 0.1496, 0.1680,\n",
       "                       0.1524, 0.1214, 0.1852, 0.2230, 0.2292, 0.1838, 0.2614, 0.1051, 0.1954,\n",
       "                       0.0867, 0.1195, 0.2358, 0.1688, 0.1692, 0.1045, 0.1345, 0.1549, 0.1056,\n",
       "                       0.1021, 0.1510, 0.1301, 0.2021, 0.2108, 0.2705, 0.1668, 0.2318, 0.2313,\n",
       "                       0.2787, 0.2123, 0.1401, 0.1860, 0.1892, 0.2096, 0.1089, 0.1707, 0.1510,\n",
       "                       0.1875, 0.1345, 0.2117, 0.2000, 0.1417, 0.1549, 0.1406, 0.2975, 0.1597,\n",
       "                       0.2058, 0.1768, 0.2825, 0.1461, 0.1981, 0.1684, 0.2814, 0.1133, 0.1289,\n",
       "                       0.2237, 0.1941, 0.1713, 0.1908, 0.1816, 0.1277, 0.1767, 0.0952, 0.1063,\n",
       "                       0.3260, 0.1043, 0.2055, 0.1371, 0.1318, 0.1167, 0.1835, 0.2222, 0.1191,\n",
       "                       0.1401, 0.1875, 0.1197, 0.1526, 0.0996, 0.1680, 0.2686, 0.1808, 0.1338,\n",
       "                       0.1691, 0.1734, 0.1484, 0.2101, 0.1347, 0.0969, 0.1493, 0.2016],\n",
       "                      device='cuda:0')),\n",
       "              ('layer4.1.bn1.bias',\n",
       "               tensor([-0.0579, -0.0329, -0.0337, -0.1005, -0.1253, -0.3986, -0.1466, -0.0611,\n",
       "                       -0.0298, -0.1287, -0.0526, -0.0897, -0.0080, -0.0833, -0.0780, -0.1508,\n",
       "                       -0.0398, -0.3133, -0.0475, -0.0178, -0.1298, -0.0287, -0.1822, -0.0724,\n",
       "                       -0.1955, -0.1202, -0.0388, -0.0490, -0.0311, -0.0449, -0.0540, -0.0606,\n",
       "                       -0.1061, -0.0385, -0.1464, -0.1380, -0.0448, -0.0335, -0.0627, -0.0361,\n",
       "                       -0.0483, -0.1853, -0.0268, -0.0320, -0.0820, -0.0553, -0.0683, -0.0797,\n",
       "                       -0.0555, -0.0904, -0.1007, -0.0703, -0.0942, -0.0219, -0.0688, -0.0550,\n",
       "                       -0.1156, -0.0035, -0.0840,  0.0086, -0.0122, -0.0737, -0.2428, -0.0449,\n",
       "                       -0.1213, -0.0420, -0.1087, -0.0803,  0.0016, -0.1539, -0.0681, -0.0163,\n",
       "                       -0.2178, -0.0658, -0.0752, -0.1246, -0.0543, -0.0956, -0.0235, -0.0675,\n",
       "                       -0.0876, -0.1693, -0.0325, -0.0795, -0.1427, -0.0015, -0.0186, -0.0281,\n",
       "                       -0.0574, -0.0626, -0.0254, -0.0620, -0.0096, -0.0669, -0.0167, -0.0545,\n",
       "                       -0.0646, -0.1237, -0.0494, -0.0293, -0.1273, -0.0448, -0.0513, -0.0776,\n",
       "                       -0.0785, -0.0811, -0.0706,  0.0080, -0.0737, -0.0977, -0.1827, -0.0320,\n",
       "                       -0.1408, -0.1871, -0.0631, -0.0941, -0.0865, -0.1817, -0.0370, -0.0373,\n",
       "                       -0.1460, -0.1369, -0.1319, -0.0768, -0.0370, -0.0501, -0.0754, -0.1544,\n",
       "                       -0.0839, -0.0764, -0.1405, -0.1389, -0.1940, -0.0613, -0.0307, -0.0609,\n",
       "                       -0.0992, -0.2529, -0.1874, -0.0608, -0.0914, -0.0174, -0.1502, -0.0123,\n",
       "                       -0.1486, -0.0364, -0.1096, -0.0584, -0.0203, -0.1914, -0.0615, -0.1249,\n",
       "                       -0.0856, -0.1006, -0.1269, -0.0662, -0.0286, -0.1573, -0.0666, -0.1273,\n",
       "                       -0.1136, -0.0010, -0.0587, -0.1019, -0.0893, -0.0323, -0.1414, -0.2206,\n",
       "                       -0.0433,  0.0253, -0.0627, -0.1392, -0.1991, -0.0314, -0.0659, -0.0103,\n",
       "                       -0.0097, -0.1375, -0.0687, -0.1441, -0.1194, -0.1938, -0.0609, -0.0707,\n",
       "                       -0.0317, -0.0277, -0.2697, -0.0802, -0.0272, -0.1260, -0.0382, -0.0268,\n",
       "                       -0.1568, -0.0454, -0.2682, -0.0796, -0.0551, -0.1041, -0.0368, -0.0890,\n",
       "                       -0.1535, -0.0124, -0.1004, -0.1041, -0.0301, -0.1184, -0.0229, -0.2014,\n",
       "                       -0.0186, -0.0325, -0.0449, -0.2170, -0.0884, -0.0196, -0.1125, -0.0204,\n",
       "                       -0.1004, -0.0460, -0.0182, -0.1174, -0.0718, -0.1138, -0.0877, -0.0859,\n",
       "                       -0.0616, -0.0597, -0.0504, -0.0825, -0.0936, -0.1596, -0.0573, -0.1334,\n",
       "                       -0.1423, -0.1543, -0.0795, -0.1090, -0.1172, -0.1728, -0.1106, -0.0375,\n",
       "                       -0.0366, -0.1028, -0.0220, -0.0026, -0.0604, -0.0369, -0.0129, -0.0905,\n",
       "                       -0.1054, -0.1469, -0.1087, -0.0810, -0.0525, -0.0853, -0.0745, -0.0224,\n",
       "                       -0.0249, -0.0494, -0.1386, -0.1928, -0.1570, -0.0279, -0.0804, -0.0965,\n",
       "                       -0.1292, -0.0630, -0.1301, -0.1137, -0.0324, -0.0546, -0.1151, -0.0980,\n",
       "                       -0.1686, -0.1965, -0.0640, -0.0657, -0.1273, -0.0454, -0.0649, -0.0484,\n",
       "                       -0.0952, -0.0110, -0.0396, -0.2055, -0.0371, -0.0897, -0.0590, -0.0319,\n",
       "                       -0.0892, -0.1536, -0.1721, -0.1081, -0.3087, -0.0866, -0.0172, -0.0149,\n",
       "                       -0.0418, -0.0157, -0.1224, -0.0531, -0.2102, -0.1513, -0.2071, -0.0683,\n",
       "                       -0.1653, -0.1310, -0.0404, -0.1942, -0.0463, -0.1518, -0.0598, -0.0625,\n",
       "                       -0.1234, -0.0680, -0.0955, -0.0486, -0.1471, -0.0703, -0.0105, -0.0249,\n",
       "                       -0.1023, -0.1077, -0.0460, -0.1164, -0.0800, -0.1501, -0.1018, -0.0334,\n",
       "                       -0.0317, -0.0614, -0.0710, -0.0267, -0.0549, -0.1342, -0.0736, -0.0307,\n",
       "                       -0.0261, -0.0669, -0.0268, -0.0885, -0.0288, -0.0563, -0.0210, -0.1177,\n",
       "                       -0.0225, -0.1186, -0.1169, -0.0591, -0.0948, -0.0031, -0.0894, -0.0519,\n",
       "                       -0.0277, -0.1476, -0.0037, -0.0603, -0.0831, -0.0440, -0.0187, -0.0509,\n",
       "                       -0.0783, -0.1062, -0.0557, -0.0115, -0.0225, -0.1621, -0.1045, -0.1071,\n",
       "                       -0.1026, -0.0576, -0.0659, -0.0416, -0.1345, -0.0680, -0.0671, -0.0881,\n",
       "                       -0.0144, -0.1846, -0.0405, -0.0758,  0.0501, -0.1244, -0.0324,  0.0016,\n",
       "                       -0.0228, -0.0377, -0.0502, -0.0561, -0.0792, -0.0417, -0.0328, -0.0434,\n",
       "                       -0.0420, -0.0940, -0.1757, -0.0165, -0.0939, -0.1060, -0.1650,  0.0040,\n",
       "                       -0.1160, -0.0435, -0.0123, -0.1715, -0.0119, -0.0309, -0.0982, -0.0306,\n",
       "                       -0.0173, -0.0334, -0.0409, -0.0400, -0.0729, -0.0128, -0.0378, -0.0477,\n",
       "                       -0.1206, -0.0636, -0.0674, -0.0486,  0.0013, -0.0930, -0.1035, -0.0633,\n",
       "                       -0.0429, -0.2102,  0.0090, -0.1319, -0.0609, -0.0829, -0.0127, -0.0967,\n",
       "                       -0.0483, -0.0026, -0.1357, -0.1154, -0.1212, -0.1400, -0.0486, -0.0587,\n",
       "                       -0.0683, -0.0718, -0.0045, -0.0751, -0.1629, -0.1764, -0.1938, -0.0678,\n",
       "                       -0.1426, -0.0512, -0.0894, -0.0390, -0.0961, -0.1634, -0.0925, -0.1326,\n",
       "                       -0.0672, -0.0440, -0.0689, -0.1483, -0.0756, -0.1421, -0.0390, -0.0804,\n",
       "                       -0.0773, -0.0389, -0.1753, -0.1163, -0.1409, -0.0983, -0.1567, -0.0086,\n",
       "                       -0.0201, -0.0252, -0.1528, -0.0498, -0.0219, -0.1493, -0.0911, -0.0114,\n",
       "                       -0.0604, -0.0831, -0.0556, -0.0411, -0.0751, -0.0321, -0.3501, -0.0495,\n",
       "                       -0.1520, -0.1282, -0.0513, -0.0502, -0.0891, -0.0580, -0.0204,  0.0025,\n",
       "                       -0.1072,  0.0286, -0.0579, -0.0232, -0.0598, -0.1052, -0.0468, -0.0368,\n",
       "                       -0.0198, -0.1020, -0.0612, -0.0792, -0.0218, -0.0372, -0.0588, -0.0735],\n",
       "                      device='cuda:0')),\n",
       "              ('layer4.1.bn1.running_mean',\n",
       "               tensor([-0.1453, -0.1954, -0.1447, -0.1068, -0.1996,  0.2355, -0.0561,  0.0295,\n",
       "                       -0.0748, -0.2509, -0.2109,  0.0093, -0.2652, -0.1557, -0.0007, -0.1643,\n",
       "                       -0.0076, -0.1230,  0.0923, -0.2060, -0.1361, -0.1843, -0.2859, -0.1880,\n",
       "                       -0.1934, -0.0996, -0.0874, -0.1767,  0.0021, -0.2176, -0.1704, -0.1416,\n",
       "                       -0.1161, -0.0018, -0.1013, -0.1408, -0.1376, -0.4434, -0.1866, -0.2301,\n",
       "                       -0.0910, -0.4111, -0.1594, -0.2731,  0.0635, -0.2039, -0.1956, -0.1402,\n",
       "                       -0.1582, -0.1601, -0.0108, -0.0486, -0.2269, -0.1632, -0.1607, -0.2427,\n",
       "                       -0.0470, -0.2415, -0.2835, -0.1302, -0.2221,  0.0046, -0.3158, -0.0706,\n",
       "                       -0.2134,  0.0641, -0.1506, -0.1230, -0.1667, -0.1611, -0.1153, -0.0367,\n",
       "                       -0.1108, -0.2522, -0.2575, -0.0899, -0.1202, -0.2258, -0.2004, -0.1302,\n",
       "                        0.0160, -0.0893, -0.1959, -0.0770, -0.0795, -0.2714, -0.2161, -0.2956,\n",
       "                       -0.1572, -0.2003, -0.1383, -0.1736, -0.2020, -0.3036, -0.1399, -0.3273,\n",
       "                       -0.1778, -0.2161, -0.2012, -0.2287, -0.0330, -0.2087, -0.3008,  0.0783,\n",
       "                       -0.1522, -0.0471, -0.1678, -0.3358, -0.1466, -0.2579, -0.1545, -0.2603,\n",
       "                        0.1137, -0.2017, -0.3255,  0.0310, -0.1042, -0.1465, -0.1228, -0.1064,\n",
       "                       -0.1722, -0.0967, -0.1552, -0.0636, -0.3123, -0.0655, -0.1260, -0.1195,\n",
       "                       -0.0868, -0.0883, -0.1624, -0.2938, -0.0657, -0.1756, -0.1722, -0.1072,\n",
       "                       -0.3070, -0.1464, -0.0330, -0.0416, -0.2104, -0.2161, -0.2714, -0.1041,\n",
       "                       -0.1456, -0.1437, -0.1529, -0.1694, -0.2501, -0.0210, -0.2363, -0.0370,\n",
       "                       -0.0213,  0.0166, -0.0516,  0.0143, -0.2405, -0.1854, -0.1793, -0.1319,\n",
       "                        0.0055, -0.2061, -0.3125, -0.1336, -0.0556, -0.1651, -0.1353, -0.1936,\n",
       "                        0.1433, -0.2625, -0.1091, -0.1983, -0.2002, -0.2636, -0.1877, -0.1353,\n",
       "                       -0.2003, -0.0890,  0.0686, -0.2236, -0.3503, -0.2859, -0.0333, -0.1001,\n",
       "                       -0.2169, -0.1102, -0.0570,  0.0598, -0.2343, -0.1223, -0.1031, -0.2164,\n",
       "                       -0.2447, -0.1143, -0.2384, -0.1951, -0.0617, -0.1641, -0.0161, -0.0448,\n",
       "                       -0.2410, -0.2157, -0.0199, -0.0734, -0.1283, -0.1911, -0.2807, -0.2900,\n",
       "                        0.0796, -0.2556, -0.2054, -0.1432, -0.2213, -0.3674, -0.2365,  0.0487,\n",
       "                       -0.1327, -0.1452, -0.2872,  0.0284, -0.1414, -0.0901, -0.0850, -0.0612,\n",
       "                       -0.0119, -0.0239, -0.0577, -0.3168, -0.0432, -0.1277, -0.2509, -0.1588,\n",
       "                       -0.0665, -0.2471, -0.2067, -0.1218, -0.0399, -0.1066, -0.1170, -0.2730,\n",
       "                        0.0410, -0.0744, -0.0657, -0.2213,  0.0413, -0.2680, -0.1214, -0.0388,\n",
       "                       -0.1246,  0.1209, -0.2817, -0.3869, -0.1386, -0.0940, -0.0367, -0.1945,\n",
       "                       -0.2436, -0.1770, -0.0615, -0.0948, -0.1873, -0.2119, -0.1184, -0.2844,\n",
       "                       -0.1457, -0.1842, -0.2360, -0.0815, -0.2872, -0.1665, -0.1639, -0.2299,\n",
       "                       -0.1878, -0.2908, -0.0665, -0.2377, -0.1361, -0.1806,  0.0612,  0.0503,\n",
       "                       -0.0368, -0.2701, -0.1052, -0.0670, -0.1592, -0.0643, -0.1218, -0.1745,\n",
       "                       -0.1221, -0.1310, -0.1747, -0.1495, -0.4175,  0.1008, -0.2381, -0.0507,\n",
       "                        0.0072, -0.2045, -0.1251, -0.3392, -0.3474, -0.2709, -0.1677, -0.1784,\n",
       "                       -0.4451, -0.0301, -0.1138, -0.2138, -0.3099, -0.0582, -0.1920, -0.1839,\n",
       "                       -0.1084, -0.1707, -0.0479, -0.1117, -0.2119, -0.0728, -0.1925, -0.2246,\n",
       "                       -0.3458, -0.1422, -0.2446, -0.2033,  0.0282, -0.1106, -0.1327, -0.2765,\n",
       "                       -0.1877, -0.0086, -0.2808, -0.1678, -0.0444, -0.2121,  0.0649, -0.0254,\n",
       "                       -0.0820, -0.2117, -0.1348, -0.0848, -0.2169, -0.2975, -0.0825,  0.1207,\n",
       "                       -0.2251, -0.0433, -0.1655, -0.2433, -0.2506, -0.2086, -0.1557, -0.3822,\n",
       "                       -0.3157, -0.1715, -0.1338,  0.0803, -0.2157, -0.2455, -0.0273,  0.0383,\n",
       "                       -0.1645,  0.0113, -0.2777, -0.2271, -0.2307, -0.1698, -0.2183, -0.1374,\n",
       "                       -0.3426, -0.2893,  0.0186,  0.0152, -0.0770, -0.1246, -0.0455, -0.0608,\n",
       "                       -0.2304, -0.1814, -0.0234, -0.2264, -0.2775, -0.2640, -0.3025, -0.3083,\n",
       "                       -0.1847, -0.1526, -0.0490, -0.3632, -0.1797, -0.0814, -0.3199, -0.1839,\n",
       "                        0.1001, -0.1192, -0.1191, -0.1933, -0.1363, -0.2019, -0.1620, -0.1785,\n",
       "                       -0.1610, -0.2107, -0.2580, -0.1282, -0.1359, -0.2280, -0.1739, -0.1107,\n",
       "                       -0.2498, -0.1042, -0.2085, -0.1603, -0.1373, -0.3111, -0.1868, -0.1995,\n",
       "                       -0.2853,  0.0799, -0.2056, -0.3347, -0.1907, -0.0684, -0.0944, -0.1763,\n",
       "                        0.1062, -0.0635, -0.3202, -0.1577, -0.2010, -0.3969, -0.1826, -0.1243,\n",
       "                        0.0402, -0.0784, -0.2898, -0.0492, -0.0644,  0.0265, -0.2469, -0.1054,\n",
       "                        0.0526, -0.1436, -0.3051, -0.0400,  0.0111, -0.0519, -0.3453, -0.1282,\n",
       "                       -0.1836, -0.2350, -0.4640, -0.1819, -0.1876, -0.1508,  0.0156, -0.2663,\n",
       "                        0.0215, -0.2570, -0.1191, -0.0572, -0.1530, -0.2081, -0.2563, -0.1028,\n",
       "                       -0.1947, -0.2853, -0.0667,  0.0347,  0.0795, -0.0603, -0.1041, -0.2951,\n",
       "                       -0.1132, -0.3144, -0.2581, -0.0706, -0.1689, -0.0980, -0.0993, -0.2407,\n",
       "                       -0.2664, -0.0884, -0.1652, -0.2766,  0.0130, -0.0831, -0.1746, -0.1192,\n",
       "                       -0.0963, -0.0153, -0.1256, -0.0593,  0.0339, -0.3793, -0.3017, -0.3227,\n",
       "                       -0.1833, -0.2361, -0.1705, -0.1296, -0.1613, -0.3169, -0.2770, -0.0967,\n",
       "                       -0.2297, -0.1673, -0.0060, -0.0601, -0.2521, -0.0026, -0.0654, -0.1110],\n",
       "                      device='cuda:0')),\n",
       "              ('layer4.1.bn1.running_var',\n",
       "               tensor([0.0302, 0.0714, 0.0407, 0.0391, 0.1251, 0.1698, 0.1051, 0.0350, 0.0365,\n",
       "                       0.0786, 0.1534, 0.3652, 0.0454, 0.0549, 0.1321, 0.1026, 0.0832, 0.1441,\n",
       "                       0.0743, 0.0373, 0.0950, 0.0401, 0.1204, 0.0949, 0.1306, 0.1657, 0.0297,\n",
       "                       0.0487, 0.3477, 0.0340, 0.0615, 0.0341, 0.1304, 0.0340, 0.0819, 0.0802,\n",
       "                       0.0346, 0.1211, 0.0591, 0.0669, 0.0265, 0.2649, 0.0719, 0.0397, 0.0266,\n",
       "                       0.0380, 0.0830, 0.0659, 0.0517, 0.0556, 0.0784, 0.0680, 0.2029, 0.0280,\n",
       "                       0.0510, 0.1031, 0.0638, 0.0533, 0.1013, 0.0389, 0.0543, 0.0452, 0.1810,\n",
       "                       0.0311, 0.0913, 0.0723, 0.1352, 0.0866, 0.0221, 0.2903, 0.0998, 0.0204,\n",
       "                       0.1539, 0.0594, 0.0751, 0.1451, 0.0610, 0.0695, 0.0561, 0.3456, 0.0207,\n",
       "                       0.2401, 0.0377, 0.0477, 0.0505, 0.0508, 0.0471, 0.0685, 0.0742, 0.0405,\n",
       "                       0.0362, 0.0659, 0.0335, 0.0760, 0.0302, 0.0928, 0.0628, 0.1200, 0.0561,\n",
       "                       0.0472, 0.2175, 0.1375, 0.0963, 0.0369, 0.1537, 0.0300, 0.0511, 0.1171,\n",
       "                       0.0786, 0.0974, 0.1761, 0.1004, 0.0310, 0.1536, 0.0890, 0.0241, 0.0403,\n",
       "                       0.0850, 0.0491, 0.0460, 0.1066, 0.1969, 0.0953, 0.0709, 0.2816, 0.0308,\n",
       "                       0.0763, 0.0823, 0.0648, 0.1023, 0.0627, 0.1270, 0.1049, 0.0642, 0.0279,\n",
       "                       0.0204, 0.1160, 0.1027, 0.0637, 0.0197, 0.1242, 0.0413, 0.2364, 0.0517,\n",
       "                       0.1371, 0.0309, 0.0645, 0.0557, 0.0509, 0.1747, 0.0685, 0.0971, 0.0882,\n",
       "                       0.0391, 0.0520, 0.0899, 0.0903, 0.1807, 0.0412, 0.0850, 0.0274, 0.0467,\n",
       "                       0.0831, 0.0582, 0.0629, 0.0442, 0.0676, 0.1038, 0.2147, 0.0588, 0.0409,\n",
       "                       0.1669, 0.0883, 0.1792, 0.0526, 0.0286, 0.0408, 0.0648, 0.0259, 0.1912,\n",
       "                       0.2337, 0.1582, 0.0194, 0.0649, 0.1496, 0.0261, 0.0693, 0.1559, 0.0457,\n",
       "                       0.0768, 0.0477, 0.0780, 0.2299, 0.0429, 0.2464, 0.0590, 0.0831, 0.0830,\n",
       "                       0.0374, 0.0792, 0.1365, 0.0307, 0.0521, 0.0462, 0.0263, 0.1186, 0.0649,\n",
       "                       0.1300, 0.0722, 0.1024, 0.0999, 0.0880, 0.1080, 0.0943, 0.1196, 0.0532,\n",
       "                       0.0467, 0.0368, 0.0763, 0.1166, 0.0865, 0.0724, 0.0531, 0.3402, 0.1030,\n",
       "                       0.0317, 0.0268, 0.1541, 0.0468, 0.2066, 0.0633, 0.1293, 0.0900, 0.0985,\n",
       "                       0.0827, 0.0780, 0.1206, 0.1136, 0.0861, 0.0633, 0.0148, 0.0952, 0.0213,\n",
       "                       0.0289, 0.0649, 0.0819, 0.0268, 0.0277, 0.1728, 0.0437, 0.0911, 0.1350,\n",
       "                       0.0647, 0.0441, 0.0562, 0.0390, 0.0455, 0.0394, 0.0815, 0.1129, 0.0863,\n",
       "                       0.0400, 0.0382, 0.1378, 0.0514, 0.0740, 0.1011, 0.0779, 0.1178, 0.0436,\n",
       "                       0.1083, 0.1276, 0.1615, 0.1456, 0.0417, 0.0509, 0.0720, 0.0252, 0.0706,\n",
       "                       0.0318, 0.1125, 0.0841, 0.0324, 0.0969, 0.0424, 0.0667, 0.0370, 0.0536,\n",
       "                       0.0617, 0.2553, 0.2451, 0.0567, 0.3442, 0.0222, 0.0588, 0.0246, 0.0631,\n",
       "                       0.0408, 0.0757, 0.1064, 0.1611, 0.2047, 0.1171, 0.0475, 0.2622, 0.0512,\n",
       "                       0.0706, 0.2105, 0.0630, 0.0847, 0.0535, 0.0861, 0.1071, 0.0488, 0.0588,\n",
       "                       0.0592, 0.0973, 0.0684, 0.0299, 0.0527, 0.1392, 0.0529, 0.0616, 0.0687,\n",
       "                       0.0502, 0.0655, 0.0605, 0.0664, 0.0416, 0.0222, 0.0827, 0.0574, 0.0350,\n",
       "                       0.1366, 0.0265, 0.0218, 0.0134, 0.0872, 0.0238, 0.0799, 0.0505, 0.0797,\n",
       "                       0.0358, 0.0409, 0.0811, 0.0755, 0.1698, 0.0691, 0.1561, 0.0467, 0.0857,\n",
       "                       0.1260, 0.0800, 0.2033, 0.0255, 0.0614, 0.0612, 0.0631, 0.0323, 0.0243,\n",
       "                       0.0792, 0.0650, 0.1216, 0.0334, 0.0665, 0.1471, 0.0523, 0.1240, 0.1464,\n",
       "                       0.0614, 0.0540, 0.0597, 0.0488, 0.0859, 0.0674, 0.1016, 0.0447, 0.1060,\n",
       "                       0.0359, 0.0424, 0.1135, 0.1064, 0.0594, 0.0847, 0.0504, 0.1248, 0.0256,\n",
       "                       0.1505, 0.1386, 0.1298, 0.0983, 0.0304, 0.0128, 0.0492, 0.1148, 0.0342,\n",
       "                       0.0602, 0.0916, 0.3547, 0.0291, 0.0916, 0.0525, 0.0547, 0.1429, 0.0209,\n",
       "                       0.0667, 0.1495, 0.0280, 0.0467, 0.0198, 0.0347, 0.0341, 0.0670, 0.0561,\n",
       "                       0.0418, 0.0554, 0.1807, 0.0620, 0.1169, 0.1258, 0.0316, 0.0412, 0.0822,\n",
       "                       0.0945, 0.0574, 0.1145, 0.1025, 0.1503, 0.1699, 0.2330, 0.0332, 0.1082,\n",
       "                       0.0111, 0.0341, 0.1445, 0.0595, 0.0583, 0.0285, 0.0860, 0.0450, 0.0160,\n",
       "                       0.0411, 0.0737, 0.0356, 0.0661, 0.0603, 0.2433, 0.0546, 0.1051, 0.1143,\n",
       "                       0.1682, 0.0980, 0.0686, 0.0997, 0.0743, 0.0916, 0.0361, 0.0765, 0.0559,\n",
       "                       0.0879, 0.0590, 0.1237, 0.0903, 0.0388, 0.0549, 0.0654, 0.2268, 0.0323,\n",
       "                       0.1010, 0.0523, 0.1942, 0.0508, 0.0748, 0.0550, 0.1312, 0.0650, 0.0778,\n",
       "                       0.1254, 0.0487, 0.0803, 0.0887, 0.0616, 0.0519, 0.0739, 0.0203, 0.0408,\n",
       "                       0.2152, 0.0209, 0.1101, 0.0841, 0.0813, 0.0251, 0.1149, 0.1259, 0.0641,\n",
       "                       0.0843, 0.0706, 0.0756, 0.0489, 0.0266, 0.0619, 0.1344, 0.0747, 0.0341,\n",
       "                       0.0781, 0.0892, 0.0759, 0.0962, 0.0545, 0.0575, 0.0916, 0.1132],\n",
       "                      device='cuda:0')),\n",
       "              ('layer4.1.bn1.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('layer4.1.conv2.weight',\n",
       "               tensor([[[[ 7.3942e-03,  6.2165e-03,  6.1172e-03],\n",
       "                         [ 3.5433e-03,  4.3926e-04,  1.0316e-03],\n",
       "                         [ 2.2312e-03, -1.6704e-03, -3.2624e-04]],\n",
       "               \n",
       "                        [[-6.6154e-04, -1.4458e-03, -2.3272e-03],\n",
       "                         [-2.0499e-03, -3.2194e-03, -2.6168e-03],\n",
       "                         [ 3.6841e-04,  1.1414e-04,  3.3816e-04]],\n",
       "               \n",
       "                        [[-9.8895e-04, -3.0656e-03, -3.1854e-03],\n",
       "                         [-5.7013e-03, -9.4142e-03, -6.2599e-03],\n",
       "                         [-3.7920e-03, -5.9176e-03, -4.6271e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.3858e-03, -3.6201e-03, -2.7147e-03],\n",
       "                         [-2.9104e-03, -2.3070e-03, -1.6524e-03],\n",
       "                         [-4.1330e-03, -3.8952e-03, -3.8796e-03]],\n",
       "               \n",
       "                        [[ 3.1332e-03,  3.4531e-03,  6.3463e-04],\n",
       "                         [ 2.7593e-04, -1.9754e-03, -3.8988e-03],\n",
       "                         [-3.7352e-03, -5.7750e-03, -6.6955e-03]],\n",
       "               \n",
       "                        [[ 3.8493e-04, -1.5627e-03, -3.5479e-04],\n",
       "                         [ 1.3144e-03,  7.8423e-04,  2.3927e-03],\n",
       "                         [-2.9784e-03, -4.1526e-03, -1.6755e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.2014e-04,  1.2748e-03,  2.0538e-03],\n",
       "                         [-6.3239e-04,  7.8712e-05,  3.4340e-04],\n",
       "                         [-1.6270e-03, -1.1239e-03, -1.0840e-03]],\n",
       "               \n",
       "                        [[ 3.3137e-03,  3.4896e-03,  3.6734e-03],\n",
       "                         [ 9.4449e-04,  2.2126e-04,  7.7186e-04],\n",
       "                         [-3.8787e-03, -4.8179e-03, -4.7333e-03]],\n",
       "               \n",
       "                        [[ 4.5125e-04, -5.8490e-04, -1.4732e-03],\n",
       "                         [ 8.5196e-04, -3.1096e-04, -1.6053e-03],\n",
       "                         [-3.4127e-04,  6.0214e-04, -1.6454e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.2519e-03, -2.2054e-03, -8.2226e-04],\n",
       "                         [-3.8488e-04, -1.5445e-03,  8.0355e-04],\n",
       "                         [ 2.9229e-03,  1.2459e-03,  1.1957e-03]],\n",
       "               \n",
       "                        [[-2.6865e-03, -2.0840e-03, -1.3229e-03],\n",
       "                         [-6.8700e-03, -6.5469e-03, -6.3313e-03],\n",
       "                         [-2.8637e-05, -3.5429e-03, -3.8049e-03]],\n",
       "               \n",
       "                        [[ 6.8062e-03,  6.7363e-03,  4.8233e-03],\n",
       "                         [ 2.0607e-03,  3.9342e-03,  3.4523e-03],\n",
       "                         [-4.7353e-03, -3.8552e-03, -2.5714e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.0971e-03, -2.5182e-03, -1.1772e-03],\n",
       "                         [-6.4261e-04, -3.0060e-03, -7.9580e-04],\n",
       "                         [-3.2893e-04, -3.7638e-04, -1.8822e-04]],\n",
       "               \n",
       "                        [[ 9.2597e-04,  2.4221e-03,  2.1034e-03],\n",
       "                         [ 4.8755e-04,  2.9346e-03,  2.5906e-03],\n",
       "                         [-9.4718e-04,  2.3232e-03,  1.0020e-03]],\n",
       "               \n",
       "                        [[-2.4296e-03, -3.8615e-03, -3.3132e-03],\n",
       "                         [-5.9034e-03, -8.5780e-03, -6.7159e-03],\n",
       "                         [-2.9461e-03, -6.0218e-03, -5.4579e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.3126e-03,  9.8555e-03,  1.0021e-02],\n",
       "                         [ 8.9701e-03,  9.9922e-03,  1.0184e-02],\n",
       "                         [ 1.0990e-02,  1.4722e-02,  1.2081e-02]],\n",
       "               \n",
       "                        [[-1.1457e-03,  2.0550e-04, -5.5146e-04],\n",
       "                         [-3.6558e-03, -2.9090e-03, -2.5399e-03],\n",
       "                         [ 5.1184e-03,  5.7087e-03,  6.1603e-03]],\n",
       "               \n",
       "                        [[ 6.4173e-03,  9.0725e-03,  7.6180e-03],\n",
       "                         [ 7.7124e-04,  2.9704e-03,  2.8445e-03],\n",
       "                         [-4.1443e-03, -5.6251e-03, -4.4825e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-1.9853e-03, -4.7082e-03, -1.3972e-03],\n",
       "                         [-2.8301e-03, -9.0589e-03, -5.4207e-03],\n",
       "                         [-4.0607e-03, -8.1512e-03, -6.6360e-03]],\n",
       "               \n",
       "                        [[-8.8490e-03, -1.0301e-02, -6.2654e-03],\n",
       "                         [-9.5129e-03, -1.2779e-02, -1.0586e-02],\n",
       "                         [-5.9707e-03, -9.0753e-03, -9.9166e-03]],\n",
       "               \n",
       "                        [[ 1.7362e-03,  3.9322e-03,  1.1319e-03],\n",
       "                         [-5.8084e-03, -3.1125e-03, -3.2206e-03],\n",
       "                         [-6.0994e-03, -3.3962e-03, -2.5813e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.6256e-03, -5.7669e-03, -6.2590e-03],\n",
       "                         [-6.0027e-03, -7.4008e-03, -7.9815e-03],\n",
       "                         [-7.6289e-03, -8.6860e-03, -9.2249e-03]],\n",
       "               \n",
       "                        [[ 2.2187e-03,  5.6571e-03,  6.5209e-03],\n",
       "                         [-1.1443e-03,  2.5715e-03,  1.4524e-03],\n",
       "                         [-2.6231e-03, -2.0432e-03, -1.5543e-03]],\n",
       "               \n",
       "                        [[-1.7410e-03,  3.6566e-04, -1.0585e-03],\n",
       "                         [-2.0770e-03, -2.8633e-03, -5.2987e-03],\n",
       "                         [-3.6226e-03, -3.7927e-03, -3.1811e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.8320e-03, -5.6548e-03, -2.2209e-03],\n",
       "                         [ 2.0936e-03, -2.4934e-03, -1.2937e-04],\n",
       "                         [ 7.5083e-03,  4.5472e-03,  4.6799e-03]],\n",
       "               \n",
       "                        [[-1.8401e-03, -4.6630e-03, -4.3496e-03],\n",
       "                         [ 3.0989e-03,  1.4738e-03,  8.1743e-04],\n",
       "                         [ 3.5873e-04,  7.6960e-04,  1.5337e-03]],\n",
       "               \n",
       "                        [[ 4.6723e-03,  5.9873e-03,  5.0034e-03],\n",
       "                         [ 6.9564e-04,  1.3091e-03,  7.9137e-04],\n",
       "                         [-3.2492e-03, -3.8465e-03, -3.3835e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.6883e-03,  1.1651e-03, -3.3431e-04],\n",
       "                         [-1.5563e-03, -5.1826e-04, -1.4158e-03],\n",
       "                         [-4.1742e-03, -3.8306e-03, -3.1954e-03]],\n",
       "               \n",
       "                        [[ 4.3588e-03,  4.3395e-03,  9.4114e-04],\n",
       "                         [ 2.4202e-04,  3.0646e-04, -3.1384e-03],\n",
       "                         [-2.1453e-03, -3.9048e-03, -4.5616e-03]],\n",
       "               \n",
       "                        [[-1.1268e-02, -1.4414e-02, -9.9955e-03],\n",
       "                         [-1.4343e-02, -2.0141e-02, -1.3179e-02],\n",
       "                         [-9.9587e-03, -1.3718e-02, -7.3002e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 6.2385e-03,  6.3634e-03,  3.3305e-03],\n",
       "                         [ 5.2777e-03,  2.3538e-03,  2.4121e-03],\n",
       "                         [ 3.0999e-04,  8.0631e-05, -6.8556e-04]],\n",
       "               \n",
       "                        [[ 2.2573e-03,  2.2302e-03,  1.3533e-03],\n",
       "                         [ 1.1046e-02,  1.3343e-02,  1.2491e-02],\n",
       "                         [ 1.0344e-02,  1.3623e-02,  1.0269e-02]],\n",
       "               \n",
       "                        [[-1.1479e-03, -4.3474e-03, -4.0780e-03],\n",
       "                         [-3.6572e-04, -5.7094e-03, -4.9125e-03],\n",
       "                         [ 3.3686e-03, -8.3837e-04, -9.4712e-04]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.5158e-03,  2.0174e-03,  1.8485e-03],\n",
       "                         [ 3.5140e-03,  8.6811e-04,  2.5126e-04],\n",
       "                         [ 4.5137e-03,  4.9455e-03,  4.8961e-03]],\n",
       "               \n",
       "                        [[ 2.0748e-03,  2.8926e-03,  4.2804e-04],\n",
       "                         [-1.9665e-03,  2.0107e-03,  1.9006e-03],\n",
       "                         [-1.7062e-03,  1.5438e-03,  1.1467e-03]],\n",
       "               \n",
       "                        [[ 1.2626e-02,  1.2251e-02,  7.3305e-03],\n",
       "                         [ 8.8850e-03,  7.6525e-03,  6.9107e-03],\n",
       "                         [ 1.5885e-03,  1.4458e-03,  3.4923e-03]]]], device='cuda:0')),\n",
       "              ('layer4.1.bn2.weight',\n",
       "               tensor([0.2663, 0.2474, 0.3287, 0.2437, 0.2500, 0.2475, 0.1995, 0.3107, 0.3099,\n",
       "                       0.3240, 0.2731, 0.3452, 0.3371, 0.2955, 0.3139, 0.2625, 0.2567, 0.2237,\n",
       "                       0.1850, 0.3294, 0.3572, 0.3567, 0.2236, 0.2196, 0.2310, 0.3102, 0.3615,\n",
       "                       0.1860, 0.3042, 0.2619, 0.2378, 0.2615, 0.3022, 0.3314, 0.1856, 0.2533,\n",
       "                       0.3610, 0.1283, 0.2251, 0.2494, 0.3408, 0.3001, 0.3916, 0.2125, 0.2374,\n",
       "                       0.2467, 0.2570, 0.2200, 0.2706, 0.2999, 0.3429, 0.2452, 0.2323, 0.3196,\n",
       "                       0.4593, 0.2794, 0.3281, 0.3240, 0.3238, 0.2436, 0.3100, 0.3599, 0.2746,\n",
       "                       0.3440, 0.2296, 0.2805, 0.2857, 0.2922, 0.2073, 0.3744, 0.2652, 0.3724,\n",
       "                       0.2216, 0.3283, 0.3914, 0.3425, 0.2961, 0.2802, 0.2557, 0.3772, 0.1881,\n",
       "                       0.1565, 0.2719, 0.2296, 0.3484, 0.2801, 0.2673, 0.2086, 0.3519, 0.1688,\n",
       "                       0.3097, 0.1639, 0.4014, 0.4621, 0.2307, 0.2432, 0.2598, 0.1851, 0.1555,\n",
       "                       0.3176, 0.2862, 0.2446, 0.2405, 0.3406, 0.1676, 0.2972, 0.4759, 0.3183,\n",
       "                       0.2441, 0.3714, 0.2178, 0.2997, 0.2867, 0.2395, 0.2883, 0.3496, 0.2174,\n",
       "                       0.2832, 0.2428, 0.2484, 0.1797, 0.3215, 0.2931, 0.2014, 0.3722, 0.3231,\n",
       "                       0.3545, 0.3634, 0.2651, 0.2489, 0.2589, 0.1505, 0.2536, 0.1902, 0.2593,\n",
       "                       0.2110, 0.2139, 0.3395, 0.3858, 0.3476, 0.1924, 0.3412, 0.3092, 0.2030,\n",
       "                       0.3010, 0.2136, 0.3077, 0.2527, 0.2521, 0.2187, 0.3429, 0.2341, 0.3119,\n",
       "                       0.3228, 0.3212, 0.3651, 0.4348, 0.3222, 0.2747, 0.1454, 0.3213, 0.2826,\n",
       "                       0.4097, 0.2765, 0.2845, 0.2749, 0.2374, 0.3074, 0.2456, 0.2971, 0.3228,\n",
       "                       0.1957, 0.3603, 0.3173, 0.2598, 0.2900, 0.2403, 0.2190, 0.2659, 0.2617,\n",
       "                       0.3175, 0.3024, 0.3220, 0.3641, 0.2223, 0.3500, 0.2802, 0.2835, 0.2190,\n",
       "                       0.2272, 0.3408, 0.1726, 0.2281, 0.3507, 0.4965, 0.1823, 0.3030, 0.2687,\n",
       "                       0.3146, 0.2651, 0.2947, 0.3628, 0.2466, 0.3991, 0.2291, 0.3354, 0.2688,\n",
       "                       0.2898, 0.3893, 0.2896, 0.2983, 0.3005, 0.2337, 0.2491, 0.3183, 0.2576,\n",
       "                       0.3201, 0.2659, 0.3237, 0.3165, 0.4822, 0.3534, 0.3118, 0.4340, 0.3059,\n",
       "                       0.2441, 0.2695, 0.3022, 0.1248, 0.1535, 0.2596, 0.2826, 0.2877, 0.2368,\n",
       "                       0.3097, 0.2967, 0.3822, 0.2280, 0.1880, 0.1811, 0.1949, 0.2639, 0.2247,\n",
       "                       0.2873, 0.2106, 0.3358, 0.2917, 0.2898, 0.1930, 0.3652, 0.3532, 0.3245,\n",
       "                       0.2462, 0.2225, 0.3054, 0.2511, 0.2792, 0.2583, 0.3328, 0.2828, 0.3259,\n",
       "                       0.2853, 0.2750, 0.3067, 0.2746, 0.1588, 0.3040, 0.3016, 0.3174, 0.3115,\n",
       "                       0.2764, 0.3383, 0.2190, 0.3359, 0.2422, 0.2388, 0.3645, 0.4150, 0.3678,\n",
       "                       0.2355, 0.1645, 0.1582, 0.3180, 0.2565, 0.2616, 0.2377, 0.1353, 0.2134,\n",
       "                       0.2537, 0.2998, 0.2405, 0.3144, 0.2819, 0.2539, 0.3439, 0.3912, 0.2522,\n",
       "                       0.1916, 0.2300, 0.3049, 0.2302, 0.2895, 0.2278, 0.2659, 0.0805, 0.4854,\n",
       "                       0.3374, 0.2361, 0.2529, 0.2810, 0.3005, 0.2458, 0.2709, 0.3238, 0.2780,\n",
       "                       0.4301, 0.2997, 0.2451, 0.1997, 0.3012, 0.3748, 0.1941, 0.1912, 0.4236,\n",
       "                       0.2632, 0.3588, 0.1332, 0.1725, 0.3024, 0.2412, 0.3256, 0.3265, 0.1925,\n",
       "                       0.3152, 0.2287, 0.3190, 0.3339, 0.3823, 0.2935, 0.2057, 0.4724, 0.2801,\n",
       "                       0.4366, 0.2871, 0.3864, 0.1898, 0.2793, 0.3053, 0.2924, 0.2936, 0.3702,\n",
       "                       0.2058, 0.2073, 0.2937, 0.1519, 0.2356, 0.2722, 0.2480, 0.3656, 0.2397,\n",
       "                       0.2412, 0.2368, 0.2295, 0.2129, 0.2549, 0.1947, 0.3255, 0.2629, 0.1992,\n",
       "                       0.3609, 0.2206, 0.2203, 0.2217, 0.3488, 0.1723, 0.2524, 0.2515, 0.2922,\n",
       "                       0.2910, 0.2174, 0.2928, 0.2655, 0.2023, 0.2809, 0.1941, 0.2000, 0.3434,\n",
       "                       0.4023, 0.3287, 0.3350, 0.2443, 0.2139, 0.2127, 0.3189, 0.2650, 0.4194,\n",
       "                       0.1730, 0.2326, 0.3844, 0.2794, 0.2577, 0.1958, 0.2635, 0.2180, 0.2664,\n",
       "                       0.2907, 0.2842, 0.2252, 0.2022, 0.3159, 0.2360, 0.3366, 0.4364, 0.3056,\n",
       "                       0.4021, 0.2453, 0.3224, 0.2610, 0.2976, 0.3040, 0.2843, 0.1836, 0.1567,\n",
       "                       0.3718, 0.2712, 0.2837, 0.2960, 0.1756, 0.2293, 0.2255, 0.3116, 0.2882,\n",
       "                       0.1879, 0.4174, 0.2853, 0.2874, 0.3083, 0.2654, 0.2619, 0.2819, 0.1752,\n",
       "                       0.2956, 0.3122, 0.3222, 0.3060, 0.2809, 0.2534, 0.2561, 0.1946, 0.1989,\n",
       "                       0.2326, 0.4189, 0.3318, 0.2097, 0.3079, 0.4268, 0.1951, 0.2715, 0.1177,\n",
       "                       0.3277, 0.1820, 0.3628, 0.2916, 0.2784, 0.1995, 0.2450, 0.5310, 0.2471,\n",
       "                       0.3868, 0.1850, 0.4110, 0.3084, 0.2005, 0.2635, 0.3381, 0.1770, 0.2522,\n",
       "                       0.1473, 0.2842, 0.2232, 0.2284, 0.2063, 0.3018, 0.2473, 0.2331, 0.1824,\n",
       "                       0.2677, 0.2925, 0.3100, 0.2587, 0.2900, 0.1934, 0.3202, 0.2707, 0.3045,\n",
       "                       0.2590, 0.2558, 0.3902, 0.2805, 0.2663, 0.2878, 0.1988, 0.3130, 0.3807,\n",
       "                       0.4019, 0.2731, 0.2952, 0.2461, 0.3313, 0.3258, 0.3370, 0.3812],\n",
       "                      device='cuda:0')),\n",
       "              ('layer4.1.bn2.bias',\n",
       "               tensor([ 1.1426e-02,  1.1364e-02,  3.7349e-02,  2.9896e-02,  2.3573e-02,\n",
       "                        5.3333e-02,  5.4153e-03,  3.7594e-03,  1.9393e-02,  2.6350e-02,\n",
       "                        1.7294e-02,  2.4080e-02,  5.5712e-02, -7.9499e-02,  5.9797e-03,\n",
       "                        2.7871e-02,  2.3371e-02,  3.1719e-02,  1.4587e-02,  1.1767e-02,\n",
       "                        6.6398e-02,  4.9215e-02,  1.8156e-02,  6.4685e-03,  3.9295e-02,\n",
       "                        1.5158e-02,  4.0547e-02,  2.0178e-02,  5.7570e-02,  4.5385e-02,\n",
       "                        2.5896e-02,  5.9811e-03,  1.1768e-02,  2.2701e-02,  3.1469e-03,\n",
       "                        2.1816e-02,  3.6074e-02,  6.1397e-04, -2.7804e-03,  4.4803e-03,\n",
       "                        5.9166e-02,  3.3131e-02,  3.6345e-02,  1.4622e-02, -2.3829e-03,\n",
       "                       -2.2482e-03, -3.7364e-03, -2.8856e-04, -1.3149e-02, -2.0382e-02,\n",
       "                        2.8810e-02, -1.9208e-03,  5.2582e-02, -2.9351e-02,  9.9460e-02,\n",
       "                        3.2923e-02,  2.2119e-02,  4.0104e-02,  1.5300e-02,  5.6092e-03,\n",
       "                        5.3614e-02,  4.0598e-02, -1.4170e-02,  4.4954e-02,  2.3872e-02,\n",
       "                        5.5202e-02,  4.6679e-02,  1.0262e-02,  4.0497e-02,  5.4113e-02,\n",
       "                        8.8959e-03,  5.3656e-02,  2.2552e-02,  9.7373e-03,  7.9475e-02,\n",
       "                        1.1460e-02,  2.7003e-02,  3.4084e-02,  2.9853e-02,  3.1302e-02,\n",
       "                        2.4932e-02, -1.1698e-01,  3.2677e-02, -1.2372e-05,  5.0576e-02,\n",
       "                        3.3145e-02, -1.1616e-02,  1.1939e-02,  3.4756e-02,  2.2048e-03,\n",
       "                        4.3518e-02,  4.9054e-03, -3.2236e-03,  5.9040e-02, -1.6424e-02,\n",
       "                       -2.4032e-02, -3.0351e-03, -2.5416e-02, -4.1372e-03,  7.9222e-02,\n",
       "                        2.1654e-02, -5.2361e-03,  5.0839e-03,  5.4873e-02,  2.1154e-02,\n",
       "                        4.5433e-02,  5.1579e-03, -1.1947e-02,  3.9835e-02,  1.8990e-02,\n",
       "                       -1.0461e-02,  2.6148e-02, -9.9381e-04,  1.2121e-02,  1.7877e-02,\n",
       "                        8.8664e-02,  2.0674e-03,  2.5375e-02,  5.2079e-03, -2.7720e-03,\n",
       "                       -1.3619e-02,  4.4154e-02,  3.1670e-02,  1.8468e-02,  5.7783e-02,\n",
       "                        6.4092e-02,  5.4933e-02,  6.2951e-02,  3.1181e-02,  3.5682e-02,\n",
       "                        2.0974e-02,  1.2204e-02, -8.4836e-04, -1.9744e-03,  2.9100e-02,\n",
       "                        1.4066e-02,  1.8268e-02,  3.7350e-02,  3.6243e-02,  7.0598e-02,\n",
       "                        1.2623e-02,  1.9538e-02,  3.5610e-02, -1.8547e-02,  1.0969e-02,\n",
       "                        1.6309e-02, -2.2451e-02,  5.0620e-02,  3.6416e-02,  2.9491e-02,\n",
       "                        4.1178e-02, -3.0199e-02, -1.8903e-02,  1.6696e-03,  2.2845e-02,\n",
       "                        2.6326e-02,  4.8813e-02,  5.0792e-02,  2.2965e-02, -2.6408e-03,\n",
       "                        4.5064e-02, -7.6053e-03,  2.2844e-02,  3.8844e-03, -9.4151e-03,\n",
       "                        6.6029e-02,  3.7919e-02,  1.2337e-02,  5.8426e-02,  2.1876e-02,\n",
       "                        3.0551e-02, -6.5593e-04,  4.6602e-02,  1.9536e-02,  3.1083e-03,\n",
       "                        2.9827e-02, -1.6209e-02,  4.5978e-03, -3.7315e-02,  3.0963e-03,\n",
       "                       -2.6935e-02, -1.1942e-02,  1.2766e-02,  4.2540e-02,  4.4603e-02,\n",
       "                        1.5982e-02,  3.4401e-02,  1.2560e-02, -2.5547e-03,  1.1606e-02,\n",
       "                        8.3286e-03,  1.2852e-02,  2.7068e-02, -4.2273e-03,  1.2092e-01,\n",
       "                        1.0166e-02,  5.6580e-02,  3.1816e-02, -5.5269e-02,  1.7599e-02,\n",
       "                        2.5336e-02, -1.0861e-03,  6.7765e-02,  7.6774e-02,  3.8614e-02,\n",
       "                       -7.4657e-04, -1.5576e-02,  6.4677e-03,  6.0307e-02, -3.8702e-02,\n",
       "                        2.5834e-02,  2.8610e-02,  1.3048e-02,  4.5604e-02,  1.8271e-02,\n",
       "                       -3.0804e-03,  2.8161e-02,  5.6387e-02,  4.6844e-03,  2.2141e-02,\n",
       "                        4.5210e-02,  3.7484e-02,  9.4611e-03,  2.0447e-02,  4.3925e-02,\n",
       "                        2.2587e-02, -1.5188e-02, -1.1223e-02, -1.6470e-02,  4.6354e-04,\n",
       "                        3.6847e-02,  2.8740e-02,  6.7695e-03,  4.1800e-02,  2.7358e-02,\n",
       "                        2.3774e-02,  7.8001e-02,  1.8139e-02, -4.5573e-03,  2.4663e-02,\n",
       "                       -8.6364e-03,  3.5530e-02,  2.0675e-02,  4.0938e-02,  2.5371e-02,\n",
       "                        6.5859e-02,  1.9866e-02,  3.7631e-02,  1.1499e-02,  2.0074e-02,\n",
       "                       -1.3819e-02, -1.5456e-02,  1.9229e-02, -1.9516e-02, -2.5442e-03,\n",
       "                        4.1330e-02,  2.6859e-02,  4.6133e-02,  3.9765e-02,  2.7349e-02,\n",
       "                        5.9042e-02,  4.3701e-02, -3.7045e-03, -1.5387e-02, -3.0509e-02,\n",
       "                       -2.7149e-02,  3.4150e-02,  3.3448e-02,  4.5841e-02, -1.5822e-03,\n",
       "                        4.3415e-02,  1.4455e-02, -2.0511e-02,  2.3898e-02,  6.3077e-03,\n",
       "                        7.4338e-03,  5.7607e-02,  9.7550e-02,  4.5694e-02,  2.0473e-02,\n",
       "                        2.4042e-02, -3.9796e-02,  1.3838e-02,  1.4693e-02, -2.1694e-02,\n",
       "                        7.0700e-03, -1.0715e-02, -5.2794e-03,  1.1660e-02,  5.4640e-02,\n",
       "                       -1.9089e-02,  3.7962e-02,  2.0591e-03,  1.6595e-02,  3.7222e-02,\n",
       "                        3.4379e-02,  1.5641e-03,  2.3466e-02, -5.8402e-04,  2.1611e-02,\n",
       "                        2.4543e-02, -6.6124e-03,  1.1541e-02, -3.9984e-02, -4.6344e-04,\n",
       "                        3.6483e-03,  6.0598e-02, -1.2609e-02,  2.4623e-02,  4.8413e-02,\n",
       "                        1.7842e-02,  4.2714e-02, -2.7314e-02,  6.4229e-02,  2.9237e-02,\n",
       "                        3.1629e-02, -1.0178e-02,  3.4144e-02,  3.3806e-02, -2.4008e-02,\n",
       "                        5.5183e-02,  1.9577e-02, -9.4467e-03,  5.4703e-02,  2.3733e-02,\n",
       "                        7.6262e-02, -5.8006e-04,  4.5725e-03, -1.7397e-03, -3.7488e-02,\n",
       "                       -1.4667e-04,  4.1146e-02,  2.0882e-02,  6.9540e-02, -8.0341e-03,\n",
       "                        3.3872e-02,  3.2394e-02, -3.9469e-02,  4.1731e-02,  4.7175e-02,\n",
       "                        5.3542e-02,  1.1436e-02,  4.3444e-02,  5.0254e-03,  1.9645e-02,\n",
       "                       -1.9255e-04,  3.7331e-02,  2.0984e-02,  4.5977e-02,  1.7947e-02,\n",
       "                       -1.1922e-04,  2.2049e-02, -1.5576e-02,  3.5885e-02,  8.9439e-03,\n",
       "                        1.8204e-02,  3.6389e-02,  8.7189e-03,  2.9005e-02,  4.4000e-03,\n",
       "                        2.0821e-02,  2.5826e-02, -5.8636e-03,  7.7009e-03,  4.1050e-02,\n",
       "                        1.2084e-02,  4.4382e-02, -2.6735e-02,  2.3588e-02,  4.6093e-02,\n",
       "                       -1.5663e-02,  2.0707e-02,  2.6509e-02,  6.9223e-02, -3.6631e-03,\n",
       "                        4.0264e-02,  1.5457e-02, -2.3385e-02,  9.3223e-04,  1.0632e-02,\n",
       "                        2.6549e-03,  4.8516e-02,  3.8949e-02,  5.6355e-02, -7.8253e-03,\n",
       "                        7.1188e-03,  4.7792e-02, -4.0318e-02,  2.3854e-02,  5.1569e-02,\n",
       "                        1.6752e-02,  1.6824e-02, -2.7845e-03,  4.8628e-02,  1.4306e-02,\n",
       "                        3.4869e-02,  8.2370e-03,  1.3002e-02,  1.6380e-02,  2.9458e-02,\n",
       "                        4.1569e-02,  1.8844e-02,  4.5540e-02,  7.5234e-03,  1.9577e-02,\n",
       "                        2.0383e-02,  4.3886e-02,  1.1080e-02,  1.0086e-02,  4.9270e-02,\n",
       "                        1.5423e-02,  3.1900e-02,  1.0251e-01,  1.3072e-02,  3.3949e-02,\n",
       "                        1.9274e-02, -2.3086e-02, -9.2445e-03, -1.1567e-03, -8.9617e-03,\n",
       "                        3.8513e-02,  8.1859e-03, -4.4017e-03, -2.6219e-02,  1.6647e-02,\n",
       "                       -2.7611e-02,  3.6335e-02,  1.5666e-03,  1.6144e-03,  3.2953e-02,\n",
       "                       -1.2751e-02,  5.1150e-02, -1.6180e-02,  8.5248e-02,  3.1878e-02,\n",
       "                        6.3944e-05,  1.3249e-02,  2.7022e-02,  2.9790e-02,  4.0247e-02,\n",
       "                        3.7841e-02,  6.1827e-04,  5.8363e-02, -3.0866e-02,  3.1436e-02,\n",
       "                        4.9897e-02,  1.6802e-02,  3.8800e-03, -9.1945e-03,  8.3300e-03,\n",
       "                        1.2135e-02,  5.0426e-02,  2.8325e-02,  2.0729e-02,  3.8966e-02,\n",
       "                       -2.0230e-02, -1.4602e-02,  1.2141e-02, -5.8988e-02,  8.2262e-03,\n",
       "                       -4.1263e-02,  2.4380e-02,  3.7760e-03,  3.2665e-02, -1.2178e-03,\n",
       "                        3.4215e-02,  3.8557e-02, -1.3738e-03,  5.7165e-02,  7.6235e-03,\n",
       "                        7.2595e-02,  7.6024e-02, -1.6013e-02,  5.1765e-02,  2.3515e-02,\n",
       "                        2.4484e-02,  1.2647e-02,  1.5263e-02,  3.6200e-02,  1.7640e-02,\n",
       "                       -1.8390e-03,  3.1310e-02,  8.7845e-03,  4.2066e-02, -3.1704e-03,\n",
       "                        2.5474e-02,  1.6071e-02,  3.4789e-02,  1.6141e-02,  2.1386e-02,\n",
       "                        4.7470e-02,  1.1994e-02,  2.0633e-02,  2.6509e-02,  5.5945e-02,\n",
       "                        1.3728e-03,  3.5165e-02,  7.7060e-02,  2.8877e-02,  2.8858e-02,\n",
       "                        1.7921e-02,  1.1459e-02,  2.0102e-02,  1.1226e-03,  5.5111e-02,\n",
       "                        1.9217e-02,  1.9962e-02, -1.2376e-02,  9.8287e-03,  5.5598e-03,\n",
       "                        1.8009e-02,  1.6824e-02], device='cuda:0')),\n",
       "              ('layer4.1.bn2.running_mean',\n",
       "               tensor([-4.8455e-02,  5.4349e-03, -3.8384e-02, -6.7388e-02, -1.0041e-01,\n",
       "                        4.6671e-02, -6.0975e-03, -1.2469e-01, -7.7127e-02,  1.0155e-01,\n",
       "                        4.3076e-02, -9.0745e-02, -7.8961e-02, -8.4050e-02, -1.1134e-01,\n",
       "                       -9.3992e-02, -6.7697e-02,  1.7816e-02, -8.5471e-02, -1.4489e-01,\n",
       "                       -5.8866e-02, -6.0908e-02, -4.1147e-02, -4.1815e-02,  2.9278e-02,\n",
       "                       -1.1014e-01, -9.4869e-02, -2.4413e-02,  5.2766e-02, -7.9708e-02,\n",
       "                        3.3648e-02, -1.1801e-01,  3.2726e-02, -1.1542e-01, -4.0202e-02,\n",
       "                       -6.6625e-02, -3.8056e-03,  7.8345e-03, -5.9088e-02, -6.1280e-02,\n",
       "                       -2.8058e-02, -3.0432e-02, -1.2702e-01,  5.0238e-03, -9.9440e-02,\n",
       "                       -7.7913e-02, -7.9116e-02, -2.4196e-02, -2.0679e-01, -1.8316e-01,\n",
       "                       -1.3771e-01, -8.8928e-02, -3.0147e-02,  4.3108e-03,  2.9700e-03,\n",
       "                        6.6842e-02, -1.6091e-03, -1.8121e-03, -5.9741e-02, -1.0399e-01,\n",
       "                       -6.7015e-02, -1.8881e-01,  1.5215e-02, -1.7021e-01, -4.3055e-02,\n",
       "                       -4.5185e-02,  4.0714e-02, -6.1957e-02, -6.8536e-02, -8.3393e-02,\n",
       "                       -1.7112e-01, -4.9846e-02, -1.0964e-02, -5.4057e-02, -3.2259e-02,\n",
       "                       -1.2096e-01, -9.3696e-02, -1.0246e-01, -1.1376e-03, -3.2751e-01,\n",
       "                       -2.4048e-02, -3.4326e-03,  4.6221e-03, -6.5560e-02, -6.7691e-02,\n",
       "                       -5.4247e-02,  2.0638e-02, -2.2968e-02, -4.2789e-02, -1.1117e-01,\n",
       "                       -1.1602e-01, -2.7943e-02,  1.4185e-01, -5.5895e-02, -7.5739e-02,\n",
       "                       -1.3987e-01,  1.7573e-02, -5.4219e-02, -8.8385e-02, -2.0510e-02,\n",
       "                       -1.3473e-01, -1.9383e-02, -1.2980e-02, -1.9855e-02, -5.3303e-02,\n",
       "                       -1.7626e-02,  3.9746e-02, -7.3215e-02, -6.1876e-02,  3.2083e-02,\n",
       "                        5.3353e-02, -1.0384e-01, -4.6710e-02, -3.4629e-02, -9.1577e-02,\n",
       "                        9.0368e-04, -1.2232e-01, -1.2709e-02, -1.3752e-01, -1.3231e-02,\n",
       "                       -1.1688e-02,  5.0208e-02, -5.2956e-02, -8.6700e-03, -4.8856e-02,\n",
       "                        7.1401e-02,  6.8209e-03, -5.9983e-02,  4.2684e-02, -2.4133e-02,\n",
       "                        3.4066e-02, -4.3590e-02, -1.0671e-01, -3.1090e-02,  1.0081e-02,\n",
       "                       -6.2032e-02, -9.9917e-02, -1.2633e-01, -4.7722e-02,  2.6964e-02,\n",
       "                        2.5235e-02, -1.4556e-01, -3.3723e-02, -6.6166e-02, -1.3078e-01,\n",
       "                       -2.1905e-02, -1.1434e-01, -3.0532e-02,  3.2972e-02, -2.9196e-02,\n",
       "                       -1.2536e-01, -1.1108e-01, -1.0458e-02,  1.4295e-02, -1.0155e-01,\n",
       "                       -6.0703e-02, -3.4286e-02, -2.9221e-02,  1.0111e-02, -1.7319e-02,\n",
       "                       -6.0011e-02, -8.3097e-02, -2.1061e-01, -1.3589e-01, -4.1434e-02,\n",
       "                       -6.6016e-03, -2.1560e-02, -8.3555e-02, -5.0662e-02, -2.8787e-02,\n",
       "                       -4.9238e-02, -1.4465e-02,  7.0528e-03, -6.1649e-03,  8.9918e-03,\n",
       "                        1.9934e-02, -7.6023e-02, -4.8420e-03, -3.2365e-02, -3.0544e-02,\n",
       "                        5.0002e-02, -1.6397e-01,  5.0262e-02, -9.5906e-02, -3.1573e-02,\n",
       "                       -9.4761e-02, -4.2764e-02, -3.6453e-02, -5.5771e-02, -3.2474e-02,\n",
       "                       -1.1866e-01, -1.8016e-02, -4.4682e-02,  3.1694e-02,  9.0354e-02,\n",
       "                       -8.8024e-02,  1.9865e-02, -4.1832e-02,  8.2612e-02, -5.4009e-02,\n",
       "                       -1.1531e-01, -1.3270e-01, -1.0308e-02, -7.6172e-02, -8.0453e-02,\n",
       "                        5.6132e-02, -2.9562e-02, -1.0811e-02,  1.2657e-01, -2.1774e-02,\n",
       "                       -2.4237e-02, -7.0752e-03, -8.2854e-02, -5.8254e-02, -1.7025e-02,\n",
       "                       -9.1363e-03, -3.3073e-02, -4.5309e-02, -1.2331e-01, -5.4219e-02,\n",
       "                       -4.5334e-02, -3.8382e-03, -9.8183e-02, -1.6766e-01,  2.1206e-02,\n",
       "                       -7.9827e-02, -1.8711e-01, -1.2129e-01, -2.6478e-02,  1.7003e-02,\n",
       "                       -4.9837e-02, -1.1326e-01, -8.3124e-02, -8.8011e-02, -4.1973e-02,\n",
       "                       -3.6830e-02, -6.0404e-02,  8.3122e-02,  3.3871e-02, -5.5042e-02,\n",
       "                       -2.6305e-02,  8.0930e-02, -1.3691e-01,  2.7061e-03, -6.6819e-04,\n",
       "                       -3.5942e-02, -6.6817e-02, -2.3135e-02, -7.6308e-02,  2.5374e-02,\n",
       "                        3.1086e-02, -6.1754e-02, -2.6154e-02,  3.1045e-02,  2.7346e-02,\n",
       "                        4.3527e-03, -1.9754e-02, -4.2312e-02, -7.6028e-02, -3.2842e-02,\n",
       "                       -1.0044e-01, -1.5688e-01, -1.6711e-01,  7.3150e-02,  7.0560e-02,\n",
       "                       -6.2317e-02, -6.6368e-02,  2.4542e-02, -1.6984e-01, -1.2730e-01,\n",
       "                        1.8790e-02, -4.1926e-02, -1.1764e-01, -1.7878e-01,  1.4668e-02,\n",
       "                       -5.6460e-02, -5.8905e-02, -1.8278e-02, -1.0352e-01, -1.4175e-01,\n",
       "                       -8.2243e-02, -5.0335e-02, -1.1328e-01, -1.5851e-01, -2.7491e-02,\n",
       "                       -3.2056e-02, -1.9842e-03, -7.8039e-02, -5.0449e-02,  1.3166e-02,\n",
       "                       -1.6736e-01, -5.4388e-02, -1.0387e-01, -2.6863e-03, -2.3817e-02,\n",
       "                       -2.1236e-01,  4.4931e-02, -2.3677e-02, -1.2487e-01, -3.3688e-02,\n",
       "                       -2.5496e-02,  9.8731e-02,  5.4773e-02,  2.9701e-03,  2.8531e-05,\n",
       "                        4.2566e-02, -2.7447e-02,  2.1391e-02, -1.3201e-01, -1.3048e-02,\n",
       "                       -1.0865e-02, -1.4223e-01,  7.5957e-02, -2.7262e-02, -3.3090e-02,\n",
       "                       -1.5860e-01, -1.4262e-01, -4.9777e-02, -4.9776e-02, -7.5662e-02,\n",
       "                       -9.6038e-04, -1.2576e-01, -3.6908e-02, -1.0417e-02, -7.1098e-02,\n",
       "                       -2.4652e-02, -4.1203e-02, -1.5980e-02, -3.8926e-02,  1.5647e-02,\n",
       "                       -1.1682e-01, -1.3615e-01, -6.1584e-03, -9.7643e-02, -1.3491e-01,\n",
       "                       -5.3719e-03, -7.2610e-02, -4.0146e-02,  3.9440e-03,  3.2080e-04,\n",
       "                       -3.7196e-02,  1.3201e-03,  3.0097e-02, -6.6266e-02, -1.2446e-01,\n",
       "                        1.1598e-02,  1.2024e-02, -7.3413e-02, -5.9525e-02, -4.7073e-02,\n",
       "                       -1.1608e-01, -5.2406e-02, -6.0851e-02, -6.3656e-02,  1.4505e-03,\n",
       "                       -5.4695e-02, -5.8461e-02, -7.7644e-02, -2.1520e-02, -1.0923e-01,\n",
       "                        3.7318e-02, -3.5595e-02, -5.5117e-02, -5.2584e-02,  1.5167e-02,\n",
       "                       -4.7185e-03, -1.1516e-01,  1.2291e-02,  3.6518e-02,  1.4657e-01,\n",
       "                       -7.5099e-02, -4.2185e-02, -1.8251e-02, -1.0085e-01, -8.5510e-02,\n",
       "                       -4.7613e-02, -8.0171e-02, -1.0694e-01, -1.0815e-01, -1.1413e-01,\n",
       "                       -4.2446e-03, -1.2954e-01, -3.3395e-02, -1.1701e-01, -2.4415e-02,\n",
       "                       -2.4304e-02, -7.2070e-02, -8.6418e-02,  1.9654e-02, -9.2669e-04,\n",
       "                       -7.9070e-02, -1.7336e-03, -8.7478e-02, -1.6551e-02,  4.6873e-02,\n",
       "                       -2.0545e-01, -6.5955e-02,  6.5005e-02, -1.5760e-01, -1.6455e-01,\n",
       "                        6.5988e-02,  1.3007e-02, -2.5173e-02, -6.8721e-02, -6.6443e-02,\n",
       "                       -6.5852e-02, -1.5584e-01,  1.2428e-03,  2.9838e-02, -3.3421e-02,\n",
       "                       -7.8933e-02,  1.0851e-01, -1.5576e-02, -1.1372e-01, -1.8186e-01,\n",
       "                       -8.3847e-02,  1.5566e-02, -1.9699e-01, -2.2092e-01, -1.6867e-01,\n",
       "                       -7.5963e-02,  4.2042e-02,  2.2240e-02,  4.2599e-03,  1.2715e-02,\n",
       "                       -5.5645e-02,  2.7214e-02, -8.2131e-02, -8.2603e-02, -5.5410e-03,\n",
       "                       -1.0970e-01,  2.3307e-02, -1.0256e-01, -1.0939e-01, -2.7707e-02,\n",
       "                        9.8146e-02, -1.6437e-01, -3.7524e-02,  6.1499e-06, -9.6348e-02,\n",
       "                       -1.6688e-02,  6.7558e-02,  1.9428e-02, -9.1731e-02, -4.9006e-02,\n",
       "                       -6.4682e-02, -6.0566e-02, -1.0848e-01,  1.9850e-02, -6.1454e-03,\n",
       "                       -2.3042e-02,  3.8774e-02, -4.5695e-02,  6.4263e-03,  3.1794e-05,\n",
       "                       -8.8874e-02,  3.7102e-02, -1.0061e-01,  1.5430e-02, -4.2876e-02,\n",
       "                       -5.9249e-03, -5.7509e-02, -1.7172e-01, -6.7540e-02, -1.3672e-02,\n",
       "                       -1.7337e-01, -8.3150e-02, -1.0309e-01, -1.3122e-01, -2.1160e-02,\n",
       "                        1.5886e-02, -5.4290e-03, -7.3627e-02, -1.6106e-01, -1.1386e-01,\n",
       "                       -1.7358e-02, -6.6827e-02, -9.7981e-03,  5.9809e-03, -9.4504e-02,\n",
       "                       -3.0662e-02, -3.3821e-02, -3.7463e-02,  7.0679e-03, -9.4030e-02,\n",
       "                        7.4794e-03, -8.1464e-02, -7.3505e-02, -6.0963e-02, -5.1984e-02,\n",
       "                       -9.0943e-02, -7.4134e-03, -6.4295e-02, -5.8150e-02, -3.6577e-02,\n",
       "                       -4.5342e-02, -6.1901e-03, -2.5960e-02, -3.5264e-02, -3.3646e-02,\n",
       "                       -1.1493e-01, -4.3581e-02,  5.7088e-02, -1.2144e-01, -2.1542e-02,\n",
       "                       -5.9148e-02,  3.3430e-02, -1.3059e-01, -1.6911e-03, -1.1441e-01,\n",
       "                       -4.9566e-02, -4.4955e-02], device='cuda:0')),\n",
       "              ('layer4.1.bn2.running_var',\n",
       "               tensor([0.0369, 0.0246, 0.0404, 0.0237, 0.0207, 0.0256, 0.0202, 0.0388, 0.0328,\n",
       "                       0.0472, 0.0314, 0.0461, 0.0279, 0.0280, 0.0336, 0.0230, 0.0296, 0.0185,\n",
       "                       0.0113, 0.0374, 0.0389, 0.0400, 0.0181, 0.0129, 0.0222, 0.0404, 0.0472,\n",
       "                       0.0122, 0.0368, 0.0255, 0.0235, 0.0211, 0.0443, 0.0404, 0.0130, 0.0258,\n",
       "                       0.0495, 0.0064, 0.0171, 0.0251, 0.0491, 0.0269, 0.0480, 0.0177, 0.0279,\n",
       "                       0.0182, 0.0283, 0.0143, 0.0252, 0.0342, 0.0336, 0.0253, 0.0207, 0.0329,\n",
       "                       0.0714, 0.0299, 0.0461, 0.0493, 0.0337, 0.0200, 0.0343, 0.0366, 0.0322,\n",
       "                       0.0375, 0.0210, 0.0240, 0.0331, 0.0315, 0.0162, 0.0415, 0.0254, 0.0471,\n",
       "                       0.0218, 0.0338, 0.0491, 0.0413, 0.0290, 0.0347, 0.0260, 0.0437, 0.0156,\n",
       "                       0.0099, 0.0245, 0.0197, 0.0363, 0.0318, 0.0305, 0.0149, 0.0478, 0.0139,\n",
       "                       0.0356, 0.0107, 0.0754, 0.0526, 0.0192, 0.0256, 0.0247, 0.0135, 0.0097,\n",
       "                       0.0318, 0.0280, 0.0169, 0.0234, 0.0440, 0.0111, 0.0335, 0.0994, 0.0533,\n",
       "                       0.0234, 0.0653, 0.0192, 0.0302, 0.0335, 0.0209, 0.0285, 0.0474, 0.0159,\n",
       "                       0.0303, 0.0204, 0.0265, 0.0160, 0.0377, 0.0300, 0.0166, 0.0480, 0.0526,\n",
       "                       0.0528, 0.0381, 0.0393, 0.0337, 0.0259, 0.0076, 0.0254, 0.0139, 0.0297,\n",
       "                       0.0162, 0.0191, 0.0352, 0.0386, 0.0495, 0.0139, 0.0410, 0.0381, 0.0143,\n",
       "                       0.0365, 0.0171, 0.0405, 0.0190, 0.0250, 0.0172, 0.0485, 0.0229, 0.0375,\n",
       "                       0.0440, 0.0363, 0.0442, 0.0470, 0.0382, 0.0342, 0.0087, 0.0437, 0.0311,\n",
       "                       0.0657, 0.0218, 0.0299, 0.0293, 0.0219, 0.0419, 0.0255, 0.0342, 0.0450,\n",
       "                       0.0111, 0.0510, 0.0341, 0.0270, 0.0334, 0.0184, 0.0215, 0.0256, 0.0225,\n",
       "                       0.0374, 0.0381, 0.0402, 0.0509, 0.0204, 0.0502, 0.0252, 0.0318, 0.0177,\n",
       "                       0.0179, 0.0465, 0.0129, 0.0199, 0.0505, 0.1213, 0.0129, 0.0409, 0.0280,\n",
       "                       0.0316, 0.0293, 0.0332, 0.0477, 0.0194, 0.0442, 0.0211, 0.0420, 0.0276,\n",
       "                       0.0253, 0.0775, 0.0342, 0.0403, 0.0331, 0.0259, 0.0234, 0.0340, 0.0254,\n",
       "                       0.0374, 0.0284, 0.0398, 0.0286, 0.0883, 0.0582, 0.0398, 0.0609, 0.0409,\n",
       "                       0.0210, 0.0230, 0.0370, 0.0061, 0.0088, 0.0194, 0.0322, 0.0274, 0.0181,\n",
       "                       0.0348, 0.0293, 0.0549, 0.0221, 0.0162, 0.0144, 0.0164, 0.0334, 0.0195,\n",
       "                       0.0274, 0.0186, 0.0305, 0.0336, 0.0386, 0.0145, 0.0629, 0.0524, 0.0384,\n",
       "                       0.0240, 0.0237, 0.0342, 0.0199, 0.0263, 0.0247, 0.0347, 0.0275, 0.0331,\n",
       "                       0.0289, 0.0246, 0.0368, 0.0285, 0.0087, 0.0299, 0.0422, 0.0347, 0.0384,\n",
       "                       0.0244, 0.0450, 0.0169, 0.0471, 0.0220, 0.0184, 0.0403, 0.0666, 0.0498,\n",
       "                       0.0199, 0.0093, 0.0101, 0.0324, 0.0277, 0.0265, 0.0265, 0.0056, 0.0191,\n",
       "                       0.0269, 0.0348, 0.0203, 0.0340, 0.0298, 0.0192, 0.0423, 0.0709, 0.0323,\n",
       "                       0.0165, 0.0177, 0.0412, 0.0218, 0.0356, 0.0224, 0.0311, 0.0020, 0.0986,\n",
       "                       0.0302, 0.0228, 0.0241, 0.0328, 0.0365, 0.0195, 0.0353, 0.0394, 0.0342,\n",
       "                       0.0607, 0.0354, 0.0241, 0.0143, 0.0374, 0.0613, 0.0130, 0.0168, 0.0664,\n",
       "                       0.0296, 0.0405, 0.0061, 0.0115, 0.0377, 0.0209, 0.0479, 0.0356, 0.0145,\n",
       "                       0.0342, 0.0182, 0.0395, 0.0447, 0.0543, 0.0315, 0.0205, 0.0816, 0.0274,\n",
       "                       0.0631, 0.0358, 0.0584, 0.0145, 0.0369, 0.0262, 0.0304, 0.0347, 0.0480,\n",
       "                       0.0159, 0.0197, 0.0239, 0.0093, 0.0180, 0.0353, 0.0196, 0.0477, 0.0218,\n",
       "                       0.0256, 0.0194, 0.0192, 0.0170, 0.0298, 0.0162, 0.0461, 0.0205, 0.0174,\n",
       "                       0.0556, 0.0212, 0.0173, 0.0190, 0.0368, 0.0090, 0.0221, 0.0210, 0.0258,\n",
       "                       0.0288, 0.0184, 0.0384, 0.0243, 0.0167, 0.0243, 0.0122, 0.0156, 0.0410,\n",
       "                       0.0621, 0.0461, 0.0382, 0.0168, 0.0192, 0.0189, 0.0443, 0.0240, 0.0642,\n",
       "                       0.0099, 0.0293, 0.0519, 0.0271, 0.0307, 0.0139, 0.0275, 0.0203, 0.0292,\n",
       "                       0.0256, 0.0254, 0.0196, 0.0161, 0.0475, 0.0185, 0.0414, 0.0608, 0.0329,\n",
       "                       0.0586, 0.0185, 0.0276, 0.0214, 0.0319, 0.0390, 0.0217, 0.0160, 0.0100,\n",
       "                       0.0509, 0.0251, 0.0303, 0.0346, 0.0115, 0.0189, 0.0205, 0.0278, 0.0303,\n",
       "                       0.0127, 0.0663, 0.0329, 0.0340, 0.0313, 0.0299, 0.0256, 0.0315, 0.0118,\n",
       "                       0.0354, 0.0405, 0.0318, 0.0327, 0.0198, 0.0217, 0.0206, 0.0122, 0.0143,\n",
       "                       0.0193, 0.0742, 0.0383, 0.0181, 0.0455, 0.0687, 0.0117, 0.0273, 0.0047,\n",
       "                       0.0499, 0.0139, 0.0497, 0.0281, 0.0243, 0.0139, 0.0231, 0.1200, 0.0235,\n",
       "                       0.0411, 0.0124, 0.0608, 0.0437, 0.0158, 0.0319, 0.0339, 0.0139, 0.0258,\n",
       "                       0.0099, 0.0334, 0.0150, 0.0197, 0.0179, 0.0321, 0.0261, 0.0218, 0.0140,\n",
       "                       0.0252, 0.0325, 0.0345, 0.0265, 0.0327, 0.0128, 0.0380, 0.0214, 0.0366,\n",
       "                       0.0158, 0.0253, 0.0517, 0.0300, 0.0268, 0.0322, 0.0149, 0.0390, 0.0467,\n",
       "                       0.0480, 0.0197, 0.0394, 0.0207, 0.0463, 0.0408, 0.0498, 0.0476],\n",
       "                      device='cuda:0')),\n",
       "              ('layer4.1.bn2.num_batches_tracked',\n",
       "               tensor(19550, device='cuda:0')),\n",
       "              ('linear.weight',\n",
       "               tensor([[ 0.1620, -0.0843, -0.0887,  ..., -0.1243,  0.1623,  0.2451],\n",
       "                       [-0.0795,  0.2017,  0.2120,  ..., -0.0881, -0.1336, -0.1965],\n",
       "                       [ 0.2074, -0.0451, -0.1169,  ...,  0.0683, -0.2113,  0.1810],\n",
       "                       ...,\n",
       "                       [-0.0021, -0.1050, -0.1362,  ...,  0.1907,  0.1966,  0.0319],\n",
       "                       [-0.1562,  0.0808, -0.0476,  ...,  0.1738, -0.1238, -0.1221],\n",
       "                       [-0.1250, -0.0791,  0.2862,  ..., -0.1580, -0.1440,  0.2127]],\n",
       "                      device='cuda:0')),\n",
       "              ('linear.bias',\n",
       "               tensor([ 0.1025, -0.2748,  0.1330,  0.2847,  0.1084,  0.1228, -0.0834, -0.0844,\n",
       "                       -0.0980, -0.2110], device='cuda:0'))])}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretrain 준비\n",
    "torch.load('./checkpoint/resnet18_cifar10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "7daa1dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_dict = torch.load('./checkpoint/resnet18_cifar10.pth')\n",
    "net_dict = net.state_dict()\n",
    "\n",
    "# 필요한 가중치만 가져오기\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in net_dict}\n",
    "\n",
    "# 선택한 가중치만 불러오기\n",
    "net_dict.update(pretrained_dict)\n",
    "net.load_state_dict(net_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f6693687",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # 기울기 계산 비활성화\n",
    "    output = net(cat_tensor)\n",
    "    predicted_class = output.argmax(1).item()\n",
    "    # torch.return_types.max(\n",
    "    # values=tensor([4.0649], device='cuda:0'),\n",
    "    # indices=tensor([3], device='cuda:0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "bc3b3fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측된 클래스: 8\n"
     ]
    }
   ],
   "source": [
    "# 예측된 클래스 확인\n",
    "print(\"예측된 클래스:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cced44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
